@' The contents of this file are subject to the MonetDB Public License
@' Version 1.1 (the "License"); you may not use this file except in
@' compliance with the License. You may obtain a copy of the License at
@' http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html
@'
@' Software distributed under the License is distributed on an "AS IS"
@' basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
@' License for the specific language governing rights and limitations
@' under the License.
@'
@' The Original Code is the MonetDB Database System.
@'
@' The Initial Developer of the Original Code is CWI.
@' Portions created by CWI are Copyright (C) 1997-2007 CWI.
@' All Rights Reserved.

@f xtables
@a M.L. Kersten, P. Boncz, A.P. de Vries, N.J. Nes -- $Id$
@v 2.2
@t Cross Table Module
@T
{\bf Copyright \copyright\ 1996-1999 by Data Distilleries, All Rights Reserved.

No part of this work covered by the copyright hereon may be reproduced or used
in any form or by no means- graphic, electronic, or mechanical, including
photocopying, recording, taping, or information storage and retrieval system -
without permission of the copyright owner. }

@{
@+ Document control
@T
(April 2005:) Niels HASH_MAX now indicates the end of the hash chain list 
(Mar 2005:) Niels removed the histolink accelerator and changed to the grp atom

(June 2001:) Arjen parameterized the size of the hashtable, which is needed
for text corpora (many different clusters (>30000), widely varying size (Zipfian)).
(May 2001:) Arjen added some minor changes to better handle `clustered' groups;
for now, limited applicability to a derived property, using
$$ \mathrm{sorted} \land \mathrm{keyed} \\implies \mathrm{clustered} $$

(before:)
\begin{verbatim}
New implementation of xtables *from*scratch*. Got fed up with histolink.
This is simple stable and fast. good memory performance.
\end{verbatim}
@
@}

@* Introduction
@T
Data mining applications require efficient construction and manipulation
of cross-tables.
The Monet kernel already provides for a histogram function over a single BAT.
This module provides extensions to support identification of groups in a
multi-dimensional space.

The prime limitation is that an underlying database of {oid->any} BATs
is assumed. This enables representation of each group using an oid,
and the value representation of the group can be accordingly be
retrieved easily. An optimized implementation in which we use positional
integer id's (as embodied by Monet's void type) is also available.

@+ Algorithms
@T
There are several approaches to build a cross table. The one chosen here
is aimed at incremental construction, such that re-use of intermediates
becomes possible. Starting with the first dimension, a BAT is derived to
represent the various groups, called a {\bf CT BAT} or cross-table BAT.

@- Cross Table (CT)
@T
A cross table is an <oid,oid> BAT where the first (head) denotes a tuple in
the cross table and the second (tail) marks all identical lists.
The tail-oids contain group identifiers; that is, {\em this value is equal
{\bf iff} two tuples belong to the same group}. The group identifiers are
chosen from the domain of the tuple-identifiers. This simplifies
getting back to the original tuples, when talking about a group.
If the tuple-oid of 'John' is chosen as a group-id, you might view this
as saying that each member of the group is 'like John' with respect
to the grouping-criterion.

@- going deeper
@T
Successively the subgroups can be identified by modifying the CT BAT or
to derive a new CT BAT for the subgroups. After all groups have been
identified this way, a BAT histogram operation can be used to obtain
the counts of each data cube. Other aggregation operations using the MIL
set aggregate construct \{X\}(bat) (see the
@[<a href="../../../FrontEnds/mil/index.html#mod_3_2_0">MIL Reference Manual</a>@)
can be used as well; note for instance that histogram == \{count\}(b.reverse).

@* Module Definition
The Monet interface module specification is shown below.
@m
.MODULE xtables;

.ATOM mapentry[32,8];
.END;
.ATOM idxentry[16,8];
.END;
.ATOM grp[8,8];
.FIX   = grp_fix; 
.UNFIX = grp_unfix;
.END;

@-
basic multi-attribute group operations, that take the incremental approach.
CT[re]group and CTderive implement GROUPBY, CTrefine implements ORDERBY.
@m
.COMMAND CTmap(grp g) : BAT[oid,oid] = CTmap;
"Return the group map."

.COMMAND CTextend(grp g) : BAT[oid,any] = CTextend;
"Return the group extend."

.COMMAND CThistogram(grp g) : BAT[any,int] = CThistogram;
"Return the groups histogram."

.COMMAND CTgroup(BAT[oid,any] attr) : grp = CTgroup;
"Cross tabulation group initialization.
Returned head values are identical as in 'attr'. Tail values are from
the same domain and indicate unique groups in 'attr' tail column."

.COMMAND _CTgroup(BAT[oid,any] attr, int N, int rng) : grp = CTgroup_custom;
"Cross tabulation group initialization like CTgroup, but with user
provided #bits in hashmask and #distinct values in range."

.COMMAND CTderive(grp ct, BAT[oid,any] attr) : grp = CTderive;
"Cross tabulation group extension step.
Returned head values are identical as in 'ct'. Tail values are from
the same domain and indicate further refinement of the groups in 'ct',
taking into account also the tail-values in 'attr'."

.COMMAND CTgroup(grp ct, BAT[oid,any] attr) : grp = CTderive;
"binary grouping; a synonym for CTderive(ct,attr)"

.COMMAND CTrefine(BAT[oid,any] b, BAT[oid,any] a) : BAT[oid,oid] = CTrefine;
"refine the ordering of a tail-ordered BAT by sub-ordering on the
values of a second bat 'a' (where the heads of a and b match 1-1).
The effect of this is similar to (hash-based) CTderive, with the
distinction that the group ids respect the ordering of the group values."

.COMMAND CTrefine_rev(BAT[oid,any] b, BAT[oid,any] a) : BAT[oid,oid] = CTrefine_rev;
"reverse sorting version of CTrefine"

.COMMAND CTsubhisto(BAT[void,bit] sel, BAT[void,oid] grp, BAT[oid,any] domain)
: BAT[oid,int] = CTsubhisto;
"optimized sub-histogram for synced grp[void,oid] and sel[void,bit]
bats on a previously known domain "

.COMMAND CThistosum(BAT[oid,oid] ct, BAT[oid,int] histo) : BAT[oid,int] = CThistosum;
"Produce sum over old histogram table"

@m
.END xtables;

@mil

PROC CTorderby(bat[oid,any] b, bat[oid,any] a) : bat[oid,oid] {
    if (not(b.reverse().ordered())) {
	   b := b.reverse().sort().reverse();
    }
    return CTrefine(b,a);
}

PROC CTorderby_rev(bat[oid,any] b, bat[oid,any] a) : bat[oid,oid] {
    if (not(b.reverse().ordered_rev())) {
	   b := b.reverse().sort_rev().reverse();
    }
    return CTrefine_rev(b,a);
}

PROC CTsubgroup(BAT[oid,oid] ct, BAT[oid,any] b, BAT[oid,any] sel) : BAT[oid,oid] {
	return ct.CTgroup(b.semijoin(sel));
}

PROC map( grp g ) : BAT[oid,oid] {
	return g.CTmap();
}

PROC extend( grp g ) : BAT[any,int] {
	return g.CTextend();
}

PROC histogram( grp g ) : BAT[any,int] {
	return g.CThistogram();
}

PROC {count}(BAT[oid,bit] sel, BAT[oid,oid] ct, BAT[oid,int] dom) : BAT[oid,int] {
	return sel.[ifthen](ct).reverse().{count}(dom);
}

PROC {count}(BAT[void,bit] sel, BAT[void,oid] ct, BAT[oid,int] dom) : BAT[oid,int] {
	return CTsubhisto(sel, ct, dom);
}

proc orderby_table(str fcn, str spec, ..bat[any::1,any]..) : void {
	var meta := new(str,str,$0);
	var first := int(spec) + 2;
	var b := $(first);
	var s := b.reverse().sort().reverse();

	while(true) {
		var idx := spec.search(',');
		if (idx < 0) break;
		spec := spec.string(idx + 1);
		s := s.CTrefine($(int(spec) + 2));
	}
	var bb := s.mirror().outerjoin(b);
	var i := 2;
	meta.insert("int", str(first - 2));
	while((i :+= 1) <= $0) {
		if (i = first) {
		    meta.insert("BAT", str(bb));
		} else {
		    meta.insert("BAT", str($(i)));
		}
	}
	call(fcn, meta);
}

proc table(str spec, bat[any::1,any] b, ..bat[any::1,any]..) : void {
	orderby_table("table", $(1..));
}

proc print(str spec, bat[any::1,any] b, ..bat[any::1,any]..) : void {
	orderby_table("print", $(1..));
}

proc CTgroup(BAT[oid,any] ct, BAT[oid,any] attr) : grp {
	return CTgroup(CTgroup(ct), attr);
}

proc CTderive(BAT[oid,any] ct, BAT[oid,any] attr) : grp {
	return CTderive(CTgroup(ct), attr);
}

@{
@* Implementation Code

@+ groups

@h
typedef struct grp_t {
	bat map;
	bat histo;
} grp;
@c
#include "monetdb4_config.h"
#include "algebra.h"
#include "xtables.h"
#include "xtables.proto.h"

@- Implementation
@c

int
CTmap(BAT **b, grp *g ) 
{
	*b = BATdescriptor(g->map); 
	return GDK_SUCCEED;
}

int
CTextend(BAT **b, grp *g ) 
{
	BAT *h = BATdescriptor(g->histo); 
	*b = VIEWhead(h);
	BBPunfix(g->histo);
	return GDK_SUCCEED;
}

int
CThistogram(BAT **b, grp *g ) 
{
	*b = BATdescriptor(g->histo); 
	return GDK_SUCCEED;
}

static int 
grp_new( grp *g, BAT *b, BAT *h ) 
{
	g->map = b->batCacheid;
	BBPincref(b->batCacheid, TRUE );
	BBPunfix(b->batCacheid);

	g->histo = 0;
	if (h) {
		BATkey(h, TRUE);
		h->tsorted = 0;
		if ((h->hsorted = BAThordered(b)) & 1) {
			if (BATcount(h) == BATcount(b)) {
				ALIGNsetH(h, BATmirror(b));
			}
		} else if (BATorder(h) == NULL) {
			BBPreclaim(h);
			return GDK_FAIL;
		}
		g->histo = h->batCacheid; 
		BBPincref(h->batCacheid, TRUE );
		BBPunfix(h->batCacheid);
	} else {
		assert(h);
	}
	return GDK_SUCCEED;
}

int 
grp_fix( grp *g ) 
{
	BBPincref(g->map, TRUE);
	if (g->histo)
		BBPincref(g->histo, TRUE);
	return GDK_SUCCEED;
}

int 
grp_unfix( grp *g ) 
{
	BBPdecref(g->map, TRUE);
	if (g->histo)
		BBPdecref(g->histo, TRUE);
	return GDK_SUCCEED;
}

@+ Core Grouping Algorithms
@T
We use hash-grouping all the way. This implementation employs
a simple sequential scan through the operands, adding group
values to a hash-table. This hash-table gives access to the group
identifiers, which are always OIDs.

This strategy is also followed on binary groupings; here
we construct a special integer consisting of the XORed hashnumber
of both columns. In such a way, we can build a hash table on
map\_entries (instead of simple atomic values -- the unary case).

In the unary group case, we optimized processing on 1-byte
and 2-byte values by using direct mapping in an array instead of
hashing.
@c
#define HASH_bte(p) ((hash_t) (*(unsigned char*) (p)))
#define HASH_sht(p) ((hash_t) (*(unsigned short*) (p)))
#define HASH_int(p) ((hash_t) *(unsigned int*) (p))
#define HASH_lng(p) ((hash_t)(((unsigned int*)(p))[0]^((unsigned int*)(p))[1]))
#define HASH_any(p) ((*hashfcn)(p))

#define match_sync(bi,p,r) r++
#define match_hash(bi,p,r) BUNfndOID(r,bi,p); if (r == BUN_NONE) continue;

#define declare_atom int any = b->ttype; hash_t (*hashfcn)(ptr) = BATatoms[any].atomHash;
#define declare_simple	/* any and hash would otherwise give unused variable warning */

#define htype_sync(b) BAThdense(b)?TYPE_void:TYPE_oid
#define htype_hash(b) TYPE_oid

#define ttype_simple(b,t) t
#define ttype_atom(b,t) b->ttype

#define STANDARD_MASK ((hash_t) 1023)

/*
   Note:
	following macros take advantage of clustered property;
	if b is clustered, then we can stop early traversing collision lists.

	BTW, simply stopping possibly breaks chain construction, so the resulting
	map is not directly reuseable as a hash table; the current Monet cannot
	however handle multiple accellerators, so this ain't a real problem for now :)
 */

#define declare_unclustered	/* avoid warning */
#define declare_clustered   int samecluster = TRUE;

#define chain_unclustered   for (zz = hash[c]; zz != HASH_MAX; zz = e->link)
#define chain_clustered     for (zz = hash[c]; (zz != HASH_MAX) && (samecluster); zz = e->link)

#define tst_grp_unclustered(eq,p,t)    (eq(p, tcur, t))
#define tst_grp_clustered(eq,p,t)      (samecluster = eq(p, tcur, t))

#define tst_derive_unclustered(eq,p,t) (e->hcur == hcur && eq(p, tcur, t))
#define tst_derive_clustered(eq,p,t)   ((samecluster = e->hcur == hcur) && eq(p, tcur, t))

/* NOTE: the first two fields of idxentry_t and mapentry_t MUST be the
   same */
typedef struct {
	oid hcur;		/* old group id */
	hash_t link;		/* hash link */
} idxentry_t;

typedef struct {
	oid hcur;		/* old group id */
	hash_t link;		/* hash link */
	oid gid;		/* new group id */
	int cnt;		/* histogram count */
} mapentry_t;

typedef struct {
	BAT *map;		/* [mapentry,value] elements */
	hash_t *hash, mask;	/* hash buckets and mask */
	Heap hp;		/* storage for hash buckets */
} map_T;

@:map_init_def(STANDARD,STANDARD_MASK,4096)@
@:map_init_def(CUSTOM,custom_MASK,custom_rng)@

@= map_init_def
#define map_init_@1(map,hash,mask,entry,mapsize)			\
	if (m) {							\
		map = m->map; hash = m->hash; mask = m->mask;		\
	} else {							\
		hash_t _yy;						\
		map = BATnew(TYPE_mapentry, tailtype(b,TRUE), @3);	\
		hash = (hash_t*) GDKmalloc((int)(sizeof(hash_t)*((mask=@2)+1))); \
		for (_yy=0; _yy<=@2; _yy++) {				\
			hash[_yy] = HASH_MAX;				\
		}							\
	}								\
	entry.cnt = 1;							\
	mapsize = BUNlast(map);
@c
#if 0
static void
map_free(map_T m)
{
	BBPreclaim(m.map);
	HEAPfree(&m.hp);
}
#endif

#ifndef offsetof
#define offsetof(type, member)	((size_t) &((type *) 0)->member)
#endif

static BAT *
map2histo(BAT *map)
{
	BUN p, q;
	BAT *bn;
	int sz;

	if (map == NULL || map->htype != TYPE_mapentry || isVIEW(map) || map->batSharecnt > 1 || BATgetaccess(map) != BAT_WRITE) {
		if (map)
			BBPreclaim(map);
		return NULL;
	}
	sz = BATcount(map);
	bn = BATnew(TYPE_oid,TYPE_int,sz);
	BATloop(map, p, q) {
		bunfastins(bn, 
			&((mapentry_t*)Hloc(map, p))->gid, 
			&((mapentry_t*)Hloc(map, p))->cnt);
	}
	BATkey(BATmirror(bn),FALSE);
	bn->tsorted = 0;
bunins_failed:
	if (map)
		BBPreclaim(map);
	return bn;
}

@T
The group macro is split along three dimensions:
\begin{description}
\item [type:] Type specific implementation for selecting the right
hash function and data size etc.;
\item [clustered:] The \{clustered and unclustered\} select the
appropriate algorithm, i.e., with or without taking advantage of
an order of values in the parent groups;
\item [physical properties:] Values \{standard and custom\},
choosing between a fixed predefined and a custom hashmask. Custom
allows the user to determine the size of the hashmask (and indirectly
the estimated size of the result). The hashmask is $2^n - 1$ where $n$
is given by the user, or 1023 otherwise, and the derived result
size is $4 \cdot 2^n$.
\end{description}

Further research should point out whether fitting a simple statistical
model (possibly a simple mixture model) can help choose these parameters
automatically; the current idea is that the user (which could be a
domain-specific extension of the higher-level language) knows the
properties of the data, especially for IR in which the standard grouping
settings differ significantly from the original datamining application.
@c
#define group_params_STANDARD	/* fixed */
#define group_params_CUSTOM   hash_t custom_MASK, int custom_rng,

@= group
static BAT *
CTgroup_@1_@4_@5(group_params_@5 BAT *b, BAT *bn, map_T *m)
{
	BATiter bi = bat_iterator(b), mapi;
	oid *hdst = (oid*) Hloc(bn, BUNfirst(bn)), *dst = (oid*) Tloc(bn, BUNfirst(bn));
	hash_t *hash, mask;
	size_t zz, mapsize;
	mapentry_t entry, *e;
	BUN p, q, r;
	BAT *map = NULL;
	declare_@3

	map_init_@5(map,hash,mask,entry,mapsize);
	if (map == NULL)
		return NULL;

	mapi = bat_iterator(map);
	/* core hash grouping algorithm */
	BATloop(b, p, q) {
		declare_@4
		ptr tcur = BUN@2(bi,p);

		/* hash-lookup of 'tcur' in map */
		hash_t c = HASH_@1(tcur);
		c = mix_int(c) & mask;
		chain_@4 {
			r = zz;
			e = (mapentry_t*) BUNhloc(mapi,r);
			if (tst_grp_@4(@3_EQ, BUN@2(mapi,r), @1)) {
				if (m == NULL)
					e->cnt++;
				goto found;
			}
		}

		/* not found-> insert new element in map (and hash) */
		if (m) {
			zz = mapsize;
		} else {
			entry.gid = *(oid*) BUNhead(bi,p);
		}
		entry.link = hash[c];
		hash[c] = mapsize++;
		bunfastins(map, &entry, tcur);
		e = &entry;

		/* TODO fix head by a column copy */
found:		/* ultra-fast 'insert' of [oid,gid] into ct */
		if (bn->htype)
			*hdst++ = *(oid*) BUNhead(bi,p);
		*dst++ = m?zz:e->gid;
	}
	BATsetcount(bn, BATcount(b));
	bn->tsorted = 0;
	ALIGNsetH(bn,b);
	if (hash && !m)
		GDKfree(hash);
	return m ? NULL : map2histo(map);
bunins_failed:
	BBPreclaim(bn);
	if (hash && !m)
		GDKfree(hash);
	return NULL;
}
@c
static int
tailtype(BAT *b, int str_trick)
{
	int tpe = ATOMstorage(b->ttype);	/* standard type remappings */

	/* more daring remappings possible under simple equality */
	switch (tpe) {
	case TYPE_chr:
		return TYPE_bte;
	case TYPE_flt:
		return TYPE_int;
	case TYPE_dbl:
		return TYPE_lng;
	case TYPE_str:
		if (str_trick && GDK_ELIMDOUBLES((b->theap)))
			return TYPE_var;	/* string offsets are identifying integers */
	}
	return tpe;
}

/* Generate both 'normal' CTgroup and clustered CTgroups */
@= wrappedgroupinner
@:group(bte,tloc,simple,@1,@2)@
@:group(sht,tloc,simple,@1,@2)@
@:group(int,tloc,simple,@1,@2)@
@:group(lng,tloc,simple,@1,@2)@
@:group(any,tail,atom,@1,@2)@

/* Generate both 'normal' CTgroup and parameterized CTgroups */
@= wrappedgroupouter
@:wrappedgroupinner(unclustered,@1)@
@:wrappedgroupinner(clustered,@1)@

@c
@:wrappedgroupouter(STANDARD)@
@:wrappedgroupouter(CUSTOM)@

@= returnvalue
	@1 =
@c
#define declare_mask_STANDARD	/* fixed */
#define declare_mask_CUSTOM	hash_t mask = (1 << *N) - 1;

int
CTgroup(grp *g,			/* put pointer to grp record here. */
	BAT *b			/* pointer to BAT[oid,oid] record. */
)
{
	@:CTgroupbody(STANDARD)@
}

int
CTgroup_custom(grp *g,		/* put pointer to grp record here. */
	       BAT *b,		/* pointer to BAT[oid,oid] record. */
	       int *N,		/* number of bits for hashmask */
	       int *rng		/* expected number of entries in map */
)
{
	@:CTgroupbody(CUSTOM)@
}

static int 
bits(size_t i)
{
	int sh;

	assert(i>0);
        for (sh = 0; i != 0; sh++) {
                i >>= 1;
        }
	return sh;
}


@= CTgroupbody
	BAT *histo = NULL, *bn = NULL;
	declare_mask_@1

	/* b->tkey, simply return mirror(0), and hist = project(reverse(bn),1) */
	if (b->tkey) {
		int one = 1;
		BAT *v = VIEWcombine(b);

		bn = v;
		if (b->batRestricted == BAT_WRITE) {
			bn = BATcopy(v, v->htype, v->ttype, FALSE);
			BBPreclaim(v);
		}
		histo = BATconst(BATmirror(bn), TYPE_int, &one);
	} else {
		bn = BATnew(b->htype, TYPE_oid, BATcount(b));
		if (bn == NULL) {
			return GDK_FAIL;
		}
		/* Poor man's clustered test: sorted & !keyed => clustered  */
		if ( ((b->tsorted)&1) && !(b->tkey) ) {
			@:choosegroup@1(tailtype(b,TRUE),bn,NULL,clustered,histo)@
		} else {
			@:choosegroup@1(tailtype(b,TRUE),bn,NULL,unclustered,histo)@
		}
		if (histo == NULL) {
			BBPreclaim(bn);
			return GDK_FAIL;
		}
		bn->tsorted = 0;
	}
	if (BATcount(histo) == BATcount(bn)) {
		BATkey(BATmirror(bn),TRUE);
	}
	ALIGNsetH(bn, b);
	return grp_new(g, bn, histo);

@= choosegroupSTANDARD
	/* Choose appropriate @4 CTgroup implementation */
	switch(@1) {
	case TYPE_bte:
		@?@5:returnvalue(@5)@ CTgroup_bte_@4_STANDARD(b,@2,@3);
		break;
	case TYPE_sht:
		@?@5:returnvalue(@5)@ CTgroup_sht_@4_STANDARD(b,@2,@3);
		break;
	case TYPE_int:
		@?@5:returnvalue(@5)@ CTgroup_int_@4_STANDARD(b,@2,@3);
		break;
	case TYPE_lng:
		@?@5:returnvalue(@5)@ CTgroup_lng_@4_STANDARD(b,@2,@3);
		break;
	default:
		@?@5:returnvalue(@5)@ CTgroup_any_@4_STANDARD(b,@2,@3);
		break;
	}

@= choosegroupCUSTOM
	/* Choose appropriate @4 CTgroup implementation */
	switch(@1) {
	case TYPE_bte:
		@?@5:returnvalue(@5)@ CTgroup_bte_@4_CUSTOM(mask,*rng,b,@2,@3);
		break;
	case TYPE_sht:
		@?@5:returnvalue(@5)@ CTgroup_sht_@4_CUSTOM(mask,*rng,b,@2,@3);
		break;
	case TYPE_int:
		@?@5:returnvalue(@5)@ CTgroup_int_@4_CUSTOM(mask,*rng,b,@2,@3);
		break;
	case TYPE_lng:
		@?@5:returnvalue(@5)@ CTgroup_lng_@4_CUSTOM(mask,*rng,b,@2,@3);
		break;
	default:
		@?@5:returnvalue(@5)@ CTgroup_any_@4_CUSTOM(mask,*rng,b,@2,@3);
		break;
	}

@c
#define SAMPLE_SIZE 	1024
hash_t
derive_mask( BAT *ct_map, BAT *ct_histo, BAT *b)
{
	size_t cnt = BATcount(b);
	int n = bits(BATcount(ct_histo)), *N = &n;

	if (BATcount(b) > (SAMPLE_SIZE<<3)) {
		BAT *s = BATsample(b, SAMPLE_SIZE);
		grp d,o;
		BUN p, q;
		BAT *histo;
		hash_t r = 0;

		o.map = ct_map->batCacheid;
		o.histo = ct_histo->batCacheid;
		if (CTderive(&d, &o, s) != GDK_SUCCEED) {
			BBPunfix(s->batCacheid);
			return GDK_FAIL;
		}
		BBPunfix(s->batCacheid);
		assert (d.histo);
		histo = BATdescriptor(d.histo);
		BATloop(histo, p, q) {
			/* + 4 for a average chain list of 4 */
			r += ((dbl)cnt/SAMPLE_SIZE)/(*(int*)BUNtloc(histo,p)+4);
		}
		BBPunfix(d.histo);
		grp_unfix(&d);
		if (bits(r) > *N)
			return (1<<bits(r))-1;
	}
	/* default to */
	return (1<<*N) - 1;
}

@= derive
static BAT *
CTderive_@1_@2_@5(BAT* ct_map, BAT *ct_histo, BAT *b, BAT *bn, map_T *m)
{
	BATiter bi = bat_iterator(b), mapi, ct_mapi = bat_iterator(ct_map);
	oid *hdst = (oid*) Hloc(bn, BUNfirst(bn)), *dst = (oid*) Tloc(bn, BUNfirst(bn));
	size_t zz, mapsize;
	hash_t *hash;
	BUN p, q, r, cp = BUNfirst(ct_map) - 1;
	mapentry_t entry, *e;
	BAT *map;
	declare_@4
	hash_t mask = derive_mask(ct_map, ct_histo, b); 
	int custom_rng = BATcount(ct_histo); /* expected number of groups */
	hash_t custom_MASK = mask;

	map_init_CUSTOM(map,hash,mask,entry,mapsize);
	if (map == NULL)
		return NULL;

	mapi = bat_iterator(map);
	/* core hash grouping algorithm */
	BATloop(b, p, q) {
		ptr tcur = BUN@3(bi,p);
		hash_t c;
		oid hcur;
		declare_@5

		/* find corresponding value in 'ct_map' */
		match_@1(ct_mapi, BUNhead(bi,p), cp);
		hcur = *(oid*) BUNtloc(ct_mapi,cp);

		/* hash-lookup of [hcur,tcur] in map */
		c = (((hash_t) hcur) ^ HASH_@2(tcur));
		c = mix_int(c) & mask;
		chain_@5 {
			r = zz;
			e = (mapentry_t*) Hloc(map,r);
			if (tst_derive_@5(@4_EQ, BUN@3(mapi,r), @2)) {
				if (m == NULL)
					e->cnt++;
				goto found;
			}
		}
		/* not found-> insert new element in map (and hash) */
		if (m) {
			zz = mapsize;
		} else {
			entry.gid = *(oid*) BUNhead(bi,p);
		}
		entry.hcur = hcur;
		entry.link = hash[c];
		hash[c] = mapsize++;
		bunfastins(map, &entry, tcur);
		e = &entry;

		/* TODO fix head by a column copy */
found:		/* ultra-fast 'insert' of [oid,gid] into result ct */
		if (bn->htype)
			*hdst++ = *(oid*) BUNhead(bi,p);
		*dst++ = m?zz:e->gid;
	}
	BATsetcount(bn, (dst-(oid*)bn->T->heap.base)); 
	if (hash && !m)
		GDKfree(hash);
	return m?NULL:map2histo(map);
bunins_failed:
	if (hash && !m)
		GDKfree(hash);
	BBPreclaim(bn);
	return NULL;
}

@c

/* Generate both 'normal' CTderive and clustered CTderive */
@= wrappedderive
@:derive(sync,bte,tloc,simple,@1)@
@:derive(sync,sht,tloc,simple,@1)@
@:derive(sync,int,tloc,simple,@1)@
@:derive(sync,lng,tloc,simple,@1)@
@:derive(sync,any,tail,atom,@1)@
@:derive(hash,bte,tloc,simple,@1)@
@:derive(hash,sht,tloc,simple,@1)@
@:derive(hash,int,tloc,simple,@1)@
@:derive(hash,lng,tloc,simple,@1)@
@:derive(hash,any,tail,atom,@1)@
@c
@:wrappedderive(unclustered)@
@:wrappedderive(clustered)@

@= choosederive
	/* Choose appropriate (@1 && @2) CTderive implementation */
	switch(tt) {
	case TYPE_bte:
		histo = CTderive_@1_bte_@2(ct_map,ct_histo,b,bn,m);
		break;
	case TYPE_sht:
		histo = CTderive_@1_sht_@2(ct_map,ct_histo,b,bn,m);
		break;
	case TYPE_int:
		histo = CTderive_@1_int_@2(ct_map,ct_histo,b,bn,m);
		break;
	case TYPE_lng:
		histo = CTderive_@1_lng_@2(ct_map,ct_histo,b,bn,m);
		break;
	default:
		histo = CTderive_@1_any_@2(ct_map,ct_histo,b,bn,m);
		break;
	}
@c
static int
derive(grp *g, grp *ct, BAT *b, int tt, map_T *m)
{
	BAT *ct_map = BATdescriptor(ct->map); 
	BAT *ct_histo = BATdescriptor(ct->histo); 
	BAT *histo = NULL, *bn = NULL;
	int synced = ALIGNsynced(ct_map, b);

	/* create the result bat 'bn' */
	int ht = (synced && BAThdense(b)) ? TYPE_void : TYPE_oid;

	if (!ct_map->tkey) { /* cannot derive more groups */
		bn = BATnew(ht, TYPE_oid, BATcount(b));
		if (bn == NULL) {
			return GDK_FAIL;
		}

		/* CTderive with correct lookup method (hash,synced) and type */
		if (synced) {
			if (((ct_map->tsorted) & 1)) {
				@:choosederive(sync,clustered)@
			} else {
				@:choosederive(sync,unclustered)@
			}
		} else {
			if (((ct_map->tsorted) & 1)) {
				@:choosederive(hash,clustered)@
			} else {
				@:choosederive(hash,unclustered)@
			}
		}
		if (histo == NULL) {
			assert(histo);
			BBPunfix(bn->batCacheid);
		}

		/* postprocess the result bat 'bn' */
		bn->tsorted = 0;
		if (BATcount(bn) == BATcount(b)) {
			ALIGNsetH(bn, b);
		} else {
			bn->hsorted = BAThordered(b);
			if (b->hkey)
				BATkey(bn, TRUE);
		}

		BBPunfix(ct_map->batCacheid);
		BBPunfix(ct_histo->batCacheid);
	} else {
		bn = ct_map;
		histo = ct_histo;
		if (!synced) {
			bn = BATsemijoin(ct_map, b);
			histo = BATsemijoin(ct_histo, BATmirror(bn));
			BBPunfix(ct_map->batCacheid);
			BBPunfix(ct_histo->batCacheid);
		}
	}
	return grp_new(g, bn, histo);
}

int
CTderive(grp *g, grp *ct, BAT *b)
{
	int ret;

	g->map = 0;
	g->histo = 0;
	ret = derive(g, ct, b, tailtype(b, TRUE), NULL);
	return ret;
}

@-
The routine CThistosum takes an grouping and a histogram and produces
a new histogram by summing the old values within the same group.
@c
int
CThistosum(
	BAT**	retval,	/* put pointer to BAT[oid,int] record here. */
	BAT*	b,	/* pointer to BAT[oid,oid] record. */
	BAT*	c	/* pointer to BAT[oid,int] record. */
)
{
	BATiter bi = bat_iterator(b), resi;
	BAT *res = BATnew(TYPE_oid, TYPE_int, BATcount(b));
	BUN p, q, qb;
	int i, *z;
	oid *ot, *oh;

	(void) c;
	if (res == NULL) {
		return GDK_FAIL;
	}
	resi = bat_iterator(res);
	BATloop(b, p, q) {
		oh = (oid *) BUNhloc(bi, p);
		i = *(int *) BUNtloc(bi, p);

		BUNfndOID(qb, bi, oh);
		if (qb == BUN_NONE) {
			GDKerror("CThistosum: Matching count entry not found\n");
			continue;
		}
		ot = (oid *) BUNtloc(bi, qb);

		BUNfndOID(qb, resi, ot);
		if (qb == BUN_NONE) {
			BUNins(res, ot, &i, FALSE);
		} else {
			z = (int *) BUNtloc(resi, qb);
			*z += i;
		}
	}
	res->hsorted = res->tsorted = 0;
	*retval = res;
	return GDK_SUCCEED;
}

int
CTsubhisto(BAT **ret, BAT *sel, BAT *grp, BAT *dom)
{
	BATiter seli = bat_iterator(sel);
	bit *filter = (bit *) BUNtloc(seli, BUNfirst(sel));
	size_t size = BATcount(dom);
	hash_t yy, mask, *hash = NULL;
	BUN r, p, q;
	BAT *bn = BATnew(TYPE_idxentry, TYPE_int, size);

	if (bn == NULL)
		return GDK_FAIL;

	/* we know the domain; go for perfect hashing */
	for (mask = 1; mask < size; mask <<= 1)
		;
	if (mask < 256)
		mask = 256;
	hash = (hash_t *) GDKmalloc(sizeof(hash_t) * mask);
	if (hash == NULL) {
		BBPreclaim(bn);
		return GDK_FAIL;
	}
	for (yy = 0; yy < mask; yy++) {
		hash[yy] = HASH_MAX;
	}
	mask--;

	/* insert all values in the hash table, and in bn with count zero */
	r = BUNfirst(bn);
	yy = 0;
	BATloop(dom, p, q) {
		oid v = *(oid *) Hloc(dom, p);
		hash_t c = v & mask;

		((idxentry_t *) Hloc(bn, r))->hcur = v;
		((idxentry_t *) Hloc(bn, r))->link = hash[c];
		*(int *) Tloc(bn, r) = 0;
		r++;
		hash[c] = yy;
		yy++;
	}
	BATsetcount(bn, r);
	bn->tsorted = 0;
	bn->htype = BATmirror(bn)->ttype = TYPE_oid;
	/* assert(offsetof(idxentry_t,hcur) == 0);
	ALIGNsetH(bn, dom); */

	/* add the counts for this selection using the hash table */
	BATloop(grp, p, q) {
		if (*filter == TRUE) {
			oid v = *(oid *) Tloc(grp, p);
			hash_t c = v & mask;

			for (yy = hash[c]; yy != HASH_MAX; yy = ((idxentry_t *) Hloc(bn, r))->link) {
				r = yy;
				if (((idxentry_t *) Hloc(bn, r))->hcur == v) {
					*(int *) Tloc(bn, r) += 1;
					break;
				}
			}
		}
		filter++;

	}
	GDKfree(hash);
	*ret = bn;
	return GDK_SUCCEED;
}

@+ Support for Order-by
@c
#define DEFAULT_SIZE 10000

static INLINE int 
sort_flush(var_t *off, oid *o, size_t size, int tpe, char *base, oid *hdst, oid *tdst, oid *idp, int reverse)
{
	int (*cmp) (ptr, ptr) = BATatoms[tpe].atomCmp;
	oid id = *idp + 1;
	ptr cur, val;
	size_t i;

	/* StM: we don't need to sort voids, do we??? */
	if (tpe != TYPE_void) {
		/* qsort works fine for small amount of tuples; with few duplicates */
		if (reverse) {
			GDKqsort_rev(off, o, base, size, sizeof(var_t), sizeof(oid), tpe);
		} else {
			GDKqsort(off, o, base, size, sizeof(var_t), sizeof(oid), tpe);
		}
	}

	cur = base + off[0];
	for (i=0; i < size; i++) {
		val = base + off[i];
		if ((*cmp) (cur, val)) {
			cur = val;
			id++;
		}
		*hdst++ = o[i];
		*tdst++ = id;
	}
	*idp = id;

	return i;
}

static int
refine(BAT **res, BAT *b, BAT *a, int rv)
{
	str rev = rv ? "_rev" : "";
	BAT *bn = NULL;

	if (BATcount(b) != BATcount(a)) {
		GDKerror("CTrefine%s: both BATs must have the same cardinality and their heads must form a 1-1 match.\n", rev);
		return GDK_FAIL;
	}
@(
	/* checking only the key property is too strict,
	 * as it might not be set although it does hold;
	 * exhaustively checking keyness is too expensive;
	 * hence, we just don't check, and keep our fingers crossed...
	 */
	if (!(b->hkey && a->hkey)) {
		if (a->hkey) {
			GDKerror("CTrefine%s: head of first BAT is not unique (key);", rev);
		} else if (b->hkey) {
			GDKerror("CTrefine%s: head of second BAT is not unique (key);", rev);
		} else {
			GDKerror("CTrefine%s: heads of both BATs are not unique (key);", rev);
		}
		GDKerror("CTrefine%s: heads of both BATs must be unique (key) to form a 1-1 match.\n", rev);
		return GDK_FAIL;
	}
@)
	if (b->tkey) {		/* if key, no further refinements can take place */
		bn = BATmark(b, 0);
	} else {
		int (*cmp) (ptr, ptr) = BATatoms[b->ttype].atomCmp, cnt = 0;
		BUN p, q, r, last = BUNfirst(b);
		char *base = a->theap ? NULL : a->T->heap.base, *this = NULL;
		size_t cur, end, off;
		var_t *offp;
		oid *ids;
		bit a_void = (a->ttype == TYPE_void);
		int xx, tpe = a_void ? TYPE_oid : a->ttype;
		size_t size = DEFAULT_SIZE;
		oid *hdst, *tdst, o, *op = &o, id = 0;
		BATiter ai = bat_iterator(a), bi = bat_iterator(b);

		/* create tmp BAT that holds one cluster; estimate required size using sampling */
		if (BATcount(b) > DEFAULT_SIZE) {
			BAT *histo = NULL, *sample = BATsample(b, DEFAULT_SIZE);

			if (sample) {
				histo = BAThistogram(sample);
				if (histo) {
					BATmax(histo, &xx);
					if (xx > 1)
						size = MAX(size, (size_t) (xx * (((float) BATcount(b)) / DEFAULT_SIZE)));
					BBPreclaim(histo);
				}
				BBPreclaim(sample);
			}
			if (histo == NULL)
				return GDK_FAIL;
		}
		/* create a temporary BAT of the estimated size holding pointers to the a tail atoms */
		cur = 0;
		end = size;
		offp = (var_t*) GDKmalloc(size * sizeof(var_t));
		ids = (oid*) GDKmalloc(size * sizeof(oid));
		if (offp == NULL || ids == NULL) {
			if (offp) GDKfree(offp);
			if (ids) GDKfree(ids);
			return GDK_FAIL;
		}
		if (a_void) {
			base = this = (char*) GDKmalloc(size * sizeof(oid));
			if (base == NULL) {
				GDKfree(offp);
				GDKfree(ids);
				return GDK_FAIL;
			}
		}

		/* create result BAT */
		bn = BATnew(TYPE_oid, TYPE_oid, BATcount(b));
		if (bn == NULL) {
			GDKfree(offp);
			GDKfree(ids);
			if (a_void)
				GDKfree(base);
			return GDK_FAIL;
		}
		bn->hsorted = bn->tsorted = FALSE;
		hdst = (oid *) Hloc(bn,BUNfirst(bn));
		tdst = (oid *) Tloc(bn,BUNfirst(bn));

		if (a_void) {
			@:refine_loop(@:refine_void_1@,@:refine_void_2@,GDKfree(base);,this = base;)@
		} else {
			@:refine_loop()@
		}
@= refine_void_2
	off = (size_t) (this - base);
	base = (char*) GDKrealloc(base, size * sizeof(oid));
	this = base + off;
@= refine_void_1
	*(oid*)this = a->tseqbase+r;
	r = this - base;
@= refine_loop
		/* merge-scan tail of b, finding chunks with equal values; then sort each chunk on a */
		BATloop(b, p, q) {
			if ((*cmp) (BUNtail(bi, last), BUNtail(bi, p))) {
				cnt = sort_flush(offp, ids, cur, tpe, base ? base : a->theap->base, hdst, tdst, &id, rv);
				hdst += cnt;
				tdst += cnt;

				last = p;
				cur = 0;
				@4
			}
			o = *(oid *) BUNhead(bi, p);
			BUNfndOID(r, ai, op);
			if (r == BUN_NONE) {
				GDKerror("CTrefine%s: value "SZFMT"@0 not found in head of second BAT;\n"
					 "CTrefine%s: heads of both BATs do not form a 1-1 match.\n", rev, (size_t) o, rev);
				BBPreclaim(bn);
				GDKfree(offp);
				GDKfree(ids);
				@3
				return GDK_FAIL;
			}
			if (cur >= end) {
				offp = (var_t*) GDKrealloc(offp, (size *= 2) * sizeof(var_t));
				ids = (oid*) GDKrealloc(ids, size * sizeof(oid));
				end = size;
				@2
			}
			@1
			offp[cur] = (base) ? r<<a->T->shift : ((var_t*)a->T->heap.base)[r];
			ids[cur] = o;
			cur++;
			this += sizeof(oid);
		}
@c
		cnt = sort_flush(offp, ids, cur, tpe, base ? base : a->theap->base, hdst, tdst, &id, rv);
		hdst += cnt;
		tdst += cnt;

		GDKfree(offp);
		GDKfree(ids);
		if (a_void)
			GDKfree(base);
		BATsetcount(bn, (((char*) tdst) - bn->T->heap.base)/Tsize(bn));
		bn->tsorted = GDK_SORTED;
	}
	*res = bn;
	return GDK_SUCCEED;
}

int
CTrefine(BAT **res, BAT *b, BAT *a)
{
	return refine(res, b, a, FALSE);
}

int
CTrefine_rev(BAT **res, BAT *b, BAT *a)
{
	return refine(res, b, a, TRUE);
}

@}
@}
