@/
The contents of this file are subject to the MonetDB Public License
Version 1.1 (the "License"); you may not use this file except in
compliance with the License. You may obtain a copy of the License at
http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html

Software distributed under the License is distributed on an "AS IS"
basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
License for the specific language governing rights and limitations
under the License.

The Original Code is the MonetDB Database System.

The Initial Developer of the Original Code is CWI.
Portions created by CWI are Copyright (C) 1997-July 2008 CWI.
Copyright August 2008-2010 MonetDB B.V.
All Rights Reserved.
@

@f opt_tarantula
@a M. Kersten
@- Multileg creatures
Query execution can be improved significantly using distributed processing.
Traditionally, this encompasses fragmentation and allocation of the base
tables over multiple sites and query plans that include on the fly transport
of intermediate results.

Breaking the database into pieces itself is a well-studied area.
Most approaches consider the workload and search for a good split
of the base tables, such that the workload performance improves.

The Tarantula optimizer, like the Octopus optimizer, use the
output of the mitosis+mergetable optimizer and produces the
actual plans for parallel execution.
The tarantula untangles the query plan into a controlling head
function and a series of subplans, one for each leg to execute concurrently.

The target for breaking the plan are the blocking operations,
in particular mat.pack(). The flow graph leading to the
the pack arguments are extracted from the query plan and
each subgraph is cast into an independent plan. 
Since the query plan is a DAG, it is perfectly possible that
a portion being extracted is shared amongst all legs.
The naive extraction then leads to a re-calculation of 
shared intermediates in each leg.

The subplan produces the argument to the blocking operator, whose
result will be assembled in the head. It is also perfectly possible
that variables assigned a value are used later on in the query graph.
These variables are identified and one leg becomes responsible to
return it also to the head to be used later on.

The orginal pack operation is replaced by a call to a function
to orchestrate the distributed processing and return the final
result. Then the next pack operation is searched and its
subgraph is derived. Again, it may share portions produced
in the first pack subgraph.

A potential more optimal scheme would be to detect each such case and
turn it into a splitting point as well. This can be detected by
looking for the last assignment and multiple use cases. [VARIANT TODO]

The allocation of a subplan to leg depends on a bidding scheme. 
Bidding can not depend on BAT arguments, because that would cause 
significant communication overhead. Scalar values could be used and
would function well in terms of using the recycler to get involved into
precise bidding. 

A snippet of an tarantula plan with two legs is shown.
The main part of the query becomes a three step procedure of
1) remote registration of subplans, 2) obtaining bids and schedule design
and 3) execute the subplans.
Each plan does not contain duplicate node ids.
@verbatim
function reg_qry_0():int;
	tarantula.register(0,"qry_0","qry_1");
	tarantula.register(1,"qry_0","qry_1");
	return 0;
end reg_qry;

function bid_qry_0(hdl:int)(leg0:int,leg1:int,leg2:int,leg3:int);
	(_4,_5) := tarantula.getBid(0,"qry_0","qry_1");
	(_6,_7) := tarantula.getBid(1,"qry_0","qry_1");
    return (leg0,leg1,leg2,leg3) := scheduler.schedule_0(_4,_5,_6,_7);
end bid_qry;

function run_qry(node_0:int,node_1:int):bat[:oid,:int]
    _87 := tarantula.execute(node_0,"leg0");
    _88 := tarantula.execute(node_1,"leg1");
    _15 := mat.pack(_87,_88);
	return run_qry := _15;
end run_qry;

function user.qry():void;
	_3 := reg_qry_0();
	(_4,_5,_6,_7):= bid_qry_0(_3);
	_15 := tarantula.run_qry(_4,_5,_6,_7);
    _16 := sql.resultSet(1,1,_15);
    sql.rsColumn(_16,"sys.squida","bid","int",32,0,_15);
    _21 := io.stdout();
    sql.exportResult(_21,_16);
end qry;
@end verbatim
The nodes addressed by the tarentula are indices into a global catalog.
The number of subplans is derived by the Mitosis as the number of pieces to consider.
The tarantula may register the subplans to more nodes than pieces.

@verbatim
function tarantula.exec_qry_0(node:str,fcn:str):bat[:oid,:int];
	conn:= remote.connect(node,"monetdb","monetdb");
	r:= remote.exec(conn,"tarantula",fcn);
	b:bat[:oid,:int]:= remote.get(conn,r);
	return b;
end exec_qry;
@end verbatim

@verbatim
function tarantula.qry_0(version:int):bat[:oid,:int];
    _53:bat[:oid,:int] := attach.bind("file://export/scratch/mk/dbfarm/demo/bat/01/001");
	_54 := algebra.slice(_53,0@0,25@0);
    _63:bat[:oid,:int] := attach.bind("file://export/scratch/mk/dbfarm/demo/bat/01/002");
	_64 := algebra.slice(_63,0@0,25@0);
    _72 := algebra.kdifference(_54,_64);
    _78 := algebra.kunion(_72,_64);
    _13:bat[:oid,:oid]  := attach.bind("file://export/scratch/mk/dbfarm/demo/bat/01/003");
    _14 := bat.reverse(_13);
    _85 := algebra.kdifference(_78,_14);
	return qry_0 := _85;
end tarantula.qry_0;

function tarantula.qry_1(version:int):bat[:oid,:int];
	... use second slice ...
end tarantula.qry_1;

@end verbatim

[Stability]
We assume that during a session, workers once started will remain alive.
No fault tolerance techniques are included.

[Recycling]
The legs contain registered functions and possible partial results in its recycler pool.
In the first implementation we assume a read-only database, where all workers are
restarted when changes to the underlying database affect the recycler pool.
Alternative, the head can clear the recycler pool explicitly upon such state change.

[Shared disk]
For a leg to work it needs access to its storage layer, which is a NAS.
It is encapsulated in the operation attach.bind("path",tuplecount,low_oid,high_oid).

The code generation for the legs currently relies on a conceptual full replication of
the database over the servers. The next version should use the attach() functionality
or use the datacylcotron to access portions.

These approaches are different from the Octopus, where the head is
the sole control over the persistent data. 

[Naming]
The legs received from the tarantula should be ensured
not to clash with those already known. Therefore, we simply
tag them by orginating site.

[Caveats]
Any update invalidates the request to distributed processing.
In the same line, multi-statement SQL transactions and
updates to global variables are ignored. 

Global variables are tricky, because they are part of the
session context. To make it work, we need to be able to perform
an upcall to that context (=dangerous).
The solution is that any variable context should be
passed through a relation.

[The hard world] The way plans are generated by mitosis leads to a large number of
mat.pack() operations, whose result is subsequently spread out over the legs again
for continual processing. This leads to a lot of transport, from leg->head->all-legs.
This situation can be circumvented by allowing each leg to call upon all tarantula legs
to solve the problem at hand. With recycling enabled in each leg, duplicate work will
be avoided and a direct copy of the data is obtained.

To make this work, we have to keep track of what input variables for a leg
are effectively the result of a tarantula call and inject its materialisation
in the leg upon first use.
@{
@mal
module tarantula; 
pattern optimizer.tarantula():str
address OPTtarantula;
pattern optimizer.tarantula(mod:str, fcn:str):str
address OPTtarantula
comment "Map-execute-reduce parallelism optimizer";

@h
#ifndef _TAR_OCTOPUS_
#define _TAR_OCTOPUS_
#include "opt_prelude.h"
#include "opt_support.h"

#ifdef WIN32
#ifndef LIBOPTIMIZER
#define opt_export extern __declspec(dllimport)
#else
#define opt_export extern __declspec(dllexport)
#endif
#else
#define opt_export extern
#endif

typedef struct REGMAL{
    str fcn;
    struct REGMAL *nxt;
} *Registry;

typedef struct {
    str uri;
    str usr;
    str pwd;
    Registry nxt; /* list of registered mal functions */
    bte active;
    str conn;
    int inuse;
} Peer;

#include "opt_mitosis.h"
#define MINLEGSIZE 5	/* number of MAL instructions to consider for a leg */
#define MAXSHARE 64		/* number of input output arguments to consider */
#define VTOP 2			/* multiplier margin, theoretical each variable can be replaced by a new one */
#define MAXSITES MAXSLICES   /* should become dynamic at some point */

opt_export Peer peers[MAXSITES];    /* registry of peer servers */
opt_export int TARnrpeers;
opt_export bte tarantulaLocal;

opt_export int TARgetPeer(str uri);
opt_export int OPTtarantulaAdviceInternal(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);

@:exportOptimizer(tarantula)@

#define OPTDEBUGtarantula  if ( optDebug & ((lng)1 <<DEBUG_OPT_TARANTULA) )

#endif
@c
#include "mal_config.h"
#include "mal_interpreter.h"	/* for showErrors() */
#include "mal_builder.h"
#include <Mapi.h>
#include "remote.h"
#include "mal_sabaoth.h"
#include "opt_tarantula.h"
#include "opt_deadcode.h"


Peer peers[MAXSITES];    /* registry of peer servers */
int TARnrpeers=0;
bte tarantulaLocal=0;

#define SHAREDDISK		1	/* assume a shared file system */
#define SHAREDINTERMEDIATES	2	/* propagate intermediates to head */
int strategy = SHAREDDISK ;	
@-
The algorithm consists of several steps. The first one
replaces the original query and creates the leg functions.
In the second phase the should be registered at the different sites.

The key observation is that whenever we encounter a mat.pack,
there is a need to bring information together for inspection.
It indicates a blocking operation.
Therefore, we recursively break a plan by looking for the
pack instructions and collect all dependent instructions.
The original block is trimmed as far as needed.

During the development we take the default number of pieces
to be equal to the thread count.
@c
int 
OPTtarantulaAdviceInternal(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{

	(void) stk;
	(void) pci;
	if ( isOptimizerEnabled(mb,tarantulaRef) )
		return GDKnr_threads;
	return -1;
}
static int
TARinitcode(Client cntxt, MalBlkPtr mb){
	InstrPtr p;
	str s;
	str l = NULL;

	(void) cntxt;

	/* _x := remote.connect(uri,"monetdb","monetdb","msql"); */
	p = newStmt(mb, remoteRef,connectRef);
	s = GDKgetenv("merovingian_uri");
	if (s == NULL) /* aparently not under Merovingian control, fall back to local only */
		SABAOTHgetLocalConnection(&l);
	p= pushStr(mb,p, s == NULL ? l : s);
	p= pushStr(mb,p,"monetdb");
	p= pushStr(mb,p,"monetdb");
	p= pushStr(mb,p,"msql");
	if (l)
		GDKfree(l);
	return getArg(p,0);
}

@-
Be prepared to catch errors from the remote site.
You should catch them, otherwise the session is not closed.
Beware, exceptions should be catched and thrown after the
connection has been closed.
@c
static void
TARexitcode(MalBlkPtr mb, int conn, int varid)
{
	InstrPtr p;

	newCatchStmt(mb, "ANYexception");
	p = newStmt(mb, remoteRef, disconnectRef);
	pushArgument(mb, p, conn);
	newRaiseStmt(mb, "ANYexception");	/* pass to caller */
	newExitStmt(mb, "ANYexception");

	p = newStmt(mb, remoteRef, disconnectRef);
	pushArgument(mb, p, conn);
	p = newAssignment(mb);
	getArg(p, 0) = getArg(getInstrPtr(mb, 0), 0);
	pushArgument(mb, p, varid);
	p->barrier = RETURNsymbol;
	pushEndInstruction(mb);
	p = newStmt(mb, optimizerRef, putName("aliases", 7));
	p = pushStr(mb, p, tarantulaRef);
	p = pushStr(mb, p, getFunctionId(getInstrPtr(mb, 0)));
}

static int
TARfindPeer(str uri)
{
	int i;
	for (i=0; i<TARnrpeers; i++){
		if ( strcmp(uri, peers[i].uri) == 0 ){
			return i;
		}
	}
	return -1;
}

/* Look for and add a peer with uri in the registry.  Return index in registry */
int
TARgetPeer(str uri)
{
	int i;

	i = TARfindPeer(uri);
	if ( i >=0 ) {
		peers[i].active = 1;
		return i;
	}
	if ( TARnrpeers == MAXSITES)
		return -1;
	i = TARnrpeers;
	peers[i].usr = GDKstrdup("monetdb");
	peers[i].uri = GDKstrdup(uri);
	peers[i].pwd = GDKstrdup("monetdb");
	peers[i].active = 1;
	peers[i].nxt = NULL;
	peers[i].inuse = 0;		
	TARnrpeers++;
	return i;
}

/* Clean function registry of non-active peers */

void TARcleanFunReg(int i)
{	
	Registry r, q;
	mal_set_lock(mal_contextLock,"tarantula.cleanFunReg");
	r = peers[i].nxt;
	peers[i].nxt = NULL;
	mal_unset_lock(mal_contextLock,"tarantula.cleanFunReg");
	while ( r ) {
			q = r->nxt;
			GDKfree(r->fcn);
			GDKfree(r);
			r = q;
	}
}

str
TARdiscover(Client cntxt)
{
	bat bid = 0;
	BAT *b;
	BUN p,q;
	str msg = MAL_SUCCEED;
	BATiter bi;
	char buf[BUFSIZ]= "*/tarantula", *s= buf;
	int i, nrworkers = 0;

	tarantulaLocal = 0;

	/* we have a new list of candidate peers */
	for (i=0; i<TARnrpeers; i++)
		peers[i].active = 0;

	msg = RMTresolve(&bid,&s);
	if ( msg == MAL_SUCCEED) {
		b = BATdescriptor(bid);
		if ( b != NULL && BATcount(b) > 0 ) {
			bi = bat_iterator(b);
			BATloop(b,p,q){
				str t= (str) BUNtail(bi,p);
				nrworkers += TARgetPeer(t) >= 0; 
			}
		}
		BBPreleaseref(bid);
	} else
		GDKfree(msg);

	if ( !nrworkers  ) {
	 	/* there is a last resort, local execution */
		SABAOTHgetLocalConnection(&s);
	
		nrworkers += TARgetPeer(s) >= 0;
		tarantulaLocal = 1; 
	}

#ifdef DEBUG_RUN_TAR
	mnstr_printf(cntxt->fdout,"Active peers discovered %d\n",nrworkers);
	for (i=0; i<TARnrpeers; i++)
	if ( peers[i].uri )
		mnstr_printf(cntxt->fdout,"%s\n", peers[i].uri);
#else
		(void) cntxt;
#endif

	for (i=0; i<TARnrpeers; i++)
		if ( !peers[i].active )
			TARcleanFunReg(i);

	return MAL_SUCCEED;
}
@-
The push instruction routine is overloaded to check for easy exchange operations of
BATs between leg, head, and persistent store. First target is to attempt sharing
of the base tables only.
Second stage would be to transport intermediates throught the file system as well.
@c
void pushTARinstruction(MalBlkPtr tm, InstrPtr p){
	VarPtr loc,low,hgh;
	InstrPtr q;

	if (strategy & SHAREDDISK &&
		 getModuleId(p) == sqlRef && ( getFunctionId(p) == bindRef || getFunctionId(p) ==binddbatRef || getFunctionId(p) == bindidxRef )){
		loc = varGetProp(tm, getArg(p,0), fileProp);
		low = varGetProp(tm, getArg(p,0), PropertyIndex("hlb"));
		hgh = varGetProp(tm, getArg(p,0), PropertyIndex("hub"));
		if ( loc ) {
			q = newStmt(tm,attachRef,bindRef);
			getArg(q,0)= getArg(p,0);
			q = pushStr(tm,q, loc->value.val.sval);
			if ( low && hgh){
				q= pushOid(tm,q,low->value.val.oval);
				setVarUDFtype(tm,getArg(q,q->argc-1));
				q= pushOid(tm,q,hgh->value.val.oval);
				setVarUDFtype(tm,getArg(q,q->argc-1));
			}
			return;
		}
	}
	pushInstruction(tm,p);
}
@-
The TARmakeLeg walks through the MAL block and extracts the dependent structure for
execution.  A few strategies apply.
To exchange intermediates the flag SHAREDINTERMEDIATES should be set in the strategy.
If it is not set then the legs will be doing duplicate work, as the mitosis
will generate identical plans for side-ways projects over the fragmented table.

The alternative is to determine the 'level' at which a variable is needed indirectly.
They then can be exported by the leg. This, however, will cause a lot of communication,
because statically we can not see if a result is represented as a cheap view over another.
@c
static MalBlkPtr 
TARmakeLeg(Client cntxt, MalBlkPtr mb, InstrPtr *old, int pc, int last, int limit, int idx, int leg, int input[MAXSLICES][MAXSHARE], int output[MAXSLICES][MAXSHARE], InstrPtr *list,int *map)
{
	MalBlkPtr tm = NULL;
	InstrPtr p = NULL, sig;
	int i, top=0, fnd, *alias;
	char buf[BUFSIZ];
	Symbol s;

	assert(old[pc]->fcnname == packRef);

	OPTDEBUGtarantula 
		mnstr_printf(cntxt->fdout,"#create leg %d for %d %d %d\n",leg,pc,idx -old[pc]->retc, getArg(old[pc],idx));
@-
The leg should have enough instructions to warrant a distributed execution. This should involve
a careful analysis of the instructions assembled. For the time being, we only allow for a leg 
if at least a sql.bind operation belongs to the list and the leg has a minimimal number of statements.
@c
	fnd = 0;
	for( i=0; list[i]; i++) {
	 fnd += getModuleId(list[i]) == sqlRef && getFunctionId(list[i]) == bindRef;
	 fnd += getModuleId(list[i]) == sqlRef && getFunctionId(list[i]) == bindidxRef;
	 fnd += getModuleId(list[i]) == sqlRef && getFunctionId(list[i]) == binddbatRef;
	}
	top = i;

	if (fnd == 0 || top - fnd <= MINLEGSIZE)
		return 0;

	OPTDEBUGtarantula{
		mnstr_printf(cntxt->fdout,"#input leg %d ",leg);
		for(i=0; input[leg][i]; i++)
			mnstr_printf(cntxt->fdout,"%d(%d), ", input[leg][i], map[input[leg][i]]);
		mnstr_printf(cntxt->fdout,"\n#output ");
		for(i=0; output[leg][i]; i++)
			mnstr_printf(cntxt->fdout,"%d(%d), ", output[leg][i], map[output[leg][i]]);
		mnstr_printf(cntxt->fdout,"\n");
	}
	alias= (int*) GDKzalloc(VTOP * mb->vtop * sizeof(int));
	assert(alias);

	snprintf(buf,BUFSIZ,"%s_%d_%d", getFunctionId(getInstrPtr(mb,0)), getArg(old[pc],0), idx-old[pc]->retc);
	putName(buf,strlen(buf));

	s= newFunction(tarantulaRef, putName(buf,strlen(buf)), FUNCTIONsymbol);
	insertSymbol(findModule(cntxt->nspace,tarantulaRef),s);
	tm= s->def;
	sig= getInstrPtr(tm,0);
	setVarType(tm,getArg(sig,0), getArgType(mb,old[pc],idx));
	setVarUDFtype(tm,getArg(sig,0));
	alias[output[leg][0]] = getArg(sig,0);

	/* add the return variables */
	for ( i = 1; output[leg][i]>0; i++){
		alias[map[output[leg][i]]] = cloneVariable(tm,mb,map[output[leg][i]]);
		sig = pushReturn(tm, sig, alias[map[output[leg][i]]]);
		setVarUDFtype(tm,getArg(sig,i));
		OPTDEBUGtarantula
			mnstr_printf(cntxt->fdout,"#map %d ->%d\n",output[leg][i], map[output[leg][i]]);
	}
	/* add the arguments from the query template */
	for ( i = 0; input[leg][i]> 0; i++){
		alias[map[input[leg][i]]] = cloneVariable(tm,mb,map[input[leg][i]]);
		sig = pushArgument(tm, sig, alias[map[input[leg][i]]]);
	}

	/* include the necessary functions */
	for (top--; top >= 0; top--){
		p = copyInstruction(list[top]);
		for (i= 0; i< p->argc; i++){
			int a= map[getArg(p,i)];
			if (alias[a]==0) {
				alias[a] = cloneVariable(tm,mb,a);
			}
			getArg(p,i) = alias[a];
		}
		pushTARinstruction(tm, p);
	}

	/* return all variables of interest */
	p = newAssignment(tm);
	p->barrier = RETURNsymbol;
	p->retc= 0;
	p->argc= 0;
	for ( i = 0; i < sig->retc; i++)
		p = pushReturn(tm,p, getArg(sig,i));
	for ( i = 0; output[leg][i]>0; i++)
		p = pushArgument(tm,p, alias[map[output[leg][i]]]);
	pushEndInstruction(tm);
	for (i = last + 1; i < limit; i++)
		if (old[i] && old[i]->token != REMsymbol)
			newStmt(tm, getModuleId(old[i]), getFunctionId(old[i]));

	clrDeclarations(tm);
	chkProgram(cntxt->nspace,tm);
	if ( tm->errors )
		mb->errors++;

	OPTDEBUGtarantula
		printFunction(cntxt->fdout, tm, 0, LIST_MAL_STMT | LIST_MAPI);
	GDKfree(alias);
	return tm;
}

static void
TARmakeRegistration(Client cntxt, MalBlkPtr mb, InstrPtr *old, int pc, int nodes)
{
	Symbol s;
	MalBlkPtr tm;
	InstrPtr p,sig;
	char fcn[BUFSIZ];
	char buf[BUFSIZ];
	int i,n,k=0;
	str name;

	snprintf(fcn,BUFSIZ,"reg_%s_%d", name = getFunctionId(getInstrPtr(mb,0)), getArg(old[pc],0));
	s= newFunction(tarantulaRef, putName(fcn,strlen(fcn)), FUNCTIONsymbol);
	insertSymbol(findModule(cntxt->nspace,tarantulaRef),s);
	tm= s->def;
	sig = getInstrPtr(tm,0);

	setVarType(tm, getArg(getInstrPtr(tm,0),0), TYPE_int);
	if ( tarantulaLocal == 0)
	for ( n= 0; n < nodes; n++, k = 0){
		p= newStmt(tm,tarantulaRef,registerRef);
		p= pushInt(tm, p,n);
		for( i=old[pc]->retc; i< old[pc]->argc; i++){
			snprintf(buf,BUFSIZ,"%s_%d_%d",name,getArg(old[pc],0), k++);
			p = pushStr(tm,p,buf);
		}
	}

	p= newAssignment(tm);
	getArg(p,0) = getArg(sig,0);
	p = pushInt(tm,p,0);
	p->barrier = RETURNsymbol;
	pushEndInstruction(tm);
	clrDeclarations(tm);
	chkProgram(cntxt->nspace,tm);
	OPTDEBUGtarantula
		printFunction(cntxt->fdout, tm, 0, LIST_MAL_STMT | LIST_MAPI);
}

@-
Ask the participants for a bid and perform the node selection for the legs.
@c
static void
TARmakeBidding(Client cntxt, MalBlkPtr mb, InstrPtr *old, int pc, int nodes)
{
	Symbol s;
	MalBlkPtr tm;
	InstrPtr p,r,sig;
	char buf[BUFSIZ], fcn[BUFSIZ];
	int i, n, tmp, k=0;
	str name, getBidRef= putName("getBid",6);

	snprintf(fcn,BUFSIZ,"bid_%s_%d", name = getFunctionId(getInstrPtr(mb,0)), getArg(old[pc],0));
	s= newFunction(tarantulaRef, putName(fcn,strlen(fcn)), FUNCTIONsymbol);
	insertSymbol(findModule(cntxt->nspace,tarantulaRef),s);
	tm= s->def;

	sig = getInstrPtr(tm,0);
	getArg(sig,0)= -1;
	r= newInstruction(NULL,ASSIGNsymbol);
	setModuleId(r,tarantulaRef);
	setFunctionId(r,putName("schedule",8));
	r->barrier = RETURNsymbol;
	/* return the node id for subplan execution */
	for (k= 0; k < nodes; k++){
		snprintf(buf,BUFSIZ,"node%d",k++);
		sig= pushReturn(tm, sig, n = newVariable(tm, GDKstrdup(buf),TYPE_int));
		r = pushReturn(tm,r,n);
	}
	sig = pushArgument(tm, sig, newTmpVariable(tm,TYPE_int));

	for (n= 0; n < nodes; n++){
		p= newInstruction(tm,ASSIGNsymbol);
		setModuleId(p, tarantulaRef);
		setFunctionId(p, getBidRef);
		p= pushInt(tm, p,n);
		for(k=0, i=old[pc]->retc; i< old[pc]->argc; k++, i++){
			snprintf(buf,BUFSIZ,"%s_%d_%d",name,getArg(old[pc],0),k);
			p = pushStr(tm,p,buf);
			p = pushReturn(tm, p, tmp = newTmpVariable(tm,TYPE_int));
			r = pushArgument(tm,r,tmp);
		}
		pushTARinstruction(tm,p);
	}
	pushTARinstruction(tm,r);
	pushEndInstruction(tm);
	clrDeclarations(tm);
	chkProgram(cntxt->nspace,tm);
	OPTDEBUGtarantula
		printFunction(cntxt->fdout, tm, 0, LIST_MAL_STMT | LIST_MAPI);
}
@-
The executor gets node assignments for each of the legs and
performs a remote operation on the subplan. The results are 
assembled using a pack and returned to the caller.
@c
static void
TARmakeStub(Client cntxt, MalBlkPtr mb, InstrPtr *old, int pc, int idx, int leg, int input[MAXSLICES][MAXSHARE], int output[MAXSLICES][MAXSHARE])
{
	Symbol s;
	MalBlkPtr tm;
	char fcn[BUFSIZ];
	InstrPtr sig, r, q;
	int conn,j,l;
	int arg[1024];

	/* generate stubb code for the remote execution */
	snprintf(fcn,BUFSIZ,"rmt_%s_%d_%d", getFunctionId(getInstrPtr(mb,0)), getArg(old[pc],0),leg);
	s= newFunction(tarantulaRef, putName(fcn,strlen(fcn)), FUNCTIONsymbol);
	insertSymbol(findModule(cntxt->nspace,tarantulaRef),s);
	tm= s->def;
	sig = getInstrPtr(tm,0);

	/* add the return values */
	setVarType(tm, getArg(sig,0), getVarType(mb,getArg(old[pc],idx)));
	setVarUDFtype(tm, getArg(sig,0));
	for ( j=1; output[leg][j]; j++)
		sig= pushReturn(tm, sig, cloneVariable(tm, mb, output[leg][j]));

	/* get the input arguments */
	sig = pushArgument(tm,sig,newVariable(tm,GDKstrdup("node"),TYPE_int));
	/* copy the query arguments */
	for ( j=0; input[leg][j]; j++)
		sig= pushArgument(tm, sig, cloneVariable(tm, mb, input[leg][j]));

	/* conn := tarantula.connect(node); */
	q = newStmt(tm, tarantulaRef,connectRef);
	conn= getArg(q,0);
	q = pushArgument(tm, q, getArg(sig,sig->retc));

	/* get addition arguments needed in a leg */
	/* k:= remote.put(conn,kvar) */
	for (j= 0; j < sig->argc; j++)
	if ( j != sig->retc ){
		q= newFcnCall(tm,remoteRef,putRef);
		setVarType(tm, getArg(q,0), TYPE_str);
		setVarUDFtype(tm, getArg(q,0));
		q= pushArgument(tm,q,conn);
		q= pushArgument(tm,q,getArg(sig,j));
		arg[j]= getArg(q,0);
	}

	/* (k1,...kn):= remote.exec(conn,tarantula,qry,version....) */
	snprintf(fcn,BUFSIZ,"%s_%d_%d", getFunctionId(getInstrPtr(mb,0)), getArg(old[pc],0),leg);
	q= newFcnCall(tm,remoteRef,execRef);
	q->retc=  q->argc= 0;
	for (j=0; j < sig->retc; j++)
		q = pushReturn(tm,q,arg[j]);
	q= pushArgument(tm,q,conn);
	q= pushStr(tm,q,tarantulaRef);
	q= pushStr(tm,q,putName(fcn,strlen(fcn)));
	/* deal with all arguments ! */
	for (j=sig->retc+1; j < sig->argc; j++)
		q = pushArgument(tm,q,arg[j]);


	/* return exec_qry; */
	r= newInstruction(tm, ASSIGNsymbol);
	r->barrier= RETURNsymbol;
	r->retc= r->argc= 0;
	for ( j=0; j< sig->retc; j++)
		r= pushReturn(tm,r, getArg(sig,j));

	/* l:=remote.get(conn,k) */
	for ( j=0; j< sig->retc; j++){
		q= newFcnCall(tm,remoteRef,getRef);
		q= pushArgument(tm,q,conn);
		q= pushArgument(tm,q,arg[j]);
		l= getArg(q,0);
		setVarType(tm,l, getArgType(tm,sig,j));
		setVarUDFtype(tm, l);
		r= pushArgument(tm,r,l);
	}

	/* catch and propagate errors */
	newCatchStmt(tm, "ANYexception");
	/* q = newStmt(tm, remoteRef,disconnectRef);
	pushArgument(tm, q, conn); */
	newRaiseStmt(tm,"ANYexception");
	newExitStmt(tm, "ANYexception");

	/* close connection 
	q = newStmt(tm, remoteRef, disconnectRef);
	pushArgument(tm,q,conn); */

	pushTARinstruction(tm,r);

	pushEndInstruction(tm);
	clrDeclarations(tm);
	chkProgram(cntxt->nspace,tm);
	OPTDEBUGtarantula
		printFunction(cntxt->fdout, tm, 0, LIST_MAL_STMT | LIST_MAPI);
}
@-
The legs of the tarantula can be executed in parallel.
Watch out, the arguments should occupy the head of the stack.
Moreover, all legs may share variables.
@c
static void
TARmakeRun(Client cntxt, MalBlkPtr mb, InstrPtr *old, int pc, int limit, int nodes, int legs, int input[MAXSLICES][MAXSHARE], int output[MAXSLICES][MAXSHARE])
{
	Symbol s;
	MalBlkPtr tm;
	char buf[BUFSIZ], fcn[BUFSIZ];
	InstrPtr ret,sig, r, p,q;
	int j,k,l,x=0;
	int *lmap;

	snprintf(fcn,BUFSIZ,"exe_%s_%d", getFunctionId(getInstrPtr(mb,0)), getArg(old[pc],0));
	s= newFunction(tarantulaRef, putName(fcn,strlen(fcn)), FUNCTIONsymbol);
	insertSymbol(findModule(cntxt->nspace,tarantulaRef),s);
	tm= s->def;

	setVarType(tm,getArg(tm->stmt[0],0), getVarType(mb,getArg(old[pc],0)));
	setVarUDFtype(tm, getArg(tm->stmt[0],0));

	ret= newInstruction(tm,ASSIGNsymbol);
	ret->barrier = RETURNsymbol;
	getArg(ret,0)= getArg(tm->stmt[0],0);
@-
Build a consolidated map for all input/output variables
@c
	lmap = (int*) GDKzalloc(2 * limit * sizeof(int));
	
	/* include the remaining return variables */
	/* is relies on the assumption that all output variables are disjoint */
	for ( l=0; l<legs; l++){
		for ( j=1;output[l][j]; j++)
		if (lmap[output[l][j]] == 0) {
			lmap[output[l][j]] = cloneVariable(tm, mb, output[l][j]);
			tm->stmt[0]= pushReturn(tm, tm->stmt[0], lmap[output[l][j]]);
			ret= pushReturn(tm,ret, lmap[output[l][j]]);
		}
	}

	/* add the execution nodes */
	for( k=0 ; k<nodes; k++){
		snprintf(buf,BUFSIZ,"node%d",k++);
		tm->stmt[0]= pushArgument(tm, tm->stmt[0], newVariable(tm, GDKstrdup(buf), TYPE_int));
	}
	/* input arguments */
	for ( l=0; l<legs; l++){
		for ( j=0; input[l][j]; j++)
		if ( lmap[input[l][j]] == 0){
			lmap[input[l][j]] = cloneVariable(tm, mb, input[l][j]);
			tm->stmt[0] = pushArgument(tm, tm->stmt[0], lmap[input[l][j]]);
		}
	}
	sig= tm->stmt[0];

	/* initialize all other return variables */
	r= newAssignment(tm);
	getArg(r,0)= getArg(sig,0);
	pushNil(tm,r,getArgType(tm,sig,0));
	for ( j=1;j < sig->retc; j++){
		r= newAssignment(tm);
		getArg(r,0)= getArg(sig,j);
		pushNil(tm,r,getArgType(tm,sig,j));
	}

	if ( tarantulaLocal == 0){
		q= newFcnCall(tm,languageRef,dataflowRef);
		q->barrier= BARRIERsymbol;
		x = getArg(q,0);
		setVarType(tm,x,TYPE_int);
	}

	r= newInstruction(tm,ASSIGNsymbol);
	setModuleId(r,matRef);
	setFunctionId(r,packRef);
	for( l=k=0; l<legs; l++, k=(k+1)%nodes){
		snprintf(fcn,BUFSIZ,"rmt_%s_%d_%d", getFunctionId(getInstrPtr(mb,0)), getArg(old[pc],0),l);
		p = newInstruction(tm,ASSIGNsymbol);
		setModuleId(p,tarantulaRef);
		setFunctionId(p,putName(fcn,strlen(fcn)));
		pushReturn(tm, p, cloneVariable(tm,mb, getArg(old[pc],k+old[pc]->retc)));
		setVarUDFtype(tm,getArg(p,0));

		/* store the remaining output */
		for ( j=1; output[l][j]; j++)
			p = pushReturn(tm,p, lmap[output[l][j]]);
		
		/* add the destination node  and function*/
		p = pushArgument(tm,p, getArg(sig, k + sig->retc));

		/* add the input arguments */
		for ( j=0; input[l][j]; j++)
			p = pushArgument(tm,p, lmap[input[l][j]]);
		r= pushArgument(tm,r, getArg(p,0));
		pushTARinstruction(tm,p);
	}

	k =getArg(r,0)= getArg(sig,0);
	pushTARinstruction(tm,r);

	if ( tarantulaLocal == 0){
		q= newAssignment(tm);
		q->barrier = EXITsymbol;
		getArg(q,0)= x;
	}

	pushTARinstruction(tm,ret);

	pushEndInstruction(tm);
	clrDeclarations(tm);
	chkProgram(cntxt->nspace,tm);
	OPTDEBUGtarantula
		printFunction(cntxt->fdout, tm, 0, LIST_MAL_STMT | LIST_MAPI);
	GDKfree(lmap);
}
@-
The tarantula is only permitted for read only queries.
The first blocking mat.pack determines the scope of the tarantula optimizer.
@c
static int
TAReligible(MalBlkPtr mb){
	int i, target = -1;
	InstrPtr p;

	/* if ( varGetProp(mb, getArg(getInstrPtr(mb,0),0), PropertyIndex("autoCommit")) != NULL )
		return -1; */
	for (i = 1; i < mb->stop; i++){
		p = getInstrPtr(mb,i);
		
		if( getModuleId(p)== sqlRef ){
			if (getFunctionId(p)== appendRef || getFunctionId(p)== deleteRef )
				return -1;
			if ( strcmp(getFunctionId(p),"getVariable")==0 )
				return -1;
			if (strcmp(getFunctionId(p),"setVariable")==0 )
				return -1;
		}
		if (p->token == ENDsymbol)
			target= i;
	}
	return target;
}
@-
The core of the optimizer. It will repeatedly optimize the program given until all
blocking operations have been handled.
Therefore we start with an analysis to determine the 'level' at which a variable is needed indirectly.
They have to be exported when SHAREDINTERMEDIATES is set.
@c

static int
OPTtarantulaImplementation(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{
	InstrPtr q, p, pp, *old;
	int last=0, i, j, k, l, limit, actions=0, block = 0, fnd;
	int leg=0, ta =0, vtop=0;
	MalBlkPtr tm;
	char fcn[BUFSIZ];
	int *map, *level, top,lev = 0;
	int itop[MAXSLICES], input[MAXSLICES][MAXSHARE];
	int otop[MAXSLICES], output[MAXSLICES][MAXSHARE];
	InstrPtr *list;
	int *needed;
	char *done;

	/* merge table may leave some mat.new() dead code 
	should be handled by the pipes
	char *msg= MAL_SUCCEED;
	msg = OPTdeadcode(cntxt, mb, stk, 0);
	if ( msg){
		GDKfree(msg);
		return 0;
	}
	*/
	if( cntxt == 0){
		/* confuscate, delay for later activation */
		TARinitcode(cntxt, mb);
		TARexitcode( mb,0,0);
	}
	if ( ( last = TAReligible(mb)) < 0 )
		return 0;
    mal_set_lock(mal_contextLock,"tarantula.register");
    if ( TARnrpeers == 0 )
        TARdiscover(cntxt);
    mal_unset_lock(mal_contextLock,"tarantula.register");
	OPTDEBUGtarantula
		printFunction(cntxt->fdout, mb, 0, LIST_MAL_STMT | LIST_MAPI);
@-
All tarantula leg code is collected in a separate module
to ease future distribution and scheduling.
The optimizer works by looking only to the mat.pack statement.

Loop through the program and determine for each variable
the level at which it would be indirectly needed as input.
@c
	(void) fixModule(cntxt->nspace,tarantulaRef);

	limit = mb->stop;
	old = mb->stmt;
	vtop= mb->vtop;
	lev = limit;
	level= (int*) GDKzalloc(VTOP * vtop * sizeof(int));
	for (i = limit; i >=0 ; i--) {
		p = old[i];
		if ( p == 0)
			continue;
		if( getModuleId(p)== matRef && getFunctionId(p)== packRef)
			lev=i;
		if ( getModuleId(p) != sqlRef){
			for (j=0; j<p->argc; j++)
			if (level[getArg(p,j)] < lev )
				level[getArg(p,j)] = lev;
		}
	}
@-
	OPTDEBUGtarantula{
		for( i=0; i< vtop; i++){
			if( i % 7 == 6) mnstr_printf(cntxt->fdout,"\n");
			mnstr_printf(cntxt->fdout,"[%3d]%3s %d\t", i, getVarName(mb,i),level[i]);
		}
		mnstr_printf(cntxt->fdout,"\n");
	}
@c
	if ( newMalBlkStmt(mb, mb->ssize) < 0)
		return 0;
	pushTARinstruction(mb, old[0]);

	map= (int*) GDKzalloc(VTOP * vtop * sizeof(int));
	assert(map);

	for ( i = 0; i < VTOP * vtop; i++)
		map[i] = i;

	for (i = 1; i < limit; i++) {
		p = old[i];
		if ( p == 0)
			continue;
		if ( p == pci){
			freeInstruction(pci);
			old[i]= 0;
			continue;
		}
		if( getModuleId(p)== matRef && getFunctionId(p)== packRef) {
@-
The critical part is to determine the input/output variable set
for this pack function. Some variables may have to be re-used
in subsequent calls. They are gathered when the SHAREDINTERMEDIATE 
flag is set.

After this pack operation has been finished, the original target variable
has been replaced with a new one. 
@c
			lev = i;
			memset((char*) itop, 0, sizeof(int)* MAXSLICES);
			memset((char*) input, 0, sizeof(int)* MAXSLICES * MAXSHARE);
			memset((char*) otop, 0, sizeof(int)* MAXSLICES);
			memset((char*) output, 0, sizeof(int)* MAXSLICES * MAXSHARE);
			for (leg =0, ta = p->retc; leg < MAXSLICES &&  ta < p->argc; ta++,leg++) {
				list = (InstrPtr*) GDKzalloc(sizeof(InstrPtr) * mb->ssize);
				needed= (int*) GDKzalloc(VTOP * mb->vtop * sizeof(int));
				
				assert(list);
				assert(needed);
				top = 0;

				needed[map[getArg(p,ta)]] = 1;
				output[leg][otop[leg]++]= getArg(p,ta);

@-
All instructions that flow into the target variable are copied
to a list. It stops at remapped target variables, because there
the underlying tarantula leg has produced it.
In shared intermediate mode, we also keep track of other variables
delivered by the leg to the head. This class should be severely be
limited, as communication overhead may be more expensive then
recalculation in the individual legs.
@c
#define Mapped(P,J) (map[getArg(P,J)] != getArg(P,J))

				for (l = i-1; l > 0; l--){
					pp = old[l];
					/* find variables needed and not mapped already */
					fnd = 0;
					for (j = 0; j < pp->retc; j++)
						fnd += needed[getArg(pp,j)] && !Mapped(pp,j);

					/* blocks are copied as is */
					switch( pp->barrier ){
						case EXITsymbol: block++; break;
						case CATCHsymbol: block--; break;
						case BARRIERsymbol: block--; break;
					}
					if ( block ){
						for (j = 0; j < pp->argc; j++)
							needed[getArg(pp,j)] = 1;
						fnd = pp->retc;
					}

					if ( fnd) { /* instruction has result variables needed */
						for (j = pp->retc; j < pp->argc; j++)
							needed[getArg(pp,j)] = !isVarConstant(mb,getArg(pp,j));
						list[top++] = pp;
					}
				}
				/* built the argument list by collecting all variables */
				for ( l=top-1; l >= 0; l--){
					pp = list[l];
					for (j = pp->retc; j < pp->argc; j++) {
					if (needed[getArg(pp,j)] ){
						/* variables should appear once in the argument list */
						int x;
						for( x=0; x < itop[leg]; x++)
							if ( map[input[leg][x]] == map[getArg(pp,j)] )
								break;
							if ( x == itop[leg] )
								input[leg][itop[leg]++] = getArg(pp,j);
						}
						needed[getArg(pp,j)]= 0;
					}
@-
The variables that are statically used more then once beyond the mat.pack 
are a target for re-use. It is controlled by SHAREDINTERMEDIATES.
Otherwise, all variable re-use within the same flow partition
are re-calculated upon need. 
Recalculations may be cheaper compared to exchange, certainly
in the face of using the recycler.
@c
					if ( strategy & SHAREDINTERMEDIATES ) {
						for ( j = 0; j<pp->retc; j++){
							if ( level[getArg(pp,j)] > lev && !Mapped(pp,j) ){ 
								assert(mb->vtop < VTOP *vtop);
								map[output[leg][otop[leg]]] = cloneVariable(mb,mb, getArg(pp,j));
								level[map[output[leg][otop[leg]]]] = level[getArg(pp,j)];
								output[leg][otop[leg]++]= getArg(pp,j);
							}
							/* no need to get it once more */
							needed[getArg(pp,j)]= 0;
						}
					} else
						for ( j = 0; j<pp->retc; j++)
							needed[getArg(pp,j)]= 0;
				}
@-
				OPTDEBUGtarantula{
					int x;
					mnstr_printf(cntxt->fdout,"Start collecting lev %d \n",lev);
					printInstruction(cntxt->fdout, mb, 0, pp, LIST_MAL_STMT );
					mnstr_printf(cntxt->fdout,"input list ");
					for( x=0; x < itop[leg]; x++)
						mnstr_printf(cntxt->fdout,"%d,", input[leg][x]);
					mnstr_printf(cntxt->fdout,"\n");
					mnstr_printf(cntxt->fdout,"output list ");
					for( x=0; x < otop[leg]; x++)
						mnstr_printf(cntxt->fdout,"%d,", output[leg][x]);
					mnstr_printf(cntxt->fdout,"\n");
					}
Create the remote function and its local stub.
@c
				tm = TARmakeLeg(cntxt, mb, old, i, last, limit, ta, leg, input, output, list,map);
				GDKfree(list);
				GDKfree(needed);
				if ( tm== 0 || tm->errors)
					goto wrapup;
				TARmakeStub(cntxt,mb,old,i,ta,leg,input, output);
			}
			TARmakeRegistration(cntxt,mb,old,i,TARnrpeers);
			TARmakeBidding(cntxt,mb,old,i,TARnrpeers);
			TARmakeRun(cntxt,mb,old,i,vtop,TARnrpeers,leg,input,output);

			/* update masterplan */
			snprintf(fcn,BUFSIZ,"reg_%s_%d", getFunctionId(getInstrPtr(mb,0)), getArg(old[i],0));
			p= newStmt(mb, tarantulaRef, putName(fcn,strlen(fcn)));
			setVarType(mb, getArg(p,0), TYPE_int);

			/* update the bids */
			snprintf(fcn,BUFSIZ,"bid_%s_%d", getFunctionId(getInstrPtr(mb,0)), getArg(old[i],0));
			q = newInstruction(mb,ASSIGNsymbol);
			setModuleId(q,tarantulaRef);
			setFunctionId(q, putName(fcn,strlen(fcn)));
			for( k=0; k<TARnrpeers; k++)
				q= pushReturn(mb, q, newTmpVariable(mb,TYPE_int));
			q = pushArgument(mb,q, getArg(p,0));
			pushTARinstruction(mb,q);

			/* call the function to replace mat.pack */
			snprintf(fcn,BUFSIZ,"exe_%s_%d", getFunctionId(getInstrPtr(mb,0)), getArg(old[i],0));
			p = newStmt(mb,tarantulaRef, putName(fcn,strlen(fcn)));
			map[getArg(old[i],0)]= getArg(p,0);
			setVarType(mb,getArg(p,0), getArgType(mb,old[i],0));

			/* safe the new variables */
			for ( l=0; l < leg; l++)
			for ( k= 1; k< output[l][k]; k++){
				if ( map[output[l][k]]  == output[l][k]) {
					map[output[l][k]] = cloneVariable(mb,mb, output[l][k]);
					level[map[output[l][k]]] = level[output[l][k]];
					p= pushReturn(mb, p, map[output[l][k]]);
					setVarUDFtype(mb,getArg(p,p->retc-1));
				}
			}
			for( k=0; k<TARnrpeers; k++)
				p= pushArgument(mb, p, getArg(q, k++));

			/* identify the other arguments that should be passed around */
			done = (char*) GDKzalloc( VTOP * mb->vtop);
			assert(done);
			for ( l=0; l < leg; l++)
			for ( k=0; k < itop[l]; k++){
				if ( done[input[l][k]]  == 0)
					p= pushArgument(mb, p, input[l][k]);
				done[input[l][k]] =1;
			}
			GDKfree(done);
			
			actions++;
			continue;
		} 
		wrapup:
		for ( j=0; j< p->argc; j++)
			getArg(p,j)= map[getArg(p,j)];

		pushTARinstruction(mb,p);
		if (p->token == ENDsymbol){
			last= i;
			break;
		}
	}
	
@-
Keep the remaining optimizers in the main program.
The leg code should be optimized by the remaining optimizers too.
@c
	for (j = last + 1; j < limit; j++)
		if (old[j])
			pushTARinstruction(mb, old[j]);

	GDKfree(old);
	GDKfree(map);
	GDKfree(level);
	(void) stk;
	return actions;
}
@include optimizerWrapper.mx
@c
#include "opt_statistics.h"
@:wrapOptimizer(tarantula,OPT_CHECK_ALL)@
@}
