@' The contents of this file are subject to the MonetDB Public License
@' Version 1.1 (the "License"); you may not use this file except in
@' compliance with the License. You may obtain a copy of the License at
@' http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html
@'
@' Software distributed under the License is distributed on an "AS IS"
@' basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
@' License for the specific language governing rights and limitations
@' under the License.
@'
@' The Original Code is the MonetDB Database System.
@'
@' The Initial Developer of the Original Code is CWI.
@' Portions created by CWI are Copyright (C) 1997-July 2008 CWI.
@' Copyright August 2008-2009 MonetDB B.V.
@' All Rights Reserved.

@f tokenizer
@a Lefteris Sidirourgos
@v 0.1
@* Tokenizer
This module implements a vertical fragmented tokenizer for strings. It is based
on the ideas of the urlbox module.

The input string is tokenized according to a separator character (for now hard
coded '/'). Each token is inserted to the next BAT with the same order of
appearance in the string. We currently support 255 tokens in each string as
this module is intended for use with short and similar strings such as URLs.
In addition we maintain a 2-dimensional index that points to the depth and
height of the last token of each string.

The operations supported is insert a string (with duplicate elimination),
retrieve a string given its oid in the 2-dimensional index, and finally
retrieve the oid of a given string or oid_nil if it does not exist.

@- Current status
The two dimensional index is implemented with 2 bats. This will change by
using only 1 bat and use the first 24 bits for height and the rest 8 for
depth (on a 64bit arch this will be 56 and 8 respectively).

There can be only one tokenizer open at the same time. This is achieved by
setting a TRANSaction bat. This might change in the future. However there
can be more than one tokenizers stored in the disk, each of which is identified
by its name (usually the name of the active schema of the db). These
administrative issues and security aspects (e.g., opening a tokenizer of
a different schema) should be addressed more thoroughly.

@mal
module tokenizer
comment "The tokenizer provides fast access to a large collection of strings
based on a vertical fragmented representation.";

command open(name:str):void
address TKNZRopen
comment "open the names tokenizer store";

command close():void
address TKNZRclose
comment "close the current tokenizer store";

pattern take(i:oid):str
address TKNZRtakeOid
comment "take the i-th string";

pattern locate(s:str):oid
address TKNZRlocate
comment "if the given string is in the store returns its oid, otherwise oid_nil";

command tokenize(u:str):oid
address TKNZRdeposit
comment "tokenize a new string, if it is a duplicate entry the oid of the first entry is used";

command depositFile(fnme:str):void
address TKNZRdepositFile
comment "batch insertion from a file of strings to tokenize, each string is seperated by a new line";

pattern toString(i:oid):str
address TKNZRtakeOid
comment "get the string representation of an element (same as take)";

command getLevel(i:int):bat[:oid,:str]
address TKNZRgetLevel
comment "administrative function that returns the bat on level i";

command getDepth():bat[:void,:bte]
address TKNZRgetDepth
comment "administrative function that returns the depth bat";

command getHeight():bat[:void,:wrd]
address TKNZRgetHeight
comment "administrative function that returns the height bat";

command getCount():bat[:int,:wrd]
address TKNZRgetCount
comment "debuging function that returns the size of the bats at each level";

command getCardinality():bat[:int,:wrd]
address TKNZRgetCardinality
comment "debuging function that returns the unique tokens at each level";

@{
@-
@+ Implementation
@h
#ifndef _TKNZR_H
#define _TKNZR_H
#include "mal.h"
#include "mal_client.h"
#include "mal_interpreter.h"

#ifdef WIN32
#ifndef LIBTOKENIZER
#define tokenizer_export extern __declspec(dllimport)
#else
#define tokenizer_export extern __declspec(dllexport)
#endif
#else
#define tokenizer_export extern
#endif

@= params
(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);

@h
tokenizer_export str TKNZRopen             (int *r, str *name);
tokenizer_export str TKNZRclose            (int *r);
tokenizer_export str TKNZRdeposit          (oid *pos, str *tuple);
tokenizer_export str TKNZRtake             @:params@
tokenizer_export str TKNZRlocate           @:params@
tokenizer_export str TKNZRtakeOid          @:params@
tokenizer_export str TKNZRdepositFile      (int *r, str *fnme);
tokenizer_export str TKNZRgetLevel         (int *r, int *level);
tokenizer_export str TKNZRgetDepth         (int *r);
tokenizer_export str TKNZRgetHeight        (int *r);
tokenizer_export str TKNZRgetCount         (int *r);
tokenizer_export str TKNZRgetCardinality   (int *r);

#endif /* _TKNZR_H */

@c
#include "mal_config.h"
#include "bat5.h"
#include "tokenizer.h"
#include "mal_linker.h"

#define MAX_TKNZR_DEPTH 256
#define DEPTH MAX_TKNZR_DEPTH
#define HEIGHT MAX_TKNZR_DEPTH+1
static int tokenDepth = 0;
static BAT *tokenBAT[MAX_TKNZR_DEPTH+2];
static BAT *TRANS = NULL;
static char name[128];

str
TKNZRopen(int *ret, str *in)
{
	int depth, r;
	bat idx;
	str batname = NULL;
	BAT *b;

	(void) ret;

	if (TRANS != NULL) {
		throw(MAL, "tokenizer.open", "another tokenizer is already open");
	}

	for (depth = 0; depth < MAX_TKNZR_DEPTH; depth++) {
		tokenBAT[depth] = 0;
	}
	tokenDepth = 0;

	TRANS = BATnew(TYPE_void, TYPE_str, MAX_TKNZR_DEPTH+2);
	if (TRANS == NULL) {
		throw(MAL, "tokenizer.open", MAL_MALLOC_FAIL);
	}
    BATseqbase(TRANS, 0);

	if (strlen(*in)>127)
		throw(MAL, "tokenizer.deposit",
				ILLEGAL_ARGUMENT " tokenizer name too long");

	snprintf(name, 128, "%s", *in);
	batname = (str) GDKmalloc(128*sizeof(char));
	snprintf(batname, 128, "%s_height", name);
	idx = BBPindex(name);

	if (idx == 0) { /* new tokenizer */

		b = BATnew(TYPE_void, TYPE_oid, 1024);
		if (b == NULL)
			throw(MAL, "tokenizer.open", MAL_MALLOC_FAIL);
		BATkey(b, FALSE);
		BATseqbase(b,0);
		tokenBAT[HEIGHT] = b;
		if (BKCsetName(&r, (int *)&(b->batCacheid), (str *) &batname)
				!= MAL_SUCCEED)
			throw(MAL, "tokenizer.open", OPERATION_FAILED);
		if (BKCsetPersistent(&r,(int *)&(b->batCacheid)) != MAL_SUCCEED)
			throw(MAL, "tokenizer.open", OPERATION_FAILED);
		BBPkeepref(b->batCacheid);
		BUNappend(TRANS, batname, FALSE);

		snprintf(batname, 128, "%s_depth", name);
		b = BATnew(TYPE_void, TYPE_chr, 1024);
		if (b == NULL)
			throw(MAL, "tokenizer.open", MAL_MALLOC_FAIL);
		BATkey(b, FALSE);
		BATseqbase(b,0);
		tokenBAT[DEPTH] = b;
		if (BKCsetName(&r, (int *) &(b->batCacheid), (str *) &batname)
				!= MAL_SUCCEED)
			throw(MAL, "tokenizer.open", OPERATION_FAILED);
		if (BKCsetPersistent(&r, (int *)  &(b->batCacheid)) != MAL_SUCCEED)
			throw(MAL, "tokenizer.open", OPERATION_FAILED);
		BBPkeepref(b->batCacheid);
		BUNappend(TRANS, batname, FALSE);

	} else { /* existing tokenizer */
		tokenBAT[HEIGHT] = BATdescriptor(idx);
		BUNappend(TRANS, batname, FALSE);
		snprintf(batname, 128, "%s_depth", name);
		idx = BBPindex(batname);
		if (idx == 0)
			throw(MAL, "tokenizer.open", RUNTIME_OBJECT_MISSING);
		tokenBAT[DEPTH] = BATdescriptor(idx);
		BUNappend(TRANS, batname, FALSE);

		for (depth = 0; depth < MAX_TKNZR_DEPTH; depth++) {
			snprintf(batname, 128, "%s_%d", name, depth);
			idx = BBPindex(batname);
			if (idx == 0) break;
			tokenBAT[depth] = BATdescriptor(idx);
			BUNappend(TRANS, batname, FALSE);
		}
		tokenDepth = depth;

	}

	GDKfree(batname);
	return MAL_SUCCEED;
}

@= init_check
if (TRANS == NULL) {
	throw(MAL, "tokenizer", "no tokenizer store open");
}

@c
str
TKNZRclose(int *r)
{
	(void) r;

	@:init_check@

	TMsubcommit(TRANS);
	BBPreclaim(TRANS);
	TRANS = NULL;
	tokenDepth = 0;

	return MAL_SUCCEED;
}

@- the actual tokenize code

@c
int
TKNZRtokenize(str url, str *parts, char tkn) {
	char *s, *t;
	int depth = 0;

	s = url;
	while (*s && *s != '\n') {
		t = s;
		while (*t && *t != '\n' && *t != tkn) t++;
		parts[depth++] = s;
		if (*t) {
			*t = 0;
			s = t+1;
		} else {
			s = t;
		}
		if (depth > MAX_TKNZR_DEPTH)
			return depth;
	}
	return depth;
}

str
TKNZRfindOid(oid *pos, char d, oid h) {
	BAT *b, *c;
	BUN p, q;
	BATiter bi;

	b = BATuselect(tokenBAT[HEIGHT], (ptr) &h, NULL);
	c = VIEWcombine(b); BBPunfix(b->batCacheid);
	b = BATfetchjoin(c, tokenBAT[DEPTH], BATcount(c)); BBPunfix(c->batCacheid);

	*pos = BUN_NONE;
	bi = bat_iterator(b);
	BATloop(b, p, q) {
		if (*((char *) BUNtail(bi, p)) == d) {
			*pos = *(oid *) BUNhead(bi, p);
			p = q;
		}
	}

	BBPunfix(b->batCacheid);
	return MAL_SUCCEED;
}

@= insert
	str parts[MAX_TKNZR_DEPTH];
	int i = 0, depth;
	BAT *b;
	BUN p;
	BUN idx = 0;
	oid prv = 0;
	str batname;
	int new, r;

	depth = TKNZRtokenize(tuple, parts, '/');
	new = depth;
	batname = (str) GDKmalloc(128*sizeof(char));

	if (depth == 0) return MAL_SUCCEED;
	if (depth > MAX_TKNZR_DEPTH)
		throw(MAL, "tokenizer",
				ILLEGAL_ARGUMENT " strings breaks to too many parts");
	if (depth > tokenDepth || tokenBAT[0] == NULL) {
		new = tokenDepth;
		for (i = tokenDepth; i < depth; i++){

			/* make new bat */
			snprintf(batname, 128, "%s_%d", name, i);
			b = BATnew(TYPE_oid, TYPE_str, 1024);
			if (b == NULL)
				throw(MAL, "tokenizer.insert", MAL_MALLOC_FAIL);
			BATkey(b, FALSE);
			tokenBAT[i] = b;

			if (BKCsetName(&r, (int *) &(b->batCacheid), (str *) &batname)
					!= MAL_SUCCEED)
				throw(MAL, "tokenizer.open", OPERATION_FAILED);
			if (BKCsetPersistent(&r, (int *)  &(b->batCacheid)) != MAL_SUCCEED)
				throw(MAL, "tokenizer.open", OPERATION_FAILED);
			BBPkeepref(b->batCacheid);
			BUNappend(TRANS, batname, FALSE);
		}
		tokenDepth = depth;
		GDKfree(batname);
	}

@-
Find the common prefix first
@= findcommon
	p = BUNfnd(BATmirror(tokenBAT[0]), parts[0]);
	if (p != BUN_NONE) {
		prv = (oid) p;
		for (i = 1; i < new; i++) {
			BAT *m = BATmirror(tokenBAT[i]);
			BATiter mi = bat_iterator(m);
			int fnd = 0;

			HASHloop_str(mi, m->H->hash, p, parts[i]) {
				if (*((oid *)BUNtail(mi,p)) == prv) {
					prv = (oid) p;
					fnd = 1;
					break;
				}
			}
			if (!fnd) break;
		}
	} else {
		i = 0;
	}

@-
Insert the remainder as a new url string
@= insremainder
	for(; i < depth; i++){
		idx = BATcount(tokenBAT[i]);
		tokenBAT[i] = BUNins(tokenBAT[i], (ptr) &prv, parts[i], FALSE);
		if (tokenBAT[i] == NULL) {
			throw(MAL, "tokenizer.insert",
					OPERATION_FAILED " could not insert");
		}
		if (tokenBAT[i]->T->hash == NULL ||
			BATcount(tokenBAT[i]) > 4 * tokenBAT[i]->T->hash->mask) {
			HASHdestroy(tokenBAT[i]);
			BAThash(BATmirror(tokenBAT[i]), 2*BATcount(tokenBAT[i]));
		}
		prv = (oid) idx;
	}

@c
str
TKNZRinsert(oid *pos, str tuple)
{
	@:insert@
	@:findcommon@

	if (i == depth) {
		TKNZRfindOid(pos, depth, prv);
		if (*pos != BUN_NONE)
			/* the string is already there */
			return MAL_SUCCEED;
	}

	@:insremainder@

	*pos = (oid) BATcount(tokenBAT[HEIGHT]);
	BUNappend(tokenBAT[DEPTH], (ptr) &depth, TRUE);
	BUNappend(tokenBAT[HEIGHT], (ptr) &prv, TRUE);
	if (tokenBAT[HEIGHT]->T->hash == NULL ||
			BATcount(tokenBAT[HEIGHT]) > 4 * tokenBAT[HEIGHT]->T->hash->mask) {
		HASHdestroy(tokenBAT[HEIGHT]);
		BAThash(BATmirror(tokenBAT[HEIGHT]), 2*BATcount(tokenBAT[HEIGHT]));
	}

	return MAL_SUCCEED;
}

#define SIZE 1*1024*1024
str
TKNZRdepositFile(int *r, str *fnme)
{

	stream *fs;
	bstream *bs;
	char *s,*t;
	int len=0;
	char buf[PATHLENGTH];
	oid pos;

	@:init_check@

	(void) r;
	if( **fnme == '/')
		snprintf(buf,PATHLENGTH,"%s", *fnme);
	else
		snprintf(buf,PATHLENGTH,"%s/%s", monet_cwd, *fnme);
	/* later, handle directory separator */
	fs= open_rastream(buf);
	if (fs == NULL)
		throw(MAL, "tokenizer.depositFile", RUNTIME_FILE_NOT_FOUND "%s",buf);
	if (stream_errnr(fs)) {
		close_stream(fs);
		throw(MAL, "tokenizer.depositFile", RUNTIME_FILE_NOT_FOUND "%s",buf);
	}
	bs = bstream_create(fs,SIZE);
	if (bs == NULL)
		throw(MAL, "tokenizer.depositFile", MAL_MALLOC_FAIL);
	while (bstream_read(bs,bs->size-(bs->len-bs->pos)) != 0 &&
		!stream_errnr(bs->s)) {
		s= bs->buf;
		for (t=s; *t;) {
			while (t < bs->buf+bs->len && *t && *t != '\n') t++;
			if (t== bs->buf+bs->len || *t != '\n') {
				/* read next block if possible after shift  */
				assert(t-s <= INT_MAX);
				len = (int) (t-s);
				memcpy(bs->buf, s, len);
				bs->len = len;
				bs->pos = 0;
				break;
			}
			/* found a string to be processed */
			*t = 0;
			TKNZRinsert(&pos, s);
			*t= '\n';
			s= t+1;
			t= s;
		}
	}

	bstream_destroy(bs);
	stream_close(fs);
	stream_destroy(fs);
	return MAL_SUCCEED;
}

@c
str
TKNZRdeposit(oid *pos, str *s)
{
	char tuple[2048];

	@:init_check@

	if (strlen(*s)<2048)
		strcpy(tuple,*s);
	else throw(MAL, "tokenizer.deposit", ILLEGAL_ARGUMENT "string too long");

	TKNZRinsert(pos, tuple);

	return MAL_SUCCEED;
}

str
TKNZRlocate(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{
	oid pos;
	str url;
	str parts[MAX_TKNZR_DEPTH];
	char tuple[2048];
	int i = 0, depth;
	BUN p;
	oid prv = 0;
	(void) cntxt;
	(void) mb;

	@:init_check@

	url = *(str*) getArgReference(stk, pci, 1);
	if (strlen(url)<2048)
		strcpy(tuple,url);
	else throw(MAL, "tokenizer.locate", ILLEGAL_ARGUMENT "string too long");

	depth = TKNZRtokenize(tuple, parts, '/');

	if (depth == 0) {
		pos = oid_nil;
	} else if (depth > MAX_TKNZR_DEPTH) {
		throw(MAL, "tokenizer.locate",
				ILLEGAL_ARGUMENT "strings breaks to too many parts");
	} else if (depth > tokenDepth) {
		pos = oid_nil;
	} else {
		p = BUNfnd(BATmirror(tokenBAT[0]), parts[0]);
		if (p != BUN_NONE) {
			prv = (oid) p;
			for (i = 1; i < depth; i++) {
				p = BUNlocate(tokenBAT[i],(ptr) &prv, parts[i]);
				if (p == BUN_NONE) {
					prv = oid_nil;
					break;
				}
				prv = (oid) p;
			}
			if (prv == oid_nil) 
				pos = oid_nil;
			else 
				TKNZRfindOid(&pos, depth, prv);
		} else {
			pos = oid_nil;
		}
	}

	VALset(getArgReference(stk,pci,0), TYPE_oid, &pos);
	return MAL_SUCCEED;
}


str
TKNZRtake(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{
	(void) stk;
	(void) pci;
	(void) cntxt;
	(void) mb;        /* fool compiler */

	@:init_check@

	return MAL_SUCCEED;
}

str
TKNZRtakeOid(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{
	oid id;
	int depth;
	str parts[MAX_TKNZR_DEPTH];
	int i;
	size_t lngth = 0;
	str ret, s;

	(void) cntxt;
	(void) mb;

	@:init_check@

	id = *(oid*) getArgReference(stk, pci, 1);
	if (id >= BATcount(tokenBAT[DEPTH])) {
		throw(MAL, "tokenizer.takeOid", OPERATION_FAILED " illegal oid");
	}
	depth = *(chr *) Tloc(tokenBAT[DEPTH], id);
	id = *(oid *) Tloc(tokenBAT[HEIGHT], id);

	for (i = depth-1; i >= 0; i--) {
		BATiter bi = bat_iterator(tokenBAT[i]);
		parts[i] = (str) BUNtail(bi, id);
		id = *(oid *) BUNhead(bi, id);
		lngth += strlen(parts[i]);
	}

	ret = (str) GDKmalloc(lngth+depth+1);
	s = ret;
	for (i = 0; i < depth; i++) {
		strcpy(s, parts[i]);
		s += strlen(parts[i]);
		*s++ = '/';
	}
	*s = '\0';

	VALset(getArgReference(stk,pci,0), TYPE_str, ret);
	return MAL_SUCCEED;
}

str
TKNZRgetLevel (int *r, int *level) {

	@:init_check@
	if( *level < 0 || *level >= tokenDepth)
		throw(MAL, "tokenizer.getLevel", OPERATION_FAILED " illegal level");
	*r = tokenBAT[*level]->batCacheid;
	BBPincref(*r, TRUE);
	return MAL_SUCCEED;
}

str
TKNZRgetDepth (int *r) {
	@:init_check@
	*r = tokenBAT[DEPTH]->batCacheid;
	BBPincref(*r, TRUE);
	return MAL_SUCCEED;
}

str
TKNZRgetHeight (int *r) {
	@:init_check@
	*r = tokenBAT[HEIGHT]->batCacheid;
	BBPincref(*r, TRUE);
	return MAL_SUCCEED;
}

str
TKNZRgetCount(int *r) {
	BAT *b;
	int i;
	lng cnt;

	@:init_check@
	b= BATnew(TYPE_int,TYPE_lng, tokenDepth+1);
	if( b== NULL)
		throw(MAL, "tokenizer.getCount", MAL_MALLOC_FAIL);
	for(i=0; i < tokenDepth; i++){
		cnt = (lng) BATcount(tokenBAT[i]);
		BUNins(b,&i, &cnt, FALSE);
	}
	*r = b->batCacheid;
	BBPkeepref(*r);
	return MAL_SUCCEED;
}

str
TKNZRgetCardinality(int *r) {
	BAT *b, *bn;
	int i;
	lng cnt;

	@:init_check@
	b= BATnew(TYPE_int,TYPE_lng, tokenDepth+1);
	if( b== NULL)
		throw(MAL, "tokenizer.getCardinality", MAL_MALLOC_FAIL);
	for(i=0; i<tokenDepth; i++){
		bn = (BAT *) BATkunique(BATmirror(tokenBAT[i]));
		cnt = (lng) BATcount(bn);
		BBPunfix(bn->batCacheid);
		BUNins(b,&i, &cnt, FALSE);
	}
	*r = b->batCacheid;
	BBPkeepref(*r);
	return MAL_SUCCEED;
}

@}
