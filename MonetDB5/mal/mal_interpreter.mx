@/
The contents of this file are subject to the MonetDB Public License
Version 1.1 (the "License"); you may not use this file except in
compliance with the License. You may obtain a copy of the License at
http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html

Software distributed under the License is distributed on an "AS IS"
basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
License for the specific language governing rights and limitations
under the License.

The Original Code is the MonetDB Database System.

The Initial Developer of the Original Code is CWI.
Portions created by CWI are Copyright (C) 1997-July 2008 CWI.
Copyright August 2008-2011 MonetDB B.V.
All Rights Reserved.
@

@a M. Kersten
@v 0.0
@* The MAL Interpreter
The MAL interpreter always works in the context of a single user session,
which provides for storage access to global variables and modules.
@menu
* MAL API::
* Exception Handling::
* Garbage Collection::
* Stack Management::
@end menu

@{
@h
#ifndef _MAL_INTERPRET_H
#define _MAL_INTERPRET_H

#include "mal_client.h"
#include "mal_factory.h"
#include "mal_profiler.h"

@-
Activation of a thread requires construction of the argument list
to be passed by a handle.
@h

/*#define DEBUG_MAL_INTERPRETER*/
/* #define DEBUG_FLOW */
/* #define DEBUG_FLOW2 */
/* #define STACKTRACE*/
/* #define DEBUG_GC*/
/* #define DEBUG_MEMORY_CLAIM*/

mal_export void showErrors(Client cntxt);
mal_export MalStkPtr prepareMALstack(MalBlkPtr mb, int size);
mal_export str runMAL(Client c, MalBlkPtr mb, int startpc, MalBlkPtr mbcaller, MalStkPtr env, InstrPtr pcicaller);
mal_export str runMALdataflow(Client cntxt, MalBlkPtr mb, int startpc, int stoppc, MalStkPtr stk, MalStkPtr env, InstrPtr pcicaller);
mal_export str reenterMAL(Client cntxt, MalBlkPtr mb, int startpc, int stoppc, MalStkPtr stk, MalStkPtr env, InstrPtr pcicaller);
mal_export str callMAL(Client cntxt, MalBlkPtr mb, MalStkPtr *glb, ValPtr argv[], char debug);
mal_export void garbageElement(Client cntxt, ValPtr v);
mal_export void garbageCollector(Client cntxt, MalBlkPtr mb, MalStkPtr stk, int flag);
mal_export void releaseBAT(MalBlkPtr mb, MalStkPtr stk, int bid);
mal_export lng getVolume(MalStkPtr stk, InstrPtr pci, int rd);

mal_export ptr getArgReference(MalStkPtr stk, InstrPtr pci, int k);

@c
#include "monetdb_config.h"
#include "mal_interpreter.h"
#include "mal_debugger.h"   /* for mdbStep() */
#include "mal_recycle.h"
#include "mal_type.h"

#define SLOW 1
#define FAST 0

static str runMALsequence(Client cntxt, MalBlkPtr mb, int startpc, int stoppc, MalStkPtr stk, MalStkPtr env, InstrPtr pcicaller);
static void displayVolume(Client cntxt, lng vol);

#define MEMORY_THRESHOLD  0.8

#ifdef USE_DFLOW_ADMISSION
static lng memorypool;      /* memory claimed by concurrent threads */
static int memoryclaims = 0;    /* number of threads active with expensive operations */
#endif

#define heapinfo(X) if((X) && (X)->base) vol = (X)->free; else vol = 0;
#define hashinfo(X) if((X) && (X)->mask) vol = ((X)->mask+(X)->lim+1)*sizeof(int) + sizeof(*(X)); else vol = 0;

#define FREE_EXCEPTION(p) { if (p && p != M5OutOfMemory) GDKfree(p); }

@-
The struct alignment leads to 40% gain in simple instructions when set.
@c
inline
ptr getArgReference(MalStkPtr stk, InstrPtr pci, int k)
{
#ifdef STRUCT_ALIGNED
	return (ptr) & stk->stk[pci->argv[k]].val.ival;
#else
	int j = 0;
	ValRecord *v = 0;
	ptr ret = NULL;

	j = pci->argv[k];
	v = &stk->stk[j];

	switch (ATOMstorage(v->vtype)) {
	case TYPE_void: ret = (ptr) & v->val.ival; break;
	case TYPE_bit: ret = (ptr) & v->val.cval[0]; break;
	case TYPE_chr: ret = (ptr) & v->val.cval[0]; break;
	case TYPE_sht: ret = (ptr) & v->val.shval; break;
	case TYPE_bat: ret = (ptr) & v->val.bval; break;
	case TYPE_int: ret = (ptr) & v->val.ival; break;
	case TYPE_wrd: ret = (ptr) & v->val.wval; break;
	case TYPE_bte: ret = (ptr) & v->val.btval; break;
	case TYPE_oid: ret = (ptr) & v->val.oval; break;
	case TYPE_ptr: ret = (ptr) & v->val.pval; break;
	case TYPE_flt: ret = (ptr) & v->val.fval; break;
	case TYPE_dbl: ret = (ptr) & v->val.dval; break;
	case TYPE_lng: ret = (ptr) & v->val.lval; break;
	case TYPE_str: ret = (ptr) & v->val.sval; break;
	default:
		ret = (ptr) & v->val.pval;
	}
	return ret;
#endif
}

/* code is obsolete, because all should be handled as exceptions */
void showErrors(Client cntxt)
{
	int i;
	if (cntxt->errbuf && *cntxt->errbuf) {
		i = (int)strlen(cntxt->errbuf);
		mnstr_printf(cntxt->fdout, "%s", cntxt->errbuf);
		if (cntxt->errbuf[i - 1] != '\n')
			mnstr_printf(cntxt->fdout, "\n");
		cntxt->errbuf[0] = '\0';
	}
}
@-
The bigfoot memory tracker keeps track on the space occupancy of BATs.
The property 'memory' illustrates the total amount of memory claimed.
It ignores for the time being the heaps for the variable sized atoms.
Moreover, it is not thread safe and it can not correctly handle
aliases embedded in MAL assignments.
This means that the footprint is only to be used as indicative.
@c
static inline void
updateBigFoot(Client cntxt, int bid, int add)
{
	BAT *b;
	lng total = 0, vol = 0;

	if (bid != bat_nil) {
		BUN cnt = 0;
		b = BBPquickdesc(ABS(bid), TRUE);
		if (b == NULL)
			return;
		if (isVIEW(b))
			return;
		/* count it once ! */
		cntxt->cnt = cnt = BATcount(b);
		@:calcFootprint@
		if (b->H->hash)
			total += cnt * sizeof(int);
		if (b->T->hash)
			total += cnt * sizeof(int);

		if (add) {
			cntxt->vmfoot += total;
			cntxt->memory += total;
		} else
			cntxt->vmfoot -= total;
		/* correct for limitations by resetting */
		if (cntxt->vmfoot < 0)
			cntxt->vmfoot = 0;
		if (cntxt->vmfoot > cntxt->bigfoot)
			cntxt->bigfoot = cntxt->vmfoot;
	}
}
@-
Copy the constant values onto the stack frame
Also we cannot overwrite values on the stack as this maybe part of a
sequence of factory calls.
BEWARE WE ASSUME THAT FIRST VARIABLES ON THE STACK ALIGN WITH THE SIGNATURE.
@= initStack
	for (i = @1; i < mb->vtop; i++) {
		lhs = &stk->stk[i];
		if (isVarConstant(mb, i) > 0) {
			if (!isVarDisabled(mb, i)) {
				rhs = &getVarConstant(mb, i);
				VALcopy(lhs, rhs);
			}
		} else{
			lhs->vtype = getVarGDKType(mb, i);
			lhs->val.pval = 0;
			lhs->len = 0;
		}
	}
@c
static int
isNotUsedIn(InstrPtr p, int start, int a)
{
	int k;
	for (k = start; k < p->argc; k++)
		if (getArg(p, k) == a)
			return 0;
	return 1;
}

MalStkPtr
prepareMALstack(MalBlkPtr mb, int size)
{
	MalStkPtr stk = NULL;
	int i;
	ValPtr lhs, rhs;

	assert(size >= mb->vsize);
	stk = newGlobalStack(size);
	memset((char *)stk, 0, stackSize(size));
	stk->stktop = mb->vtop;
	stk->stksize = size;
	stk->blk = mb;

	@:initStack(1)@
	return stk;
}

str runMAL(Client cntxt, MalBlkPtr mb, int startpc, MalBlkPtr mbcaller,
		   MalStkPtr env, InstrPtr pcicaller)
{
	MalStkPtr stk = NULL;
	int i;
	ValPtr lhs, rhs;
	InstrPtr pci = getInstrPtr(mb, 0);
	str ret;
	@:performanceVariables@

	if (mb->errors) {
		showErrors(cntxt);
		if (cntxt->itrace == 0) /* permit debugger analysis */
			return createScriptException(mb, 0, MAL, NULL, "Syntax error in script");
	}
@-
Prepare a new interpreter call. This involves two steps, (1) allocate
the minimum amount of stack space needed, some slack resources
are included to permit code optimizers to add a few variables at run time,
(2) copying the arguments into the new stack frame.
Notice that arguments are always the first entries on the stack.

The env stackframe is set when a MAL function is called recursively.
Alternatively, there is no caller but a stk to be re-used for interpretation.
We assume here that it aligns with the variable table of the routine
being called.
@c
	/* allocate space for value stack */
	/* the global stack should be large enough */
	if (mbcaller == NULL && env != NULL) {
		stk = env;
		if (mb != stk->blk)
			showScriptException(mb, 0, MAL, "runMAL:misalignment of symbols\n");
		if (mb->vtop > stk->stksize)
			showScriptException(mb, 0, MAL, "stack too small\n");
		pci = pcicaller;
	} else {
		newStack(stk, mb->vsize);
		stk->stktop = mb->vtop;
		stk->stksize = mb->vsize;
		stk->blk = mb;
		stk->cmd = cntxt->itrace;    /* set debug mode */
		if (env) {
			/*safeguardStack*/
			stk->stkdepth = stk->stksize + env->stkdepth;
			stk->calldepth = env->calldepth + 1;
			if (stk->calldepth > 256)
				throw(MAL, "mal.interpreter", MAL_CALLDEPTH_FAIL);
			if ((unsigned)stk->stkdepth > THREAD_STACK_SIZE / sizeof(mb->var[0]) / 4 && THRhighwater())
				/* we are running low on stack space */
				throw(MAL, "mal.interpreter", MAL_STACK_FAIL);
		}
	}

	if (env && mbcaller) {
		InstrPtr pp;
		int k;
@-
Beware, a function signature f(a1..an):(b1..bn) is parsed in such a way that
the symbol table and stackframe contains the sequence
f,a1..an,b1..bn. This slightly complicates the implementation
of the return statement.
@c
		pci = pcicaller;
		pp = getInstrPtr(mb, 0);
		/* set return types */
		for (i = 0; i < pci->retc; i++) {
			lhs = &stk->stk[i];
			lhs->vtype = getVarGDKType(mb, i);
		}
		for (k = pp->retc; i < pci->argc; i++, k++) {
			lhs = &stk->stk[pp->argv[k]];
			/* variable arguments ? */
			if (k == pp->argc - 1) k--;

			rhs = &env->stk[pci->argv[i]];
			VALcopy(lhs, rhs);
			if (lhs->vtype == TYPE_bat)
				BBPincref(lhs->val.bval, TRUE);
		}
		stk->up = env;
	}
@-
An optimization is to copy all constant variables used in functions immediately
onto the value stack. Then we do not have to check for their location
later on any more. At some point, the effect is optimal, if at least several
constants are referenced in a function (a gain on tst400a of 20% has been
observed due the small size of the function).

Moreover, we have to copy the result types to the stack for later
use. The stack value is cleared to avoid misinterpretation of left-over
information. Since a stack frame may contain values of a previous call,
we should first remove garbage.
@c
	if (env && mbcaller) {
		@:initStack(pci->argc)@
	} else if (env && env->stkbot) {
		@:initStack(env->stkbot)@
	} else {
		@:initStack(mbcaller ? pci->argc:1)@
	}

	if (stk->cmd && env && stk->cmd != 'f')
		stk->cmd = env->cmd;
	ret = runMALsequence(cntxt, mb, startpc, 0, stk, env, pcicaller);

	/* pass the new debug mode to the caller */
	if (stk->cmd && env && stk->cmd != 'f')
		env->cmd = stk->cmd;
	if (!stk->keepAlive && garbageControl(getInstrPtr(mb, 0)))
		garbageCollector(cntxt, mb, stk, env != stk);
	@:endProfile(stk) @
	if (stk && stk != env)
		GDKfree(stk);
	return ret;
}
@-

@+ Single instruction
It is possible to re-enter the interpreter at a specific place.
This is used in the area where we need to support co-routines.

A special case for MAL interpretation is to execute just one instruction.
This is typically used by optimizers and schedulers that need part of the
answer to direct their actions. Or, a dataflow scheduler could step in
to enforce a completely different execution order.
@c
str reenterMAL(Client cntxt, MalBlkPtr mb, int startpc, int stoppc,
			   MalStkPtr stk, MalStkPtr env, InstrPtr pcicaller)
{
	str ret;
	int keepAlive;

	if (stk == NULL)
		throw(MAL, "mal.interpreter", MAL_STACK_FAIL);
	keepAlive = stk->keepAlive;
	if (env && stk && stk->cmd != 'f') stk->cmd = env->cmd;

	ret = runMALsequence(cntxt, mb, startpc, stoppc, stk, env, pcicaller);

	/* pass the new debug mode to the caller */
	if (env && stk->cmd != 'f') env->cmd = stk->cmd;
	if (keepAlive == 0 && garbageControl(getInstrPtr(mb, 0)))
		garbageCollector(cntxt, mb, stk, env != stk);
	return ret;
}
@-
Front ends may benefit from a more direct call to any of the MAL
procedural abstractions. The argument list points to the arguments
for the block to be executed. An old stack frame may be re-used,
but it is then up to the caller to ensure it is properly
initialized.
The call does not return values, they are ignored.
@c
str
callMAL(Client cntxt, MalBlkPtr mb, MalStkPtr *env, ValPtr argv[], char debug)
{
	MalStkPtr stk = NULL;
	str ret = MAL_SUCCEED;
	int i;
	ValPtr lhs, rhs;
	InstrPtr pci = getInstrPtr(mb, 0);
	@:performanceVariables@

#ifdef DEBUG_CALLMAL
	mnstr_printf(cntxt->fdout, "callMAL\n");
	printInstruction(cntxt->fdout, mb, 0, pci, LIST_MAL_ALL);
#endif
	switch (pci->token) {
	case FUNCTIONsymbol:
	case FCNcall:
@-
Prepare the stack frame for this operation. Copy all the arguments
in place. We assume that the caller has supplied pointers for
all arguments and return values.
@c
		if (*env == NULL) {
			stk = newGlobalStack(mb->vsize);
			memset((char *)stk, 0, stackSize(mb->vtop));
			stk->stktop = mb->vtop;
			stk->stksize = mb->vsize;
			stk->blk = mb;
			stk->up = 0;
			@:initStack(pci->argc)@
			*env = stk;
		} else stk = *env;
		assert(stk);
		for (i = pci->retc; i < pci->argc; i++) {
			lhs = &stk->stk[pci->argv[i]];
			VALcopy(lhs, argv[i]);
			if (lhs->vtype == TYPE_bat)
				BBPincref(lhs->val.bval, TRUE);
		}
		stk->cmd = debug;
		ret = runMALsequence(cntxt, mb, 1, 0, stk, 0, 0);
		break;
	case FACTORYsymbol:
	case FACcall:
		ret = callFactory(cntxt, mb, argv, debug);
		break;
	case PATcall:
	case CMDcall:
	default:
		throw(MAL, "mal.interpreter", RUNTIME_UNKNOWN_INSTRUCTION);
	}
	@:endProfile(stk)@
	return ret;
}
@-
The core of the interpreter is presented next. It takes the context information
and starts the interpretation at the designated instruction.
Note that the stack frame is aligned and initialized in the enclosing routine.
@c
str runMALsequence(Client cntxt, MalBlkPtr mb, int startpc,
				   int stoppc, MalStkPtr stk, MalStkPtr env, InstrPtr pcicaller)
{
	ValPtr lhs, rhs, v;
	int i, k;
	InstrPtr pci = 0;
	int exceptionVar, prevpc = 0;
	str ret = 0;
#if FAST
	int stamp = -1;
#endif
	bat *backup = (bat*)alloca(mb->maxarg * sizeof(bat));
	str *sbackup = (str*)alloca(mb->maxarg * sizeof(str));
	int *garbage = (int*)alloca(mb->maxarg * sizeof(int));
	lng oldtimer = 0;
	struct Mallinfo oldMemory;
	int stkpc = 0;
	MT_Lock *lock = NULL;
	int tid = 0;

#ifdef HAVE_SYS_RESOURCE_H
	int oldinblock = 0;
	int oldoublock = 0;
	struct rusage oldResource;
#endif
	@:performanceVariables@

	if (stk == NULL)
		throw(MAL, "mal.interpreter", MAL_STACK_FAIL);
	if (cntxt->flags & timerFlag)
		oldtimer = cntxt->timer = GDKusec();
	oldMemory.arena = 0;

	stkpc = startpc;
	exceptionVar = -1;
@-
From this point onwards we should differentiate fast processing
against monitored processing. Fast processing is possible if there is
no call to the debugger statically/dynamically set. Same holds for
performance control statements.
The code currently does not statically checks the mode change.
Preferrably we should introduce a itrace flag PROFILE
We rely on optimizing compilers to remove the redundant code.
@c
	if (mb->recycle == TRUE && malProfileMode == 0 &&
		cntxt->itrace == 0 && cntxt->flags == 0 && GDKdebug == 0) {
		while (stkpc < mb->stop && stkpc != stoppc) {
			pci = getInstrPtr(mb, stkpc);
			if (malProfileMode + cntxt->itrace)
				goto workslow;

				@:MALrecycleStart(stk)@ {
				@:MALinterpret(FAST)@
			}
			@:MALflowofcontrol(FAST,continue)@
		}
	} else if (malProfileMode == 0 && cntxt->itrace == 0 && cntxt->flags == 0 && GDKdebug == 0) {
		while (stkpc < mb->stop && stkpc != stoppc) {
			pci = getInstrPtr(mb, stkpc);
			if (malProfileMode + cntxt->itrace + mb->trap)
				goto workslow;

			@:MALinterpret(FAST)@
			@:MALflowofcontrol(FAST,continue)@
		}
	} else {
		while (stkpc < mb->stop && stkpc != stoppc) {
			pci = getInstrPtr(mb, stkpc);
workslow:
			if (cntxt->itrace || mb->trap) {
				lng t = 0;

				if (stk->cmd == 0)
					stk->cmd = cntxt->itrace;
				if (oldtimer)
					t = GDKusec();
				if (cntxt->flags & bbpFlag)
					BBPTraceCall(cntxt, mb, stk, prevpc);
				prevpc = stkpc;
				mdbStep(cntxt, mb, stk, stkpc);
				if (stk->cmd == 'x' || cntxt->mode == FINISHING) {
					stk->cmd = 0;
					stkpc = mb->stop;
					continue;
				}
				if (oldtimer) {
					/* ignore debugger waiting time*/
					t = GDKusec() - t;
					oldtimer += t;
#ifdef HAVE_SYS_RESOURCE_H
					getrusage(RUSAGE_SELF, &oldResource);
#endif
					if (cntxt->flags & memoryFlag)
						oldMemory = MT_mallinfo();
				}
			}

			@:beginProfile(stk,1)@
			@:MALrecycleStart(stk)@ {
				@:MALinterpret(FAST)@
			}
			@:MALflowofcontrol(FAST,continue)@
			@:endProfile(stk)@
		}
	}
	@:MALwrapup@
	return ret;
}
@- Out of order execution
The alternative is to execute the instructions out of order
using dataflow dependencies and as an independent process.
Dataflow processing only works on a code
sequence that does not include additional (implicit) flow of control
statements and, ideally, consist of expensive BAT operations.
The dataflow interpreter selects cheap instructions
using a simple costfunction based on the size of the BATs involved.

The dataflow portion is identified as a guarded block,
whose entry is controlled by the function language.dataflow();
This way the function can inform the caller to skip the block
when dataflow execution was performed.
@h
mal_export str runMALdataflow(Client cntxt, MalBlkPtr mb, int startpc, int stoppc, MalStkPtr stk, MalStkPtr env, InstrPtr pcicaller);
@-
The flow graphs should be organized such that parallel threads can
access it mostly without expensive locking.
@c
#define DFLOWpending 0		/* runnable */
#define DFLOWrunning 1		/* currently in progress */
#define DFLOWwrapup  2		/* done! */
#define DFLOWretry   3		/* reschedule */

typedef struct queue {
	int size;	/* size of queue */
	int last;	/* last element in the queue */
	void **data;
	MT_Lock l;	/* its a shared resource, ie we need locks */
	MT_Sema s;	/* threads wait on empty queues */
} queue;


@-
The dataflow dependency is administered in a graph list structure. 
For each instruction we keep the list of instructions that
should be checked for eligibility once we are finished with it.
@c 
typedef struct {
	MT_Id tid;
	int id;
	queue *todo;		/* pending actions for this client */
	lng clk;
	struct DataFlow *flow;
} FlowTask;

typedef struct FLOWSTATUS {
	Client cntxt;		/* for debugging and client resolution */
	MalBlkPtr mb;		/* carry the context */
	MalStkPtr stk;
	int pc;			/* pc in underlying malblock */
	int blocks; 	/* awaiting for variables */
	sht state;		/* of execution */
	sht cost;
	lng hotclaim;	/* memory foot print of result variables */
	lng argclaim;	/* memory foot print of arguments */
	str error;
} *FlowStatus, FlowStatusRec;

typedef struct DataFlow {
	int start, stop;	/* guarded block under consideration*/
	FlowStatus status;		/* status of each instruction */
	int *nodes;			/* dependency graph nodes */
	int *edges;			/* dependency graph */
	queue *done;		/* work finished */
	queue *todo;		/* pending actions for this client */
	int    nway;		/* number of workers */
	FlowTask *worker;	/* worker threads for the client */
	struct DataFlow *free;	/* free list */
} *DataFlow, DataFlowRec;

@-
Calculate the size of the dataflow dependency graph.
@c
static int
DFLOWgraphSize(MalBlkPtr mb, int start, int stop)
{
	int cnt = 0;
	int i;

	for (i = start; i < stop; i++)
		cnt += getInstrPtr(mb, i)->argc;
	return cnt;
}

@-
Running all eligible instructions in parallel creates
resource contention. This means we should implement
an admission control scheme where threads are temporarily
postponed if the claim for memory exceeds a threshold
In general such contentions will be hard to predict,
because they depend on the algorithm, the input sizes,
concurrent use of the same variables, and the output produced.

The heuristic is based on calculating the storage footprint
of the operands and assuming it preferrably should fit in memory.
Ofcourse, there may be intermediate structures being
used and the size of the result is not a priori known.
For this, we use a high watermark on the amount of
physical memory we pre-allocate for the claims.

Instructions are eligible to be executed when the
total footprint of all concurrent executions stays below
the high-watermark or it is the single expensive
instruction being started.

When we run out of memory, the instruction is delayed.
How long depends on the other instructions to free up
resources. The current policy simple takes a local
decision by delaying the instruction based on its
past and the size of the memory pool size.
The waiting penalty decreases with each step to ensure
it will ultimately taken into execution, with possibly
all resource contention effects.

Another option would be to maintain a priority queue of
suspended instructions.
@= calcFootprint
	heapinfo(&b->H->heap); total += vol;
	heapinfo(b->H->vheap); total += vol;
	hashinfo(b->H->hash); total += vol;

	heapinfo(&b->T->heap); total += vol;
	heapinfo(b->T->vheap); total += vol;
	hashinfo(b->T->hash); total += vol;
@c
/*
 * The memory claim is the estimate for the amount of memory hold.
 * Views are consider cheap and ignored
*/
static lng
getMemoryClaim(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci, int i, int flag)
{
	lng total = 0, vol = 0;
	BAT *b;

	(void)mb;
	if (stk->stk[getArg(pci, i)].vtype == TYPE_bat) {
		b = BATdescriptor(stk->stk[getArg(pci, i)].val.bval);
		if (b == NULL)
			return 0;
		if (flag && isVIEW(b)) {
			BBPunfix(b->batCacheid);
			return 0;
		}
		@:calcFootprint@
		total = total > (lng)(MEMORY_THRESHOLD * monet_memory) ? (lng)(MEMORY_THRESHOLD * monet_memory) : total;
		BBPunfix(b->batCacheid);
	}
	return total;
}

/*
 * The hotclaim indicates the amount of data recentely written.
 * as a result of an operation. The argclaim is the sum over the hotclaims
 * for all arguments.
 * The argclaim provides a hint on how much we actually may need to execute
 * The hotclaim is a hint how large the result would be.
 */
#ifdef USE_DFLOW_ADMISSION
/* experiments on sf-100 on small machine showed no real improvement
   Q10 became even 3x slower.
*/
int
DFLOWadmission(lng argclaim, lng hotclaim)
{
	/* optimistically set memory */
	if (argclaim == 0)
		return 0;

	mal_set_lock(mal_contextLock, "DFLOWdelay");
	if (memorypool <= 0 && memoryclaims == 0)
		memorypool = (lng)(MEMORY_THRESHOLD * monet_memory);

	if (argclaim > 0) {
		if (memoryclaims == 0 || memorypool > argclaim + hotclaim) {
			memorypool -= (argclaim + hotclaim);
			memoryclaims++;
			PARDEBUG
			mnstr_printf(GDKstdout, "#DFLOWadmit %3d thread %d pool " LLFMT "claims " LLFMT "," LLFMT "\n",
						 memoryclaims, THRgettid(), memorypool, argclaim, hotclaim);
			mal_unset_lock(mal_contextLock, "DFLOWdelay");
			return 0;
		}
		PARDEBUG
		mnstr_printf(GDKstdout, "#Delayed due to lack of memory " LLFMT " requested " LLFMT "\n", memorypool, argclaim + hotclaim);
		mal_unset_lock(mal_contextLock, "DFLOWdelay");
		return -1;
	}
	/* release memory claimed before */
	memorypool += -argclaim - hotclaim;
	memoryclaims--;
	PARDEBUG
	mnstr_printf(GDKstdout, "#DFLOWadmit %3d thread %d pool " LLFMT " claims " LLFMT "," LLFMT "\n",
				 memoryclaims, THRgettid(), memorypool, argclaim, hotclaim);
	assert(memoryclaims >= 0);
	mal_unset_lock(mal_contextLock, "DFLOWdelay");
	return 0;
}
#endif

@-
The dataflow execution is confined to a barrier block.
Within the block there are multiple flows, which, in principle,
can be executed in parallel.
@c

static queue*
q_create(int sz)
{
	queue *q = (queue*)GDKmalloc(sizeof(queue));

	if (q == NULL)
		return NULL;
	q->size = ((sz << 1) >> 1); /* we want a multiple of 2 */
	q->last = 0;
	q->data = (void*)GDKmalloc(sizeof(void*) * q->size);
	if (q->data == NULL) {
		GDKfree(q);
		return NULL;
	}

	MT_lock_init(&q->l, "q_create");
	MT_sema_init(&q->s, 0, "q_create");
	return q;
}

/*
static void
q_destroy(queue *q)
{
	GDKfree(q->data);
	GDKfree(q);
}
*/

/* keep a simple LIFO queue. It won't be a large one, so shuffles of requeue is possible */
/* we might actually sort it for better scheduling behavior */
static void
q_enqueue_(queue *q, FlowStatus d)
{
	if (q->last == q->size) {
		/* enlarge buffer */
		q->size <<= 1;
		q->data = GDKrealloc(q->data, sizeof(void*) * q->size);
	}
	q->data[q->last++] = (void*)d;
}
static void
q_enqueue(queue *q, FlowStatus d)
{
	MT_lock_set(&q->l, "q_enqueue");
	q_enqueue_(q, d);
	MT_lock_unset(&q->l, "q_enqueue");
	MT_sema_up(&q->s, "q_enqueue");
}

/*
 * A priority queue over the hot claims of memory may
 * be more effective. It priorizes those instructions
 * that want to use a big recent result
 */

static void
q_requeue_(queue *q, void *d)
{
	int i;
	if (q->last == q->size) {
		/* enlarge buffer */
		q->size <<= 1;
		q->data = GDKrealloc(q->data, sizeof(void*) * q->size);
	}
	for (i = q->last; i > 0; i--)
		q->data[i] = q->data[i - 1];
	q->data[0] = (void*)d;
	q->last++;
}
static void
q_requeue(queue *q, void *d)
{
	MT_lock_set(&q->l, "q_requeue");
	q_requeue_(q, d);
	MT_lock_unset(&q->l, "q_requeue");
	MT_sema_up(&q->s, "q_requeue");
}

static void *
q_dequeue(queue *q)
{
	void *r = NULL;

	MT_sema_down(&q->s, "q_dequeue");
	MT_lock_set(&q->l, "q_dequeue");
	assert(q->last > 0);
	/* LIFO favors garbage collection */
	r = q->data[--q->last];
	/* try out random draw *
	{
		int i;
		i = rand() % q->last;
		r = q->data[i];
		for (i++; i < q->last; i++)
			q->data[i - 1] = q->data[i];
		q->last--; i
	}
	 */

	MT_lock_unset(&q->l, "q_dequeue");
	return r;
}

/* it makes sense to give priority to those
 * instructions that carry a lot of temporary arguments
 * It will reduce the footprint of the database.
 */
static void
queue_sort(queue *q)
{
	int i, j;
	void *f;

	for (i = 0; i < q->last; i++)
		for (j = i + 1; j < q->last; j++)
			if (((FlowStatus)q->data[i])->argclaim > ((FlowStatus)q->data[j])->argclaim) {
				f = q->data[i];
				q->data[i] = q->data[j];
				q->data[j] = f;
			}
	/* decay, because it is likely flushed */
	for (i = 0; i < q->last; i++)
		((FlowStatus)q->data[i])->argclaim /= 2;
}

@-
We simply move an instruction into the front of the queue.
Beware, we assume that variables are assigned a value once, otherwise
the order may really create errors.
The order of the instructions should be retained as long as possible.
@-
Delay processing when we run out of memory.  Push the instruction back
on the end of queue, waiting for another attempt. Problem might become
that all threads but one are cycling through the queue, each time
finding an eligible instruction, but without enough space.
Therefore, we wait for a few milliseconds as an initial punishment.

The process could be refined by checking for cheap operations,
i.e. those that would require no memory at all (aggr.count)
This, however, would lead to a dependency to the upper layers,
because in the kernel we don't know what routines are available
with this property. Nor do we maintain such properties.
@c
static str
DFLOWstep(FlowTask *t, FlowStatus fs)
{
	DataFlow flow = t->flow;
	int stkpc = fs->pc;

	ValPtr lhs, rhs, v;
	int i, k;
	int exceptionVar = -1;
	str ret = MAL_SUCCEED;
#if FAST
	int stamp = -1;
#endif
	bat *backup = (bat*)alloca(fs->mb->maxarg * sizeof(bat));
	str *sbackup = (str*)alloca(fs->mb->maxarg * sizeof(str));
	int *garbage = (int*)alloca(fs->mb->maxarg * sizeof(int));
	Client cntxt = fs->cntxt;
	MalBlkPtr mb = fs->mb;
	MalStkPtr stk = fs->stk;
	int startpc = fs->pc;
	InstrPtr pci;
	lng oldtimer = 0;
	struct Mallinfo oldMemory;
	MT_Lock *lock = &flow->done->l;
	int tid = t->id, prevpc = 0;

#ifdef HAVE_SYS_RESOURCE_H
	int oldinblock = 0;
	int oldoublock = 0;
	struct rusage oldResource;
#endif
	@:performanceVariables@

	if (cntxt->flags & memoryFlag)
		oldMemory = MT_mallinfo();
	else
		oldMemory.arena = 0;
	if (stk == NULL || stkpc < 0)
		throw(MAL, "mal.interpreter", MAL_STACK_FAIL);

	pci = getInstrPtr(fs->mb, stkpc);
#ifdef DEBUG_FLOW
	printf("#EXECUTE THREAD %d \n", tid);
	printInstruction(GDKstdout, flow->mb, 0, pci, LIST_MAL_STMT | LIST_MAPI);
#endif
	THRset_errbuf(THRget(THRgettid()), cntxt->errbuf);  /* where to leave errors */
	if (stk->cmd || mb->trap) {
		lng tm = 0;
		if (oldtimer)
			tm = GDKusec();
		if (cntxt->flags & bbpFlag)
			BBPTraceCall(cntxt, mb, stk, prevpc);
		prevpc = stkpc;
		mdbStep(cntxt, mb, stk, getPC(mb, pci));
		if (stk->cmd == 'x' || cntxt->mode == FINISHING) {
			/* need a way to skip */
			stkpc = mb->stop;
			fs->state = -1;
			return ret;
		}
		if (oldtimer) {
			/* ignore debugger waiting time*/
			tm = GDKusec() - tm;
			oldtimer += tm;
#ifdef HAVE_SYS_RESOURCE_H
			getrusage(RUSAGE_SELF, &oldResource);
#endif
			if (cntxt->flags & memoryFlag)
				oldMemory = MT_mallinfo();
		}
	}

	@:beginProfile(t,0)@
	ret = MAL_SUCCEED;
	@:MALrecycleStart(t)@ {
		@:beginProfile(t,1)@
@-
The number of instructions allowed is severely limited.
We don't allow sequential flow control here, which is enforced by the dataflow optimizer;
@c
		switch (pci->token) {
		case ASSIGNsymbol: 
			@:assignStmt(FAST,fs->pc = -fs->pc; return ret,t)@ 
			break;
		case PATcall: 
			@:patterncall(FAST,fs->pc = -fs->pc; return ret,t)@ 
			break;
		case CMDcall: 
			@:commandcall(FAST,fs->pc = -fs->pc; return ret,t)@ 
			break;
		case FACcall: 
			@:factorycall(FAST,fs->pc = -fs->pc; return ret,t)@ 
			break;
		case FCNcall: 
			@:functioncall(FAST,fs->pc = -fs->pc; return ret,t)@ 
			break;
		case NOOPsymbol:
		case REMsymbol:
			break;
		default:
			if (pci->token < 0) {
				/* temporary NOOP instruction */
				break;
			}
			ret = createScriptException(mb, stkpc, MAL,
				NULL, "unkown operation");
		}
	}
	@:endProfile(t)@
	if (ret)
		fs->pc = -fs->pc;
	return ret;
}

@-
A consequence of multiple threads is that they may claim more
space then available. This may cause GDKmalloc to fail.
In many cases this situation will be temporary, because
threads will ultimately release resources.
Therefore, we wait for it.

Alternatively, a front-end can set the flow administration
program counter to -1, which leads to a soft abort.
[UNFORTUNATELY this approach does not (yet) work
because there seem to a possibility of a deadlock
between incref and bbptrim. Furthermore, we have
to be assured that the partial executed instruction
does not lead to ref-count errors.]

The worker produces a result which will potentially unblock
instructions. This it can find itself without the help of the scheduler
and without the need for a lock. (does it?, parallel workers?)
It could also give preference to an instruction that eats away the object
just produced. THis way it need not be saved on disk for a long time.
@c
static void
runDFLOWworker(void *t)
{
	FlowStatus fs, nxtfs = 0;
	FlowTask *task = (FlowTask*)t;
	InstrPtr p;
	Thread thr;
	int i, local = 0, last = 0;

	thr = THRnew(MT_getpid(), "DFLOWworker");
	while (task) {
		local = nxtfs != 0;
		if (nxtfs == 0)
			fs = (FlowStatus)q_dequeue(task->todo);
		else 
			fs = nxtfs;
#ifdef USE_DFLOW_ADMISSION
		if (DFLOWadmission(fs->argclaim, fs->hotclaim)) {
			fs->hotclaim = 0;   /* don't assume priority anymore */
			MT_sleep_ms(fs->argclaim / 1000000);
			q_requeue(task->todo, fs);
			nxtfs = 0;
			continue;
		}
#endif
		assert(fs->pc > 0);
		PARDEBUG mnstr_printf(GDKstdout, "#execute pc= %d thr= %d claim= %d,%d %s\n", fs->pc, task->id, fs->argclaim, fs->hotclaim, fs->error ? fs->error : "");
		fs->error = DFLOWstep(task, fs);

		PARDEBUG mnstr_printf(GDKstdout, "#execute pc= %d thr= %d finished %s\n", fs->pc, task->id, fs->error ? fs->error : "");

#ifdef USE_DFLOW_ADMISSION
		/* release the memory claim */
		DFLOWadmission(-fs->argclaim, -fs->hotclaim);
#endif

		p = getInstrPtr(fs->mb, ABS(fs->pc));
		fs->hotclaim = 0;
		for (i = 0; i < p->retc; i++)
			fs->hotclaim += getMemoryClaim(fs->mb, fs->stk, p, i, FALSE);

		/* see if you can find an eligible instruction that uses the
		 * result just produced. Then we can continue with it right away.
		 * We are just looking for the last block, which means we are safe from concurrent actions
		 */
		nxtfs = 0;
		if (fs->pc >= 0)
			for (last = fs->pc - task->flow->start; last >= 0 && (i = task->flow->nodes[last]) > 0; last = task->flow->edges[last])
				if (task->flow->status[i].state == DFLOWpending &&
					task->flow->status[i].blocks == 1) {
					task->flow->status[i].state = DFLOWrunning;
					task->flow->status[i].blocks = 0;
					task->flow->status[i].hotclaim = fs->hotclaim;
					task->flow->status[i].argclaim += fs->hotclaim;
					task->flow->status[i].error = NULL;
					nxtfs = task->flow->status + i;
					PARDEBUG mnstr_printf(GDKstdout, "#continue pc= %d thr= %d claim= %d\n", nxtfs->pc, task->id, task->flow->status[i].argclaim);
					break;
				}

		/* all non-local choices are handled by the main scheduler */
		/* we always return the instruction handled */
		/* be careful, the local continuation should be last in the queue */
		if (local)
			q_requeue(task->flow->done, fs);
		else
			q_enqueue(task->flow->done, fs);
	}
	THRdel(thr);
}

@-
The dataflow administration is based on administration of
how many variables are still missing before it can be executed.
For each instruction we keep a list of instructions whose
blocking counter should be decremented upon finishing it.
@c
static void
DFLOWinit(DataFlow flow, Client cntxt, MalBlkPtr mb, MalStkPtr stk, int size)
{
	int pc, i, j, k, n, etop = 0;
	int *assign;
	InstrPtr p;

	PARDEBUG printf("Initialize dflow block\n");
	assign = (int*)GDKzalloc(mb->vtop * sizeof(int));
	etop = flow->stop - flow->start;
	for (n = 0, pc = flow->start; pc < flow->stop; pc++, n++) {
		p = getInstrPtr(mb, pc);

		/* initial state, ie everything can run */
		flow->status[n].cntxt = cntxt;
		flow->status[n].mb = mb;
		flow->status[n].stk = stk;
		flow->status[n].pc = pc;
		flow->status[n].state = DFLOWpending;
		flow->status[n].cost = -1;
		flow->status[n].error = NULL;

		/* administer flow dependencies */
		for (j = p->retc; j < p->argc; j++) {
			if (!isVarConstant(mb, getArg(p, j)) && (k = assign[getArg(p, j)])) {
				/* add edge to the target instruction for wakeup call */
				k -= flow->start;
				if (flow->nodes[k]) {
					/* add wakeup to tail of list */
					for (i = k; flow->edges[i] > 0; i = flow->edges[i])
						;
					flow->nodes[etop] = n;
					flow->edges[etop] = -1;
					flow->edges[i] = etop;
					etop++;
					(void)size;
					assert(etop < size);
				} else {
					flow->nodes[k] = n;
					flow->edges[k] = -1;
				}

				flow->status[n].blocks++;
			}
			/* be careful, watch out for garbage collection interference */
			/* those should be scheduled after all its other uses */
			k = getEndOfLife(mb, getArg(p, j));
			if (k != pc && k < flow->stop && k > flow->start) {
				/* add edge to the target instruction for wakeup call */
				PARDEBUG mnstr_printf(GDKstdout, "forward %d -> %d\n", n + flow->start, k);
				k -= flow->start;
				if (flow->nodes[n]) {
					/* add wakeup to tail of list */
					for (i = n; flow->edges[i] > 0; i = flow->edges[i])
						;
					flow->nodes[etop] = k;
					flow->edges[etop] = -1;
					flow->edges[i] = etop;
					etop++;
					(void)size;
					assert(etop < size);
				} else {
					flow->nodes[n] = k;
					flow->edges[n] = -1;
				}
				flow->status[k].blocks++;
			}
		}

		for (j = 0; j < p->retc; j++)
			assign[getArg(p, j)] = pc;  /* ensure recognition of dependency on first instruction and constant */
	}
	GDKfree(assign);
	PARDEBUG for (n = 0; n < flow->stop - flow->start; n++) {
		mnstr_printf(GDKstdout, "#[%d] %d: ", flow->start + n, n);
		printInstruction(GDKstdout, mb, 0, getInstrPtr(mb, n + flow->start), LIST_MAL_STMT | LIST_MAPI);
		mnstr_printf(GDKstdout, "#[%d]Dependents blocks %d:", flow->start + n, flow->status[n].blocks);
		for (j = n; flow->edges[j]; j = flow->edges[j]) {
			mnstr_printf(GDKstdout, "%d ", flow->start + flow->nodes[j]);
			if (flow->edges[j] == -1)
				break;
		}
		mnstr_printf(GDKstdout, "\n");
	}
}

@-
Parallel processing is mostly driven by dataflow, but within this context
there may be different schemes to take instructions into execution.
The admission scheme (and wrapup) are the necessary scheduler hooks.
A scheduler registers the functions needed and should release them
at the end of the parallel block.
They take effect after we have ensured that the basic properties for
execution hold.
@c
static str
DFLOWscheduler(DataFlow flow)
{
	int queued = 0, oldq = 0, last;
	int pc = 0, i, j;
	int todo = flow->stop - flow->start;
	str ret = MAL_SUCCEED;
	FlowStatus fs, f = 0;
	InstrPtr p;

	if (todo == 0)
		throw(MAL, "dataflow", "Empty dataflow block");
	/* initialize the eligible statements */
	fs = flow->status;

/* old code
    assert(f->stk->wrapup == 0);
    assert(f->stk->admit == 0);
 */

	if (fs[0].cntxt->flags & timerFlag)
		fs[0].cntxt->timer = GDKusec();

	/* enter all dependencies before releasing the queue  */
	MT_lock_set(&flow->todo->l, "q_enqueue");
	for (i = 0; i < todo; i++)
		if (flow->status[i].blocks == 0) {
			p = getInstrPtr(fs[0].mb, i);
			for (j = p->retc; j < p->argc; j++)
				flow->status[i].argclaim += getMemoryClaim(flow->status[0].mb, flow->status[0].stk, p, j, FALSE);
			queued++;
			flow->status[i].state = DFLOWrunning;
			PARDEBUG mnstr_printf(GDKstdout, "#enqueue pc=%d claim=%d queue %d\n", flow->status[i].pc, flow->status[i].argclaim, queued);
			q_enqueue_(flow->todo, flow->status + i);
		}
	MT_lock_unset(&flow->todo->l, "q_enqueue");
	while (oldq++ < queued)
		MT_sema_up(&flow->todo->s, "q_enqueue");

	/* consume the remainder */
	PARDEBUG mnstr_printf(GDKstdout, "#run %d instructions in dataflow block\n", todo);
	while (queued) {
		PARDEBUG mnstr_printf(GDKstdout, "#waiting for results, queued %d\n", queued);
		f = q_dequeue(flow->done);
		queued--;

		if (f->pc < 0) {
			PARDEBUG mnstr_printf(GDKstdout, "#errors encountered %s ", f->error ? f->error : "unknown");
			if (ret == MAL_SUCCEED)
				ret = f->error;
			else {
				/* collect all errors encountered */
				str z = (char*)GDKmalloc(strlen(ret) + strlen(f->error) + 2);
				if (z) {
					strcpy(z, ret);
					if (z[strlen(z) - 1] != '\n') strcat(z, "\n");
					strcat(z, f->error);
					GDKfree(f->error);
					GDKfree(ret);
					ret = z;
				}
			}
		}

		/*
		 * When an instruction is finished we have to reduce the blocked
		 * counter for all dependent instructions.  for those where it
		 * drops to zero we can scheduler it Moreover, we add the return
		 * variable claim size to the target instruction and remember
		 * the last increment as hotclaim.
		 */
		f->state = DFLOWwrapup;
		last = ABS(f->pc) - flow->start;
		PARDEBUG mnstr_printf(GDKstdout, "#finished pc=%d claim %d\n", f->pc, f->hotclaim);

		/* enter all dependencies before releasing the queue  */
		MT_lock_set(&flow->todo->l, "q_enqueue");

		oldq = queued;
		for (; last >= 0 && (i = flow->nodes[last]) > 0; last = flow->edges[last])
			if (flow->status[i].state == DFLOWpending) {
				flow->status[i].argclaim += f->hotclaim;
				if (flow->status[i].blocks == 1 && ret == MAL_SUCCEED) {
					queued++;
					q_enqueue_(flow->todo, flow->status + i);
					flow->status[i].state = DFLOWrunning;
					flow->status[i].blocks--;
					PARDEBUG
					mnstr_printf(GDKstdout, "#enqueue pc=%d claim=%d queued= %d\n", flow->status[i].pc, flow->status[i].argclaim, queued);
				} else {
					 if (ret == MAL_SUCCEED)
						PARDEBUG mnstr_printf(GDKstdout, "#await   pc %d block %d claim= %d\n", flow->start + i, flow->status[i].blocks, flow->status[i].argclaim);
					flow->status[i].blocks--;
				}
			} else { /* worker stole the candidate */
				PARDEBUG mnstr_printf(GDKstdout, "#woke up pc %d block %d claim %d\n", flow->start + i, flow->status[i].blocks, flow->status[i].argclaim);
				queued++;
				oldq++;
			}
		if (0 && oldq != queued) /* invalidate */
			queue_sort(flow->todo);
		MT_lock_unset(&flow->todo->l, "q_enqueue");

		if (ret == MAL_SUCCEED)
			while (oldq++ < queued)
				MT_sema_up(&flow->todo->s, "q_enqueue");
	}
	PARDEBUG {
		mnstr_printf(GDKstdout, "#end of data flow %d todo %d \n", pc, flow->stop - flow->start);
		for (i = 0; i < flow->stop - flow->start; i++)
			if (fs[i].state != DFLOWwrapup && fs[i].pc >= 0) {
				mnstr_printf(GDKstdout, "#missed %d %d %d ", i, fs[i].state, fs[i].pc);
				printInstruction(GDKstdout, fs[i].mb, 0, getInstrPtr(fs[i].mb, fs[i].pc), LIST_MAL_STMT | LIST_MAPI);
			}
	}
	return ret;
}

static DataFlow flows = NULL;
static int workerid = 0;

str runMALdataflow(Client cntxt, MalBlkPtr mb, int startpc,
				   int stoppc, MalStkPtr stk, MalStkPtr env, InstrPtr pcicaller)
{
	DataFlow flow = NULL;
	str ret = MAL_SUCCEED;
	int size;

#ifdef DEBUG_FLOW
	mnstr_printf(GDKstdout, "runMALdataflow for block %d - %d\n", startpc, stoppc);
	printFunction(GDKstdout, mb, 0, LIST_MAL_STMT | LIST_MAPI);
#endif

	/*
	 * TODO improve cost of DFLOWeligible
	 if (stoppc && stoppc - startpc > 10000)
		 return runMALsequence(cntxt, mb, startpc + 1, stoppc, stk, env, pcicaller);
	 */

	(void)env;
	(void)pcicaller;

	/* in debugging mode we should not start multiple threads */
	if (stk->cmd)
		return MAL_SUCCEED;

	assert(stoppc > startpc);
	mal_set_lock(mal_contextLock, "runMALdataflow");
	flow = flows;

	if (flow) {
		flows = flow->free;
	} else {
		int i;

		flow = (DataFlow)GDKzalloc(sizeof(DataFlowRec));

		/* seems enough for the time being */
		flow->done = q_create(2048);
		flow->todo = q_create(2048);

		/* queues are available? */
		if (flow->done == NULL || flow->todo == NULL) {
			mal_unset_lock(mal_contextLock, "runMALdataflow");
			return MAL_SUCCEED;
		}

		flow->worker = NULL;
		flow->nway = GDKnr_threads ? GDKnr_threads : 1;
		flow->worker = (FlowTask *)GDKzalloc(sizeof(FlowTask) * flow->nway);
		for (i = 0; i < flow->nway; i++) {
			flow->worker[i].id = workerid++;
			flow->worker[i].todo = flow->todo;
			flow->worker[i].flow = flow;
			/* create the thread and let it wait */
			MT_create_thread(&flow->worker[i].tid, runDFLOWworker, flow->worker + i, MT_THR_DETACHED);
		}
	}
	/* keep real block count, exclude brackets */
	flow->start = startpc + 1;
	flow->stop = stoppc;

	flow->status = (FlowStatus)GDKzalloc((flow->stop - flow->start + 1) * sizeof(FlowStatusRec));
	size = DFLOWgraphSize(mb, startpc, stoppc);
	flow->nodes = (int*)GDKzalloc(sizeof(int) * size);
	flow->edges = (int*)GDKzalloc(sizeof(int) * size);
	DFLOWinit(flow, cntxt, mb, stk, size);
	mal_unset_lock(mal_contextLock, "runMALdataflow");

	ret = DFLOWscheduler(flow);
	GDKfree(flow->status);
	flow->status = 0;
	GDKfree(flow->edges);
	flow->edges = 0;
	GDKfree(flow->nodes);
	flow->nodes = 0;
	mal_set_lock(mal_contextLock, "runMALdataflow");
	flow->free = flows;
	flows = flow;
	mal_unset_lock(mal_contextLock, "runMALdataflow");
	return ret;
}
@+ Independent threads
Distributed execution calls for asynchronous execution of MAL
instructions. To simplify the interpreter, we assume that all
the code to be executed is already grouped in a MAL function,
which is called independently. The result variables are initialized
to NIL before the code is started. When the process crashes,
an exception is raised.

@h
mal_export str runMALprocess(Client cntxt, MalBlkPtr mb, MalStkPtr stk, int start, int stop);
@c
typedef struct {
	MT_Id tid;
	Client cntxt;
	MalBlkPtr mb;
	MalStkPtr stk;
	int start,stop;
} Ptask;

/* runMALdetached is typically called as part of
 * starting a separate interpreter thread.
 */
static void
runMALdetached(void *t)
{
	Ptask *p = (Ptask *)t;
	Client cntxt = p->cntxt;
	MalBlkPtr mb = p->mb;
	MalStkPtr stk = p->stk;
	int sve;
	str msg = MAL_SUCCEED;

#ifdef DEBUG_DETACHED
	mnstr_printf(cntxt->fdout, "start thread in background\n");
#endif
	if (stk == NULL) {
		GDKerror("mal.interpreter: " MAL_STACK_FAIL);
		return;
	}
	sve = stk->keepAlive;
	stk->keepAlive = TRUE;
	msg = reenterMAL(cntxt, mb, p->start, p->stop, stk, 0, 0);
	stk->keepAlive = sve;
	if (msg != MAL_SUCCEED)
		GDKerror(msg);      /* indirect way to pass an error */
#ifdef DEBUG_DETACHED
	mnstr_printf(cntxt->fdout, "finished thread in background\n");
#endif
}
str runMALprocess(Client cntxt, MalBlkPtr mb, MalStkPtr stk, int start, int stop)
{
	Ptask p;

	p.cntxt = cntxt;
	p.mb = mb;
	p.stk = stk;
	p.start = start;
	p.stop = stop;

	MT_create_thread(&p.tid, runMALdetached, &p, MT_THR_DETACHED);
	return MAL_SUCCEED;
}

@= MALwrapup
	if (exceptionVar >= 0) {
		if (ret) {
			str oldret = ret;
			ret = createScriptException(mb, mb->stop - 1,
				getExceptionType(getVarName(mb, exceptionVar)),
				ret, "Exception not caught");
			FREE_EXCEPTION(oldret);
		} else {
			if (stk->stk[exceptionVar].vtype == TYPE_str) {
				ret = createScriptException(mb, mb->stop - 1, MAL,
					stk->stk[exceptionVar].val.sval,
					"Exception not caught");
			} else {
				ret = createScriptException(mb, mb->stop - 1, MAL,
					NULL, "Exception not caught");
			}
		}
	}
@+ Safeguarding
The physical stack for each thread is an operating system parameter.
We do not want recursive programs crashing the server, so once in
a while we check whether we are running dangerously low on available
stack space.

This situation can be detected by calling upon the GDK functionality
of by limiting the depth of a function calls.
Expensive? 70 msec for 1M calls. Use with care.
@h
mal_export str safeguardStack(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);
@c
str
safeguardStack(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{
	int depth = *(int*)getArgReference(stk, pci, 1);
	(void)cntxt;
	if (stk->stkdepth > depth * mb->vtop && THRhighwater()) {
		throw(MAL, "mal.interpreter", MAL_STACK_FAIL);
	}
	return MAL_SUCCEED;
}

@+ The interpreter loop
The interpreter is geared towards execution a MAL procedure together
with all its decendant invocations. As such, it provides the
MAL abtract machine processor.

The value-stack frame of the surrounding scope is needed to resolve
binding values.  Getting (putting) a value from (into) a surrounding
scope should be guarded with the exclusive access lock.
This situation is encapsulated by a bind() function call, whose parameters
contain the access mode required.

The formal procedure arguments are assumed to always occupy the first
elements in the value stack.
@+ The major switch

@= MALinterpret
	ret = 0;
	switch (pci->token) {
	case ASSIGNsymbol: 
		@:assignStmt(@1,continue,stk)@ 
		break;
	case PATcall: 
		@:patterncall(@1,continue,stk)@ 
		break;
	case CMDcall: 
		@:commandcall(@1,continue,stk)@ 
		break;
	case FACcall: 
		@:factorycall(@1,continue,stk)@ 
		break;
	case FCNcall: 
		@:functioncall(@1,continue,stk)@ 
		break;
	case NOOPsymbol:
	case REMsymbol:
		break;
	case ENDsymbol:
		if (getInstrPtr(mb, 0)->token == FACTORYsymbol)
			ret = shutdownFactory(cntxt, mb, 0);
#if @1
		if (oldtimer)
			cntxt->timer = oldtimer;
#endif
		if (pcicaller && garbageControl(getInstrPtr(mb, 0)))
			garbageCollector(cntxt, mb, stk, TRUE);
#if @1
		@:endProfile(stk)@
#endif
		stkpc = mb->stop;
		continue;
	default:
		if (pci->token < 0) {
			/* temporary NOOP instruction */
			break;
		}
		ret = createScriptException(mb, stkpc, MAL,
			NULL, "unkown operation");
#if @1
		@:endProfile(stk)@
#endif
		stkpc= mb->stop;
		continue;
	}
@-
After the expression has been evaluated we should check for a
possible change in the control flow.
@= MALflowofcontrol
	switch (pci->barrier) {
	case BARRIERsymbol:
		@:barrierControl@ 
		stkpc++;
		break;
	case LEAVEsymbol:
	case REDOsymbol:
		v = &stk->stk[getDestVar(pci)];
		/* skip to end of barrier, depending on the type */
		switch (v->vtype) {
		case TYPE_bit:
			if (v->val.cval[0] == TRUE && v->val.cval[0] != bit_nil)
				stkpc = pci->jump;
			else 
				stkpc++;
			break;
		case TYPE_chr:
			if (v->val.cval[0])
				stkpc = pci->jump;
			else 
				stkpc++;
			break;
		case TYPE_str:
			if (v->len > 0 && v->val.sval != str_nil)
				stkpc = pci->jump;
			else 
				stkpc++;
			break;
		case TYPE_sht:
			if (v->val.shval >= 0 && v->val.shval != sht_nil)
				stkpc = pci->jump;
			else 
				stkpc++;
			break;
		case TYPE_bat:
			if (v->val.bval > 0)
				stkpc = pci->jump;
			else 
				stkpc++;
			break;
		case TYPE_int:
			if (v->val.ival >= 0 && v->val.ival != int_nil)
				stkpc = pci->jump;
			else 
				stkpc++;
			break;
		case TYPE_wrd:
			if (v->val.wval >= 0 && v->val.wval != wrd_nil)
				stkpc = pci->jump;
			else 
				stkpc++;
			break;
		case TYPE_bte:
			if (v->val.btval >= 0 && v->val.btval != bte_nil)
				stkpc = pci->jump;
			else 
				stkpc++;
			break;
		case TYPE_lng:
			if (v->val.lval >= 0 && v->val.lval != lng_nil)
				stkpc = pci->jump;
			else
				stkpc++;
			break;
		default:
			break;
		}
		break;
	case CATCHsymbol:
		/* catch blocks are skipped unless
		   searched for explicitly*/
		if (exceptionVar < 0) {
			stkpc = pci->jump;
			break;
		}
		exceptionVar = -1;
		stkpc++;
		break;
	case EXITsymbol:
		if (getDestVar(pci) == exceptionVar)
			exceptionVar = -1;
		stkpc++;
		break;
	case RAISEsymbol:
		exceptionVar = getDestVar(pci);
		ret = NULL;
		if (getVarType(mb, getDestVar(pci)) == TYPE_str) {
			ret = createScriptException(mb, stkpc, MAL, NULL,
				stk->stk[getDestVar(pci)].val.sval);
		}
		@:skipToCatch(exceptionVar, @2, stk)@
		if (stkpc == mb->stop)
			ret = createScriptException(mb, stkpc, MAL, ret,
				"Exception raised");
		break;
	case YIELDsymbol:     /* to be defined */
		if (oldtimer)
			cntxt->timer = oldtimer;
		return yieldFactory(mb, pci, stkpc);
	case RETURNsymbol:
		/* Return from factory involves cleanup */

		if (getInstrPtr(mb, 0)->token == FACTORYsymbol) {
			yieldResult(mb, pci, stkpc);
			shutdownFactory(cntxt, mb, TRUE);
		} else
		/* a fake multi-assignment */
		if (env != NULL && pcicaller != NULL) {
			InstrPtr pp = pci;
			@:endProfile(stk)@
			pci = pcicaller;
			for (i = 0; i < pci->retc; i++) {
				rhs = &stk->stk[pp->argv[i]];
				lhs = &env->stk[pci->argv[i]];
				VALcopy(lhs, rhs);
				if (lhs->vtype == TYPE_bat)
					BBPincref(lhs->val.bval, TRUE);
			}
			if (garbageControl(getInstrPtr(mb, 0)))
				garbageCollector(cntxt, mb, stk, TRUE);
			/* reset the clock */
			if (oldtimer)
				cntxt->timer = oldtimer;
		} else {
			@:endProfile(stk)@
		}
		stkpc = mb->stop;
		continue;
	default:
		stkpc++;
	}

@+ Assignment command
The assignment statement copies values around on the stack frame,
including multiple assignments.

Pushing constants/initial values onto the stack is a separate operation.
It takes the constant value discovered at compile time and stored in the
symbol table and moves it to the stackframe location. This activity
is made part of the start-up procedure.

The before after calls should be reconsidered here, because
their. They seem superflous and the way they are used will
cause errors in multi-assignment statements.
@-
@= assignStmt
{
	@:safeTarget(@1)@
	for (k = 0, i = pci->retc; k < pci->retc && i < pci->argc; i++, k++) {
		lhs = &stk->stk[pci->argv[k]];
		rhs = &stk->stk[pci->argv[i]];
		VALcopy(lhs, rhs);
		if (lhs->vtype == TYPE_bat && lhs->val.bval)
			BBPincref(lhs->val.bval, TRUE);
	}
	@:restoreTarget(@1, @3)@
	ret = 0;
	@:exceptionHndlr(@1, @2, @3)@
	@:timingHndlr(@1)@
}
@}
@-
@node MAL API, Exception Handling, The MAL Interpreter, The MAL Interpreter

@+ MAL API
The linkage between MAL interpreter and compiled C-routines
is kept as simple as possible.
Basically we distinguish four kinds of calling conventions:
CMDcall, FCNcall, FACcall, and  PATcall.
The FCNcall indicates calling a MAL procedure, which leads
to a recursive call to the interpreter.

CMDcall initiates calling a linked function, passing pointers
to the parameters and result variable, i.e.  f(ptr a0,..., ptr aN)
The function returns a MAL-SUCCEED upon success and a pointer
to an exception string upon failure.
Failure leads to raise-ing an exception in the interpreter loop,
by either looking up the relevant exception message in the module
administration or construction of a standard string.

The PATcall initiates a call which contains the MAL context,
i.e. f(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
The mb provides access to the code definitions. It is primarilly
used by routines intended to manipulate the code base itself, such
as the optimizers. The Mal stack frame pointer provides access
to the values maintained. The arguments passed are offsets
into the stack frame rather than pointers to the actual value.

@{
BAT parameters require some care. Ideally, a BAT should not be kept
around long. This would mean that each time we access a BAT it has to be
pinned in memory and upon leaving the function, it is unpinned.
This degrades performance significantly.
After the parameters are fixed, we can safely free the destination
variable and re-initialize it to nil.

Before we execute an instruction the variables to be garbage collected
are identified. In the post-execution phase they are removed.
@= safeTarget
#ifdef STACKTRACE
	printf("safeTarget %d\n", garbageControl(pci));
	printInstruction(cntxt->fdout, mb, pci, LIST_MAL_ALL);
#endif
	if (garbageControl(pci)) {
		for (i = 0; i < pci->argc; i++) {
			sbackup[i] = 0;
			backup[i] = 0;
			garbage[i] = -1;
			if (stk->stk[getArg(pci, i)].vtype == TYPE_bat && getEndOfLife(mb, getArg(pci, i)) == stkpc && isNotUsedIn(pci, i + 1, getArg(pci, i))) {
				garbage[i] = getArg(pci, i);
#ifdef DEBUG_GC
				mnstr_printf(GDKstdout, "GC %d %s prep\n", getArg(pci, i), getArgName(mb, pci, i));
#endif
			}

			if (i < pci->retc && stk->stk[getArg(pci, i)].vtype == TYPE_bat) {
				backup[i] = stk->stk[getArg(pci, i)].val.bval;
#if @1
				stamp = BBPcurstamp();
#endif
			} else if (i < pci->retc && stk->stk[getArg(pci, i)].vtype == TYPE_str) {
				backup[i] = stk->stk[getArg(pci, i)].len;
				sbackup[i] = stk->stk[getArg(pci, i)].val.sval;
				backup[i] += (sbackup[i] != NULL);
			}
		}
	}
@= restoreTarget
#ifdef STACKTRACE
	printf("restoreTarget %d\n", garbageControl(pci));
#endif
	/* Provide debugging support */
#if @1
	if (GDKdebug & 10 && exceptionVar < 0) {
		BAT *b;

		for (i = 0; i < pci->retc; i++) {
			if (garbage[i] == -1 && stk->stk[getArg(pci, i)].vtype == TYPE_bat &&
				stk->stk[getArg(pci, i)].val.bval) {
				b = BATdescriptor(stk->stk[getArg(pci, i)].val.bval);
				if (b == NULL) {
					ret = createException(MAL, "mal.propertyCheck", RUNTIME_OBJECT_MISSING);
					continue;
				}
				if (b->batStamp <= stamp) {
					if (GDKdebug & 8) {
						if (b->H != b->T) {
							BATpropcheck(BATmirror(b), BATPROPS_QUICK);
						}
						BATpropcheck(b, BATPROPS_QUICK);
					}
				} else if (GDKdebug & 2) {
					if (b->H != b->T) {
						BATpropcheck(BATmirror(b), BATPROPS_QUICK);
					}
					BATpropcheck(b, BATPROPS_QUICK);
				}
				BBPunfix(b->batCacheid);
			}
		}
	}
#endif
	@:MALrecycleExit(@2)@
	if (ret == MAL_SUCCEED && garbageControl(pci)) {
		for (i = 0; i < pci->argc; i++) {
			if (isaBatType(getArgType(mb, pci, i))) {
				bat bid = stk->stk[getArg(pci, i)].val.bval;

				/* update the bigfoot information only if we need to gc */
				if (cntxt->flags & bigfootFlag)
					updateBigFoot(cntxt, bid, TRUE);
				if (i < pci->retc && backup[i]) {
					if (backup[i] != bid && i < pci->retc) {
						/* possible garbage collect the variable */
						if (cntxt->flags & bigfootFlag)
							updateBigFoot(cntxt, backup[i], FALSE);
					}
					BBPdecref(backup[i], TRUE);
					backup[i] = 0;
				}
				if (garbage[i] >= 0) {
					bid = ABS(stk->stk[garbage[i]].val.bval);
					BBPdecref(bid, TRUE);
					PARDEBUG mnstr_printf(GDKstdout, "#GC pc=%d bid=%d %s done\n", stkpc, bid, getVarName(mb, garbage[i]));
					stk->stk[garbage[i]].val.bval = 0;
				}
			} else if (i < pci->retc && stk->stk[getArg(pci, i)].vtype == TYPE_str) {
				int a = getArg(pci, i);
				if (sbackup[i] && sbackup[i] != stk->stk[a].val.sval) {
					if (backup[i] > 0)
						GDKfree(sbackup[i]);
					if (i >= pci->retc) {
						stk->stk[getArg(pci, i)].val.sval = 0;
						stk->stk[getArg(pci, i)].len = 0;
					}
					backup[i] = 0;
					sbackup[i] = 0;
				}
			}
		}
	}
@-
@= commandcall
{
	@:safeTarget(@1)@
	/* improve performance with 20 ms/1M calls*/
	assert(pci->fcn != NULL);
	switch (pci->argc) {
	case 0: ret = (str)(*pci->fcn)(); 
		break;
	case 1: ret = (str)(*pci->fcn)(
			(ptr)getArgReference(stk, pci, 0)); 
		break;
	case 2: ret = (str)(*pci->fcn)(
			(ptr)getArgReference(stk, pci, 0),
			(ptr)getArgReference(stk, pci, 1));
		break;
	case 3: ret = (str)(*pci->fcn)(
			(ptr)getArgReference(stk, pci, 0),
			(ptr)getArgReference(stk, pci, 1),
			(ptr)getArgReference(stk, pci, 2));
		break;
	case 4: ret = (str)(*pci->fcn)(
			(ptr)getArgReference(stk, pci, 0),
			(ptr)getArgReference(stk, pci, 1),
			(ptr)getArgReference(stk, pci, 2),
			(ptr)getArgReference(stk, pci, 3));
		break;
	case 5: ret = (str)(*pci->fcn)(
			(ptr)getArgReference(stk, pci, 0),
			(ptr)getArgReference(stk, pci, 1),
			(ptr)getArgReference(stk, pci, 2),
			(ptr)getArgReference(stk, pci, 3),
			(ptr)getArgReference(stk, pci, 4));
		break;
	case 6: ret = (str)(*pci->fcn)(
			(ptr)getArgReference(stk, pci, 0),
			(ptr)getArgReference(stk, pci, 1),
			(ptr)getArgReference(stk, pci, 2),
			(ptr)getArgReference(stk, pci, 3),
			(ptr)getArgReference(stk, pci, 4),
			(ptr)getArgReference(stk, pci, 5));
		break;
	case 7: ret = (str)(*pci->fcn)(
			(ptr)getArgReference(stk, pci, 0),
			(ptr)getArgReference(stk, pci, 1),
			(ptr)getArgReference(stk, pci, 2),
			(ptr)getArgReference(stk, pci, 3),
			(ptr)getArgReference(stk, pci, 4),
			(ptr)getArgReference(stk, pci, 5),
			(ptr)getArgReference(stk, pci, 6));
		break;
	case 8: ret = (str)(*pci->fcn)(
			(ptr)getArgReference(stk, pci, 0),
			(ptr)getArgReference(stk, pci, 1),
			(ptr)getArgReference(stk, pci, 2),
			(ptr)getArgReference(stk, pci, 3),
			(ptr)getArgReference(stk, pci, 4),
			(ptr)getArgReference(stk, pci, 5),
			(ptr)getArgReference(stk, pci, 6),
			(ptr)getArgReference(stk, pci, 7));
		break;
	case 9: ret = (str)(*pci->fcn)(
			(ptr)getArgReference(stk, pci, 0),
			(ptr)getArgReference(stk, pci, 1),
			(ptr)getArgReference(stk, pci, 2),
			(ptr)getArgReference(stk, pci, 3),
			(ptr)getArgReference(stk, pci, 4),
			(ptr)getArgReference(stk, pci, 5),
			(ptr)getArgReference(stk, pci, 6),
			(ptr)getArgReference(stk, pci, 7),
			(ptr)getArgReference(stk, pci, 8));
		break;
	case 10: ret = (str)(*pci->fcn)(
			(ptr)getArgReference(stk, pci, 0),
			(ptr)getArgReference(stk, pci, 1),
			(ptr)getArgReference(stk, pci, 2),
			(ptr)getArgReference(stk, pci, 3),
			(ptr)getArgReference(stk, pci, 4),
			(ptr)getArgReference(stk, pci, 5),
			(ptr)getArgReference(stk, pci, 6),
			(ptr)getArgReference(stk, pci, 7),
			(ptr)getArgReference(stk, pci, 8),
			(ptr)getArgReference(stk, pci, 9));
		break;
	case 11: ret = (str)(*pci->fcn)(
			(ptr)getArgReference(stk, pci, 0),
			(ptr)getArgReference(stk, pci, 1),
			(ptr)getArgReference(stk, pci, 2),
			(ptr)getArgReference(stk, pci, 3),
			(ptr)getArgReference(stk, pci, 4),
			(ptr)getArgReference(stk, pci, 5),
			(ptr)getArgReference(stk, pci, 6),
			(ptr)getArgReference(stk, pci, 7),
			(ptr)getArgReference(stk, pci, 8),
			(ptr)getArgReference(stk, pci, 9),
			(ptr)getArgReference(stk, pci, 10));
		break;
	case 12: ret = (str)(*pci->fcn)(
			(ptr)getArgReference(stk, pci, 0),
			(ptr)getArgReference(stk, pci, 1),
			(ptr)getArgReference(stk, pci, 2),
			(ptr)getArgReference(stk, pci, 3),
			(ptr)getArgReference(stk, pci, 4),
			(ptr)getArgReference(stk, pci, 5),
			(ptr)getArgReference(stk, pci, 6),
			(ptr)getArgReference(stk, pci, 7),
			(ptr)getArgReference(stk, pci, 8),
			(ptr)getArgReference(stk, pci, 9),
			(ptr)getArgReference(stk, pci, 10),
			(ptr)getArgReference(stk, pci, 11));
		break;
	default:
		ret = createScriptException(mb, stkpc, MAL, NULL,
			"too many arguments for command call");
	}
	@:restoreTarget(@1,@3)@
	@:exceptionHndlr(@1,@2,@3)@
	@:timingHndlr(@1,@2)@
}
@-
@= patterncall
	if (pci->fcn == NULL) {
		ret = createScriptException(mb, stkpc, MAL, NULL,
			"address of pattern %s.%s missing", pci->modname, pci->fcnname);
	} else {
		@:safeTarget(@1)@
		ret = (str)(*pci->fcn)(cntxt, mb, stk, pci);
		@:restoreTarget(@1,@3)@
	}
	@:exceptionHndlr(@1,@2,@3)@
	@:timingHndlr(@1,@2)@
@-
MAL function calls are relatively expensive, because they have to assemble
a new stack frame and do housekeeping, such as garbagecollection of all
non-returned values.

@-
@= functioncall
{
	stk->pcup = stkpc;
	@:safeTarget(@1)@
	ret = runMAL(cntxt, pci->blk, 1, mb, stk, pci);
	@:restoreTarget(@1,@3)@
	@:exceptionHndlr(@1,@2,@3)@
	@:timingHndlr(@1)@
}
@-
Factory calls are more involved. At this stage it is a synchrononous
call to the factory manager.
Factory calls should deal with the reference counting.
@= factorycall
	if (pci->blk == NULL)
		ret = createScriptException(mb, stkpc, MAL, NULL,
			"reference to MAL function missing");
	else
		ret = runFactory(cntxt, pci->blk, mb, stk, pci);
	@:exceptionHndlr(@1,@2,@3)@
	@:timingHndlr(SLOW)@
@-
The type dispatching table in getArgReference can be removed if we
determine at compile time the address offset within a ValRecord.
We leave this optimization for the future, it leads to about 10%
improvement (100ms for 1M calls).

@+ Flow of control statements
Each assignment (function call) may be part of the initialization
of a barrier- block. In that case we have to test the
outcome of the operation and possibly skip the block altogether.
The latter is implemented as a linear scan for the corresponding
labeled statemtent. This might be optimized later.

@= barrierControl
{
	v = &stk->stk[getDestVar(pci)];
	/* skip to end of barrier, depends on the type */
	switch (v->vtype) {
	case TYPE_bit:
		if (v->val.cval[0] == FALSE || v->val.cval[0] == bit_nil)
			stkpc = pci->jump;
		break;
	case TYPE_chr:
		if (v->val.cval[0] == chr_nil)
			stkpc = pci->jump;
		break;
	case TYPE_oid:
		if (v->val.oval == oid_nil)
			stkpc = pci->jump;
		break;
	case TYPE_sht:
		if (v->val.shval < 0 || v->val.shval == sht_nil)
			stkpc = pci->jump;
		break;
	case TYPE_int:
		if (v->val.ival < 0 || v->val.ival == int_nil)
			stkpc = pci->jump;
		break;
	case TYPE_lng:
		if (v->val.lval < 0 || v->val.lval == lng_nil)
			stkpc = pci->jump;
		break;
	case TYPE_flt:
	case TYPE_dbl:
		if (v->val.dval < 0 || v->val.dval == dbl_nil)
			stkpc = pci->jump;
		break;
	case TYPE_str:
		if (v->len == 0 || v->val.sval == str_nil)
			stkpc = pci->jump;
		break;
	default:
		ret = createScriptException(mb, stkpc, MAL, NULL,
			"%s: Unknown barrier type",
			getVarName(mb, getDestVar(pci)));
	}
}

@-
You can skip to a catch block by searching for the corresponding 'lab'
The return value should be set to pass the error automatically upon
reaching end of function block.
@-
@= skipToCatch
	if (stk->cmd == 'C' || mb->trap) {
		stk->cmd = 'n';
		if (cntxt->flags & bbpFlag)
			BBPTraceCall(cntxt, mb, stk, prevpc);
		prevpc = stkpc;
		mdbStep(cntxt, mb, stk, stkpc);
		if (stk->cmd == 'x' || cntxt->mode == FINISHING) {
			stkpc = mb->stop;
			@2;
		}
	}
	/* skip to catch block or end */
	for (; stkpc < mb->stop; stkpc++) {
		InstrPtr l = getInstrPtr(mb, stkpc);
		if (l->barrier == CATCHsymbol) {
			int j;
			for (j = 0; j < l->retc; j++)
				if (getArg(l, j) == @1) 
					break;
				else if (getArgName(mb, l, j) ||
						 strcmp(getArgName(mb, l, j), "ANYexception") == 0)
					break;
			if (j < l->retc) 
				break;
		}
	}
	if (stkpc == mb->stop) {
		@:endProfile(@3)@
		@2;
	}
@-
Each time we enter a barrier block, we could keep its position in the
interpreter stack frame. It forms the starting point to issue a redo.
Unfortunately, this does not easily work in the presence of optimizers, which
may change the order/block structure. Therefore, we simple have to search
the beginning or ensure that during chkProgram the barrier/redo/leave/catch
jumps are re-established.

@}
@-
@node Exception Handling, Garbage Collection, MAL API, The MAL Interpreter
@+ Exception handling
Calling a built-in or user-defined routine may lead to an error or a
cached status message to be dealt with in MAL.
To improve error handling in MAL, an exception handling
scheme based on @sc{catch}-@sc{exit} blocks. The @sc{catch}
statement identifies a (string-valued) variable, which carries the
exception message from
the originally failed routine or @sc{raise} exception assignment.
During normal processing @sc{catch}-@sc{exit} blocks are simply skipped.
Upon receiving an exception status from a function call, we set the
exception variable and skip to the first associated @sc{catch}-@sc{exit}
block.
MAL interpretation then continues until it reaches the end of the block.
If no exception variable was defined, we should abandon the function
alltogether searching for a catch block at a higher layer.

@{
For the time being we have ignored cascaded/stacked exceptions.
The policy is to pass the first recognized exception to a context
in which it can be handled.

@}
@-
Exceptions raised within a linked-in function requires some care.
First, the called procedure does not know anything about the MAL
interpreter context. Thus, we need to return all relevant information
upon leaving the linked library routine.

Second, exceptional cases can be handled deeply in the recursion, where they
may also be handled, i.e. by issueing an GDKerror message. The upper layers
merely receive a negative integer value to indicate occurrence of an
error somewhere in the calling sequence.
We then have to also look into GDKerrbuf to see if there was
an error raised deeply inside the system.

The policy is to require all C-functions to return a string-pointer.
Upon a successfull call, it is a NULL string. Otherwise it contains an
encoding of the exceptional state encountered. This message
starts with the exception identifer, followed by contextual details.
@h
mal_export str catchKernelException(Client cntxt, str ret);
@c
str catchKernelException(Client cntxt, str ret)
{
	str z;
	if (cntxt->errbuf && cntxt->errbuf[0]) {
		if (ret != MAL_SUCCEED) {
			z = (char*)GDKmalloc(strlen(ret) + strlen(cntxt->errbuf) + 2);
			if (z) {
				strcpy(z, ret);
				if (z[strlen(z) - 1] != '\n') strcat(z, "\n");
				strcat(z, cntxt->errbuf);
			}
		} else {
			/* trap hidden (GDK) exception */
			z = (char*)GDKmalloc(strlen("GDKerror:") + strlen(cntxt->errbuf) + 2);
			if (z)
				sprintf(z, "GDKerror:%s\n", cntxt->errbuf);
		}
		/* did we eat the error away of not */
		if (z)
			cntxt->errbuf[0] = '\0';
	} else
		z = ret;
	return z;
}
@{
@= exceptionHndlr
if (cntxt->errbuf && cntxt->errbuf[0]) {
	str oldret = ret;
	ret = catchKernelException(cntxt, ret);
	FREE_EXCEPTION(oldret);
}

if (ret != MAL_SUCCEED) {
	str msg = 0;

	if (stk->cmd || mb->trap) {
		mnstr_printf(cntxt->fdout, "!ERROR: %s\n", ret);
		stk->cmd = '\n'; /* in debugging go to step mode */
		mdbStep(cntxt, mb, stk, stkpc);
		if (stk->cmd == 'x' || stk->cmd == 'q' || cntxt->mode == FINISHING) {
			stkpc = mb->stop;
			@2;
		}
		if (stk->cmd == 'r') {
			stk->cmd = 'n';
			stkpc = startpc;
			exceptionVar = -1;
			@2;
		}
	}
	/* Detect any exception received from the implementation. */
	/* The first identifier is an optional exception name */
	if (strstr(ret, "!skip-to-end")) {
		GDKfree(ret);       /* no need to check for M5OutOfMemory */
		ret = MAL_SUCCEED;
		stkpc = mb->stop;
		@2;
	}
	/*
	 * Exceptions are catched based on their name, which is part of the
	 * exception message. The ANYexception variable catches all.
	 */
	exceptionVar = -1;
	msg = strchr(ret, ':');
	if (msg) {
		*msg = 0;
		exceptionVar = findVariableLength(mb, ret, (int)(msg - ret));
		*msg = ':';
	}
	if (exceptionVar == -1)
		exceptionVar = findVariableLength(mb, (str)"ANYexception", 12);

	/* unknown exceptions lead to propagation */
	if (exceptionVar == -1) {
		@:endProfile(@3)@
		stkpc = mb->stop;
		@2;
	}
	/* assure correct variable type */
	if (getVarType(mb, exceptionVar) == TYPE_str) {
		v = &stk->stk[exceptionVar];
		if (v->val.sval)
			FREE_EXCEPTION(v->val.sval);    /* old exception*/
		v->vtype = TYPE_str;
		v->val.sval = ret;
		v->len = (int)strlen(v->val.sval);
		ret = 0;
	} else {
		mnstr_printf(cntxt->fdout, "%s", ret);
		FREE_EXCEPTION(ret);
	}
	/* position yourself at the catch instruction for further decisions */
	@:skipToCatch(exceptionVar,@2,@3)@
	pci = getInstrPtr(mb, stkpc);
}
@-
@+ Result Recycler
An optimization scheme for query sequences is to re-use variables
as much as possible.
The recycler works for any variable and relies on policy functions
registered.
@= MALrecycleStart
	if (pci->recycle > 0)
		@1->clk = GDKusec();
	if (!RECYCLEentry(cntxt, mb, stk, pci))
@= MALrecycleExit
	if (pci->recycle > 0) {
		RECYCLEexit(cntxt, mb, stk, pci, @1->clk);
	}
@}
@-
@node Garbage Collection, Stack Management, Exception Handling, The MAL Interpreter
@+ Garbage collection
Garbage collection is relatively straightforward, because most values are
retained on the stackframe of an interpreter call. However, two storage
types and possibly user-defined type garbage collector definitions
require attention: BATs and strings.

A key issue is to deal with temporary BATs in an efficient way.
References to bats in the buffer pool may cause dangling references
at the language level. This appears as soons as your share
a reference and delete the BAT from one angle. If not carefull, the
dangling pointer may subsequently be associated with another BAT

All string values are private to the VALrecord, which means they
have to be freed explicitly before a MAL function returns.
The first step is to always safe the destination variable
before a function call is made.
@{
@-
@c
void garbageElement(Client cntxt, ValPtr v)
{
	if (v->vtype == TYPE_str) {
		if (v->val.sval) {
			GDKfree(v->val.sval);
			v->val.sval = NULL;
		}
		v->len = 0;
		return;
	}
	if (v->vtype == TYPE_bat) {
@}
@-
All operations are responsible to properly set the
reference count of the BATs being produced or destroyed.
The libraries should not leave the
physical reference count being set. This is only
allowed during the execution of a GDK operation.
All references should be logical.
@-
@{
@c
		bat bid = ABS(v->val.bval);
		/* printf("garbage collecting: %d lrefs=%d refs=%d\n",
		   bid, BBP_lrefs(bid),BBP_refs(bid));*/
		v->val.bval = 0;
		if (bid == 0)
			return;
		if (!BBP_lrefs(bid))
			return;
		if (cntxt && cntxt->flags & bigfootFlag)
			updateBigFoot(cntxt, bid, FALSE);
		BBPdecref(bid, TRUE);
	}
}
@-
@}

Before we return from the interpreter, we should free all
dynamically allocated objects and adjust the BAT reference counts.
Early experience shows that for small stack frames the overhead
is about 200 ms for a 1M function call loop (tst400e). This means that
for the time being we do not introduce more complex garbage
administration code.

Also note that for top-level stack frames (no environment available),
we should retain the value stack because it acts as a global variables.
This situation is indicated by the 'global' in the stack frame.
@{
Upon termination of the session, the stack should be cleared.
Beware that variables may be know polymorphic, their actual
type should be saved for variables that recide on a global
stack frame.
@c
void garbageCollector(Client cntxt, MalBlkPtr mb, MalStkPtr stk, int flag)
{
	int k;
	ValPtr v;

#ifdef STACKTRACE
	mnstr_printf(cntxt->fdout, "#--->stack before garbage collector\n");
	printStack(cntxt->fdout, mb, stk, 0);
#endif
	for (k = 0; k < mb->vtop; k++) {
		if (isVarCleanup(mb, k) && (flag || isTmpVar(mb, k))) {
			garbageElement(cntxt, v = &stk->stk[k]);
			v->vtype = TYPE_int;
			v->val.ival = int_nil;
		}
	}
#ifdef STACKTRACE
	mnstr_printf(cntxt->fdout, "#-->stack after garbage collector\n");
	printStack(cntxt->fdout, mb, stk, 0);
#else
	(void)cntxt;
#endif
}
@-
Sometimes it helps to release a BAT when it won;t be used anymore.
In this case, we have to assure that all references are cleared
as well. The routine below performs this action in the local
stack frame and its parents only.
@c
void releaseBAT(MalBlkPtr mb, MalStkPtr stk, int bid)
{
	int k;

	do {
		for (k = 0; k < mb->vtop; k++)
			if (stk->stk[k].vtype == TYPE_bat && abs(stk->stk[k].val.bval) == bid) {
				BBPdecref(bid, TRUE);
				stk->stk[k].val.ival = 0;
			}
		if (stk->up) {
			stk = stk->up;
			mb = stk->blk;
		} else
			break;
	} while (stk);
}

@-
@+ Performance section
Running the program under dataflow control will screw up the
order in which performance trace data is displayed. Moreover,
we do not clearly see the start and end of the dataflow execution,
because the performance data is the result of the 'failed' runMALdataflow().
It simply skips the barrier block upon return.

@= performanceVariables
	lng newclk = 0;
	int ppc = -2;
	lng tcs = 0;
	(void)tcs;
	if (malProfileMode) {
		setFilterOnBlock(mb, 0, 0);
		ppc = -1;
	}
@= beginProfile
	if (stk) {
		gettimeofday(&stk->clock, NULL);
		if (mb->profiler != NULL) {
			@1->clk = GDKusec();
			mal_set_lock(mal_contextLock, "DFLOWdelay");
			if (mb->profiler[stkpc].trace) {
				ppc = stkpc;
				mb->profiler[ppc].clk = 0;
				mb->profiler[ppc].ticks = 0;
				mb->profiler[ppc].clock = stk->clock;
				/* emit the instruction upon start as well */
				if (@2)
					profilerEvent(cntxt->idx, mb, stk, stkpc);
#ifdef HAVE_TIMES
				times(&stk->timer);
				mb->profiler[ppc].timer = stk->timer;
#endif
				mb->profiler[ppc].clk = @1->clk;
			}
			mal_unset_lock(mal_contextLock, "DFLOWdelay");
		}
	}
@= endProfile
	if (stk != NULL) {
		if (malProfileMode == 0)
			/* mostly true */;
		else if (@1 != NULL && ppc >= 0 && mb->profiler != NULL && mb->profiler[ppc].trace && mb->profiler[ppc].clk) {
			newclk = GDKusec();
			mb->profiler[ppc].counter++;
			mb->profiler[ppc].ticks = newclk - @1->clk;
			mb->profiler[ppc].clk += mb->profiler[ppc].clk;
			if (pci) {
				mb->profiler[ppc].rbytes = getVolume(stk, pci, 0);
				mb->profiler[ppc].wbytes = getVolume(stk, pci, 1);
			}
			profilerEvent(cntxt->idx, mb, stk, ppc);
			ppc = -1;
		}
		if (cntxt->qtimeout && time(NULL) - stk->clock.tv_usec > cntxt->qtimeout)
			throw(MAL, "mal.interpreter", RUNTIME_QRY_TIMEOUT);
	}

@-
#if @1
@= timingHndlr
if (cntxt->flags && stk->cmd != 't' && stk->cmd != 'C') {
	if (lock)
		MT_lock_set(&*lock, "timing");
	mnstr_printf(cntxt->fdout, "= ");    /* single column rendering */
	if (cntxt->flags & timerFlag) {
		char buf[32];
		snprintf(buf, sizeof(buf), LLFMT, GDKusec() - cntxt->timer);
		mnstr_printf(cntxt->fdout, "%8s usec ", buf);
	}
	if (cntxt->flags & threadFlag)
		mnstr_printf(cntxt->fdout, "\@%d ", tid);
#ifdef HAVE_SYS_RESOURCE_H
	if (cntxt->flags & ioFlag) {
		struct  rusage resource;
		getrusage(RUSAGE_SELF, &resource);
		mnstr_printf(cntxt->fdout, " %3d R",
			resource.ru_inblock - oldinblock);
		mnstr_printf(cntxt->fdout, " %3d W ",
			resource.ru_oublock - oldoublock);
	}
#endif
	if (cntxt->flags & memoryFlag) {
		struct Mallinfo memory;
		memory = MT_mallinfo();
		if (memory.arena - oldMemory.arena > 0)
			mnstr_printf(cntxt->fdout, " " SZFMT " bytes ",
				(size_t)(memory.arena - oldMemory.arena));
	}
	if (cntxt->flags & flowFlag) {
		/* calculate the read/write byte flow */
		displayVolume(cntxt, getVolume(stk, pci, 0));
		mnstr_printf(cntxt->fdout, "/");
		displayVolume(cntxt, getVolume(stk, pci, 1));
		mnstr_printf(cntxt->fdout, " ");
	}
	if (cntxt->flags & bigfootFlag) {
		displayVolume(cntxt, cntxt->vmfoot);
		mnstr_printf(cntxt->fdout, ":");
		displayVolume(cntxt, cntxt->bigfoot);
		mnstr_printf(cntxt->fdout, " ");
	}
	if (cntxt->flags & cntFlag) {
		char buf[32];
		snprintf(buf, sizeof(buf), BUNFMT, cntxt->cnt);
		mnstr_printf(cntxt->fdout, ":%6s ", buf);
	}
	{
		str line;
		line = instruction2str(mb, stk, pci, LIST_MAL_DEBUG);
		if (line) {
			mnstr_printf(cntxt->fdout, " %s\n", line);
			GDKfree(line);
		}
	}
	if (cntxt->flags & timerFlag)
		cntxt->timer = GDKusec();
	if (lock)
		MT_lock_unset(&*lock, "timing");
}
@-
#endif
@-
For performance evaluation it is handy to know the
maximal amount of bytes read/written. The actual
amount is harder to guess, because it too much
depends on the operation.
@c
lng getVolume(MalStkPtr stk, InstrPtr pci, int rd)
{
	int i, limit;
	lng vol = 0;
	BAT *b;
	int isview = 0;

	limit = rd == 0 ? pci->retc : pci->argc;
	i = rd ? pci->retc : 0;

	if (stk->stk[getArg(pci, 0)].vtype == TYPE_bat) {
		b = BBPquickdesc(ABS(stk->stk[getArg(pci, 0)].val.bval), TRUE);
		if (b)
			isview = isVIEW(b);
	}
	for (; i < limit; i++) {
		if (stk->stk[getArg(pci, i)].vtype == TYPE_bat) {
			BUN cnt = 0;

			b = BBPquickdesc(ABS(stk->stk[getArg(pci, i)].val.bval), TRUE);
			if (b == NULL)
				continue;
			cnt = BATcount(b);
			/* Usually reading views cost as much as full bats.
			   But when we output a slice that is not the case. */
			vol += ((rd && !isview) || !VIEWhparent(b)) ? headsize(b, cnt) : 0;
			vol += ((rd && !isview) || !VIEWtparent(b)) ? tailsize(b, cnt) : 0;
		}
	}
	return vol;
}

void displayVolume(Client cntxt, lng vol)
{
	char buf[32];
	formatVolume(buf, (int)sizeof(buf), vol);
	mnstr_printf(cntxt->fdout, "%s", buf);
}
@h
#endif /*  _MAL_INTERPRET_H*/
@}
