@' The contents of this file are subject to the Pathfinder Public License
@' Version 1.1 (the "License"); you may not use this file except in
@' compliance with the License.  You may obtain a copy of the License at
@' http://monetdb.cwi.nl/Legal/PathfinderLicense-1.1.html
@'
@' Software distributed under the License is distributed on an "AS IS"
@' basis, WITHOUT WARRANTY OF ANY KIND, either express or implied.  See
@' the License for the specific language governing rights and limitations
@' under the License.
@'
@' The Original Code is the Pathfinder system.
@'
@' The Original Code has initially been developed by the Database &
@' Information Systems Group at the University of Konstanz, Germany and
@' is now maintained by the Database Systems Group at the Technische
@' Universitaet Muenchen, Germany.  Portions created by the University of
@' Konstanz and the Technische Universitaet Muenchen are Copyright (C)
@' 2000-2005 University of Konstanz and (C) 2005-2006 Technische
@' Universitaet Muenchen, respectively.  All Rights Reserved.

@f pf_support
@a Stefan Manegold
@v 1.0
@t MIL primitives to support the XQuery front-end "Pathfinder"

@* Introduction
This module provides new MIL primitives to support the XQuery
implementation on top of MonetDB within the "Pathfinder" project.
@
@* Module Definition 
@m
.MODULE pf_support;

.USE malalgebra;
.USE lock;
.USE monettime;
.USE streams;

@- XML shredder (shredder.mx)
@m
.COMMAND shred_url(BAT[str,bat], str url, lng percentage, lock l) : void = CMDshred_url;
"PARAMETERS:
url - document locates at this uri is shredded. 
percentage - a number [0,100] indicating the amount of free space to reserve for updates. percentage=0 leads to a read-only document!" 

.COMMAND shred_str(BAT[str,bat], str buffer, lng percentage, lock l) : void = CMDshred_str;
"PARAMETERS:
buffer - the XML string to shred. 
percentage - a number [0,100] indicating the amount of free space to reserve for updates. percentage=0 leads to a read-only document!" 

.COMMAND shred_stream(BAT[str,bat], Stream s, lng percentage, lock l) : void = CMDshred_stream;
"PARAMETERS:
s - XML input stream. 
percentage - a number [0,100] indicating the amount of free space to reserve for updates. percentage=0 leads to a read-only document!" 


@- XML print functions (serialize.mx)
@m
.COMMAND print_doc(str,BAT[void,bat], str) : void = xquery_print_doc_main;
 "C interface to Workset print routine"

.COMMAND print_result(str mode, BAT[oid,bat] ws,
                      BAT[oid,any] loop, BAT[void,oid] iter,
                      BAT[void,oid] item, BAT[void,int] kind, 
                      BAT[oid,lng] int_values, BAT[oid,dbl] dbl_values, 
                      BAT[oid,str] str_values) : void = xquery_print_result_loop;
 "C interface to Workset result print routine, that can print multiple iters"

.COMMAND print_result(str mode, BAT[void,bat] ws,
                      BAT[void,oid] item, BAT[void,int] kind,
                      BAT[void,lng] int_values, BAT[void,dbl] dbl_values,
                      BAT[void,dbl] dec_values, BAT[void,str] str_values) : 
                            void = xquery_print_result_main;
 "C interface to Workset result print routine"



@- Multi Join
@m
.COMMAND mposjoin( BAT[oid,oid] pre, BAT[oid,oid] cont, BAT[oid, bat] ws_item )
		: BAT[void,any] = CMDmposjoin;
"PARAMETERS:
BAT[oid,oid] - the values which have to be looked up
BAT[oid,oid] - the corresponding containers in which the values have to be looked up
BAT[oid,BAT[oid,any]] - the list of bats where the values are looked up
All BAT-heads must be dense.
DESCRIPTION:
looks up the values in a list of bats. The first argument specifies the
value to be looked up (joined) and the second one saves which bat contains
the value (see also 'mvaljoin').
The result is a bat with the tail values from the batlist (any) and the same
void column like the first two arguments"

.COMMAND mvaljoin( BAT[oid,oid] pre, BAT[oid,oid] cont, BAT[oid, bat] ws_item )
		: BAT[oid,oid] = CMDmvaljoin;
"PARAMETERS:
BAT[oid,oid] - the values which have to be joined
BAT[oid,oid] - the corresponding containers in which the values have to be looked up
BAT[oid,BAT[oid,oid]] - the list of bats where the tail values are joined
All BAT-heads must be dense.
DESCRIPTION:
joins the tail values of the first argument with the tail values of the bat
from one bat of the third argument. Which bat from the list is chosen is
specified by the second argument (see also 'mposjoin').
The result is a bat with the head values of the first two arguments in the head
and the head values from the batlist"


@- new algebraic primitives
@m
.COMMAND mark_grp( BAT[any::1,oid] b , BAT[oid,oid] g)
		: BAT[any::1,OID] = CMDmark_grp_1; 
"\"grouped mark\": Produces a new BAT with per group a locally unique dense
 ascending sequense of OIDs in the tail. The tail of the first BAT (b)
 identifies the group that each BUN of b belongs to. The second BAT (g)
 represents the group extend, i.e., the head is the unique list of group IDs
 from b's tail. The tail of g gives for each group the base value for the new
 OID sequence."

.COMMAND mark_grp( BAT[any::1,oid] b , BAT[oid,any] g, oid s)
		: BAT[any::1,OID] = CMDmark_grp_2; 
"\"grouped mark\": Produces a new BAT with per group a locally unique dense
 ascending sequense of OIDs in the tail. The tail of the first BAT (b)
 identifies the group that each BUN of b belongs to. The second BAT (g)
 represents the group extend, i.e., the head is the unique list of group IDs
 from b's tail. The third argument (s) gives the base value for the new
 OID sequence of each group."

.COMMAND merged_union( any left, any right, ..any.. )
		: BAT[void,BAT] = CMDmerged_union;
"PARAMETERS:
Even number of BAT[oid,any] with dense heads and pairs of equal tail type;
all odd BATs must be head-aligned and all even BATs must be head-aligned;
first two BATs must be sorted on tail values.
DESCRIPTION:
Merges pairs of bats according to the order as defined by the first pair's tails."
@(
"Returns the union of two *tail-sorted* BATs. All BUNs of both BATs appear
 in the result, i.e., duplicates are not eliminated. As opposed to standard
 "union", the sortedness on the tail column is maintained in the result and
 all BUNs in the result appear in the same order as in their respective
 input."
@)

.COMMAND ll_tokenize( BAT[void,str] strs, BAT[void,str] seps )
		: BAT[oid,str] = CMDll_strSplit;
"PARAMETERS:
BAT[void,str] - the strings which are going to be tokenized
BAT[void,str] - separators for the strings
DESCRIPTION:
ll_tokenize is a special version of [split](bat(void,str),bat(void,str)), which
tokenizes a string using the aligned separator string and adds a row for
each substring, with the oid of the input head identifying the original boundaries."

.COMMAND round_up(dbl x) : dbl = math_unary_up_ROUND;
"PARAMETERS:
dbl - the argument to round
DESCRIPTION:
round_up rounds to 0 digits after the point. The only difference to
round(dbl, 0) is that negative numbers with .5 are rounded up 
(e.g., round(-1.5) = -1.0)."

.COMMAND normSpace(str string)
		: str = CMDnormSpace;
"PARAMETERS:
BAT[void,str] - the strings which are going to be normalized
DESCRIPTION:
normSpace normalizes the whitespaces to a single space."

.COMMAND combine_text_string( BAT[void,oid] iter, BAT[void,oid] kind, BAT[void,str] str_value, int result_size )
		: BAT[oid,str] = CMDcombine_text_string;
"PARAMETERS:
BAT[void,oid] - iter values which have to be ordered
BAT[void,oid] - one of three different kinds (strings '2@0'; text-nodes '1@0' and other nodes '0@0')
BAT[void,str] - string values of the strings and text-nodes; an empty string for each other node
DESCRIPTION:
very specialized helper function for the translation of the item-sequence-to-node-sequence function in XQuery.
It expects three aligned columns and creates one string out of adjacent strings and text-nodes,
which can be translated into a text-node again. Every other node and every new iter divide the strings.
A space is inserted if two strings are adjacent, and no space is inserted if a text-node is in between.
Empty strings are not added to the output."

.COMMAND string_join( BAT[oid,str] iter_str, BAT[oid,str] separator )
		: BAT[oid,str] = CMDstring_join;
"PARAMETERS:
BAT[oid,str] - sorted iters in the head, string values in the tail
BAT[oid,str] - separator which is added between strings, within an iter
DESCRIPTION:
string_join constructs for each iter one strings by appending the strings
with the separator for this iter in between."

.COMMAND enumerate( BAT[void,lng] startval, BAT[void,lng] length) : BAT[oid,lng] = CMDenumerate;
"PARAMETERS:
BAT[void,oid] - list of start values
BAT[void,oid] - list of length values
DESCRIPTION:
enumerate creates for each input row #length rows with the values beginning
at startval and increasing by one with every row."

.COMMAND ebv(BAT[oid, bit] b) : BAT[oid, bit] = CMDebv;
"PARAMETERS
BAT[oid, bit], sorted on head values.
DESCRIPTION:
This is a helper function to implement the XQuery ``effective boolean\n
value.'' Grouped by the head values, it will look at the tail values.\n
If for a head value there is exactly one BUN whose tail equals `true',\n
the result for this group will be `true' as well. In any other case\n
(a single `false' BUN, or multiple BUNs for this group), a `false'\n
tuple will be in the result for this group."

.COMMAND invalid_qname(BAT[any,str]) : str = CMDinvalid_qname;
"PARAMETERS
BAT[any, str] 
DESCRIPTION:
This is a helper function that tries to find an invalid qname
string. It returns the first invalid one it sees or str(nil) 
if all are ok." 

.COMMAND lastmod_time(str filename) : timestamp = CMDlastmod_time;
 "return the last modification time of a file"

.COMMAND correct_sizes(bat[void,oid] iter, bat[void,oid] item, bat[void,int] size)
                      : bat[void,int] = CMDcorrect_sizes;
 "correct subtree sizes when copying subtrees;
  silently modifies third argument (size-BAT) in place."

@- Constant Columns

In XQuery, we often have the case that BAT[void,T] all contain the same tail value
'constant columns'. In this case, we represent the column variable by a MIL
constant. The new 'constant' MIL module mimics the BAT algebra on such constants.

Regrettably, we cannot always represent constants as single MIL (non-bat) values.
Constants sometimes *need* to go into bats-of-bats. Particular cases in XQuery are 
the working set BAT[void,BAT] that contains a set of columns, and the result of staircase 
join (ditto). 

Our solution here is to represent constant columns inside a bat of bats as a 'fake' 
BAT[void,T] with a single entry [nil,c].  The routines constant2bat/bat2constant switch
between the MIL constant and the 'fake' BAT[nil,c] representation (obviously, non-constant
bats are unaffected by these calls). The switching is done automatically when 
bats fetched from a bat-of-bats (using an overloaded fetch) and put into them (with
an overloaded insert).
@m
.COMMAND is_constant(any) : bit = CMDisFakeProject;
"checks whether the parameter is a BAT[nil,c] constant column"

.COMMAND constant2bat(any col) : bat[any,any] = CMDfakeProject;
"if a column is a MIL constant c, change it into a BAT[nil,c] constant column."

.COMMAND bat2constant(any col) : any = CMDdeFakeProject;
"convert BAT[nil,c] constant column into a simple MIL constant 'c'"

.COMMAND fetch(BAT[any,bat] b, int pos) : any = CMDfetchConvert;
"fetches a bat from a bat-of-bats, and if it is a fake-bat converts it to a MIL constant"

.COMMAND insert(BAT[any::1,bat] b, any::1 head, any tail) : BAT[any::1,bat] = CMDinsertConvert;
"insert into a bat-of-bats; if a non-bat tail is inserted, it is inserted as a fake-bat."

.COMMAND append(BAT[any::1,bat] b, any tail) : BAT[any::1,bat] = CMDappendConvert;
"append into a bat-of-bats; if a non-bat tail is appended, it is appended as a fake-bat."

@- Path steps (staircase join) 
@m
@:prec_foll(following)@
@:prec_foll(preceding)@

@= prec_foll
.COMMAND @1_void (BAT[void,int] pre_size,
               BAT[oid,any] ctx,
               BAT[oid,oid] doc_pre,
               int upperbound) : BAT[oid,void] = PF@1_void;
"PARAMETERS
  pre_size: the complete size BAT (preorder rank, size)
  ctx: context node sequence (preorder rank, *)
  doc_pre: table of document containers (doc id, preorder start value)
  upperbound: upperbound for size of result context node sequence
DESCRIPTION
axis step evaluation on the @1 axis from the given context."
@m
@:scj_cmd(descorself,descendant-or-self)@
@:scj_cmd(desc,descendant)@
@:scj_cmd(ancorself,ancestor-or-self)@
@:scj_cmd(anc,ancestor)@

@= scj_cmd
.COMMAND scj_@1(BAT[void,int] pre_size,
                BAT[oid,any] ctx,
                int upperbound): BAT[oid,void] = PFscj_@1_void;
"PARAMETERS
  pre_size: the complete size BAT (preorder rank, size)
  ctx: context node sequence (preorder rank, *)
  upperbound: upperbound for size of result context node sequence
DESCRIPTION
axis step evaluation on the @2 axis from the given context."
@m
@:ll_cmd(descendant)@
@:ll_cmd(descendant_or_self)@
@:ll_cmd(child)@

@= ll_cmd
.COMMAND ll_@1(BAT[oid,oid] iter,
                   BAT[oid,oid] ctx,
                   BAT[oid,int] pre_size,
                   BAT[void,any] cands,
                   bit one_iter, bit one_ctx,
                   oid min_iter, oid max_iter,
                   bit no_iter_order, chr kind_test): BAT[oid,oid] = PFll_@1;
"PARAMETERS:
BAT[void,oid] iter (grouping relation; sorted on tail within each ctx group)
BAT[void,oid] ctx (context set; sorted on tail)
BAT[void,int] pre_size (from the working set)
BAT[oid,oid]  cands (sorted list of result candidate OIDs in the tail)
bit           one_iter (only one iter?)
bit           one_ctx  (only one ctx node, i.e., the same for all iters?)
oid           min_iter,max_iter (smallest and largest iter id)
bit           no_iter_order (descendant & descendant_or_self, only: 
               result will be ordered on item, but not sub-ordered on iter)
DESCRIPTION:
returns all nodes on the @1 axis of the ctx-nodes duplicate free for each group."
@m
@:ll_upwards(parent,parent)@
@:ll_upwards(ancestor,ancestor)@
@:ll_upwards(ancestor_or_self,ancestor-or-self)@

@= ll_upwards
.COMMAND ll_@1(BAT[oid,oid] iter,
                   BAT[oid,oid] ctx,
                   BAT[oid,int] pre_size): BAT[oid,oid] = PFll_@1;
"PARAMETERS:
BAT[void,oid] iter (grouping relation; sorted on tail within each ctx group)
BAT[void,oid] ctx (context set; sorted on tail)
BAT[void,int] pre_size (from the working set)
DESCRIPTION:
returns all nodes on the @2 axis of the ctx-nodes duplicate free for each group."
@m
@:lev_cmd(child,child)@
@:lev_cmd(parent,parent)@
@:lev_cmd(fs,following-sibling)@
@:lev_cmd(ps,preceding-sibling)@

@= lev_cmd
.COMMAND lev_@1(BAT[void,chr] pre_level,
                BAT[oid,any] ctx,
                int upperbound) : BAT[oid,void] = PFlev_@1;
"PARAMETERS
  pre_level: the complete level BAT (preorder rank, level)
  ctx: context node sequence (preorder rank, *)
  upperbound: upperbound for size of result context node sequence
DESCRIPTION
axis step evaluation on the @2 axis from the given context."

@- update primitives
@m
.COMMAND delete_nodes_prepare_pre_size (BAT[void,int] pre_size, BAT[oid,void] pre_)
	: BAT[oid,int] = CMDdelete_nodes_prepare_pre_size;
"PARAMETERS:
 BAT[void,int] pre_size
 BAT[oid,void] pre_ (pre-order ranks of nodes to be deleted)
RESULT:
 BAT[oid,int] pre-order ranks and 'fake-size' of nodes to be deleted
DESCRIPTION:
 Calculates new 'fake-sizes' of nodes to be deleted;
 optimizes 'holes' in pre_size."

@- string primitives
@m
.COMMAND splitbat(BAT[oid,str], str sep) : BAT[oid,BAT] = CMDSplitBat;
"Split the strings in the BAT on the separator sep which may not be empty.
Returns a BAT with as many BATs as the maximum number of substrings.
Each of those BATs is the same size as the input BAT and contains either
the next substring or str(nil) if there are no more substrings."

.COMMAND splitkind(BAT[oid,chr]) : BAT[oid,BAT] = CMDSplitKind;
"Split a \"kind\" BAT into separate BATs.
Returns a BAT of 5 BATs where the ith BAT is like the result of a uselect(i),
but does this in a single scan."

@- bit manipulations
@= nilarithMIL
.COMMAND nil@1(int v1, int v2) : int = CMDnil@1;
"Compute @1 on the two arguments, viewing nil as just another bit pattern."
@m
@:nilarithMIL(and)@
@:nilarithMIL(or)@
@:nilarithMIL(plus)@

@- bootstrap
@m
.COMMAND pflock(int i) : lock = CMDpflock;
 "provide a pointer to a global lock"

.PRELUDE = pf_support_prelude;
.EPILOGUE = pf_support_epilogue;

.END pf_support;

@mil
module("xtables");
module("aggrX3");
module("bat_arith");
module("mmath");
module("pcre");
module("malalgebra");
module("monettime");
module("lock");

# global constants using in the MIL translation
const empty_kind_bat := bat(void,int,0).seqbase(0@0).access(BAT_READ);
const EMPTY_STRING := 0@0;
const empty_dbl__bat := bat(void,dbl,0).seqbase(0@0).access(BAT_READ);
const empty_dec__bat := empty_dbl__bat;
const empty_str__bat := bat(void,str,0).seqbase(0@0).access(BAT_READ);
const empty_int__bat := bat(void,lng,0).seqbase(0@0).access(BAT_READ);
const bool_not := bat(void,oid,2).append(1@0).append(0@0).seqbase(0@0).access(BAT_READ);
const bool_str := bat(void,str,2).append("false").append("true").seqbase(0@0).access(BAT_READ);

# nil constants (saves some run-time casting)
const bit_nil       := bit(nil);
const chr_nil       := chr(nil);
const int_nil       := int(nil);
const lng_nil       := lng(nil);
const dbl_nil       := dbl(nil);
const oid_nil       := oid(nil);
const str_nil       := str(nil);
const stream_nil    := Stream(nil);
const lock_nil      := lock(nil);
const timestamp_nil := timestamp(nil);

PROC addValues(bat[void,any::1] container, any::1 delta) : oid
{
    container.append(delta);
    return container.reverse().find(delta);
}

PROC addValues(bat[void,any::1] container, bat[oid,any::1] delta) : bat[oid,oid]
{
    container.append(delta);
    return delta.leftjoin(container.reverse());
}

PROC mposjoin( BAT[oid,oid] pre, oid cont, BAT[oid, bat] ws_item ) : BAT[void,any] 
{
    return pre.leftfetchjoin(bat2constant(ws_item.find(cont)));
}

PROC mvaljoin( BAT[oid,oid] pre, oid cont, BAT[oid, bat] ws_item ) : BAT[oid,oid] 
{
    return pre.leftjoin(ws_item.find(cont).reverse());
}

PROC tmark_unique( any::1 col, BAT[void,any] ipik) : BAT[oid,oid]
{
    return bat(void,oid).append(reverse(ipik).fetch(0)).seqbase(0@0).access(BAT_READ);
}

PROC tmark_unique( BAT[oid,any] col, BAT[oid,any] ipik) : BAT[oid,oid]
{
    return tmark(kunique(reverse(col)),0@0);
}

PROC tmark_grp_unique( any iter, BAT[oid,any] ipik) : BAT[oid,oid]
{
    return ipik.mark(1@0);
}

PROC tmark_grp_unique( BAT[any,any] iter, BAT[oid,any] ipik) : BAT[oid,oid]
{
    if (is_constant(iter)) return ipik.mark(1@0);
    return iter.mark_grp(iter.tunique(), 1@0);
}

PROC is_type (int kind, int type_) : bit
{
        return kind.and(63) = type_;
}

PROC get_type (bat[void,int] kind, int type_) : bat[oid,void]
{
        return kind.[and](63).ord_uselect(type_); # 63 = 2^6 - 1
}

PROC get_type_node (bat[void,int] kind) : bat[oid,void]
{
        return kind.ord_uselect(NODE, int_nil);
}

PROC get_type_atomic (bat[void,int] kind) : bat[oid,void]
{
        return kind.ord_uselect(int_nil, ATOMIC);
}

PROC get_container (int kind) : oid
{
        return kind.>>(6).oid();
}

PROC get_container (bat[oid,int] kind) : bat[oid,oid]
{
        return kind.[>>](6).[oid]();
}

PROC get_container (bat[void,int] kind) : bat[void,oid]
{
        return kind.[>>](6).[oid]();
}

PROC set_kind (oid cont, int type_) : int
{
        return cont.int().<<(6).or(type_);
}

PROC set_kind (bat[void,oid] cont, int type_) : bat[void,int]
{
        return cont.[int]().[<<](6).[or](type_);
}

PROC get_types (bat[void,int] kind) : bat[void,int]
{
        return kind.[and](63); # 63 = 2^6 - 1
}

PROC correct_sizes (oid iter, bat[void,oid] item, bat[void,int] size) : bat[void,int]
{
	return correct_sizes (constant2bat(iter), item, size);
}

@- get_root
We now have frag_root populated for all XML document collections (previously only
the transient document container). Finding the root of an item entails establishing
the largest root PRE that is smaller than that item. In the general case, we need
a thetajoin for that (root < item) with a per-item {max} aggregate.

The thetajoin can get quickly out of hand in MonetDB, so we actually do a 
chunked thetajoin A.K.A. blocked nested-loops (by hand, by taking slices).
@mil
PROC replace_root(BAT[void,oid] result, BAT[oid,oid] frag_item, BAT[oid,oid] frag_frag) : void
{
        # MonetDB bogus: avoid materialized cartesian product in thetajoin using blocked nested loop
        var delta := 100000 / count(frag_frag); # generate 100K intermediate tuples max
        var cur := 0, end := count(frag_item);
        while(cur < end) {
                result.replace(leftthetajoin(frag_item.slice(cur, cur+delta), frag_frag, GE).{max}());
                cur :+= delta + 1;
        }
}

PROC get_root(BAT[oid,bat] ws, oid item, int kind, oid cont) : oid
{
        var nid_rid   := ws.fetch(NID_RID).fetch(cont);
        var map_pid   := ws.fetch(MAP_PID).fetch(cont);
        var frag_root := ws.fetch(FRAG_ROOT).fetch(cont).tmark(0@0).leftfetchjoin(nid_rid).[swizzle](map_pid);

        if (kind.is_type(ATTR)) { # convert attributes to a pre
                item := ws.fetch(ATTR_OWN).fetch(cont).find(item);
                item := nid_rid.find(item).swizzle(map_pid);
        }

        item := max(frag_root.select(oid_nil,item));
        return item;
}

PROC get_root(BAT[oid,bat] ws, BAT[void,oid] item, int kind, oid cont) : BAT[void,oid]
{
        if ((count(item) = 1)) {
        	# short-cut to avoid some extra work...
		var root := bat(void,oid).seqbase(seqbase(item));
		root.append(get_root(ws, item.fetch(0), kind, cont));
                return root.access(BAT_READ);
        }

        var seqbase := item.seqbase();
        var nid_rid   := ws.fetch(NID_RID).fetch(cont);
        var map_pid   := ws.fetch(MAP_PID).fetch(cont);
        var frag_root := ws.fetch(FRAG_ROOT).fetch(cont).tmark(0@0).leftfetchjoin(nid_rid).[swizzle](map_pid);

        if (kind.is_type(ATTR)) { # convert attributes to a pre
                item := item.leftfetchjoin(ws.fetch(ATTR_OWN).fetch(cont));
                item := item.leftfetchjoin(nid_rid).[swizzle](map_pid);
                item := item.tmark(seqbase);
        }

        var result := item.copy().access(BAT_WRITE);
        replace_root(result, item, mirror(reverse(frag_root)));
        return result.access(BAT_READ).tmark(seqbase);
}

PROC get_root(BAT[oid,bat] ws, BAT[void,oid] item, BAT[void,int] kind, BAT[void,oid] cont) : BAT[void,oid] 
{
        if ((count(kind) = 1) and (count(cont) = 1)) {
        	# short-cut avoid some extra work...
                return get_root(ws, item, kind.fetch(0), cont.fetch(0));
        }

        var seqbase := item.seqbase();
        var result := item.copy().access(BAT_WRITE);

        var attr_cont := kind.get_type(ATTR).mirror().leftfetchjoin(cont);

        # look up root fragment
        var conts := cont.tunique();
        conts@batloop() {
                var nid_rid   := ws.fetch(NID_RID).fetch($h);
                var map_pid   := ws.fetch(MAP_PID).fetch($h);
                var frag_root := ws.fetch(FRAG_ROOT).fetch($h).tmark(0@0).leftfetchjoin(nid_rid).[swizzle](map_pid);
                var frag_item := cont.ord_uselect($h).mirror().leftfetchjoin(result);
                var attr_item := attr_cont.ord_select($h);
                if (count(attr_item) > 0) {
                        attr_item := attr_item.mirror().leftfetchjoin(item);
                        attr_item := attr_item.leftfetchjoin(ws.fetch(ATTR_OWN).fetch($h));
                        attr_item := attr_item.leftfetchjoin(nid_rid).[swizzle](map_pid);
                        result.replace(attr_item);
                }
                var frag_item := cont.ord_uselect($h).mirror().leftfetchjoin(result);
                replace_root(result, frag_item, mirror(reverse(frag_root)));
                var frag_item := cont.ord_uselect($h).mirror().leftfetchjoin(result);
        }
        return result.access(BAT_READ).tmark(seqbase);
}

@- order-preserving xquery join with existential semantics

The below proc handles xquery theta-joins between l[oid,any::1] and r[oid,any::1]
(iter,value) combinations with a join predicate PRED = { LT, LE, EQ, GE, GT }.

The result are the [oid,oid] iter numbers that should be ordered on head, and within 
head on tail (hence the term 'htordered') to preserve proper xquery sequence order.

We may also get optional lx[void,any] and rx[void,any] bats that substitute the
head and tail result oid-s for something else (backmapping). These lx/rx are not always 
present though.  They are pushed inside the thetajoin when sampling indicates the result 
will become big, or when the any types are smaller than oid-s (thus always make the 
result smaller).  In this case it is better to go into the join with the substitution 
already performed.  In other cases, the  substitution is done after computing the join.

The join is *existential*, that is, each [iter_l,iter_r] is unique in the result,
and should be there iff there exists any [iter_l,v_l] and [iter_r,v_r] for which 
(v_l PRED v_r) holds. 

For equi-joins, we compute the full join and then eliminate
duplicate [oid,oid] combinations. Given the htordered result characteristic, this will 
use a merge-algorithm. However for <,>,<=,>= we even *avoid* duplicates by joining {min}(l) 
with {max}(r) for <,<= (and vice versa for >,>=). Note  that these {min}() and {max}() 
are also efficient as they also can use a merge-algorithm for aggregation.

For non-equi-joins, use use either sort-merge or nested-loop join. Note that the latter join 
does not require any reordering to achieve htordered-ness. This is a plus, but nested-loop is 
of course quadratic in complexity. On the other hand, non-equi-joins tend to be quadratic 
in their result size anyway. We check this using run-time sampling. Nested-loop is chosen if 
sampling indicates a large join result.

Finally, the theta-join is loop-lifted, in that it may be executed between two loop-lifted
expressions. In that case, only matching outer iterations (lo and ro) should be joined on value. 
In effect, it requires a join condition "(l_val PRED r_val) and (lo = ro)". As MonetDB cannot 
handle such multi-column theta-joins efficiently, the current solution exploits the fact
that the loop-lifted iterations appear contiguous in both inputs. Thus, each iteration
is a slice of both input BATs. We just go through all outer iterations, take slices, and
execute the join for corresponding iter slices on l and r; concatenating all results.
@mil
var samp256 := bat(void,lng,256LL);
{ var i := 0LL; while(i < 256LL) { samp256.append(i); i :+= 1LL; } samp256.seqbase(0@0); }

PROC htordered_unique_thetajoin( int mode,
                                 bat[oid,any::1] l, bat[oid,any::1] r,
                                 any lx, any rx) : bat[any,any]
{
    var lcnt := int(l).count();
    var rcnt := int(r).count();
    if ((lcnt = 0LL) or (rcnt = 0LL))
        return bat(oid,oid,1LL).access(BAT_READ);

    if (not(ordered(l)) or not(ordered(r)))
        ERROR("htordered_unique_thetajoin(): ordered left and right head columns (iters) expected.\n");

    if (rcnt = 1LL) {
        # it is a selection; not a join
        var v := r.fetch(0);
        var t := r.reverse().fetch(0);
        var lo := (mode >= EQ).ifthenelse(v,cast(nil,ttype(l)));
        var hi := (mode <= EQ).ifthenelse(v,cast(nil,ttype(l)));
        var sel;
        if ((mode = GT) or (mode = LT)) {
            sel := l.ord_select(lo,hi).[!=](v).ord_uselect(true);
        } else {
            sel := l.ord_uselect(lo,hi);
        }
        if (type(lx) = bat) sel := reverse(reverse(sel).leftfetchjoin(lx));
        if (type(rx) = bat) t := rx.find(t);
        return sel.project(t);
    }
    if (lcnt = 1LL) {
        return reverse(htordered_unique_thetajoin(-(mode), r, l, rx, lx));
    }
    if (mode != EQ) {
        # try to reduce footprint, first:
        # join with lx/rx only if smaller than l/r
        if (type(lx) = bat) {
            if (htype(lx) <= sht) { l := reverse(leftfetchjoin(reverse(l),lx)); lx := nil; }
        }
        if (type(rx) = bat) {
            if (htype(rx) <= sht) { r := reverse(leftfetchjoin(reverse(r),rx)); rx := nil; }
        }
        # trick: as we eliminate double matches anyway, let's not generate them to start with
        # pumps are efficient because merge-based
        if ((mode = GT) or (mode = GE)) {
            l := {max}(l);
            r := {min}(r);
        } else {
            l := {min}(l);
            r := {max}(r);
        }
        var samp := [oid]([*](samp256, int(l).count()/256LL)).leftfetchjoin(l.reverse().mark(0@0).reverse());
        var res := nlthetajoin(samp, reverse(r), mode, int(r).count() * 64LL);
        if (((2LL * batsize(res) * int(l).count()) / (1LL + int(samp).count())) > mem_maxsize()) {
            var cnt := int(res).count(); res := nil;
            # if not done, yet, join with lx/rx
            if (type(lx) = bat) l := reverse(leftfetchjoin(reverse(l),lx));
            if (type(rx) = bat) r := reverse(leftfetchjoin(reverse(r),rx));
            # a large intermediate result is better handled with nested loop (no reordering necessary)
            return nlthetajoin(l, reverse(r), mode, ((cnt+cnt) / int(samp).count())*int(r).count());
        }
    }
    var join_order := leftthetajoin(l, reverse(r), mode);

    # avoid error (lng(max(bat(oid,oid))) = nil)
    if (join_order.count() = 0) { return join_order; }

    var snd_iter := join_order.reverse().mark(0@0).reverse();
    var fst_iter := join_order.mark(0@0).reverse();
    var sorting := fst_iter.CTrefine(snd_iter); # this may hurt
    if (lng(max(sorting)) != int(sorting).count()) {
        # the output of CTrefine allows to easily check if it is kunique
        sorting := sorting.reverse().kunique().reverse(); # merge-based kunique
    }
    join_order := join_order.fetch(sorting); # this may hurt as well
    # joins with lx/rx can only be done after the CTrefine() and kunique()
    if (type(lx) = bat) join_order := reverse(leftfetchjoin(reverse(join_order),lx));
    if (type(rx) = bat) join_order := leftfetchjoin(join_order,rx);
    return join_order;
}

PROC log2(lng i) : int 
{
  var n := 0;
  while(i >= 1LL)  {
     i >>= 1; n :+= 1;
  }
  return n;
}

var lng_oid := ifthenelse(isnil(oid(LNG_MAX)),lng,oid);

# loop-lifted variant; lo and ro are the outer iteration numbers that should match
PROC ll_htordered_unique_thetajoin( int mode,
                                    bat[oid,any::2] l, bat[oid,any::2] r,
                                    bat[void,oid] lo, bat[void,oid] ro,
                                    any lx, any rx) : bat[any,any]
{
    var lo_histo := histogram(lo), lr_histo := reverse(lo_histo);
    var ro_histo := histogram(ro), rr_histo := reverse(ro_histo);
    var li := 0LL, lp := 0LL, lc := count(int(lo_histo));
    var ri := 0LL, rp := 0LL, rc := count(int(ro_histo));
    var b := new(void,bat,min(lc,rc));
    var tpe := ttype(l);

    if (not(reverse(lo).ordered()) or not(reverse(ro).ordered()))
        ERROR("htordered_unique_thetajoin(): ordered left and right outer columns (iters) expected.\n");

    # trivial case; not handled below as log2() cannot cope with max() of an empty BAT being NIL
    if ((lc = 0LL) or (rc = 0LL)) {
        return bat(oid, oid, 0).access(BAT_READ);
    }

    # in case of integer equi-join, we shift iter and value together in a lng and do a single join on that
    if ((mode = EQ) and or(or((tpe = int), (tpe = oid)), (tpe = lng)))  {
        var iter_max := 32;
        var combine := true;
        if ((tpe = lng) or (lng_oid = lng)) {
            iter_max := log2(lng(max(max(lr_histo),max(rr_histo))));
            combine := (iter_max + log2(lng(max(max(l),max(r))))) < 64;
        }
        if (combine) {
            lo := [lng](lo).access(BAT_WRITE); 
            ro := [lng](ro).access(BAT_WRITE); 
	    [:+=](lo, [<<]([lng](l.tmark(0@0)), iter_max)).access(BAT_READ);
	    [:+=](ro, [<<]([lng](r.tmark(0@0)), iter_max)).access(BAT_READ);
	    l := l.mark(0@0).leftfetchjoin(lo); 
	    r := r.mark(0@0).leftfetchjoin(ro); 
            return htordered_unique_thetajoin(EQ, l, r, lx, rx);
        }
    }

    # otherwise iterate over the outer scopes; execute the join only for a single outer iter at a time
    while((lp < lc) and (rp < rc)) {
        var lv := lr_histo.fetch(lp);
        var rv := rr_histo.fetch(rp);
        var ln := lng(lo_histo.fetch(lp));
        var rn := lng(ro_histo.fetch(rp));
        if (lv = rv) {
            # only join corresponding slices of l an r
            var bn := htordered_unique_thetajoin(mode, l.slice(li,li+ln-1), r.slice(ri,ri+rn-1), lx, rx);
            if (count(int(bn)) > 0LL) b.append(bn);
        }
        if (lv <= rv) { lp :+= 1; li :+= ln; }
        if (rv <= lv) { rp :+= 1; ri :+= rn; }
    }

    # concatenate all results
    if (count(int(b)) = 1LL) return b.fetch(0);
    var bn := bat(oid, oid, sum_lng([count]([int](b)))).access(BAT_WRITE);
    if (count(int(b)) > 0LL) [insert](const bn,b);
    return bn.access(BAT_READ);
}

@- loop-lifted staircase join
@mil
#############################################
# MIL WRAPPER for AXIS STEPS 
#
# In order to simplify the invocation of the axis steps functions, this
# interface provides...
# 

@(
@:step(descendant,descendant,scj_desc,,@:sizes_code@,,)@
@:step(descendant_or_self,descendant-or-self,scj_descorself,,@:sizes_code@,,)@
@)

@:wrap(descendant)@
@:wrap(descendant_or_self)@

@(
@:step(parent,parent,lev_parent,@:level_intro@,@:level_code@,,)@
@:step(ancestor,ancestor,scj_anc,,@:sizes_code@,,)@
@:step(ancestor_or_self,ancestor-or-self,scj_ancorself,,@:sizes_code@,,)@
@)

@:upwards(parent)@
@:upwards(ancestor)@
@:upwards(ancestor_or_self)@

@(
@:step(child,child,lev_child,@:level_intro@,@:level_code@,,)@
@)

@:wrap(child)@

@:step(following_sibling,following-sibling,lev_fs,@:level_intro@,@:level_code@,,)@
@:step(preceding_sibling,preceding-sibling,lev_ps,@:level_intro@,@:level_code@,,)@
@:step(following,following,following_void,,@:sizes_code@, @:foll_prec_code@,@:doc_pre@)@
@:step(preceding,preceding,preceding_void,,@:sizes_code@, @:foll_prec_code@,@:doc_pre@)@

@= chk_order
	if ( and(order,1) = @2 ) {
		@3 := @3.chk_order(); # just in case...
	}
@= one_iter_many_items
	# 1 iter, n items
	one_iter := TRUE;
	@:chk_order(@1@2,0,item)@
	# =>  we do not need to sort the input
	order := or(order,1);
@= many_iters_one_item
	# n iters, 1 item 
	one_item := TRUE;
	@:chk_order(@1@2,1,iter)@
	# =>  we do not need to sort the input
	order := or(order,1);
@= wrap
PROC @1 (BAT[oid,oid] iter, BAT[oid,oid] item, oid cont, BAT[oid,bat] ws, int order, BAT[void,any] cands, chr kind_test) : BAT[void,bat]
{
	var result := nil;
	var one_iter := FALSE;
	var one_item := FALSE;
	var min_iter := oid_nil;
	var max_iter := oid_nil;
	var skip_self := 1;
	if ( "@1" = "descendant_or_self" ) {
		skip_self := 0;
	}

	# check consistency
	if ( isnil(seqbase(iter)) or isnil(seqbase(item)) ) {
		ERROR("@1(0): heads of iter & item/ctx must not be NIL!");
	}
	if ( (count(iter) != count(item)) or (seqbase(iter) != seqbase(item)) ) {
		ERROR("@1(1): heads of iter & item/ctx must be aligned (count(iter)="+str(count(iter))+", count(item)="+str(count(item))+", seqbase(iter)="+str(seqbase(iter))+", seqbase(item)="+str(seqbase(item))+") !");
	}
	@:chk_order(@1(3),0,iter)@
	@:chk_order(@1(4),1,item)@
	cands := cands.chk_order(); # just in case...

	var pre_size := ws.fetch(PRE_SIZE).fetch(cont);

	# trivial cases	
	if ( (count(item) = 0) or (count(cands) = 0) or (count(pre_size) = 0) ) {
		result := new(void,bat,2).seqbase(0@0)
		          .append(bat(void,oid,0).seqbase(0@0).access(BAT_READ))
		          .append(bat(void,oid,0).seqbase(0@0).access(BAT_READ))
		          .access(BAT_READ);
		return result;
	}
	
	# special cases
	if ( count(item) = 1 ) {
		# 1 iter, 1 item
		one_iter := TRUE;
		one_item := TRUE;
		# =>  we do not need to sort neither input nor output
		order := 3;
		iter := iter.chk_order(); # just in case...
		item := item.chk_order(); # just in case...
	} else {
	# first: try cheap min==max checks on ordered columns
	if ( ordered(reverse(iter)) and (min(iter) = max(iter)) ) {
		@:one_iter_many_items(@1,(6))@
	} else {
	if ( ordered(reverse(item)) and (min(item) = max(item)) ) {
		@:many_iters_one_item(@1,(7))@
	} else {
	# then: invest in one scan to check order to save two scans for min/max
	iter := iter.chk_order(); # just in case...
	if ( ordered(reverse(iter)) and (min(iter) = max(iter)) ) {
		@:one_iter_many_items(@1,(8))@
	} else {
	item := item.chk_order(); # just in case...
	if ( ordered(reverse(item)) and (min(item) = max(item)) ) {
		@:many_iters_one_item(@1,(9))@
	}}}}}

	min_iter := min(iter);
	max_iter := max(iter);

	# pre-sort input
	if ( and(order,1) = 0 ) {
		var ord := item.tsort();
		    ord := ord.CTrefine(iter).mark(0@0).reverse();
		iter := ord.leftfetchjoin(iter);
		item := ord.leftfetchjoin(item);
		iter := iter.chk_order();
		item := item.chk_order();
	}

	# the actual location step
	if ( isnil(result) ) {
		var res := ll_@1 (iter, item, pre_size, cands, one_iter, one_item, 
		                   min_iter, max_iter, (and(order,2) = 0), kind_test);
		result := new(void,bat,2).seqbase(0@0)
		          .append(res.mark(0@0).reverse())
		          .append(res.reverse().mark(0@0).reverse())
		          .access(BAT_READ);
	}
	
	# post-sort output
	if ( (and(order,2) = 2) and not(ordered(reverse(result.fetch(1)))) ) {
		iter := result.fetch(0);
		item := result.fetch(1);
		var ord := item.tsort();
		    ord := ord.CTrefine(iter).mark(0@0).reverse();
		result := new(void,bat,2).seqbase(0@0)
		          .append(ord.leftfetchjoin(iter).chk_order())
		          .append(ord.leftfetchjoin(item).chk_order())
		          .access(BAT_READ);
	}
	
	# post-sort output
	if ( (and(order,2) = 0) and not(ordered(reverse(result.fetch(0)))) ) {
		iter := result.fetch(0);
		item := result.fetch(1);
		var ord := iter.tsort();
		    ord := ord.CTrefine(item).mark(0@0).reverse();
		result := new(void,bat,2).seqbase(0@0)
		          .append(ord.leftfetchjoin(iter).chk_order())
		          .append(ord.leftfetchjoin(item).chk_order())
		          .access(BAT_READ);
	}
	
	return result;
}
ADDHELP("@1", "tsheyar", "Sep 2004",
"PARAMETERS:\n\
BAT[void,oid] iter (grouping relation)\n\
BAT[void,oid] item (context set)\n\
oid cont (the current container of the ws)\n\
BAT[void,bat] ws (working set)\n\
int order (input & output order properties:\n\
           bit 0: input is sorted on iter(0) or item(1)\n\
           bit 1: output must be sorted on iter(0) or item(1))\n\
BAT[oid,oid] cands (sorted list of result candidate OIDs in the tail)\n\
DESCRIPTION:\n\
returns all nodes on the @1 axis of the ctx-nodes duplicate free for each group.",
"pf_support");
@
# use size concept
@= sizes_code
pre_sizes
@
# use level concept
@= level_intro
    var pre_levels := ws.fetch(PRE_LEVEL).fetch(cont);
@
@= level_code
pre_levels
@
# code for following and preceding steps
@= foll_prec_code
    # find the document root-pre's for prec_foll
    var nid_rid := ws.fetch(NID_RID).fetch(cont);
    var map_pid := ws.fetch(MAP_PID).fetch(cont);
    var doc_pre := ws.fetch(FRAG_ROOT).fetch(cont).tmark(0@0).leftfetchjoin(nid_rid).[swizzle](map_pid);
@
@= doc_pre
doc_pre,
@

@= step
PROC @1(BAT[void,oid] iter, BAT[void,oid] ctx, oid cont, BAT[void,bat] ws, int order ) : BAT[void,bat]
{
    # "order" is not (yet?) used, here.

    var pre_sizes := ws.fetch(PRE_SIZE).fetch(cont);
    @4

    var unq := {count}(iter.reverse(), iter.tunique(),FALSE);

    var offset := 0;
    var ctx_slice;

    @6

    var res_iter, res_item;
    if (count(unq) = 1) {
        res_iter := constant2bat(unq.reverse().fetch(0));
	    ctx_slice := ctx.reverse().project(nil);
	    ctx_slice := ctx_slice.chk_order(); # have to check because step expects it sorted
        res_item := @3( @5, ctx_slice, @7 pre_sizes.count()).hmark(0@0);
        res_item := res_item.chk_order();
    } else {
        res_iter := bat(void,oid);
        res_item := bat(void,oid);
        unq@batloop () {
            ctx_slice := ctx.slice(offset, offset + $t - 1).reverse().project(nil);
            ctx_slice := ctx_slice.chk_order(); # have to check because step expects it sorted
            var res := @3( @5, ctx_slice, @7 pre_sizes.count()).reverse();
            res := res.chk_order();
            res_item.append(res);
            var l := count(res);
            if (l <= $t) {
                res_iter.append(iter.slice(offset, offset + l - 1));
            } else {
                res_iter.append(res.project($h));
            }
            offset := offset + $t;
        }
        res_iter := res_iter.seqbase(0@0).access(BAT_READ).chk_order();
        res_item := res_item.seqbase(0@0).access(BAT_READ).chk_order();
    }
    return new(void,bat,2).seqbase(0@0)
           .append(res_iter)
           .append(res_item)
           .access(BAT_READ);
}
ADDHELP("@1", "tsheyar", "Sep 2004",
"PARAMETERS:\n\
BAT[void,any] iter (grouping relation)\n\
BAT[void,any] ctx (context set)\n\
oid cont (the current container of the ws)\n\
BAT[void,bat] ws (working set)\n\
DESCRIPTION:\n\
returns all nodes on the @2 axis of the ctx-nodes duplicate free for each group.",
"pf_support");

@= upwards
PROC @1(BAT[void,oid] iter, BAT[void,oid] ctx, oid cont, BAT[void,bat] ws, int order) : BAT[void,bat]
{
    # "order" is not (yet?) used, here.
    var pre_sizes := ws.fetch(PRE_SIZE).fetch(cont);
    var res := ll_@1(iter.chk_order(), ctx.chk_order(), pre_sizes);
    return new(void,bat,2).seqbase(0@0).append(hmark(res,0@0)).append(tmark(res,0@0)).access(BAT_READ);
}
@

@mil
@:loop_lifted_scj_step1(ancestor)@
@:loop_lifted_scj_step1(ancestor_or_self)@

@:loop_lifted_scj_wrap1(child)@
@:loop_lifted_scj_wrap1(descendant)@
@:loop_lifted_scj_wrap1(descendant_or_self)@

@:loop_lifted_scj_step1(parent)@
@:loop_lifted_scj_step1(following)@
@:loop_lifted_scj_step1(following_sibling)@
@:loop_lifted_scj_step1(preceding)@
@:loop_lifted_scj_step1(preceding_sibling)@
@
#==================================================================
# expansions of the loop lifted scj
# kind argument
@= kind_args
, chr kind
@
@= kind_params
, kind
@
# tagname argument
@= ns_args
, str ns
@
@= ns_params
, ns
@
@= loc_args
, str loc
@
@= loc_params
, loc
@
@= tgt_args
, str tgt
@
@= tgt_params
, tgt
@
@= nsloc_args
, str ns, str loc
@
@= nsloc_params
, ns, loc
@
@= params2
, cands, kind_test
@= postfilter
if (postfilter) {
	var pre_cont := ws.fetch(PRE_CONT).fetch(contID);
	var pre_kind := ws.fetch(PRE_KIND).fetch(contID);
	var pre_prop := ws.fetch(PRE_PROP).fetch(contID);
	if (is_constant(pre_cont)) {
                # determine a sel [qnid,qnid] of qualifying nslocs (i.e. prop IDs)
		var sel := ws.fetch(@1).fetch(bat2constant(pre_cont)).ord_uselect(@2);

                # first join on prop, getting some false hits for non ELEMENT nodes
                tmp_res := result_part_item.leftfetchjoin(pre_prop).leftjoin(sel).hmark(0@0);

                # remove false hits
                tmp_res := tmp_res.leftfetchjoin(result_part_item).leftfetchjoin(pre_kind).ord_uselect(@3).hmark(0@0).leftfetchjoin(tmp_res);
        } else {
                # the cont value refers back to multiple different containers (XPath step in transient doc container)

                # first select the element nodes
                var X := result_part_item.leftfetchjoin(pre_kind).ord_uselect(@3).hmark(0@0);

                # fetch cont and prop values
                tmp_res := X.leftfetchjoin(result_part_item);
                var X_cont  := tmp_res.leftfetchjoin(pre_cont);
                var X_prop  := tmp_res.leftfetchjoin(pre_prop);

                # get qnames using mposjoin from the source containers
		var X_nsloc := mposjoin(X_prop, X_cont, ws.fetch(@1));

                # final select
		tmp_res := X_nsloc.ord_uselect(@2).hmark(0@0).leftfetchjoin(X);
        } 
	@:mapping_code@
}
@= mapping_code
	result_part_iter := tmp_res.leftfetchjoin(result_part_iter);
	result_part_item := tmp_res.leftfetchjoin(result_part_item);
	tmp_res := nil;
@= nsloc_post
      { var nsloc := ns + ":" + loc; @:postfilter(QN_URI_LOC,nsloc,ELEMENT)@ }
@= loc_post
        @:postfilter(QN_LOC,loc,ELEMENT)@
@= ns_post
        @:postfilter(QN_URI,ns,ELEMENT)@
@= target_post
        @:postfilter(PROP_TGT,tgt,PI)@
@= kind_post
        if (postfilter) {
      		var pre_kind := ws.fetch(PRE_KIND).find(contID);
               	tmp_res := result_part_item.leftfetchjoin(pre_kind).ord_uselect(@1).hmark(0@0);
	       	@:mapping_code@
        }
@= no_pre
	cands := ws.fetch(PRE_SIZE).fetch(contID).mirror(); # no selection: cands is everything
@= kind_pre
      { cands := ws.fetch(PRE_KIND).fetch(contID); kind_test := kind; }
@= nsloc_pre
      { var nsloc := ns + ":" + loc; @:prefilter(nsloc,QN_URI_LOC)@ }
@= loc_pre
      { @:prefilter(loc,QN_LOC)@ }
@= ns_pre
      { @:prefilter(ns,QN_URI)@ }
@= prefilter
	       cands := ws.fetch(PRE_SIZE).fetch(contID).mirror();
	var pre_cont := ws.fetch(PRE_CONT).fetch(contID);
	if (is_constant(pre_cont)) {
		var qn_sel := ws.fetch(@2).fetch(bat2constant(pre_cont)).ord_uselect(@1);
                if (isnil(CATCH(cands := ws_lookup(ws, contID, qn_sel.mirror())))) {
	        	var map_pid  := ws.fetch(MAP_PID).fetch(contID);
                        var isolate := (ttype(map_pid) = oid);
                        if (isolate) {
	        	    var nid_rid  := ws.fetch(NID_RID).fetch(contID);
                	    cands := cands.leftfetchjoin(nid_rid);
                	    cands := cands.[swizzle](map_pid); 
                	    cands := cands.tsort(); 
                        } else {
                	    cands.assert_order(); 
                        }
	                if ( (count(cands) > 0) and (count(result_part_item) > 0) ) {
                                var min_cand := min(cands);
                                var min_item := min(result_part_item);
                                if ( min_cand < min_item ) {
                                        cands := cands.ord_select(min_item,oid_nil);
                                }
                        }
                        if ( (count(cands) > 0) and (count(result_part_item) > 0) ) {
                                var max_cand := max(cands);
                                var max_item := max(result_part_item);
                                if ( max_cand < max_item ) {
                                        tmp_res := result_part_item.ord_uselect(oid_nil,max_cand).hmark(0@0);
                                        @:mapping_code@
                                }
                        }
                	postfilter := false; # we have a true candidate list
                }
       } # else we use postfilter (after SCJ)

# expanding the scj for the different tests
@= loop_lifted_scj_wrap1
@:loop_lifted_scj_wrap_pre(@1)@
@
@= loop_lifted_scj_wrap_pre
@:loop_lifted_scj_step2(@1,,,,,                                                               @:params2@,@:no_pre@)@
@:loop_lifted_scj_step2(@1,_with_kind_test,  @:kind_args@, @:kind_params@,,                   @:params2@,@:kind_pre(kind)@)@
@:loop_lifted_scj_step2(@1,_with_nsloc_test, @:nsloc_args@,@:nsloc_params@,@:nsloc_post@,     @:params2@,@:nsloc_pre@)@
@:loop_lifted_scj_step2(@1,_with_ns_test,    @:ns_args@,   @:ns_params@,   @:ns_post@,        @:params2@,@:ns_pre@)@
@:loop_lifted_scj_step2(@1,_with_loc_test,   @:loc_args@,  @:loc_params@,  @:loc_post@,       @:params2@,@:loc_pre@)@
@:loop_lifted_scj_step2(@1,_with_target_test,@:tgt_args@,  @:tgt_params@,  @:target_post@,    @:params2@,@:no_pre@)@
@
@= loop_lifted_scj_wrap_post
@:loop_lifted_scj_step2(@1,,,,,                                                               @:params2@,@:no_pre@)@
@:loop_lifted_scj_step2(@1,_with_kind_test,  @:kind_args@, @:kind_params@, @:kind_post(kind)@,@:params2@,@:no_pre@)@
@:loop_lifted_scj_step2(@1,_with_nsloc_test, @:nsloc_args@,@:nsloc_params@,@:nsloc_post@,     @:params2@,@:no_pre@)@
@:loop_lifted_scj_step2(@1,_with_ns_test,    @:ns_args@,   @:ns_params@,   @:ns_post@,        @:params2@,@:no_pre@)@
@:loop_lifted_scj_step2(@1,_with_loc_test,   @:loc_args@,  @:loc_params@,  @:loc_post@,       @:params2@,@:no_pre@)@
@:loop_lifted_scj_step2(@1,_with_target_test,@:tgt_args@,  @:tgt_params@,  @:target_post@,    @:params2@,@:no_pre@)@
@
@= loop_lifted_scj_step1
@:loop_lifted_scj_step2(@1,,,,,,                                                               )@
@:loop_lifted_scj_step2(@1,_with_kind_test,  @:kind_args@, @:kind_params@, @:kind_post(kind)@,,)@
@:loop_lifted_scj_step2(@1,_with_nsloc_test, @:nsloc_args@,@:nsloc_params@,@:nsloc_post@     ,,)@
@:loop_lifted_scj_step2(@1,_with_ns_test,    @:ns_args@,   @:ns_params@,   @:ns_post@        ,,)@
@:loop_lifted_scj_step2(@1,_with_loc_test,   @:loc_args@,  @:loc_params@,  @:loc_post@       ,,)@
@:loop_lifted_scj_step2(@1,_with_target_test,@:tgt_args@,  @:tgt_params@,  @:target_post@    ,,)@
@
#==================================================================
# actual definition of the scj proc
@= loop_lifted_scj_per_cont
	result_part_iter := result_part_iter.chk_order();
	result_part_item := result_part_item.chk_order();
        result_part_cont := nil;

	# pre-test
	@4

        var result := @1 (result_part_iter, result_part_item, contID, ws, order @3);
	result_part_iter := result.fetch(0);
	result_part_item := result.fetch(1);
        result_part_cont := constant2bat(contID);
	cands := nil;

	# post-test
	@2
@
@= loop_lifted_scj_step2
PROC loop_lifted_@1_step@2 (bat[void, oid] iter, bat[void, oid] item, bat[void, oid] cont, bat[void, bat] ws @3) : bat[void,bat]
{
     return loop_lifted_@1_step@2 (iter, item, cont, ws, 0 @4);
}
PROC loop_lifted_@1_step@2 (bat[void, oid] iter, bat[void, oid] item, bat[void, oid] cont, bat[void, bat] ws, int order @3) : bat[void,bat]
{
    # handle empty results correctly
    if (iter.count() = 0) {
	var empty := bat(void,oid,0).seqbase(0@0).access(BAT_READ);
	return bat(void,bat,3).seqbase(0@0)
			    .append(empty)
			    .append(empty)
			    .append(empty)
			    .access(BAT_READ);
    }

    var result;
    var result_iter;
    var result_item;
    var result_cont;
    var tmp_res;
    var cands;
    var kind_test := chr_nil;
    var postfilter := true;

    var uniqueCont := cont.tunique().sort();
    var contID := uniqueCont.reverse().fetch(0);
    if (uniqueCont.count() = 1) {
        var result_part_cont := oid_nil;
        var result_part_iter := iter;
        var result_part_item := item;

        @:loop_lifted_scj_per_cont(@1,@5,@6,@7)@

        result_iter := result_part_iter;
        result_item := result_part_item;
        result_cont := result_part_cont;
        result_part_iter := nil;
        result_part_item := nil;
        result_part_cont := nil;
    } else {
        var result_part_cont := cont.ord_uselect(contID).hmark(0@0);
        var result_part_iter := result_part_cont.leftfetchjoin(iter);
        var result_part_item := result_part_cont.leftfetchjoin(item);

        @:loop_lifted_scj_per_cont(@1,@5,@6,@7)@

        result_iter := result_part_iter;
        result_item := result_part_item;
        result_cont := result_part_cont;
        result_part_iter := nil;
        result_part_item := nil;
        result_part_cont := nil;

        var res_mu;
	uniqueCont.slice(1,uniqueCont.count() - 1)@batloop () {
	    contID := $h;
            result_part_cont := cont.ord_uselect(contID).hmark(0@0);
            result_part_iter := result_part_cont.leftfetchjoin(iter);
            result_part_item := result_part_cont.leftfetchjoin(item);

            @:loop_lifted_scj_per_cont(@1,@5,@6,@7)@

            if ( and(order,2) = 2 )
	    {
	         res_mu := merged_union(result_item, result_part_item,
	             		   result_iter, result_part_iter,
	             		   result_cont, result_part_cont);
                 result_part_iter := nil;
                 result_part_item := nil;
                 result_part_cont := nil;
                 result_item := res_mu.fetch(0);
                 result_iter := res_mu.fetch(1);
                 result_cont := res_mu.fetch(2);
                 res_mu := nil;
	    }
	    else
	    {
	         res_mu := merged_union(result_iter, result_part_iter,
	             		   result_item, result_part_item,
	             		   result_cont, result_part_cont);
                 result_part_iter := nil;
                 result_part_item := nil;
                 result_part_cont := nil;
                 result_iter := res_mu.fetch(0);
                 result_item := res_mu.fetch(1);
                 result_cont := res_mu.fetch(2);
                 res_mu := nil;
	    }
        }
    }
    
    result_iter.access(BAT_READ);
    result_item.access(BAT_READ);
    result_cont.access(BAT_READ);
    var result_scj := bat(void,bat,3).seqbase(0@0);
    result_scj.append(result_iter);
    result_scj.append(result_item);
    result_scj.append(result_cont);

    return result_scj.access(BAT_READ);
}
@


@- update primitives
@mil

# the UPDATE_INSERT_* commands MUST be consecutive, the
# UPDATE_INSERT_LAST and UPDATE_INSERT_BEFORE commands also MUST be
# consecutive
const UPDATE_INSERT_FIRST := 1LL;
const UPDATE_INSERT_LAST := 2LL;
const UPDATE_INSERT_BEFORE := 3LL;
const UPDATE_INSERT_AFTER := 4LL;
const UPDATE_DELETE := 5LL;
const UPDATE_RENAME := 6LL;
const UPDATE_REPLACE := 7LL;

PROC myinsert(bat[any::1,any::2] oldbat, bat[any::1,any::2] newbat) : bat[any::1,any::2]
{
  if (oldbat.htype() = void) {
    # we want to maintain the void head if at all possible
    # therefore we split the update into a replace of pre-existing
    # keys and an insert of new keys where the new keys are
    # sorted
    newbat := newbat.access(BAT_WRITE).order().access(BAT_READ);
    var replvals := newbat.reverse().select(oid_nil, oid(lng(oldbat.seqbase()) + oldbat.count()), true, false).reverse();
    var newvals := newbat.reverse().select(oid(lng(oldbat.seqbase()) + oldbat.count()), oid_nil).reverse();
    oldbat.replace(replvals, true).append(newvals, true);
  } else {
    oldbat.insert(newbat);
  }
  return oldbat;
}
ADDHELP("myinsert", "sjoerd", "Apr 13 2006",
"Combination of insert and replace: insert new values and replace existing ones.",
"pf_support");

PROC myinsert(bat[any::1,any::2] oldbat, any::1 key, any::2 val) : bat[any::1,any::2]
{
  if (oldbat.htype() = void) {
    # we want to maintain the void head if at all possible
    # therefore we check whether the key already exists and do a
    # replace if it does
    if (oldbat.exist(key)) {
      oldbat.replace(key, val);
    } else {
      oldbat.insert(key, val);
    }
  } else {
    oldbat.insert(key, val);
  }
  return oldbat;
}
ADDHELP("myinsert", "sjoerd", "Apr 13 2006",
"Combination of insert and replace: insert new values and replace existing ones.",
"pf_support");

# the following four procs basically do [+] on two string bats, but they
# also work on constant values
PROC strconcat(str a, str b) : str
{
  return a + b;
}
ADDHELP("strconcat", "sjoerd", "Apr 13 2006",
"[+] on strings, except that either or both arguments can be strings instead of BATs.
If both arguments are strings, the result is a string, otherwise a BAT.",
"pf_support");
PROC strconcat(str a, bat[void,str] b) : bat[void,str]
{
  return [+](a,b);
}
ADDHELP("strconcat", "sjoerd", "Apr 13 2006",
"[+] on strings, except that either or both arguments can be strings instead of BATs.
If both arguments are strings, the result is a string, otherwise a BAT.",
"pf_support");
PROC strconcat(bat[void,str] a, str b) : bat[void,str]
{
  return [+](a,b);
}
ADDHELP("strconcat", "sjoerd", "Apr 13 2006",
"[+] on strings, except that either or both arguments can be strings instead of BATs.
If both arguments are strings, the result is a string, otherwise a BAT.",
"pf_support");
PROC strconcat(bat[void,str] a, bat[void,str] b) : bat[void,str]
{
  return [+](a,b);
}
ADDHELP("strconcat", "sjoerd", "Apr 13 2006",
"[+] on strings, except that either or both arguments can be strings instead of BATs.
If both arguments are strings, the result is a string, otherwise a BAT.",
"pf_support");

PROC findupdate(BAT[any::1,any::2] oldbat, BAT[any::1,any::2] newbat, any::1 key): any::2
{
  if (newbat.exist(key)) {
    return newbat.find(key);
  } else {
    return oldbat.find(key);
  }
}

# convert a PRE value to a RID value using the given map
PROC antiswizzle(oid o, BAT[oid,oid] map) : oid
{
  var pid := oid(lng(o) >> REMAP_PAGE_BITS);
  var revmap := map.reverse();
  if (revmap.exist(pid))
    return oid(<<(lng(revmap.find(pid)),REMAP_PAGE_BITS) + and(lng(o),REMAP_PAGE_MASK));
  return o;
}

# Move data starting at "from" of length "size" by "delta".  The
# destination *must* be a hole (XXX check this).
# Delta can be positive (move data down) or negative (move data up).
PROC movedata(bat[void,bat] ws, oid cont, oid from, int size, int delta): void
{
  if (delta = 0)
    return;			# not moving, so nothing to do

# The picture shows the layout of the tables and what the important
# variables represent.  When delta > 0, the data is moved down (and
# thus the hole is moved up).
#
#       delta > 0 (moving down)                delta < 0 (moving up)
#             |         |                            |         |
#             |         |                            |         |
# before ---->|         |                before ---->|         |
#             |---------|                            |---------|
# from ------>| ^       |<- newholefirst holefirst ->| ^       |
#             | |       |                            | |       |
#             | | size  |                            | | delta |
#             | |       |<- newholelast  holelast -->| |       |
#             | | - - - |                            |---------|
# last ------>| v       |                from ------>| ^       |
#             |---------|                            | | - - - |
# holefirst ->| |       |                            | |       |<- newholefirst
#             | | delta |                            | | size  |
#             | |       |                            | |       |
# holelast -->| v       |                last ------>| v       |<- newholelast
#             |---------|                            |---------|
# after ----->|         |                after ----->|         |
#             |         |                            |         |
#             |         |                            |         |
#
# The following areas are of interest:
# - data to be moved, this is the data with PRE values "from" to "last"
#   and given by the parameters "from" and "size";
# - hole to be overwritten, this is the hole after (if delta > 0) or
#   before (if delta < 0) the data to be moved with PRE values
#   "holefirst" to "holelast" and size "abs(delta)";
# - affected area, this is the combination of the above two areas;
# - the area before the affected area;
# - the area after the affected area.
#
# We distinguish the following nodes that each get their own treatment:
# - nodes in the area before the affected area that end inside the data
#   to be moved;
# - nodes in the area before the affected area that end inside the hole
#   to be overwritten;
# - nodes in the data to be moved that end in the hole to be overwritten
#   (only applicable if delta > 0);
# - nodes in the data to be moved that end in the area after the
#   affected area.

  var map_pid := ws.fetch(MAP_PID).find(cont);
  var map_pid_update := ws.fetch(MAP_PID_UPDATE).find(cont);

  # some helpful values
  var pageno := oid(lng(from) >> REMAP_PAGE_BITS); # page number where all this takes place
  var pageid := map_pid_update.reverse().find(pageno);
  var isoldpage := false;
  if (map_pid.exist(pageid)) {
    isoldpage := not(isnil(map_pid.find(pageid)));
  }
  # we're using RID values exclusively in this function
  from := antiswizzle(from, map_pid_update);

# var delta;                    # displacement (< 0: up, > 0: down) (parameter)
  var holefirst;                # ID of start of hole
  var holelast;                 # ID of end of hole
  var before;                   # ID of last node before area being moved and hole
# var from;                     # ID of first node being moved (parameter)
  var last;                     # ID of last node being moved
# var size;                     # size of area being moved (parameter)
  var after;                    # ID of first node after area being moved and hole
  var newholefirst;             # ID if start of to-be-created hole
  var newholelast;              # ID if end of to-be-created hole

  last := oid((lng(from) + size) - 1);
  if (delta < 0) {
    holefirst := oid(lng(from) + delta);
    holelast := oid(lng(from) - 1);
    before := oid(lng(holefirst) - 1);
    after := oid(lng(last) + 1);
    newholefirst := oid(lng(holefirst) + size);
    newholelast := oid(lng(holelast) + size);
  } else {
    holefirst := oid(lng(from) + size);
    after := oid(lng(holefirst) + delta);
    holelast := oid(lng(after) - 1);
    before := oid(lng(from) - 1);
    newholefirst := from;
    newholelast := oid(lng(from) + delta - 1);
  }

  var pre_size := ws.fetch(PRE_SIZE).find(cont);
  var rid_size := ws.fetch(_RID_SIZE).find(cont);
  var rid_size_update := ws.fetch(RID_SIZE_UPDATE).find(cont);
  var pre_level := ws.fetch(PRE_LEVEL).find(cont);
  var rid_level := ws.fetch(_RID_LEVEL).find(cont);
  var rid_level_update := ws.fetch(RID_LEVEL_UPDATE).find(cont);
  var pre_kind := ws.fetch(PRE_KIND).find(cont);
  var rid_kind := ws.fetch(_RID_KIND).find(cont);
  var rid_kind_update := ws.fetch(RID_KIND_UPDATE).find(cont);
  var pre_prop := ws.fetch(PRE_PROP).find(cont);
  var rid_prop := ws.fetch(_RID_PROP).find(cont);
  var rid_prop_update := ws.fetch(RID_PROP_UPDATE).find(cont);
  var pre_nid := ws.fetch(PRE_NID).find(cont);
  var rid_nid := ws.fetch(_RID_NID).find(cont);
  var rid_nid_update := ws.fetch(RID_NID_UPDATE).find(cont);

  # for each page prior to the one we're actually moving in, and for
  # all nodes in the page we're moving in before the affected area,
  # find the nodes (holes or real nodes) that end inside the affected
  # area (i.e. inside the data being moved or the hole that is going
  # to be overwritten) and fix up the size
  var i := 0@0;
  while (i <= pageno) {
    var pgid := map_pid_update.reverse().find(i);
    var isoldpg := map_pid.exist(pgid);
    var off := int(pgid) << REMAP_PAGE_BITS;
    var pg; # updated page
    var pgold; # original page (only valid when no update page exists)
    if (isoldpg) {
      var off_pre := int(map_pid.find(pgid)) << REMAP_PAGE_BITS;
      pgold := pg := pre_size.slice(off_pre, int(off_pre + REMAP_PAGE_MASK)).seqbase(oid(off));
      if (i = pageno) {
        pgold := pgold.reverse().select(oid_nil, before).reverse();
      }
      var rid_size_update_page := rid_size_update.reverse().select(oid(off), oid(off + REMAP_PAGE_MASK)).reverse();
      pg := pg.access(BAT_WRITE).key(true).replace(rid_size_update_page);
    } else {
      # read master page since it is exclusively ours
      pg := rid_size.slice(off, int(off + REMAP_PAGE_MASK));
    }
    if (i = pageno) {
      pg := pg.reverse().select(oid_nil, before).reverse();
    }

    # remember where the holes are
    var ishole := [niland](pg, int_nil);
    # figure out where each element in the page ends
    var pgend := [oid]([+]([int](pg.mirror()), [niland](pg, INT_MAX)));
    # select those that end in the data being moved
    var pgdata := pgend.uselect(from, last);
    # calculate new values
    if (pgdata.count() > 0) {
      var pg_update := [nilplus](pgdata.mirror().join(pg), delta);
      # apply update
      if (isoldpg) {
        rid_size_update.myinsert(pg_update);
      } else {
        rid_size.replace(pg_update, true);
      }
    }
    # select those that end in the hole being overwritten
    var pghole := pgend.uselect(holefirst, holelast);
    if (pghole.count() > 0) {
      # clamp to edge
      if (delta < 0) {
        pghole := [int]([-](int(before), [int](pghole.mirror())));
      } else {
        pghole := [int]([-](int(last), [int](pghole.mirror())));
      }
      # add hole back in and replace values on page
      var pg_update := [nilplus](pghole, pghole.mirror().join(ishole));
      if (isoldpg) {
        rid_size_update.myinsert(pg_update);
      } else {
        rid_size.replace(pg_update, true);
      }
    }
    i := oid(lng(i) + 1);
  }

  # the PRE_SIZE table has the correct sizes, but we now need to
  # actually move the data in all PRE tables
  var update_hole;
  var from_pre := swizzle(from, map_pid);
  var last_pre := swizzle(last, map_pid);

  {
    var data;
    if (isoldpage) {
      data := pre_size.reverse().select(from_pre, last_pre).reverse().copy().access(BAT_WRITE).seqbase(from).key(true);
      data.myinsert(rid_size_update.reverse().select(from, last).reverse());
    } else {
      data := rid_size.reverse().select(from, last).reverse().access(BAT_WRITE).key(true);
    }

    # update the sizes of the moved data

    # table with int(nil) for all RID values that represent holes and 0 otherwise
    var ishole := [niland](data, int_nil);
    var end_data := [oid]([+]([int](data.mirror()), [niland](data, INT_MAX)));
    # find the nodes that end inside the hole that is to disappear
    if (delta > 0) {
      var holeend := end_data.uselect(holefirst, holelast);
      var newsizes := [-](int(last), [int](holeend.mirror()));
      newsizes := [nilor](newsizes.mirror().join(ishole), newsizes);
      data.replace(newsizes);
    } # else
      # if moving backward (delta < 0) no nodes that are to be moved end
      # in the hole
    # find the nodes that end past the hole and compensate for the move
    var pastend := end_data.uselect(after, oid_nil);
    if (pastend.count() > 0) {
      var newsizes := [-](pastend.mirror().join(data), delta);
      data.replace(newsizes);
    }

    # now fix the head values (i.e. move the data)
    var update_data := data.reverse().mark(oid(lng(from) + delta)).reverse();
    # we're not actually using the tail value here...
    update_hole := rid_size.reverse().select(newholefirst, newholelast).reverse();
    if (update_hole.count() < delta) {
      var i := update_hole.count();
      update_hole := update_hole.access(BAT_WRITE).key(true);
      while (i < delta) {
        update_hole := update_hole.append(int_nil);
        i :+= 1;
      }
    }
    update_hole := [nilor]([-](update_hole.project(int(newholelast)), [int](update_hole.mirror())), int_nil);

    if (isoldpage) {
      rid_size_update.myinsert(update_hole).myinsert(update_data);
    } else {
      rid_size.replace(update_hole, true).replace(update_data, true);
    }
  }

  {
    var update_data;
    if (isoldpage) {
      update_data := pre_level.reverse().select(from_pre, last_pre).reverse().copy().seqbase(from);
      update_data := update_data.access(BAT_WRITE).key(true).myinsert(rid_level_update.reverse().select(from, last).reverse());
    } else {
      update_data := rid_level.reverse().select(from, last).reverse();
    }
    update_data := update_data.reverse().mark(oid(lng(from) + delta)).reverse();
    update_hole := update_hole.project(cast(nil, rid_level.ttype()));
    if (isoldpage) {
      rid_level_update.myinsert(update_hole).myinsert(update_data);
    } else {
      rid_level.replace(update_hole, true).replace(update_data, true);
    }
  }

  {
    var update_data;
    if (isoldpage) {
      update_data := pre_kind.reverse().select(from_pre, last_pre).reverse().copy().seqbase(from);
      update_data := update_data.access(BAT_WRITE).key(true).myinsert(rid_kind_update.reverse().select(from, last).reverse());
    } else {
      update_data := rid_kind.reverse().select(from, last).reverse();
    }
    update_data := update_data.reverse().mark(oid(lng(from) + delta)).reverse();
    update_hole := update_hole.project(cast(nil, rid_kind.ttype()));
    if (isoldpage) {
      rid_kind_update.myinsert(update_hole).myinsert(update_data);
    } else {
      rid_kind.replace(update_hole, true).replace(update_data, true);
    }
  }

  {
    var update_data;
    if (isoldpage) {
      update_data := pre_prop.reverse().select(from_pre, last_pre).reverse().copy().seqbase(from);
      update_data := update_data.access(BAT_WRITE).key(true).myinsert(rid_prop_update.reverse().select(from, last).reverse());
    } else {
      update_data := rid_prop.reverse().select(from, last).reverse();
    }
    update_data := update_data.reverse().mark(oid(lng(from) + delta)).reverse();
    update_hole := update_hole.project(oid_nil);
    if (isoldpage) {
      rid_prop_update.myinsert(update_hole).myinsert(update_data);
    } else {
      rid_prop.replace(update_hole, true).replace(update_data, true);
    }
  }

  {
    var update_data;
    if (isoldpage) {
      update_data := pre_nid.reverse().select(from_pre, last_pre).reverse().copy().seqbase(from);
      update_data := update_data.access(BAT_WRITE).key(true).myinsert(rid_nid_update.reverse().select(from, last).reverse());
    } else {
      update_data := rid_nid.reverse().select(from, last).reverse();
    }
    update_data := update_data.reverse().mark(oid(lng(from) + delta)).reverse();
    update_hole := update_hole.project(oid_nil);
    if (isoldpage) {
      rid_nid_update.myinsert(update_hole).myinsert(update_data);
    } else {
      rid_nid.replace(update_hole, true).replace(update_data, true);
    }
    var update_nid := update_data.select(oid_nil, oid_nil).reverse();
    var nid_rid_update := ws.fetch(NID_RID_UPDATE).find(cont);
    nid_rid_update.myinsert(update_nid);
  }
}
ADDHELP("movedata", "sjoerd", "Oct 4 2005",
"Move data starting in WS for document CONT, starting at FROM of size
SIZE by DELTA. Delta may be positive (move data down) or
negative. Data should only be moved over an existing hole (not
currently checked). Returns the first argument which details the
changed already made to the BATs in the working set.",
"pf_support");

PROC play_update_tape(bat[void, bat] ws, bat[void, oid] item, bat[void, int] kind, bat[void,lng] int_values, bat[void,str] str_values) : void
{
  if (MAP_PID_UPDATE != ws.count()) {
    # assert that the const values above are correct
    ERROR("Internal error: MAP_PID_UPDATE has incorrect value.");
  }

  # [void,oid] list of all conts of affected documents
  var affected_conts := [and]([lng](item.mirror()), 3LL).ord_uselect(1LL).mirror().leftfetchjoin(kind).get_container().reverse().kunique().mark(0@0).reverse();

  if (affected_conts.count() = 0) {
    # nothing to do
    # this is actually not expected to happen, but it doesn't do any harm
    return;
  }

  # check that all containers are updatable (i.e. that none are read-only)
  if ([ttype](affected_conts.join(ws.fetch(MAP_PID))).uselect(void).count() > 0) {
    ERROR("updating read-only document.\n");
  }

  # this is where we're going to collect all changes
  ws.access(BAT_WRITE);
  ws.append(new(oid,bat).key(true)); # MAP_PID_UPDATE
  ws.append(new(oid,bat).key(true)); # RID_SIZE_UPDATE
  ws.append(new(oid,bat).key(true)); # RID_LEVEL_UPDATE
  ws.append(new(oid,bat).key(true)); # RID_KIND_UPDATE
  ws.append(new(oid,bat).key(true)); # RID_PROP_UPDATE
  ws.append(new(oid,bat).key(true)); # RID_NID_UPDATE
  ws.append(new(oid,bat).key(true)); # NID_RID_UPDATE
  ws.append(new(oid,bat).key(true)); # ATTR_QN_UPDATE
  ws.append(new(oid,bat).key(true)); # ATTR_PROP_UPDATE
  ws.append(new(oid,bat).key(true)); # ATTR_OWN_UPDATE
  ws.append(new(oid,oid).set(true)); # UPDATED_TEXT
  ws.append(new(oid,bat).key(true)); # NID_QN_INS_UPDATE
  ws.append(new(oid,bat).key(true)); # NID_QN_DEL_UPDATE
  affected_conts@batloop() {
    ws.fetch(MAP_PID_UPDATE).insert($t, ws.fetch(MAP_PID).find($t).copy().access(BAT_WRITE).key(true));
    ws.fetch(RID_SIZE_UPDATE).insert($t, new(oid,int).key(true));
    ws.fetch(RID_LEVEL_UPDATE).insert($t, new(oid,chr).key(true));
    ws.fetch(RID_KIND_UPDATE).insert($t, new(oid,chr).key(true));
    ws.fetch(RID_PROP_UPDATE).insert($t, new(oid,oid).key(true));
    ws.fetch(RID_NID_UPDATE).insert($t, new(oid,oid).key(true));
    ws.fetch(NID_RID_UPDATE).insert($t, new(oid,oid).key(true));
    ws.fetch(ATTR_QN_UPDATE).insert($t, new(oid,oid).key(true));
    ws.fetch(ATTR_PROP_UPDATE).insert($t, new(oid,oid).key(true));
    ws.fetch(ATTR_OWN_UPDATE).insert($t, new(oid,oid).key(true));
    ws.fetch(NID_QN_INS_UPDATE).insert($t, new(oid,oid).key(true));
    ws.fetch(NID_QN_DEL_UPDATE).insert($t, new(oid,oid).key(true));
  }

  # extract the commands from the update tape 
  var update_cmd := [and]([lng](item.mirror()), 3LL).ord_uselect(0LL).mirror().leftfetchjoin(item).leftfetchjoin(int_values);

  {
    var rename_update := update_cmd.ord_uselect(UPDATE_RENAME);
    if (rename_update.count() > 0) {
      var update_node_item := [oid]([+]([lng](rename_update.mirror()), 1)).leftfetchjoin(item);
      var update_node_kind := [oid]([+]([lng](rename_update.mirror()), 1)).leftfetchjoin(kind);
      var update_rename := [oid]([+]([lng](rename_update.mirror()), 2)).leftfetchjoin(item).leftfetchjoin(str_values);

      # now select all the unique nodes (both item and kind must be
      # the same), and when there are multiple occurences, select the
      # *last*.
      if (update_node_item.count() > 1) {
        var update_node_unique := update_node_item.access(BAT_WRITE).revert().CTgroup().CTderive(update_node_kind.access(BAT_WRITE).revert()).CTmap().tunique().mirror();
        update_node_item := update_node_unique.leftjoin(update_node_item);
        update_node_kind := update_node_unique.leftjoin(update_node_kind);
        update_rename := update_node_unique.leftjoin(update_rename);
      }

      # now make the three BATs void-headed
      update_node_item := update_node_item.tmark(0@0);
      update_node_kind := update_node_kind.tmark(0@0);
      update_rename := update_rename.tmark(0@0);

      # do the work
      do_update_rename(ws, update_node_item, update_node_kind, update_rename);
    }
  }

  {
    var replace_update := update_cmd.ord_uselect(UPDATE_REPLACE);
    if (replace_update.count() > 0) {
      var update_node_item := [oid]([+]([lng](replace_update.mirror()), 1)).leftfetchjoin(item);
      var update_node_kind := [oid]([+]([lng](replace_update.mirror()), 1)).leftfetchjoin(kind);
      var update_replace := [oid]([+]([lng](replace_update.mirror()), 2)).leftfetchjoin(item).leftfetchjoin(str_values);

      # now select all the unique nodes (both item and kind must be
      # the same), and when there are multiple occurences, select the
      # *last*.
      if (update_node_item.count() > 1) {
        var update_node_unique := update_node_item.access(BAT_WRITE).revert().CTgroup().CTderive(update_node_kind.access(BAT_WRITE).revert()).CTmap().tunique().mirror();
        update_node_item := update_node_unique.leftjoin(update_node_item);
        update_node_kind := update_node_unique.leftjoin(update_node_kind);
        update_replace := update_node_unique.leftjoin(update_replace);
      }

      # now make the three BATs void-headed
      update_node_item := update_node_item.tmark(0@0);
      update_node_kind := update_node_kind.tmark(0@0);
      update_replace := update_replace.tmark(0@0);

      # do the work
      do_update_replace(ws, update_node_item, update_node_kind, update_replace);
    }
  }

  {
    var insert_update := update_cmd.ord_select(UPDATE_INSERT_FIRST, UPDATE_INSERT_AFTER);
    if (insert_update.count() > 0) {
      var update_node_item := [oid]([+]([lng](insert_update.mirror()), 1)).leftfetchjoin(item);
      var update_node_kind := [oid]([+]([lng](insert_update.mirror()), 1)).leftfetchjoin(kind);
      var update_insert_node_item := [oid]([+]([lng](insert_update.mirror()), 2)).leftfetchjoin(item);
      var update_insert_node_kind := [oid]([+]([lng](insert_update.mirror()), 2)).leftfetchjoin(kind);

      # UPDATE_INSERT_LAST and UPDATE_INSERT_BEFORE commands must be executed in reverse order
      var order := insert_update.ord_uselect(UPDATE_INSERT_LAST, UPDATE_INSERT_BEFORE).mark(0@0);
      if (order.count() > 0) {
        update_node_item.access(BAT_WRITE).replace(order.leftjoin(order.mirror().leftjoin(update_node_item).access(BAT_WRITE).revert().tmark(0@0)));
        update_node_kind.access(BAT_WRITE).replace(order.leftjoin(order.mirror().leftjoin(update_node_kind).access(BAT_WRITE).revert().tmark(0@0)));
        update_insert_node_item.access(BAT_WRITE).replace(order.leftjoin(order.mirror().leftjoin(update_insert_node_item).access(BAT_WRITE).revert().tmark(0@0)));
        update_insert_node_kind.access(BAT_WRITE).replace(order.leftjoin(order.mirror().leftjoin(update_insert_node_kind).access(BAT_WRITE).revert().tmark(0@0)));
        insert_update.access(BAT_WRITE).replace(order.leftjoin(order.mirror().leftjoin(insert_update).access(BAT_WRITE).revert().tmark(0@0)));
      }

      # unlike the cases above no double elimination here

      # now make the five BATs void-headed
      update_node_item := update_node_item.tmark(0@0);
      update_node_kind := update_node_kind.tmark(0@0);
      update_insert_node_item := update_insert_node_item.tmark(0@0);
      update_insert_node_kind := update_insert_node_kind.tmark(0@0);
      insert_update := insert_update.tmark(0@0);

      # do the work
      do_update_insert(ws, insert_update, update_node_item, update_node_kind, update_insert_node_item, update_insert_node_kind);
    }
  }

  {
    var delete_update := update_cmd.ord_uselect(UPDATE_DELETE);
    if (delete_update.count() > 0) {
      var update_node_item := [oid]([+]([lng](delete_update.mirror()), 1)).leftfetchjoin(item);
      var update_node_kind := [oid]([+]([lng](delete_update.mirror()), 1)).leftfetchjoin(kind);

      # now select all the unique nodes (both item and kind must be
      # the same).
      if (update_node_item.count() > 1) {
        var update_node_unique := update_node_item.CTgroup().CTderive(update_node_kind).CTmap().tunique().mirror();
        update_node_item := update_node_unique.leftjoin(update_node_item);
        update_node_kind := update_node_unique.leftjoin(update_node_kind);
      }

      # now make the two BATs void-headed
      update_node_item := update_node_item.tmark(0@0);
      update_node_kind := update_node_kind.tmark(0@0);

      # do the work
      do_update_delete(ws, update_node_item, update_node_kind);
    }
  }

  var texts := ws.fetch(UPDATED_TEXT);
  fix_consecutive_texts(ws, texts);

  # get containers in the order in which we must commit them ([COLL_ID,CONT])
  var cont_order := affected_conts.reverse().mirror().leftfetchjoin(ws.fetch(CONT_COLL)).reverse().sort();
  # acquire locks by calling ws_precommit (must be done in the correct order)
  cont_order@batloop() {
    # every change to nodes changes RID_PROP
    var cont := $t;
    var rid_prop_update := ws.fetch(RID_PROP_UPDATE).find(cont);
    var rid_prop_update_pages := [oid]([>>]([lng](rid_prop_update.mirror()), REMAP_PAGE_BITS));
    var pages := rid_prop_update_pages.tunique(); # [pg,nil]
    var rid_size_update := ws.fetch(RID_SIZE_UPDATE).find(cont);
    var rid_size_update_page := [oid]([>>]([lng](rid_size_update.mirror()), REMAP_PAGE_BITS)); # [rid,pg]
    var modified_rid := rid_size_update_page.join(pages).reverse(); # [any,rid]
    var ancestor_rid := rid_size_update_page.tdiff(pages.reverse()).reverse(); # [any,rid]
    var rid_nid := ws.fetch(_RID_NID).find(cont);
    var modified_nid := modified_rid.leftjoin(rid_nid).tmark(0@0); # [void,nid]
    var ancestor_nid := ancestor_rid.leftjoin(rid_nid).tmark(0@0); # [void,nid]
    var modified_page := pages.hmark(0@0);
    var attr_prop_update := ws.fetch(ATTR_PROP_UPDATE).find(cont);
    var attr_qn_update := ws.fetch(ATTR_QN_UPDATE).find(cont);
    var modified_attr := attr_prop_update.project(nil).kunion(attr_qn_update.project(nil)).hmark(0@0);
    ws_precommit(ws, cont, modified_page, ancestor_nid, modified_nid, modified_attr);
  }

  cont_order@batloop() {
    var cont := $t;
    ws.fetch(_MAP_PID).find(cont).access(BAT_WRITE).delete().myinsert(ws.fetch(MAP_PID_UPDATE).find(cont));
    ws.fetch(_RID_SIZE).find(cont).access(BAT_WRITE).myinsert(ws.fetch(RID_SIZE_UPDATE).find(cont));
    ws.fetch(_RID_LEVEL).find(cont).access(BAT_WRITE).myinsert(ws.fetch(RID_LEVEL_UPDATE).find(cont));
    ws.fetch(_RID_KIND).find(cont).access(BAT_WRITE).myinsert(ws.fetch(RID_KIND_UPDATE).find(cont));
    ws.fetch(_RID_PROP).find(cont).access(BAT_WRITE).myinsert(ws.fetch(RID_PROP_UPDATE).find(cont));
    ws.fetch(_RID_NID).find(cont).access(BAT_WRITE).myinsert(ws.fetch(RID_NID_UPDATE).find(cont));
    ws.fetch(_NID_RID).find(cont).access(BAT_WRITE).myinsert(ws.fetch(NID_RID_UPDATE).find(cont));
    ws.fetch(_ATTR_QN).find(cont).access(BAT_WRITE).myinsert(ws.fetch(ATTR_QN_UPDATE).find(cont));
    ws.fetch(_ATTR_PROP).find(cont).access(BAT_WRITE).myinsert(ws.fetch(ATTR_PROP_UPDATE).find(cont));
    ws.fetch(_ATTR_OWN).find(cont).access(BAT_WRITE).myinsert(ws.fetch(ATTR_OWN_UPDATE).find(cont));
  }

  cont_order@batloop() {
    var cont := $t;
    ws_postcommit(ws, cont, ws.fetch(NID_QN_INS_UPDATE).find(cont).reverse(), ws.fetch(NID_QN_DEL_UPDATE).find(cont).reverse(), empty_bat);
  }

  commit(); # XXX when logging and checkpointing is implemented, this commit() *must* go
}

# due to the order in which updates are executed, do_update_rename and
# do_update_replace don't have to contend with inserted pages or with
# nodes having changed their PRE value
PROC do_update_rename(bat[void, bat] ws, bat[void,oid] update_node_item, bat[void,int] update_node_kind, bat[void,str] update_rename) : void
{
  var conts := update_node_kind.get_container();
  var types := update_node_kind.get_types();
  var attrs := types.ord_uselect(ATTR);
  var elems := types.ord_uselect(ELEM);

  if (attrs.count() > 0) {
    attrs := attrs.mirror();
    var aitem := attrs.leftjoin(update_node_item); # [i,ATID]
    var aconts := attrs.leftjoin(conts); # [i,CONT]
    aconts.tunique()@batloop() {
      var cont := $h;
      var list := aconts.ord_uselect(cont).mirror(); # [i,i] (attributes in current container)
      var aqn := list.leftjoin(update_rename); # [i,newQName]
      var aqnid := find_qn_bulk(ws, cont, [+]("::", aqn), true); # [i,newQNID]
      var attr_qn_updates := ws.fetch(ATTR_QN_UPDATE).find(cont);
      # list.leftjoin(aitem) [i,ATID]
      # list.leftjoin(aitem).reverse() [ATID,i]
      # list.leftjoin(aitem).reverse().leftjoin(aqnid) [ATID,QNID]
      attr_qn_updates.insert(list.leftjoin(aitem).reverse().leftjoin(aqnid));
    }
  }

  if (elems.count() > 0) {
    elems := elems.mirror();
    var eitem := elems.leftjoin(update_node_item); # [i,PRE]
    var econts := elems.leftjoin(conts); # [i,CONT]
    econts.tunique()@batloop() {
      var cont := $h;

      var pre_kind := ws.fetch(PRE_KIND).find(cont);
      var rid_prop_update := ws.fetch(RID_PROP_UPDATE).find(cont);
      var pid_map := ws.fetch(PID_MAP).find(cont);

      var list := econts.ord_uselect(cont).mirror(); # [i,i] (nodes in current container)
      var epres := list.leftjoin(eitem); # [i,PRE]
      var ekinds := epres.leftfetchjoin(pre_kind); # [i,KIND]
      var esplit := ekinds.splitkind();
      var eelem := esplit.fetch(int(ELEMENT)).mirror(); # [i,i] element nodes in current container
      var epi := esplit.fetch(int(PI)).mirror(); # [i,i] processing instruction nodes in current container
      if ((esplit.fetch(int(TEXT)).count() > 0) or (esplit.fetch(int(COMMENT)).count() > 0) or (esplit.fetch(int(DOCUMENT)).count() > 0)) {
        ERROR("node must be of type ELEMENT, PI, or ATTRIBUTE\n");
      }
      if (eelem.count() > 0) {
        var eqn := eelem.leftjoin(update_rename); # [i,newQName]
        var eqnid := find_qn_bulk(ws, cont, [+]("::", eqn), true); # [i,newQNID]
        {
          var pre_nid := ws.fetch(PRE_NID).find(cont);
          var eelempre := eelem.leftjoin(epres); # [i,PRE]
          var eelemnid := eelempre.leftjoin(pre_nid); # [i,NID]
          var pre_prop := ws.fetch(PRE_PROP).find(cont);
          var eelemqnold := eelempre.leftjoin(pre_prop); # [i,oldQNID]
          var eoldnidqn := eelemnid.reverse().join(eelemqnold); # [NID,oldQNID]
          var enewnidqn := eelemnid.reverse().join(eqnid); # [NID,newQNID]
          ws.fetch(NID_QN_INS_UPDATE).find(cont).insert(enewnidqn);
          ws.fetch(NID_QN_DEL_UPDATE).find(cont).insert(eoldnidqn);
        }
        var erids := eelem.leftjoin(epres).[swizzle](pid_map); # [i,RID]
        var upd := erids.reverse().join(eqnid); # [RID,QNID]
        rid_prop_update.insert(upd);
      }
      if (epi.count() > 0) {
        var prop_ins := ws.fetch(_PROP_INS).find(cont);
        var erids := epi.leftjoin(epres).[swizzle](pid_map); # [i,RID]
        # rename comes before replace, so we don't have to deal with updated properties
        var pre_prop := ws.fetch(PRE_PROP).find(cont);
        var etgt := epi.leftjoin(update_rename); # [i,tgt]
        var eins := epi.leftjoin(epres).leftjoin(pre_prop).leftjoin(prop_ins); # [i,ins]
        var evalid := add_pi_bulk(ws, cont, etgt, eins); # [i,PROPID]
        var upd := erids.reverse().join(evalid); # [RID,PROPID]
        rid_prop_update.insert(upd);
      }
    }
  }
}

PROC do_update_replace(bat[void, bat] ws, bat[void,oid] update_node_item, bat[void,int] update_node_kind, bat[void,str] update_replace) : void
{
  var conts := update_node_kind.get_container();
  var types := update_node_kind.get_types();
  var attrs := types.ord_uselect(ATTR);
  var elems := types.ord_uselect(ELEM);
  if ((attrs.count() + elems.count()) != types.count()) {
    ERROR("node must be of type ELEMENT or ATTRIBUTE\n");
  }

  if (attrs.count() > 0) {
    attrs := attrs.mirror(); # [i,i]
    var aitem := attrs.leftjoin(update_node_item); # [i,ATID]
    var aconts := attrs.leftjoin(conts); # [i,CONT]
    aconts.tunique()@batloop() {
      var cont := $h;
      var list := aconts.ord_uselect(cont).mirror(); # [i,i]
      var aval := list.leftjoin(update_replace); # [i,update_replace]
      var avalid := add_string_bulk(ws, cont, _PROP_VAL, aval);
      var attr_prop := ws.fetch(_ATTR_PROP).find(cont);
      var attr_prop_updates := ws.fetch(ATTR_PROP_UPDATE).find(cont);
      attr_prop_updates.insert(list.leftjoin(aitem).reverse().leftjoin(avalid));
    }
  }

  if (elems.count() > 0) {
    elems := elems.mirror(); # [i,i]
    var eitem := elems.leftjoin(update_node_item); # [i.PRE]
    var econts := elems.leftjoin(conts); # [i,CONT]
    econts.tunique()@batloop() {
      var cont := $h;

      var pre_kind := ws.fetch(PRE_KIND).find(cont);
      var rid_prop := ws.fetch(_RID_PROP).find(cont);
      var rid_prop_update := ws.fetch(RID_PROP_UPDATE).find(cont);
      var pre_nid := ws.fetch(PRE_NID).find(cont);
      var pid_map := ws.fetch(PID_MAP).find(cont);

      var list := econts.ord_uselect(cont).mirror(); # [i,i] current container
      var epres := list.leftjoin(eitem); # [i,PRE]
      var ekinds := epres.leftfetchjoin(pre_kind); # [i,KIND]
      var esplit := ekinds.splitkind();
      var etext := esplit.fetch(int(TEXT)).mirror(); # [i,i] text node in current container
      var ecomment := esplit.fetch(int(COMMENT)).mirror(); # [i,i] comment node in current container
      var epi := esplit.fetch(int(PI)).mirror(); # [i,i] processing instruction node in current container
      if ((esplit.fetch(int(ELEMENT)).count() > 0) or (esplit.fetch(int(DOCUMENT)).count() > 0)) {
        ERROR("node must be of type TEXT, COMMENT, PI, or ATTRIBUTE\n");
      }
      if (etext.count() > 0) {
        var elval := etext.leftjoin(update_replace); # [i,update_replace]
        var elvalid := add_string_bulk(ws, cont, _PROP_TEXT, elval); # [i,PROPID]
        var erids := etext.leftjoin(epres).[swizzle](pid_map); # [i,RID]
        var upd := erids.reverse().join(elvalid); # [RID,PROPID]
        rid_prop_update.insert(upd);
      }
      if (ecomment.count() > 0) {
        var elval := ecomment.leftjoin(update_replace); # [i,update_replace]
        var elvalid := add_string_bulk(ws, cont, _PROP_COM, elval); # [i,PROPID]
        var erids := ecomment.leftjoin(epres).[swizzle](pid_map); # [i,RID]
        var upd := erids.reverse().join(elvalid); # [RID,PROPID]
        rid_prop_update.insert(upd);
      }
      if (epi.count() > 0) {
        var prop_tgt := ws.fetch(_PROP_TGT).find(cont);
        var erids := epi.leftjoin(epres).[swizzle](pid_map); # [i,RID]
        # replace comes after rename: deal with renamed processing instruction targets
        var props := erids.leftjoin(rid_prop_update); # [i,old PROPID]
        if (props.count() > 0) {
          var eins := props.mirror().leftjoin(update_replace); # [i,ins]
          var etgt := props.leftjoin(prop_tgt); # [i,tgt]
          var elvalid := add_pi_bulk(ws, cont, etgt, eins); # [i,new PROPID]
          var upd := erids.reverse().join(elvalid); # [RID,PROPID]
          rid_prop_update.replace(upd);
          epi := epi.kdiff(props); # only do the remaining ones
        }
        if (epi.count() > 0) {
          var pre_prop := ws.fetch(PRE_PROP).find(cont);
          var eins := epi.leftjoin(update_replace); # [i,ins]
          var etgt := epi.leftjoin(epres).leftjoin(pre_prop).leftjoin(prop_tgt);
          var elvalid := add_pi_bulk(ws, cont, etgt, eins); # [i,PROPID]
          var upd := erids.reverse().join(elvalid); # [RID,PROPID]
          rid_prop_update.insert(upd);
        }
      }
    }
  }
}

PROC do_update_insert(bat[void, bat] ws, bat[void,lng] insert_update, bat[void,oid] update_node_item, bat[void,int] update_node_kind, bat[void,oid] update_insert_node_item, bat[void,int] update_insert_node_kind) : void
{
  # extract container ID from update_insert_node_kind
  var batdoccont := update_node_kind.get_container();
  var batcont := update_insert_node_kind.get_container();

  # separate out attribute
  var types := update_insert_node_kind.get_types();
  var attrs := types.ord_uselect(ATTR);
  var elems := types.ord_uselect(ELEM);
  if ((attrs.count() + elems.count()) != types.count()) {
    ERROR("node must be of type ELEMENT or ATTRIBUTE\n");
  }

  if (attrs.count() > 0) {
    # insert attributes into node
    attrs := attrs.mirror(); # [i.i]
    var attrconts := attrs.leftjoin(batdoccont);
    attrconts.tunique()@batloop() {
      var cont := $h;

      var attr_prop_update := ws.fetch(ATTR_PROP_UPDATE).find(cont);
      var attr_own_update := ws.fetch(ATTR_OWN_UPDATE).find(cont);
      var attr_qn_update := ws.fetch(ATTR_QN_UPDATE).find(cont);
      var attr_own := ws.fetch(ATTR_OWN).find(cont);
      var attr_qn := ws.fetch(ATTR_QN).find(cont);

      var list := attrconts.ord_uselect(cont).mirror(); # [i,i]
      var aconts := list.leftjoin(batcont); # [i,ATTR_CONT]
      var aitems := list.leftjoin(update_insert_node_item); # [i,ATTR_ATTRID]

      var mapping := aitems.mark(0@0); # [i,j] mposjoin wants dense heads, so add a mapping
      var taitems := aitems.tmark(0@0); # [j,ATTR_ATTRID]
      var taconts := aconts.tmark(0@0); # [j,ATTR_CONT]

      var aqns := mposjoin(taitems, taconts, ws.fetch(ATTR_QN)); # [j,ATTR_QNID]
      var aqncont := mposjoin(taitems, taconts, ws.fetch(ATTR_CONT)); # [j,ATTR_QN_CONT]
      var aprefuriloc := mposjoin(aqns, aqncont, ws.fetch(QN_PREFIX_URI_LOC)); # [j,ATTR_PREFIX_URI_LOC]
      var aqnid := find_qn_bulk(ws, cont, aprefuriloc, true); # [j,DOC_QNID]
      aqnid := mapping.leftjoin(aqnid); # [i,DOC_QNID] map back to original numbering

      var aprops := mposjoin(taitems, taconts, ws.fetch(ATTR_PROP)); # [j,ATTR_PROPID]
      var avals := mposjoin(aprops, taconts, ws.fetch(PROP_VAL)); # [j,ATTR_VAL]
      var avalid := add_string_bulk(ws, cont, _PROP_VAL, avals); # [j,DOC_VALID]
      avalid := mapping.leftjoin(avalid); # [i,DOC_VALID]

      var aownid := list.leftjoin(update_node_item).leftjoin(ws.fetch(PRE_NID).find(cont)); # [i,DOC_NID]

      # check whether attribute already occurs on element and if so, raise error
      var aownunique := aownid.tunique().mirror(); # [DOC_NID,DOC_NID] unique owners of to-be-inserted attributes
      # get the (updated) set of attributes that belong to affected owners
      var owners := attr_own.join(aownunique).kdiff(attr_own_update) # [DOC_ATID,DOC_NID]
        .access(BAT_WRITE).insert(attr_own_update.join(aownunique));
      # for those attributes, get the (updated) QNIDs
      var qnames := owners.mirror().leftjoin(attr_qn).kdiff(attr_qn_update) # [DOC_ATID,DOC_QNID]
        .access(BAT_WRITE).insert(owners.mirror().leftjoin(attr_qn_update));
      # compbine the two
      var oldownqn := owners.reverse().join(qnames); # [DOC_NID,DOC_QNID]
      # same for the new combos
      var newownqn := aownid.reverse().join(aqnid); # [DOC_NID,newDOC_QNID]
      # intersection must be empty
      if (sintersect(oldownqn, newownqn).count() > 0) {
        ERROR("inserted attribute already present on element: use replace value\n");
      }

      # figure out an ID for the new attribute
      var attrid;
      {
        coll_lock_set(ws, cont);
        var _attr_own := ws.fetch(_ATTR_OWN).find(cont);
        var _attr_prop := ws.fetch(_ATTR_PROP).find(cont);
        var _attr_qn := ws.fetch(_ATTR_QN).find(cont);
        _attr_own.append(oid_nil, true);
        _attr_prop.append(oid_nil, true);
        _attr_qn.append(oid_nil, true);
        attrid := oid(_attr_prop.count() - 1);
        coll_lock_unset(ws, cont);
      }

      # record updates
      attr_own_update.insert(list.leftjoin(aownid).tmark(attrid));
      attr_qn_update.insert(list.leftjoin(aqnid).tmark(attrid));
      attr_prop_update.insert(list.leftjoin(avalid).tmark(attrid));
    }
  }

  if (elems.count() > 0) {
    # insert new nodes
    elems := elems.mirror(); # [i,i]
    # one at a time
    elems.leftjoin(update_insert_node_item)@batloop() {
#       if (debug) printf("\nstart of loop for argument %%d\n", int($h));
      # insertcont - container from which to insert an element
      # insertitem - item to insert
      var insertcont := batcont.fetch($h);
      var insertitem := $t;

      if (not(isnil(ws.fetch(PRE_KIND).find(insertcont).find(insertitem)))) { # don't insert holes
        # insertsize - size of item to be inserted
        # doccont - container of document-to-be-modified
        var insertsize := ws.fetch(PRE_SIZE).find(insertcont).find(insertitem) + 1;
        var doccont := batdoccont.fetch($h);
        var map_pid := ws.fetch(MAP_PID).find(doccont);
        var map_pid_update := ws.fetch(MAP_PID_UPDATE).find(doccont);

        # figure out where to insert the new element
        # the position is identified using two values: the ID of the node
        # *after* which the element is to be inserted, and the level at which
        # it is to be inserted.
        var docinsertafter := update_node_item.fetch($h);
        var docinsertlevel := ws.fetch(PRE_LEVEL).find(doccont).find(docinsertafter);
        {
          var docinsertcmd := insert_update.fetch($h);
          if (docinsertcmd = lng(UPDATE_INSERT_FIRST)) {
            docinsertlevel :+= chr(1);
          } else if (docinsertcmd = lng(UPDATE_INSERT_LAST)) {
            docinsertlevel :+= chr(1);
            docinsertafter := oid(lng(docinsertafter) + lng(ws.fetch(PRE_SIZE).find(doccont).find(docinsertafter)));
          } else if (docinsertcmd = lng(UPDATE_INSERT_BEFORE)) {
            docinsertafter := oid(lng(docinsertafter) - 1LL);
          } else if (docinsertcmd = lng(UPDATE_INSERT_AFTER)) {
            docinsertafter := oid(lng(docinsertafter) + lng(ws.fetch(PRE_SIZE).find(doccont).find(docinsertafter)));
          }
        }
        var pre_size := ws.fetch(PRE_SIZE).find(doccont);
        var rid_size := ws.fetch(_RID_SIZE).find(doccont);
        var rid_size_update := ws.fetch(RID_SIZE_UPDATE).find(doccont);
        var pre_level := ws.fetch(PRE_LEVEL).find(doccont);
        var rid_level := ws.fetch(_RID_LEVEL).find(doccont);
        var rid_level_update := ws.fetch(RID_LEVEL_UPDATE).find(doccont);
        var pre_kind := ws.fetch(PRE_KIND).find(doccont);
        var rid_kind := ws.fetch(_RID_KIND).find(doccont);
        var rid_kind_update := ws.fetch(RID_KIND_UPDATE).find(doccont);
        var pre_prop := ws.fetch(PRE_PROP).find(doccont);
        var rid_prop := ws.fetch(_RID_PROP).find(doccont);
        var rid_prop_update := ws.fetch(RID_PROP_UPDATE).find(doccont);
        var pre_nid := ws.fetch(PRE_NID).find(doccont);
        var rid_nid := ws.fetch(_RID_NID).find(doccont);
        var rid_nid_update := ws.fetch(RID_NID_UPDATE).find(doccont);
        var nid_rid := ws.fetch(NID_RID).find(doccont);
        var nid_rid_update := ws.fetch(NID_RID_UPDATE).find(doccont);

        var docsize;		# current size of document
        # if the size of item 0 was changed, used the new size, else use the original size
        # we assume that page 0 on which item 0 is located already exists...
        {
          var root_rid := antiswizzle(0@0, map_pid_update);
          if (rid_size_update.exist(root_rid)) {
            docsize := rid_size_update.find(root_rid);
          } else {
            docsize := pre_size.find(0@0);
          }
          docsize :+= 1;        # count element as well (not just size of descendants)
        }

        {
          # docinsertafter may point to a hole, so back track to a non-hole
          # item; this uses the original (unmodified) document
          var pre_kind := ws.fetch(PRE_KIND).find(doccont);
          if (isnil(pre_kind.find(docinsertafter))) {
            docinsertafter := pre_kind.reverse().select(oid_nil, docinsertafter, true, false).reverse().uselect(chr_nil, chr_nil).reverse().max();
          }
        }

        # docinsertafter uses the "old" numbering scheme (i.e. the unmodified
        # document), translate to the modified document numbering
        var docinsertafter_rid := findupdate(nid_rid, nid_rid_update, ws.fetch(PRE_NID).find(doccont).find(docinsertafter));
        docinsertafter := swizzle(docinsertafter_rid, map_pid_update);
        var docinsertbefore := oid(lng(docinsertafter) + 1);
        var docinsertbefore_rid := antiswizzle(docinsertbefore, map_pid_update);

        # the start of the page on which the new element is to be inserted
        var pageno := oid(lng(docinsertbefore) >> REMAP_PAGE_BITS);
        # the physical page id
        var pageid := map_pid_update.reverse().find(pageno);
        # the rid of the first element on the page
        var pagebase := oid(lng(pageid) << REMAP_PAGE_BITS);
        var pagelast := oid(lng(pagebase) + REMAP_PAGE_MASK);
        var isoldpage := false;
        if (map_pid.exist(pageid)) {
          isoldpage := not(isnil(map_pid.find(pageid)));
        }

        # figure out the number of holes on the page on which the new
        # element is to be inserted (we use the PRE_KIND table for this,
        # holes are indicated with NIL)
        var docpagefreespace;
        var rid_kind_page;
        if (isoldpage) {
          rid_kind_page := pre_kind.reverse().select(swizzle(pagebase, map_pid), swizzle(pagelast, map_pid)).reverse().seqbase(pagebase);
          var rid_kind_page_update := rid_kind_update.reverse().select(pagebase, pagelast).reverse();
          rid_kind_page := rid_kind_page.access(BAT_WRITE).key(true).myinsert(rid_kind_page_update);
        } else {
          rid_kind_page := rid_kind.reverse().select(pagebase, pagelast).reverse();
        }
        docpagefreespace := int((REMAP_PAGE_SIZE - rid_kind_page.count()) + rid_kind_page.uselect(chr_nil).count());

        if (insertsize > docpagefreespace) {
          # not enough space on the current page

          # size of hole at end of page
          var holeatend;
          {
            var non_hole := rid_kind_page.uselect(chr_nil, chr_nil);
            if (non_hole.count() = 0) {
              # one big hole
              holeatend := rid_kind_page.count();
            } else {
              holeatend := int(rid_kind_page.reverse().max()) - int(non_hole.reverse().max());
            }
          }
          # datasize is the size of the data after the insertpoint and before the hole at the end
          var datasize := int((REMAP_PAGE_SIZE - (lng(docinsertbefore) and REMAP_PAGE_MASK)) - holeatend);

          # number of new pages needed (we need to insert insertsize, we
          # have holeatend available; round up to whole number of pages)
          var npages := ((insertsize - holeatend) + int(REMAP_PAGE_MASK)) >> REMAP_PAGE_BITS;
          # the size of the hole we're going to insert
          # we move the bit after the insert point to the end of the last inserted page
          var shiftsize := npages << REMAP_PAGE_BITS;

          var newpages := new(void, oid, npages);
          var lastpage;
          var i := 0;
          while (i < npages) {
            lastpage := ws_newpage(ws, doccont);
            newpages.append(lastpage);
            i :+= 1;
          }
          var cpstart, cpsize, cpwhere;
          if ((holeatend = 0) and (datasize > int(REMAP_PAGE_SIZE / 2))) {
            # insert new pages before current
            newpages := newpages.seqbase(pageno);
            map_pid_update.replace([oid]([+]([int](map_pid_update.select(pageno, oid_nil, true, true)), npages)));
            map_pid_update.myinsert(newpages.reverse());
            docinsertafter_rid := antiswizzle(docinsertafter, map_pid_update);
            docinsertbefore_rid := antiswizzle(docinsertbefore, map_pid_update);
            # we need to copy the initial part of the current page to the first new page
            cpstart := oid(lng(pageid) << REMAP_PAGE_BITS);
            cpsize := int(REMAP_PAGE_SIZE) - datasize;
            cpwhere := oid(lng(newpages.fetch(0)) << REMAP_PAGE_BITS);
          } else {
            # insert new pages after current
            newpages := newpages.seqbase(oid(lng(pageno) + 1));
            map_pid_update.replace([oid]([+]([int](map_pid_update.select(pageno, oid_nil, false, true)), npages)));
            map_pid_update.myinsert(newpages.reverse());
            # we need to copy the data at the end to the end of the last new page
            cpstart := docinsertbefore_rid;
            cpsize := datasize;
            var pgstart := oid(lng(lastpage) << REMAP_PAGE_BITS);
            cpwhere := oid((lng(pgstart) + REMAP_PAGE_SIZE) - cpsize);

            if (lng(cpsize) < REMAP_PAGE_SIZE) {
              # fix up hole on last page since it doesn't extend to the
              # end of the page anymore (this will be (partially)
              # overwritten again)
              var update_hole := rid_size.reverse().select(pgstart, cpwhere, true, false).reverse();
              update_hole := [nilor]([-](update_hole.project(int(cpwhere) - 1), [int](update_hole.mirror())), int_nil);
              rid_size.replace(update_hole, true);
            }
          }

          # move data after insert point to end of last inserted page
          if (cpsize > 0) {
            var rid_size_data;
            var rid_level_data;
            var rid_kind_data;
            var rid_prop_data;
            var rid_nid_data;
            if (isoldpage) {
              var cpstart_pre := swizzle(cpstart, map_pid);
              var cpend_pre := oid((lng(cpstart_pre) + cpsize) - 1);
              rid_size_data := pre_size.reverse().select(cpstart_pre, cpend_pre).reverse().seqbase(cpstart);
              rid_level_data := pre_level.reverse().select(cpstart_pre, cpend_pre).reverse().seqbase(cpstart);
              rid_kind_data := pre_kind.reverse().select(cpstart_pre, cpend_pre).reverse().seqbase(cpstart);
              rid_prop_data := pre_prop.reverse().select(cpstart_pre, cpend_pre).reverse().seqbase(cpstart);
              rid_nid_data := pre_nid.reverse().select(cpstart_pre, cpend_pre).reverse().seqbase(cpstart);
              # update slice with replacement values
              var rid_level_update_data := rid_level_update.reverse().select(cpstart, oid(lng(cpstart) + cpsize), true, false).reverse();
              var rid_kind_update_data := rid_kind_update.reverse().select(cpstart, oid(lng(cpstart) + cpsize), true, false).reverse();
              var rid_prop_update_data := rid_prop_update.reverse().select(cpstart, oid(lng(cpstart) + cpsize), true, false).reverse();
              var rid_nid_update_data := rid_nid_update.reverse().select(cpstart, oid(lng(cpstart) + cpsize), true, false).reverse();
              var rid_size_update_data := rid_size_update.reverse().select(cpstart, oid(lng(cpstart) + cpsize), true, false).reverse();
              rid_level_data := rid_level_data.access(BAT_WRITE).key(true).myinsert(rid_level_update_data);
              rid_kind_data := rid_kind_data.access(BAT_WRITE).key(true).myinsert(rid_kind_update_data);
              rid_prop_data := rid_prop_data.access(BAT_WRITE).key(true).myinsert(rid_prop_update_data);
              rid_nid_data := rid_nid_data.access(BAT_WRITE).key(true).myinsert(rid_nid_update_data);
              rid_size_data := rid_size_data.access(BAT_WRITE).key(true).myinsert(rid_size_update_data);
            } else {
              var cpend := oid((lng(cpstart) + cpsize) - 1);
              rid_size_data := rid_size.reverse().select(cpstart, cpend).reverse();
              rid_level_data := rid_level.reverse().select(cpstart, cpend).reverse();
              rid_kind_data := rid_kind.reverse().select(cpstart, cpend).reverse();
              rid_prop_data := rid_prop.reverse().select(cpstart, cpend).reverse();
              rid_nid_data := rid_nid.reverse().select(cpstart, cpend).reverse();
            }
            if (holeatend > 0) {
              # adjust sizes of moved data that point beyond the end of it
              # there cannot be any sizes that end inside the hole, since
              # they necessarily have to start in the same hole, so they're
              # going to be overwritten
              var rid_end_data := [+]([int](rid_size_data.mirror()), [niland](rid_size_data, INT_MAX));
              var past_hole := rid_end_data.uselect(oid(lng(cpstart) + cpsize + holeatend), oid_nil, true, false);
              rid_size_data.replace([nilplus](past_hole.mirror().join(rid_size_data), -(holeatend)));
            }
            rid_size.replace(rid_size_data.tmark(cpwhere), true);
            rid_level.replace(rid_level_data.tmark(cpwhere), true);
            rid_kind.replace(rid_kind_data.tmark(cpwhere), true);
            rid_prop.replace(rid_prop_data.tmark(cpwhere), true);
            rid_nid.replace(rid_nid_data.tmark(cpwhere), true);
            var nid_rid_data := rid_nid_data.tmark(cpwhere).select(oid_nil, oid_nil).reverse();
            nid_rid_update.myinsert(nid_rid_data);

            # overwrite the just moved data with a hole
            rid_size_data := [nilor]([-](rid_size_data.project((int(cpstart) + cpsize) - 1), [int](rid_size_data.mirror())), int_nil);
            rid_level_data := rid_level_data.project(cast(nil, rid_level.ttype()));
            rid_kind_data := rid_kind_data.project(cast(nil, rid_kind.ttype()));
            rid_prop_data := rid_prop_data.project(oid_nil);
            rid_nid_data := rid_nid_data.project(oid_nil);
            if (isoldpage) {
              rid_size_update.myinsert(rid_size_data);
              rid_level_update.myinsert(rid_level_data);
              rid_kind_update.myinsert(rid_kind_data);
              rid_prop_update.myinsert(rid_prop_data);
              rid_nid_update.myinsert(rid_nid_data);
            } else {
              rid_size.replace(rid_size_data, true);
              rid_level.replace(rid_level_data, true);
              rid_kind.replace(rid_kind_data, true);
              rid_prop.replace(rid_prop_data, true);
              rid_nid.replace(rid_nid_data, true);
            }
          }

          # We've inserted new pages and copied the data on the rest of the
          # page to the end of the last inserted page.  Now increase the
          # sizes of all ancestors.  Note that no holes can cross the
          # insert point (docinsertafter points to a non-hole element)
          i := 0@0;
          while (i <= pageno) {
            var pgid := map_pid_update.reverse().find(i);
            # add this value to a RID for this page to get a PRE
            var rid2pre := (int(i) - int(pgid)) << REMAP_PAGE_BITS;
            var pgbase := oid(lng(pgid) << REMAP_PAGE_BITS);
            var pglast := oid(lng(pgbase) + REMAP_PAGE_MASK);
            var pg;
            var pgold; # original page (only valid when no update page exists)
            var isoldpg := false;
            if (map_pid.exist(pgid)) {
              isoldpg := not(isnil(map_pid.find(pgid)));
            }
            if (isoldpg) {
              var pgbase_pre := swizzle(pgbase, map_pid);
              var pglast_pre := swizzle(pglast, map_pid);
              pg := pre_size.reverse().select(pgbase_pre, pglast_pre).reverse().seqbase(pgbase);
              pgold := pg;
              if (i = pageno) {
                pgold := pgold.reverse().select(oid_nil, docinsertbefore_rid, true, false).reverse();
              }
              var rid_size_update_page := rid_size_update.reverse().select(pgbase, pglast).reverse();
              pg := pg.access(BAT_WRITE).key(true).replace(rid_size_update_page);
            } else {
              pg := rid_size.reverse().select(pgbase, pglast).reverse();
            }
            if (i = pageno) {
              pg := pg.reverse().select(oid_nil, docinsertbefore_rid, true, false).reverse();
            }

            # figure out where each element in the page ends (make [RID,PRE] bat)
            var pgend := [+]([+]([int](pg.mirror()), rid2pre), [int](pg));
            # select those that start before and end inside the moved data
            var pgdata := pgend.uselect(int(docinsertafter), int(docinsertafter) + datasize, false, true);
            if (pgdata.count() > 0) {
              var pg_update := [+](pgdata.mirror().join(pg), shiftsize + holeatend);
              # effectively insert the big hole
              if (isoldpg) {
                rid_size_update.myinsert(pg_update);
              } else {
                # we can write directly to the page
                rid_size.replace(pg_update, true);
              }
            }
            # select those that end after the moved data
            pgdata := pgend.uselect(int(docinsertafter) + datasize, int_nil, false, true);
            if (pgdata.count() > 0) {
              var pg_update := [+](pgdata.mirror().join(pg), shiftsize);
              # effectively insert the big hole
              if (isoldpg) {
                rid_size_update.myinsert(pg_update);
              } else {
                # we can write directly to the page
                rid_size.replace(pg_update, true);
              }
            }
            i := oid(lng(i) + 1);
          }
          # recalculate isoldpage (and pageid) after having inserted the new pages
          pageid := map_pid_update.reverse().find(pageno);
          isoldpage := false;
          if (map_pid.exist(pageid)) {
            isoldpage := not(isnil(map_pid.find(pageid)));
          }
        } else {
          # the inserted data fits on the current page but we may have to
          # move data around to make a hole big ineough in the right place

          # holesize is the size of the hole after the node where we have to insert
          var holesize := 0;
          {
            var rid := docinsertbefore_rid;
            var pre := docinsertbefore;
            if (int(pre) >= docsize) {
              holesize := int(REMAP_PAGE_SIZE - (lng(docsize) and REMAP_PAGE_MASK));
            }
            while ((int(pre) < docsize) and (rid <= pagelast)) {
              var s := 0;
              if (isoldpage) {
                if (rid_size_update.exist(rid)) {
                  s := rid_size_update.find(rid);
                } else {
                  s := pre_size.find(swizzle(rid, map_pid));
                }
              } else if (rid_size.exist(rid)) {
                s := rid_size.find(rid);
              }
              if (isnil(niland(s, int_nil))) {
                # we're looking at a hole
                var h := niland(s, INT_MAX) + 1;
                holesize :+= h;
                pre := oid(lng(pre) + h);
                rid := oid(lng(rid) + h);
              } else {
                # not a hole, terminate loop
                pre := oid(docsize);
              }
            }
          }
          if (holesize < insertsize) {
            # not enough space in the right place
            var holeneeded := insertsize - holesize;
            var i := 1;                 # slowly widen search
            while (holeneeded > 0) {
              # hole below?
              var rid := (int(docinsertbefore_rid) + holesize) + i;
              var pre := (int(docinsertbefore) + holesize) + i;
              # still on same page?
              if (rid <= int(pagelast)) {
                # yes
                if (pre >= docsize) {
                  # big gaping hole after the document
                  var hs := int(REMAP_PAGE_SIZE) - (docsize and int(REMAP_PAGE_MASK));
                  if (hs > holeneeded) {
                    hs := holeneeded;
                  }
#                   if (debug) printf("movedata %%d %%d %%d\n", int(docinsertafter) + holesize + 1, i, hs);
                  movedata(ws, doccont, oid(lng(docinsertbefore) + holesize), i, hs);
                  holeneeded :-= hs;
                  holesize :+= hs;
                  docsize :+= hs;
                } else {
                  # looking at hole?
                  var s := 0;
                  if (isoldpage) {
                    if (rid_size_update.exist(oid(rid))) {
                      s := rid_size_update.find(oid(rid));
                    } else {
                      s := pre_size.find(swizzle(oid(rid), map_pid));
                    }
                  } else if (rid_size.exist(oid(rid))) {
                    s := rid_size.find(oid(rid));
                  }
                  if (isnil(niland(s, int_nil))) {
                    var hs := niland(s, INT_MAX) + 1;
                    if (hs > holeneeded) {
                      hs := holeneeded;
                    }
                    # move the hole to just below the hole already at docinsertafter
#                     if (debug) printf("movedata %%d %%d %%d\n", int(docinsertafter) + holesize + 1, i, hs);
                    movedata(ws, doccont, oid(lng(docinsertbefore) + holesize), i, hs);
                    holeneeded :-= hs;
                    holesize :+= hs;
                  }
                }
              }
              rid := (int(docinsertbefore_rid) - 1) - i; # must be int/lng because can become negative
              if ((rid >= int(pagebase)) and (holeneeded > 0)) {
                # hole above?
                var knd;
                if (isoldpage) {
                  if (rid_kind_update.exist(oid(rid))) {
                    knd := rid_kind_update.find(oid(rid));
                  } else {
                    knd := pre_kind.find(swizzle(oid(rid), map_pid));
                  }
                } else {
                  knd := rid_kind.find(oid(rid));
                }
                if (isnil(knd)) {
                  # yes, find out how large, but stop when we have a hole
                  # that is big enough (and stay on the page)
                  var pgkd;
                  if (isoldpage) {
                    pgkd := pre_kind.reverse().select(swizzle(pagebase, map_pid), swizzle(oid(rid - 1), map_pid)).reverse().seqbase(pagebase);
                    var pgkdup := rid_kind_update.reverse().select(pagebase, oid(rid - 1)).reverse();
                    if (pgkdup.count() > 0) {
                      pgkd := pgkd.access(BAT_WRITE).key(true).myinsert(pgkdup);
                    }
                  } else {
                    pgkd := rid_kind.reverse().select(pagebase, oid(rid - 1)).reverse();
                  }
                  var non_holes := pgkd.uselect(chr_nil, chr_nil);
                  var hs;
                  if (non_holes.count() > 0) {
                    hs := rid - int(non_holes.reverse().max());
                  } else {
                    hs := (rid and int(REMAP_PAGE_MASK)) + 1;
                  }
                  if (hs > holeneeded) {
                    hs := holeneeded;
                  }
#                   if (debug) printf("movedata %%d %%d %%d\n", int(docinsertafter) - i, i, -(hs));
                  movedata(ws, doccont, oid(lng(docinsertbefore) - i), i, -(hs));
                  docinsertafter := oid(lng(docinsertafter) - hs);
                  docinsertafter_rid := oid(lng(docinsertafter_rid) - hs);
                  holeneeded :-= hs;
                  holesize :+= hs;
                }
              }
              i :+= 1;
            }
          }
        }

        # we now have a hole that is big enough below docinsertafter

        # We must adjust the sizes of all ancestors of the new element;
        # this means all elements that currently end at the newly created
        # hole and whose level is less than the level of the new element
        {
          var i := 0@0;
          while (i <= pageno) {
            var pgid := map_pid_update.reverse().find(i);
            # add this value to a RID for this page to get a PRE
            var rid2pre := (int(i) - int(pgid)) << REMAP_PAGE_BITS;
            var pgbase := oid(lng(pgid) << REMAP_PAGE_BITS);
            var pglast := oid(lng(pgbase) + REMAP_PAGE_MASK);
            var szpg;
            var szpgold; # original page (only valid when no update page exists)
            var lvpg;
            var isoldpg := false;
            if (map_pid.exist(pgid)) {
              isoldpg := not(isnil(map_pid.find(pgid)));
            }
            if (isoldpg) {
              var pgbase_pre := swizzle(pgbase, map_pid);
              var pglast_pre := swizzle(pglast, map_pid);
              lvpg := pre_level.reverse().select(pgbase_pre, pglast_pre).reverse().seqbase(pgbase);
              szpg := pre_size.reverse().select(pgbase_pre, pglast_pre).reverse().seqbase(pgbase);
              szpgold := szpg;
              if (i = pageno) {
                szpgold := szpgold.reverse().select(oid_nil, docinsertbefore_rid, true, false).reverse();
              }
              szpg := szpg.access(BAT_WRITE).key(true).replace(rid_size_update.reverse().select(pgbase, pglast).reverse());
              lvpg := lvpg.access(BAT_WRITE).key(true).replace(rid_level_update.reverse().select(pgbase, pglast).reverse());
            } else {
              lvpg := rid_level.reverse().select(pgbase, pglast).reverse();
              szpg := rid_size.reverse().select(pgbase, pglast).reverse();
            }
            if (i = pageno) {
              szpg := szpg.reverse().select(oid_nil, docinsertbefore_rid, true, false).reverse();
            }

            # figure out where each element in the page ends
            var szpgend := [+]([+]([int](szpg.mirror()), rid2pre), szpg);
            # select those that start before and end at the insertpoint
            szpgend := szpgend.reverse().select(oid_nil, docinsertafter).reverse();
            var szpgdata := szpgend.uselect(int(docinsertafter));
            if (szpgdata.count() > 0) {
              # subselect those elements with level < docinsertlevel
              # these are the elements whose size we have to adjust
              szpgdata := szpgdata.mirror().join(lvpg).uselect(chr_nil, chr(docinsertlevel), true, false);
              if (szpgdata.count() > 0) {
                var szpg_update := [+](szpgdata.mirror().join(szpg), insertsize);
                if (isoldpg) {
                  rid_size_update.myinsert(szpg_update);
                } else {
                  # we can write directly to the page
                  rid_size.replace(szpg_update, true);
                }
              }
            }
            i := oid(lng(i) + 1);
          }
        }

        # copy the new element to the hole and do all the other work
        # only look at unedited version of to-be-inserted document
        # (required semantics)

        # get NID values for new nodes
        var newnids := ws_newnids(ws, doccont, insertsize).hmark(0@0); # [idx,NID]
        var newnididx := 0@0;

        var insert_pre_size := ws.fetch(PRE_SIZE).find(insertcont);
        var insert_pre_level := ws.fetch(PRE_LEVEL).find(insertcont);
        var insert_pre_prop := ws.fetch(PRE_PROP).find(insertcont);
        var insert_pre_kind := ws.fetch(PRE_KIND).find(insertcont);
        var insert_pre_nid := ws.fetch(PRE_NID).find(insertcont);
        var insert_pre_cont := ws.fetch(PRE_CONT).find(insertcont);
        var samedoc := false;     # perhaps we can optimize
        if (is_constant(insert_pre_cont)) {
          insert_pre_cont := bat2constant(insert_pre_cont);
          if (insert_pre_cont = doccont) {
            samedoc := true;
          }
        }
        var insert_attr_own := ws.fetch(ATTR_OWN).find(insertcont);
        var insert_attr_qn := ws.fetch(ATTR_QN).find(insertcont);
        var insert_attr_cont := ws.fetch(ATTR_CONT).find(insertcont);
        var sameattrdoc := false;
        if (is_constant(insert_attr_cont)) {
          insert_attr_cont := bat2constant(insert_attr_cont);
          if (insert_attr_cont = doccont) {
            sameattrdoc := true;
          }
        }
        var insert_attr_prop := ws.fetch(ATTR_PROP).find(insertcont);

        var attr_own := ws.fetch(ATTR_OWN).find(doccont);
        var attr_own_update := ws.fetch(ATTR_OWN_UPDATE).find(doccont);
        var attr_qn_update := ws.fetch(ATTR_QN_UPDATE).find(doccont);
        var attr_prop_update := ws.fetch(ATTR_PROP_UPDATE).find(doccont);
        var nid_qn_ins_update := ws.fetch(NID_QN_INS_UPDATE).find(doccont);

        # the difference in level for inserted elements between original
        # document and updated document
        var leveldiff := int(docinsertlevel) - int(insert_pre_level.find(insertitem));
#         if (debug) printf("leveldiff %%d\n", leveldiff);

        if (insert_pre_kind.find(insertitem) = TEXT) {
          # if we're inserting a text node, we may have to merge
          # consecutive text nodes
          # we remember the position in a hacky place
          # note, insertsize == 1 in this case
          var texts := ws.fetch(UPDATED_TEXT);
          texts.insert(doccont, newnids.find(newnididx));
        }

        # do the actual insert: copy the data from the source document
        # into the prepared hole
        # docinsertpoint is the point at which the next batch is going to be inserted
        var docinsertpoint := oid(lng(docinsertafter) + 1);
        while (insertsize > 0) {
          # docinsertpoint_rid is the RID for the new data
          var docinsertpoint_rid := antiswizzle(docinsertpoint, map_pid_update);
          # one page at a time
          var batchsize := REMAP_PAGE_SIZE - (lng(docinsertpoint) and REMAP_PAGE_MASK);
          if (batchsize > lng(insertsize)) {
            batchsize := lng(insertsize);
          }
          var insprop := insert_pre_prop.reverse().select(insertitem, oid(lng(insertitem) + batchsize), true, false).reverse();
          var inskind := insert_pre_kind.reverse().select(insertitem, oid(lng(insertitem) + batchsize), true, false).reverse();
          var inssize := insert_pre_size.reverse().select(insertitem, oid(lng(insertitem) + batchsize), true, false).reverse();
          var inslevel := insert_pre_level.reverse().select(insertitem, oid(lng(insertitem) + batchsize), true, false).reverse();
          var insnid := insert_pre_nid.reverse().select(insertitem, oid(lng(insertitem) + batchsize), true, false).reverse();
          inslevel := [chr]([+]([int](inslevel), leveldiff));
          var texts, comments, pis, elems;
          var lastdata := insertitem;
          {
            var kindbats := inskind.splitkind();
            texts := kindbats.fetch(int(TEXT));
            comments := kindbats.fetch(int(COMMENT));
            pis := kindbats.fetch(int(PI));
            elems := kindbats.fetch(int(ELEMENT));
            var docs := kindbats.fetch(int(DOCUMENT));
            if (docs.count() > 0) {
              lastdata := docs.reverse().max();
            }
          }
          var insnnids := inskind.uselect(chr_nil, chr_nil).mark(newnididx).join(newnids); # PRE-New NID
          newnididx := oid(wrd(newnididx) + insnnids.count());
          if (not(samedoc)) {
            insprop := insprop.copy().access(BAT_WRITE);
            if (texts.count() > 0) {
              lastdata := max(lastdata, texts.reverse().max());
              texts := texts.mirror().tmark(0@0);
              var textval := mposjoin(texts.leftjoin(insert_pre_prop), texts.leftjoin(insert_pre_cont), ws.fetch(PROP_TEXT));
              var textids := add_string_bulk(ws, doccont, _PROP_TEXT, textval);
              insprop.replace(texts.reverse().join(textids));
            }
            if (comments.count() > 0) {
              lastdata := max(lastdata, comments.reverse().max());
              comments := comments.mirror().tmark(0@0);
              var commentval := mposjoin(comments.leftjoin(insert_pre_prop), comments.leftjoin(insert_pre_cont), ws.fetch(PROP_COM));
              var commentids := add_string_bulk(ws, doccont, _PROP_COM, commentval);
              insprop.replace(comments.reverse().join(commentids));
            }
            if (pis.count() > 0) {
              lastdata := max(lastdata, pis.reverse().max());
              pis := pis.mirror().tmark(0@0);
              var insval := mposjoin(pis.leftjoin(insert_pre_prop), pis.leftjoin(insert_pre_cont), ws.fetch(PROP_INS));
              var tgtval := mposjoin(pis.leftjoin(insert_pre_prop), pis.leftjoin(insert_pre_cont), ws.fetch(PROP_TGT));
              var piids := add_pi_bulk(ws, doccont, tgtval, insval);
              insprop.replace(pis.reverse().join(pis.reverse().join(piids)));
            }
          }
          if (elems.count() > 0) {
            lastdata := max(lastdata, elems.reverse().max());
            elems := elems.mirror(); # PRE-PRE subset of the elements
            var prenids := elems.leftjoin(insert_pre_nid); # PRE-NID subset of the elements
            var preattrs := prenids.leftjoin(insert_attr_own.reverse()); # PRE_ATID of all attrs on the element subset, ATID is key
            var attrattrs := preattrs.reverse().mirror(); # ATID-ATID
            var attrnqnids; # ATID-New QNID
            if (sameattrdoc) {
              attrnqnids := attrattrs.leftjoin(insert_attr_qn);
            } else {
              var a := attrattrs.tmark(0@0);
              var prefurilocval := mposjoin(a.leftjoin(insert_attr_qn), a.leftjoin(insert_attr_cont), ws.fetch(QN_PREFIX_URI_LOC));
              attrnqnids := a.reverse().leftjoin(find_qn_bulk(ws, doccont, prefurilocval, true));
            }
            var attrnprops; # ATID-New PROPID
            if (sameattrdoc) {
              attrnprops := attrattrs.leftjoin(insert_attr_prop);
            } else {
              var a := attrattrs.tmark(0@0);
              var propval := mposjoin(a.leftjoin(insert_attr_prop), a.leftjoin(insert_attr_cont), ws.fetch(PROP_VAL));
              attrnprops := a.reverse().leftjoin(add_string_bulk(ws, doccont, _PROP_VAL, propval));
            }
            if (attrattrs.count() > 0) {
              # first claim enough entries in the ATTR table with the lock set
              var attrattrsnil := attrattrs.project(oid_nil);
              coll_lock_set(ws, doccont);
              var _attr_own := ws.fetch(_ATTR_OWN).find(doccont);
              var _attr_prop := ws.fetch(_ATTR_PROP).find(doccont);
              var _attr_qn := ws.fetch(_ATTR_QN).find(doccont);
              _attr_own.append(attrattrsnil, true);
              _attr_prop.append(attrattrsnil, true);
              _attr_qn.append(attrattrsnil, true);
              var attr_id := oid(_attr_prop.count() - attrattrs.count());
              coll_lock_unset(ws, doccont);

              var nattrattrs := attrattrs.tmark(attr_id); # New ATID-ATID
              var nattrnqnids := nattrattrs.join(attrnqnids); # New ATID-New QNID
              var nattrnids := nattrattrs.join(preattrs.reverse()).join(insnnids); # New ATID-New NID
              var nattrnprops := nattrattrs.join(attrnprops); # New ATID-New PROPID
              attr_own_update.insert(nattrnids);
              attr_qn_update.insert(nattrnqnids);
              attr_prop_update.insert(nattrnprops);
            }
            if (not(samedoc)) {
              var e := elems.tmark(0@0);
              var prefurilocval := mposjoin(e.leftjoin(insprop), e.leftjoin(insert_pre_cont), ws.fetch(QN_PREFIX_URI_LOC));
              var elemids := e.reverse().leftjoin(find_qn_bulk(ws, doccont, prefurilocval, true));
              insprop.replace(elemids);
            }
            var newnidqn := insnnids.reverse().join(insprop); # [newNID,newQNID]
            nid_qn_ins_update.insert(newnidqn);
          }
          var lastsize := inssize.find(oid((lng(insertitem) + batchsize) - 1));
          if (isnil(niland(lastsize, int_nil))) {
            if (niland(lastsize, INT_MAX) > 0) {
              # last to-be-inserted node is in the middle of a hole, fix the hole to end at this node
              var hole := inssize.reverse().select(lastdata, oid_nil, false, true).reverse();
              inssize := inssize.copy().access(BAT_WRITE).replace([nilor]([-](hole.project(hole.count()), [int](hole.mark(1@0))), int_nil));
            }
          }
          insnid := insnid.copy().access(BAT_WRITE).replace(insnnids);
          insnid := insnid.tmark(docinsertpoint_rid);
          nid_rid_update.insert(insnid.select(oid_nil, oid_nil).reverse());
          insprop := insprop.tmark(docinsertpoint_rid);
          inssize := inssize.tmark(docinsertpoint_rid);
          inslevel := inslevel.tmark(docinsertpoint_rid);
          inskind := inskind.tmark(docinsertpoint_rid);
          if (isoldpage) {
            rid_size_update.myinsert(inssize);
            rid_level_update.myinsert(inslevel);
            rid_kind_update.myinsert(inskind);
            rid_prop_update.myinsert(insprop);
            rid_nid_update.myinsert(insnid);
          } else {
            rid_size.replace(inssize, true);
            rid_level.replace(inslevel, true);
            rid_kind.replace(inskind, true);
            rid_prop.replace(insprop, true);
            rid_nid.replace(insnid, true);
          }

          insertsize :-= int(batchsize);
          docinsertpoint := oid(lng(docinsertpoint) + batchsize);
          insertitem := oid(lng(insertitem) + batchsize);
        }
      }
    }
  }
}

PROC do_update_delete(bat[void, bat] ws, bat[void,oid] update_node_item, bat[void,int] update_node_kind) : void
{
  var conts := update_node_kind.get_container();
  var types := update_node_kind.get_types();
  var attrs := types.ord_uselect(ATTR);
  var elems := types.ord_uselect(ELEM);

  if (attrs.count() > 0) {
    attrs := attrs.mirror();
    var aconts := attrs.leftjoin(conts);
    aconts.tunique()@batloop() {
      var cont := $h;
      var list := aconts.ord_uselect(cont).mirror();
      var attr_prop_updates := ws.fetch(ATTR_PROP_UPDATE).find(cont);
      var attr_own_updates := ws.fetch(ATTR_OWN_UPDATE).find(cont);
      var attr_qn_updates := ws.fetch(ATTR_QN_UPDATE).find(cont);
      var attrlist := list.leftjoin(update_node_item).reverse().project(oid_nil);
      attr_prop_updates.insert(attrlist);
      attr_own_updates.insert(attrlist);
      attr_qn_updates.insert(attrlist);
    }
  }

  if (elems.count() > 0) {
    # extract the update_node_item and conts values that refer to
    # elements and renumber them so that the tables have dense heads
    elems := elems.mirror();
    update_node_item := elems.leftjoin(update_node_item);

    # the "update_node_item" parameter contains PRE values
    # instead of NID values; the PRE values refer to the unmodified
    # document
    update_node_item@batloop() {
      var oldpre := $t;         # the original PRE value of the to-be-deleted node
      var cont := conts.fetch($h);
      # translate PRE value to NID value which is also valid in the modified document
      var pre_nid := ws.fetch(PRE_NID).find(cont);
      var nid := pre_nid.find(oldpre);
      var map_pid := ws.fetch(MAP_PID).find(cont);
      var map_pid_update := ws.fetch(MAP_PID_UPDATE).find(cont);
      var nid_rid := ws.fetch(NID_RID).find(cont);
      var nid_rid_update := ws.fetch(NID_RID_UPDATE).find(cont);
      var rid;
      if (nid_rid_update.exist(nid)) {
        rid := nid_rid_update.find(nid);
      } else {
        rid := nid_rid.find(nid);
      }
      # if (isnil(rid)) the element is already gone, so nothing more to do
      if (not(isnil(rid))) {
        var pre := swizzle(rid, map_pid_update);
        var pre_size := ws.fetch(PRE_SIZE).find(cont);
        var rid_size := ws.fetch(_RID_SIZE).find(cont);
        var rid_size_update := ws.fetch(RID_SIZE_UPDATE).find(cont);
        var pageno := oid(lng(pre) >> REMAP_PAGE_BITS);
        var pageid := oid(lng(rid) >> REMAP_PAGE_BITS);
        var isoldpage := false;
        if (map_pid.exist(pageid)) {
          isoldpage := not(isnil(map_pid.find(pageid)));
        }

        var size;
        if (isoldpage) {
          if (rid_size_update.exist(rid)) {
            size := rid_size_update.find(rid);
          } else {
            size := pre_size.find(oldpre);
          }
        } else {
          size := rid_size.find(rid);
        }

        if (not(isnil(niland(size, int_nil)))) { # result of niland(size, int_nil) is either 0 or int_nil
          var next_pagebase := oid((lng(pageno) + 1) << REMAP_PAGE_BITS);
          var nid_rid_update := ws.fetch(NID_RID_UPDATE).find(cont);
          var pre_kind := ws.fetch(PRE_KIND).find(cont);
          var rid_kind := ws.fetch(_RID_KIND).find(cont);
          var rid_kind_update := ws.fetch(RID_KIND_UPDATE).find(cont);
          var rid_level := ws.fetch(_RID_LEVEL).find(cont);
          var rid_level_update := ws.fetch(RID_LEVEL_UPDATE).find(cont);
          var pre_prop := ws.fetch(PRE_PROP).find(cont);
          var rid_prop := ws.fetch(_RID_PROP).find(cont);
          var rid_prop_update := ws.fetch(RID_PROP_UPDATE).find(cont);
          var pre_nid := ws.fetch(PRE_NID).find(cont);
          var rid_nid := ws.fetch(_RID_NID).find(cont);
          var rid_nid_update := ws.fetch(RID_NID_UPDATE).find(cont);
          var nid_qn_ins_update := ws.fetch(NID_QN_INS_UPDATE).find(cont);
          var nid_qn_del_update := ws.fetch(NID_QN_DEL_UPDATE).find(cont);

          # record where we're deleting a node
          {
            var docsize;                # current size of document
            # if the size of item 0 was changed, used the new size, else use the original size
            # we assume that page 0 on which item 0 is located already exists...
            {
              var root_rid := antiswizzle(0@0, map_pid_update);
              if (rid_size_update.exist(root_rid)) {
                docsize := rid_size_update.find(root_rid);
              } else {
                docsize := pre_size.find(0@0);
              }
            }
            var nxtpre := oid(lng(pre) + size + 1), nxtrid, nxtsiz := 0;
            if (int(nxtpre) < docsize) {
              nxtrid := antiswizzle(nxtpre, map_pid_update);
              if (map_pid.exist(oid(lng(nxtrid) >> REMAP_PAGE_BITS))) {
                if (rid_size_update.exist(nxtrid)) {
                  nxtsiz := rid_size_update.find(nxtrid);
                } else {
                  nxtsiz := pre_size.find(swizzle(nxtrid, map_pid));
                }
              } else {
                nxtsiz := rid_size.find(nxtrid);
              }
            }
            while ((int(nxtpre) < docsize) and isnil(niland(nxtsiz, int_nil))) {
              nxtpre := oid(lng(nxtpre) + niland(nxtsiz, INT_MAX) + 1);
              if (int(nxtpre) < docsize) {
                nxtrid := antiswizzle(nxtpre, map_pid_update);
                if (map_pid.exist(oid(lng(nxtrid) >> REMAP_PAGE_BITS))) {
                  if (rid_size_update.exist(nxtrid)) {
                    nxtsiz := rid_size_update.find(nxtrid);
                  } else {
                    nxtsiz := pre_size.find(swizzle(nxtrid, map_pid));
                  }
                } else {
                  nxtsiz := rid_size.find(nxtrid);
                }
              }
            }
            # only record spot if next node is a TEXT since only then do
            # we have to worry about coalescing text nodes
            if (int(nxtpre) < docsize) {
              var nxtknd;
              var nxtnid;
              if (map_pid.exist(oid(lng(nxtrid) >> REMAP_PAGE_BITS))) {
                if (rid_kind_update.exist(nxtrid)) {
                  nxtknd := rid_kind_update.find(nxtrid);
                } else {
                  nxtknd := pre_kind.find(swizzle(nxtrid, map_pid));
                }
                if (rid_nid_update.exist(nxtrid)) {
                  nxtnid := rid_nid_update.find(nxtrid);
                } else {
                  nxtnid := pre_nid.find(swizzle(nxtrid, map_pid));
                }
              } else {
                nxtknd := rid_kind.find(nxtrid);
                nxtnid := rid_nid.find(nxtrid);
              }
              if (nxtknd = TEXT) {
                ws.fetch(UPDATED_TEXT).insert(cont, nxtnid);
              }
            }
          }

          while (size >= 0) {
            var nsize; # new size we're going to write (may join with consecutive hole)
            var pgsize; # size of hole we're dealing with this iteration (does not cross page boundary)
            if (oid(lng(pre) + size) >= next_pagebase) {
              # new hole extends into next page
              nsize := (int(next_pagebase) - int(pre)) - 1;
              pgsize := nsize;
            } else {
              # new hole wholly contained on this page
              pgsize := size;
              if (oid((lng(pre) + size) + 1) >= next_pagebase) {
                # new hole ends at page boundary
                nsize := size;
              } else {
                # room to spare after new hole, maybe coalesce with consecutive hole
                var next_rid := oid((lng(rid) + size) + 1);
                if (isoldpage) {
                  if (rid_size_update.exist(next_rid)) {
                    nsize := rid_size_update.find(next_rid);
                  } else {
                    nsize := pre_size.find(swizzle(next_rid, map_pid));
                  }
                } else {
                  nsize := rid_size.find(next_rid);
                }
                if (isnil(niland(nsize, int_nil))) { # result of niland(nsize, int_nil) is either 0 or int_nil
                  # there is a following hole
                  nsize := (size + niland(nsize, INT_MAX)) + 1;
                } else {
                  # no following hole
                  nsize := size;
                }
              }
            }

            var update_data := rid_nid.reverse().select(rid, oid(lng(rid) + pgsize)).reverse();
            {
              var nid_qn_del;
              if (isoldpage) {
                var rk := update_data.mirror().outerjoin(rid_kind_update).access(BAT_WRITE); # [newRID,KIND/nil]
                rk.replace(rk.uselect(chr_nil).mirror().[swizzle](map_pid).join(pre_kind));  # [newRID,KIND]
                var r := rk.uselect(ELEMENT).mirror();                                       # [newRID,newRID] (elements)
                var rn := r.outerjoin(rid_nid_update).access(BAT_WRITE);                     # [newRID,NID/nil]
                rn.replace(rn.uselect(oid_nil).mirror().[swizzle](map_pid).join(pre_nid));   # [newRID,NID]
                var rp := rn.join(nid_rid)          # [newRID,oldRID]
                  .[swizzle](map_pid)               # [newRID,oldPRE]
                  .join(pre_prop);                  # [newRID,oldPROP]
                nid_qn_del := rn.reverse().join(rp);
              } else {
                nid_qn_del := update_data.reverse() # [NID,newRID]
                  .join(rid_kind)                   # [NID,KIND]
                  .uselect(ELEMENT)                 # [NID,nil] (only elements)
                  .mirror()                         # [NID,NID] (only elements)
                  .join(nid_rid)                    # [NID,oldRID]
                  .[swizzle](map_pid)               # [NID,oldPRE]
                  .join(pre_prop);                  # [NID,oldPROP]
              }
              nid_qn_ins_update.delete(nid_qn_del);
              nid_qn_del_update.insert(nid_qn_del);
            }

            update_data := [nilor]([-](update_data.project(nsize), [int](update_data.mark(0@0))), int_nil);
            if (isoldpage) {
              rid_size_update.myinsert(update_data);
            } else {
              rid_size.replace(update_data, true);
            }

            update_data := update_data.project(cast(nil, rid_level_update.ttype()));
            if (isoldpage) {
              rid_level_update.myinsert(update_data);
            } else {
              rid_level.replace(update_data, true);
            }

            update_data := update_data.project(cast(nil, rid_kind_update.ttype()));
            if (isoldpage) {
              rid_kind_update.myinsert(update_data);
            } else {
              rid_kind.replace(update_data, true);
            }

            update_data := update_data.project(oid_nil);
            if (isoldpage) {
              rid_prop_update.myinsert(update_data);
            } else {
              rid_prop.replace(update_data, true);
            }

            update_data := update_data.project(oid_nil);
            if (isoldpage) {
              rid_nid_update.myinsert(update_data);
            } else {
              rid_nid.replace(update_data, true);
            }
            var rid_nid_page := rid_nid.reverse().select(rid, oid(lng(rid) + pgsize)).reverse();
            if (isoldpage) {
              var rid_nid_page_update := rid_nid_update.reverse().select(rid, oid(lng(rid) + pgsize));
              rid_nid_page := rid_nid_page.access(BAT_WRITE).key(true).replace(rid_nid_page_update);
            }
            var nid_rid_updates := rid_nid_page.select(oid_nil, oid_nil).reverse().project(oid_nil);
            nid_rid_update := myinsert(nid_rid_update, nid_rid_updates);

            size :-= pgsize + 1;
            pre := oid((lng(pre) + pgsize) + 1);
            if (pre >= next_pagebase) {
              # per page house keeping
              pageno := oid(lng(pre) >> REMAP_PAGE_BITS);
              pageid := map_pid_update.reverse().find(pageno);
              next_pagebase := oid((lng(pageno) + 1) << REMAP_PAGE_BITS);
              isoldpage := false;
              if (map_pid.exist(pageid)) {
                isoldpage := not(isnil(map_pid.find(pageid)));
              }
            }
            rid := oid((lng(pre) and REMAP_PAGE_MASK) or (lng(pageid) << REMAP_PAGE_BITS));
          }
        }
      }
    }
  }
}

PROC add_string_bulk(bat[void,bat] ws, oid cont, int tableid, bat[oid,str] valbat) : bat[oid,oid]
{
  var table := ws.fetch(tableid).find(cont);
  var validbat := valbat.outerjoin(table.reverse());
  var newvallist := validbat.uselect(oid_nil);
  if (newvallist.count() > 0) {
    # insert missing strings
    coll_lock_set(ws, cont);
    # we depend on the key-ness of the value column to avoid races
    table.append(newvallist.mirror().join(valbat).tunique().reverse(), true);
    coll_lock_unset(ws, cont);
    # try finding the IDs again (they should now all be found)
    validbat := valbat.outerjoin(table.reverse());
  }
  return validbat;
}

PROC add_pi_bulk(bat[void,bat] ws, oid cont, bat[oid,str] tgtbat, bat[oid,str] insbat) : bat[oid,oid]
{
  var prop_ins := ws.fetch(_PROP_INS).find(cont);
  var prop_tgt := ws.fetch(_PROP_TGT).find(cont);
  var prop_ins_tgt := [+]([+](prop_ins, ":"), prop_tgt);
  var instgtbat := [+]([+](insbat, ":"), tgtbat);
  var idbat := instgtbat.outerjoin(prop_ins_tgt.reverse());
  var newidlist := idbat.uselect(oid_nil);
  if (newidlist.count() > 0) {
    # insert missing strings
    coll_lock_set(ws, cont);
    # recalculate what's missing now that we have the lock
    prop_ins_tgt := [+]([+](prop_ins, ":"), prop_tgt);
    instgtbat := [+]([+](insbat, ":"), tgtbat);
    idbat := instgtbat.outerjoin(prop_ins_tgt.reverse());
    newidlist := idbat.uselect(oid_nil);
    # then figure out unique combinations
    var instgtunique := newidlist.mirror().join(instgtbat).tunique().reverse().seqbase(0@0);
    # then extract instruction and target
    var instgtuniquesplit := instgtunique.splitbat(":");
    # and finally add them to respective BATs
    prop_ins.append(instgtuniquesplit.fetch(0), true);
    prop_tgt.append(instgtuniquesplit.fetch(1), true);
    coll_lock_unset(ws, cont);
    prop_ins_tgt := [+]([+](prop_ins, ":"), prop_tgt);
    idbat := instgtbat.outerjoin(prop_ins_tgt.reverse());
  }
  return idbat;
}

PROC find_qn_bulk(bat[void,bat] ws, oid cont, bat[oid,str] pref_uri_loc, bit add) : bat[oid,oid]
{
  var qn_prefix_uri_loc := ws.fetch(_QN_PREFIX_URI_LOC).find(cont);

  var qn_map := pref_uri_loc.outerjoin(qn_prefix_uri_loc.reverse());
  if (add) {
    var miss := qn_map.uselect(oid_nil);
    if (miss.count() > 0) {
      coll_lock_set(ws, cont);
      # get the unique missing strings and append them
      var _pref_uri_loc := reverse(miss).join(pref_uri_loc).tunique().mark(0@0).reverse();
      var _split := splitbat(_pref_uri_loc, ":");
      var _pref  := _split.fetch(0);
      var _uri   := _split.fetch(1);
      var _loc   := _split.fetch(2);
      ws.fetch(_QN_LOC).find(cont).append(_loc, true);
      ws.fetch(_QN_URI).find(cont).append(_uri, true);
      ws.fetch(_QN_PREFIX).find(cont).append(_pref, true);
      ws.fetch(_QN_URI_LOC).find(cont).append([+]([+](_uri, ":"), _loc), true);
      qn_prefix_uri_loc.append(_pref_uri_loc, true); 
      coll_lock_unset(ws, cont);

      # recalculate map now
      qn_map := pref_uri_loc.outerjoin(qn_prefix_uri_loc.reverse());
    }
  }
  return qn_map;
}

PROC fix_consecutive_texts(bat[void, bat] ws, bat[oid,oid] contnid) : void
{
  # for now ignore position information
  contnid.reverse().tunique()@batloop() {
    var cont := $h;

    var map_pid := ws.fetch(MAP_PID).find(cont);
    var map_pid_update := ws.fetch(MAP_PID_UPDATE).find(cont);

    var pre_level := ws.fetch(PRE_LEVEL).find(cont);
    var rid_level := ws.fetch(_RID_LEVEL).find(cont);
    var rid_level_update := ws.fetch(RID_LEVEL_UPDATE).find(cont);
    var pre_kind := ws.fetch(PRE_KIND).find(cont);
    var rid_kind := ws.fetch(_RID_KIND).find(cont);
    var rid_kind_update := ws.fetch(RID_KIND_UPDATE).find(cont);

    var lvkd := new(oid, sht, rid_level.count()); # [PRE,(level<<8)|kind]

    map_pid_update.select(oid_nil, oid_nil).reverse().sort()@batloop() {
      var pageno := $h;
      var pageid := $t;

      var isoldpage := false;
      if (map_pid.exist(pageid)) {
        isoldpage := not(isnil(map_pid.find(pageid)));
      }

      var pagestart := oid(lng(pageno) << REMAP_PAGE_BITS);
      var pagelast := oid(lng(pagestart) + REMAP_PAGE_MASK);

      var lvpg;
      var kdpg;
      if (isoldpage) {
        lvpg := pre_level.reverse().select(swizzle(pagestart, map_pid), swizzle(pagelast, map_pid)).reverse().seqbase(pagestart);
        var lvpgup := rid_level_update.reverse().select(pagestart, pagelast).reverse();
        lvpg := lvpg.access(BAT_WRITE).key(true).replace(lvpgup);
        kdpg := pre_kind.reverse().select(swizzle(pagestart, map_pid), swizzle(pagelast, map_pid)).reverse().seqbase(pagestart);
        var kdpgup := rid_kind_update.reverse().select(pagestart, pagelast).reverse();
        kdpg := kdpg.access(BAT_WRITE).key(true).replace(kdpgup);
      } else {
        lvpg := rid_level.reverse().select(pagestart, pagelast).reverse();
        kdpg := rid_kind.reverse().select(pagestart, pagelast).reverse();
      }

      # select all non-hole entries for both level and kind tables
      var l := lvpg.ord_select(chr_nil,chr_nil); # [RID,level]
      var k := l.mirror().leftfetchjoin(kdpg); # [RID,kind]
      # combine them into a single table
      var x := [+]([<<]([sht](l),8),[sht](k)); # [RID,(level<<8)|kind]
      lvkd.insert([sht]([swizzle]([oid](x).reverse(), map_pid_update).reverse()));
    }

    lvkd := [sht]([swizzle]([oid](lvkd).reverse(), map_pid_update).reverse()); # [PRE,(level<<8)|kind]] 

    # use an undocumented feature of CTrefine: it does not check whether
    # the lhs is sorted
    # we now get unique OIDs for each stretch of consecutive elements
    # with the same value
    var r := CTrefine(lvkd, lvkd.project(nil)); # [PRE,GRP] tsorted
    # s is a list of nodes where there are more than one consecutive
    # nodes of the same type at the same level, the rhs is the per-group OID
    var s := r.leftjoin(r.reverse().{count}().ord_uselect(2, int_nil).mirror()); # [PRE,GRP] tsorted subselection of r
    # and now select the text elements from there
    var t := [and](lvkd, sht(255)).ord_uselect(sht(TEXT)).mirror().leftjoin(s).chk_order(); # [PRE,GRP] hsorted,tsorted subselection of s
    # at this point we must do the real merging and deleting of text
    # nodes, but at least we know where they are
    if (t.count() > 0) {
      var rid_size := ws.fetch(_RID_SIZE).find(cont);
      var rid_size_update := ws.fetch(RID_SIZE_UPDATE).find(cont);
      var pre_prop := ws.fetch(PRE_PROP).find(cont);
      var rid_prop := ws.fetch(_RID_PROP).find(cont);
      var rid_prop_update := ws.fetch(RID_PROP_UPDATE).find(cont);
      var pre_nid := ws.fetch(PRE_NID).find(cont);
      var rid_nid := ws.fetch(_RID_NID).find(cont);
      var rid_nid_update := ws.fetch(RID_NID_UPDATE).find(cont);
      var pid_map_update := map_pid_update.select(oid_nil, oid_nil).reverse().sort().tmark(0@0);
      var t1 := [swizzle](t.reverse(), pid_map_update).reverse(); # [RID,GRP]

      var t1p := [oid]([>>]([lng](t1.mirror()), REMAP_PAGE_BITS)); # [RID,PGID]
      # [RID,RID] combos from t1.mirror() that refer to old pages
      var t1mold := t1p.leftjoin(map_pid).mirror();
      # [RID,RID] combos from t1.mirror() that refer to new pages
      var t1mnew := t1p.reverse().kdiff(map_pid).reverse().mirror();

      var t2 := [swizzle](t1mold, map_pid); # [RID,PRE]
      # [RID,PROP] combination from unmodified nodes, modified nodes, and new nodes
      var rp := t2.join(pre_prop).access(BAT_WRITE).key(true).myinsert(t1mold.join(rid_prop_update)).myinsert(t1mnew.join(rid_prop)); # [RID,PROP]

      var gp := t1.reverse().leftjoin(rp); # [GRP,PROP]
      var c := gp.leftfetchjoin(ws.fetch(_PROP_TEXT).find(cont)); # [GRP,content] hsorted
      var v := string_join(c, c.kunique().project("")); # [GRP,content] combined content with unique GRP values
      var i := add_string_bulk(ws, cont, _PROP_TEXT, v); # [GRP,SID] OID into _PROP_TEXT table
      var p := t.reverse().kunique().reverse(); # [PRE,GRP] one representative from t per group
      var p1 := [swizzle](p.reverse(), pid_map_update).reverse(); # [RID,GRP]
      var h1 := kdiff(t1, p1).project(oid_nil); # [RID,nil] the other RIDs

      p1.leftjoin(i)@batloop() {
        var pageid := oid(lng($h) >> REMAP_PAGE_BITS);
        var isoldpage := false;
        if (map_pid.exist(pageid)) {
          isoldpage := not(isnil(map_pid.find(pageid)));
        }
        if (isoldpage) {
          rid_prop_update.myinsert($h, $t);
        } else {
          rid_prop.replace($h, $t, true);
        }
      }
      var nid_rid_update := ws.fetch(NID_RID_UPDATE).find(cont);
      h1@batloop() {
        var pageid := oid(lng($h) >> REMAP_PAGE_BITS);
        var isoldpage := false;
        if (map_pid.exist(pageid)) {
          isoldpage := not(isnil(map_pid.find(pageid)));
        }
        var nid;
        if (isoldpage) {
          if (rid_nid_update.exist($h)) {
            nid := rid_nid_update.find($h);
          } else {
            nid := pre_nid.find(swizzle($h, map_pid));
          }
          rid_prop_update.myinsert($h, $t);
          rid_size_update.myinsert($h, int_nil);
          rid_nid_update.myinsert($h, $t);
          rid_kind_update.myinsert($h, chr_nil);
          rid_level_update.myinsert($h, chr_nil);
        } else {
          nid := rid_nid.find($h);
          rid_prop.replace($h, $t, true);
          rid_size.replace($h, int_nil, true);
          rid_nid.replace($h, $t, true);
          rid_kind.replace($h, chr_nil, true);
          rid_level.replace($h, chr_nil, true);
        }
        nid_rid_update.myinsert(nid, oid_nil);
      }
    }
  }
}
@* Module Implementation
@h
#ifndef PF_SUPPORT_H
#define PF_SUPPORT_H

#include <monet.h>
#include "pathfinder.h"
#include "pf_support.proto.h"
#include <monet_interpreter.h>
#include <monettime.h>

#endif
@c

#include "pf_support.h"
#include <gdk_scanselect.h> /* for type-specific HT_bunfastins_nocheck_noinc(), until they're moved to gdk.mx */
#include <algebra.h> /* needed for result size estimation in CMDenumerate */
#include <math.h> /* needed for round_up */

#if SIZEOF_OID == SIZEOF_INT
#define oidoid_bunfastins(b,h,t) intint_bunfastins(b,h,t);
#define oidoid_bunfastins_nocheck_noinc(b,p,h,t) intint_bunfastins_nocheck_noinc(b,p,h,t);
#else
#define oidoid_bunfastins(b,h,t) lnglng_bunfastins(b,h,t);
#define oidoid_bunfastins_nocheck_noinc(b,p,h,t) lnglng_bunfastins_nocheck_noinc(b,p,h,t);
#endif
@c
int CMDdelete_nodes_prepare_pre_size( BAT** ret, BAT *pre_size, BAT *pre_ )
{
	BAT *res = NULL;
	size_t cnt = 0;
	int bs_res;
	BUN dst_res;
	int new_size = int_nil;
	bit triv_prop;

	BATcheck(pre_size, "delete_nodes_prepare_pre_size");
	BATcheck(pre_,     "delete_nodes_prepare_pre_size");
	ERRORcheck(!BAThdense(pre_size),
	           "delete_nodes_prepare_pre_size: head of BAT pre_size must be dense.\n");
	ERRORcheck((pre_->htype!=TYPE_oid) && (pre_->htype!=TYPE_void),
	           "ERRORcheck: head of BAT pre_ must be oid.\n");
	ERRORcheck((pre_->htype==TYPE_void) && !BAThdense(pre_),
	           "ERRORcheck: head of BAT pre_ must not be nil.\n");
	ERRORcheck(!(BAThordered(pre_)&1),
	           "delete_nodes_prepare_pre_size: head of BAT pre_ must be sorted.\n");

	cnt = BATcount(pre_);
        res = BATnew(TYPE_oid,TYPE_int,cnt);
	if (res == NULL) {
		GDKerror("delete_nodes_prepare_pre_size: BATnew(TYPE_oid, TYPE_int, "SZFMT") failed.\n", cnt);
		return GDK_FAIL;
	}
	bs_res   = BUNsize(res);
	dst_res  = BUNfirst(res) + ((cnt-1) * bs_res);

	if (BAThdense(pre_)) {
		oid fst_pre = pre_->hseqbase;
		oid lst_pre = fst_pre + cnt;
		oid cur_pre;
		BUN src_pre_size = NULL;
		BUNfndVOID(src_pre_size, pre_size, &lst_pre);
		if (src_pre_size != NULL) {
			int old_size = *(int*)BUNtloc(pre_size, src_pre_size);
			if (old_size&(1<<31)) {
				new_size = (((old_size&GDK_int_max) + 1) | 1<<31);
			} else {
				new_size = 1<<31;
			}
		} else {
			new_size = 1<<31;
		}
		
		for (cur_pre = lst_pre - 1 ; cur_pre >= fst_pre ; cur_pre--) {
			oidint_bunfastins_nocheck_noinc(res, dst_res, &cur_pre, &new_size);
			dst_res -= bs_res;
			new_size = (((new_size&GDK_int_max) + 1) | 1<<31); /* new_size--; */
		}
	} else {
		oid prev_pre = oid_nil;
		int bs_pre_  = BUNsize(pre_);
		BUN fst_pre_ = BUNfirst(pre_);
		BUN lst_pre_ = BUNlast(pre_);
		BUN cur_pre_;
		for (cur_pre_ = lst_pre_ - bs_pre_ ; cur_pre_ >= fst_pre_ ; cur_pre_ -= bs_pre_) {
			oid cur_pre = *(oid*)BUNhloc(pre_, cur_pre_);
			if (cur_pre + 1 != prev_pre) {
				BUN src_pre_size = NULL;
				prev_pre = cur_pre + 1;
				BUNfndVOID(src_pre_size, pre_size, &prev_pre);
				if (src_pre_size != NULL) {
					int old_size = *(int*)BUNtloc(pre_size, src_pre_size);
					if (old_size&(1<<31)) {
						new_size = (((old_size&GDK_int_max) + 1) | 1<<31); /* old_size - 1 */
					} else {
						new_size = 1<<31;
					}
				} else {
					new_size = 1<<31;
				}
			}
			oidint_bunfastins_nocheck_noinc(res, dst_res, &cur_pre, &new_size);
			prev_pre = cur_pre;
			dst_res -= bs_res;
			new_size = (((new_size&GDK_int_max) + 1) | 1<<31); /* new_size--; */
		}
	}
	

        if (!res->batDirty) res->batDirty = TRUE;
	res->batBuns->free = cnt * bs_res;
	BATsetcount(res, cnt);
        triv_prop = (BATcount(res) < 2);
        BATkey(res,TRUE);
        BATkey(BATmirror(res),triv_prop);
        res->hsorted = GDK_SORTED;
        res->tsorted = (triv_prop?GDK_SORTED:FALSE);
        res->hdense = (triv_prop || BAThdense(pre_));
        res->tdense = FALSE;
        if (BATcount(res) == 0) {
                BATseqbase(res, (oid)0);
        } else if (res->hdense) {
                BATseqbase(res, *(oid*)BUNhloc(res,BUNfirst(res)));
        }
	BATseqbase(BATmirror(res), oid_nil);

        *ret = res;
	return GDK_SUCCEED;
}  

int 
CMDisFakeProject(bit *r, ptr v, int tpe) {
	*r = (tpe == TYPE_bat)?is_fake_project((BAT*) v):1;
	return GDK_SUCCEED;
}

int
CMDfakeProject(BAT **res, ptr val, int tpe) 
{
	assert(val);
	if (tpe == TYPE_bat) {
		*res = (BAT*) val;
		BBPfix((*res)->batCacheid);
		return GDK_SUCCEED;
	}
	*res = BATnew(TYPE_void, tpe, 1);
	if (*res) {
		if (BUNappend(*res, val, FALSE)) return GDK_SUCCEED;
		BBPreclaim(*res);
	}
	return GDK_FAIL;
}

#include <constant.proto.h> /* for CMDconstCopy */

int
CMDdeFakeProject(ptr ret, int *tpe, ptr val, int t) 
{
	if (t == TYPE_bat) {
		BAT *b = (BAT*) val;
		if (!is_fake_project(b)) {
			*tpe = TYPE_bat;
			*(BAT**) ret = b;
			BBPfix(b->batCacheid);
			return GDK_SUCCEED;
		}
		val = BUNtail(b, BUNfirst(b));
		t = ATOMtype(b->ttype);
	} 
	return CMDconstCopy(ret, val, *tpe = t);
}

int
CMDfetchConvert(ptr res, int *tpe, BAT* b, int* pos) 
{
	int ret = GDK_FAIL;
	if (*pos >= 0 || ((size_t) *pos) < BATcount(b)) {
		bat bid = *(bat*) BUNtail(b, BUNptr(b, BUNindex(b, BUNfirst(b))+*pos));
		int fix = BBPfix(bid);
		BAT *bn = NULL;
		if (fix == 0 || (bn=BBPdescriptor(bid)) == NULL) {
			if (fix) BBPunfix(bid);
			GDKerror("fetch(%s) illegal BAT at position %d.\n", BBP_logical(b->batCacheid), *pos); 
		} else if (is_fake_project(bn)) {
			ret = CMDconstCopy(res, BUNfirst(bn), *tpe = ATOMtype(bn->ttype));
			BBPunfix(bid);
		} else {
			ret = GDK_SUCCEED;
			*(BAT**)res = bn;
			*tpe = TYPE_bat;
		}
	} else {
		GDKerror("fetch(%s) illegal position %d.\n", BBP_logical(b->batCacheid), *pos); 
	}
	return ret;
}

int
CMDinsertConvert(BAT** res, BAT *b, ptr h, ptr t, int tpe) 
{
	int ret = GDK_FAIL;
	BAT *bn = NULL;

	if (!tpe)
		return GDK_FAIL;
	assert(h);
	assert(t);
	if (CMDfakeProject(&bn, t, tpe) == GDK_SUCCEED) {
		if (BUNins(*res = b, BAThtype(b) == TYPE_bat ? (ptr) &((BAT *) h)->batCacheid : h, &bn->batCacheid, FALSE)) {
			BBPfix(b->batCacheid);
			ret = GDK_SUCCEED;
		}
		BBPunfix(bn->batCacheid);
	}
	return ret;
}

int
CMDappendConvert(BAT** res, BAT *b, ptr t, int tpe) 
{
	int ret = GDK_FAIL;
	BAT *bn = NULL;

	if (!tpe)
		return GDK_FAIL;
	assert(t);
	if (CMDfakeProject(&bn, t, tpe) == GDK_SUCCEED) {
		if (BUNappend(*res = b, &bn->batCacheid, FALSE)) {
			BBPfix(b->batCacheid);
			ret = GDK_SUCCEED;
		}
		BBPunfix(bn->batCacheid);
	}
	return ret;
}

@= mark_grp_init
	BUN w;

	BUNfnd@1(w, g, (ptr)&v);
	if (w) {
		n = *(oid*) BUNtloc(g, w);
	} else {
		n = oid_nil;
	}
@
@= mark_grp_loop4
	oid u = oid_nil;
	oid n = oid_nil;
	BATloopFast(b, p, q, xx) {
		oid v = *(oid*)BUNt@2(b, p);

		if (v != u) {
			@3
			u = v;
		} else if (n != oid_nil) {
			n++;
		}
		anyoid_bunfastins_nocheck_noinc(bn, r, BUNh@1(b, p), &n);
		r += yy; 
	}
@
@= mark_grp_loop3
	BATloopFast(b, p, q, xx) {
		oid n = oid_nil;
		BUN w;
		ptr v = BUNt@2(b, p);

		BUNfnd@3(w, gc, v);
		if (w) {
			oid *m = (oid*) BUNtloc(gc, w);
			if (*m != oid_nil) {
				n = (*m)++;
			}
		}
		anyoid_bunfastins_nocheck_noinc(bn, r, BUNh@1(b, p), &n);
		r += yy; 
	}
@
@= mark_grp_loop2
	if (gc) {
		if (BAThdense(gc)) {
			@:mark_grp_loop3(@1,@2,VOID)@
		} else {
			@:mark_grp_loop3(@1,@2,OID)@
		}
	} else {
		if (s) {
			@:mark_grp_loop4(@1,@2,n = *s;,s);
		} else {
			if (BAThdense(g)) {
				@:mark_grp_loop4(@1,@2,@:mark_grp_init(VOID)@,VOID);
			} else {
				@:mark_grp_loop4(@1,@2,@:mark_grp_init(OID)@,OID);
			}
		}
	}
@
@= mark_grp_loop1
	if (b->ttype==TYPE_void) {
		@:mark_grp_loop2(@1,var)@
	} else {
		@:mark_grp_loop2(@1,loc)@
	}
@
@= mark_grp_loop
{	BUN p, q, r = BUNfirst(bn);
	int xx, yy = BUNsize(bn);
	if (b->hvarsized) {
		@:mark_grp_loop1(var)@
	} else {
		@:mark_grp_loop1(loc)@
	}
	bn->batBuns->free = r - bn->batBuns->base;
	BATsetcount(bn, BATcount(b));
}
@
@c
static BAT *BATmark_grp( BAT *b, BAT *g, oid *s )
{
        BAT *bn, *gc = NULL;
        bit trivprop = FALSE;
 
        BATcheck(b, "BATmark_grp");
        BATcheck(g, "BATmark_grp");
	ERRORcheck((b->ttype!=TYPE_void) && (b->ttype!=TYPE_oid),
	           "BATmark_grp: tail of BAT b must be oid.\n");
	ERRORcheck((g->htype!=TYPE_void) && (g->htype!=TYPE_oid),
	           "BATmark_grp: head of BAT g must be oid.\n");
	ERRORcheck((b->ttype==TYPE_void) && (b->tseqbase==oid_nil),
	           "BATmark_grp: tail of BAT b must not be nil.\n");
	ERRORcheck((g->htype==TYPE_void) && (g->hseqbase==oid_nil),
	           "BATmark_grp: head of BAT g must not be nil.\n");
	ERRORcheck(s && (*s == oid_nil),
	           "BATmark_grp: base oid s must not be nil.\n");
	ERRORcheck(!s && (g->ttype!=TYPE_oid),
	           "BATmark_grp: tail of BAT g must be oid.\n");

	if (BATcount(b) == 0 || BATcount(g) == 1) {
		if (s) {
			return BATmark(b, *s);
		} else {
			return BATmark(b, *(oid*)BUNtloc(g, BUNfirst(g)));
		}
	}

	if (!BATtordered(b)) {
		if (s) {
			BUN p, q, r;
			int xx, yy;
			if (BAThdense(g)) {
				gc = BATnew(TYPE_void, TYPE_oid, BATcount(g));
				if (gc == NULL) return NULL;
				r = BUNfirst(gc);
				yy = BUNsize(gc);
				BATloopFast(g, p, q, xx) {
					voidoid_bunfastins_nocheck_noinc(gc, r, NULL, s); 
					r += yy; 
				}
			} else {
				gc = BATnew(TYPE_oid,  TYPE_oid, BATcount(g));
				if (gc == NULL) return NULL;
				r = BUNfirst(gc);
				yy = BUNsize(gc);
				BATloopFast(g, p, q, xx) {
					oidoid_bunfastins_nocheck_noinc(gc, r, BUNhloc(g, p), s); 
					r += yy; 
				}
			}
			gc->batBuns->free = r - gc->batBuns->base;
			BATsetcount(gc, BATcount(g));
			gc->hdense = BAThdense(g);
			if (BAThdense(gc)) {
				BATseqbase(gc, g->hseqbase);
				gc->hsorted = GDK_SORTED;
			} else {
				gc->hsorted = BAThordered(g);
			}
			BATkey(gc, TRUE);
		} else {
			gc = BATcopy(g, g->htype, g->ttype, TRUE);
			if (gc == NULL) return NULL;
		}
	}
	bn = BATnew(b->htype, TYPE_oid, BATcount(b));
	if (bn == NULL) {
		if (gc) BBPreclaim(gc);
		return NULL;
	}

	@:mark_grp_loop@

	trivprop = (BATcount(bn) < 2);
	ALIGNsetH(bn,b);
	bn->hsorted = (trivprop ? GDK_SORTED : BAThordered(b));
	bn->hdense = BAThdense(b) || (trivprop && b->htype==TYPE_oid);
	if (BAThdense(bn)) {
		BATseqbase(bn, b->hseqbase);
	}
	BATkey(bn, (bn->hdense || b->hkey!=0));
	bn->tsorted = (trivprop ? GDK_SORTED : FALSE);
	bn->tdense = trivprop;
	if (BATtdense(bn)) {
		BATseqbase(BATmirror(bn), *(oid*)BUNtloc(bn, BUNfirst(bn)));
	}
	BATkey(BATmirror(bn), trivprop);

	if (gc) BBPreclaim(gc);
        return bn;
bunins_failed:
	if (gc) BBPreclaim(gc);
	BBPreclaim(bn);
	return NULL;
}

int CMDmark_grp_1( BAT** res, BAT *b, BAT *g )
{
	return (*res=BATmark_grp(b, g, NULL))?GDK_SUCCEED:GDK_FAIL;
}

int CMDmark_grp_2( BAT** res, BAT *b, BAT *g, oid *s)
{
	return (*res=BATmark_grp(b, g, s))?GDK_SUCCEED:GDK_FAIL;
}


static int 
merged_union( BAT** res, int nbats, BAT **b) 
{
	BAT *bn[MAXPARAMS>>1], *BN;
	BUN cur[MAXPARAMS], dst[MAXPARAMS>>1], DST;
	int bs[MAXPARAMS], bns[MAXPARAMS>>1], BS;
	size_t idx[MAXPARAMS], cnt[MAXPARAMS];
	int npairs = 1, i, j, k, any, b0 = -1, b1 = -1;
	bit concat = FALSE;
	chr *w = NULL;
	size_t sze = 0, h = 0;
	
	*res = NULL;

	/* check arguments */
	ERRORcheck(BATcount(b[0])>1 && !(BATtordered(b[0])&1), "merged_union: tail of first BAT must be sorted.\n");
	ERRORcheck(BATcount(b[1])>1 && !(BATtordered(b[1])&1), "merged_union: tail of second BAT must be sorted.\n");
	if (nbats&1) {
		GDKerror("merged_union: uneven number of BATs: %d.\n", nbats);
		return GDK_FAIL;
	}
	npairs = nbats>>1;

	for (i=0; i<nbats; i+=2) {
		bit ci, cj;
		j = i+1;
		ci = !is_fake_project(b[i]);
		cj = !is_fake_project(b[j]);
		if (ci && b0 < 0) {
			b0 = i;
		}
		if (cj && b1 < 0) {
			b1 = j;
		}
		if (ci && !BAThdense(b[i])) {
			GDKerror("merged_union: BAT %d must have a dense head.\n", i+1);
			return GDK_FAIL;
		}
		if (cj && !BAThdense(b[j])) {
			GDKerror("merged_union: BAT %d must have a dense head.\n", j+1);
			return GDK_FAIL;
		}
		if (ATOMtype(b[i]->ttype) != ATOMtype(b[j]->ttype)) {
			GDKerror("merged_union: BATs %d (ttype=%d) & %d (ttype=%d) must have the same tail types.\n", 
					i+1, b[i]->ttype, j+1, ATOMtype(b[j]->ttype));
			return GDK_FAIL;
		}
		if (ci && b0 >= 0 && b[i]->hseqbase != b[b0]->hseqbase) {
			GDKerror("merged_union: BAT %d (hseqbase="OIDFMT") must have the same hseqbase as BAT %d (hseqbase="OIDFMT").\n", 
					i+1, b[i]->hseqbase, b0+1, b[b0]->hseqbase);
			return GDK_FAIL;
		}
		if (cj && b1 >= 0 && b[j]->hseqbase != b[b1]->hseqbase) {
			GDKerror("merged_union: BAT %d (hseqbase="OIDFMT") must have the same hseqbase as BAT %d (hseqbase="OIDFMT").\n", 
					j+1, b[j]->hseqbase, b1+1, b[b1]->hseqbase);
			return GDK_FAIL;
		}
		if (ci && b0 >= 0 && BATcount(b[i]) != BATcount(b[b0])) {
			GDKerror("merged_union: BAT %d ("SZFMT" BUNs) must have the same size as BAT %d ("SZFMT" BUNs).\n", 
					i+1, BATcount(b[i]), b0+1, BATcount(b[b0]));
			return GDK_FAIL;
		}
		if (cj && b1 >= 0 && BATcount(b[j]) != BATcount(b[b1])) {
			GDKerror("merged_union: BAT %d ("SZFMT" BUNs) must have the same size as BAT %d ("SZFMT" BUNs).\n", 
					j+1, BATcount(b[j]), b1+1, BATcount(b[b1]));
			return GDK_FAIL;
		}
	}
	if (b0 < 0) {
		GDKerror("merged_union: at least one of the 'odd' BATs must be materialized, i.e., no 'fake_project'.\n");
		return GDK_FAIL;
	}
	if (b1 < 0) {
		GDKerror("merged_union: at least one of the 'even' BATs must be materialized, i.e., no 'fake_project'.\n");
		return GDK_FAIL;
	}

	/* create result BATs */

	sze = BATcount(b[b0]) + BATcount(b[b1]);
	BN = BATnew(TYPE_void, TYPE_bat, npairs);
	if (BN == NULL) {
		GDKerror("merged_union: BATnew(TYPE_void, TYPE_bat, %d) failed.\n", npairs);
		return GDK_FAIL;
	}
	for (k=0; k<npairs; k++) {
		i = k<<1;
		bn[k] = BATnew(TYPE_void, ATOMtype(b[i]->ttype), sze);
		if (bn[k] == NULL) {
			GDKerror("merged_union: BATnew(TYPE_void, %s, " SZFMT ") failed.\n", ATOMname(ATOMtype(b[i]->ttype)), sze);
			while (k>0) {
				BBPreclaim(bn[--k]);
			}
			BBPreclaim(BN);
			return GDK_FAIL;
		}
	}
	if (sze > 0) {
		w = (chr*)GDKmalloc(sze);
		if (w == NULL) {
			GDKerror("merged_union: GDKmalloc(" SZFMT ") failed.\n", sze);
			goto cleanup;
		}
	}

	/* do the merged_union */

	for (k=0; k<npairs; k++) {
		bns[k] = BUNsize(bn[k]);
		dst[k] = BUNlast(bn[k]);
	}
	for (i=0; i<nbats; i++) {
		if (is_fake_project(b[i])) {
			bs[i] = 0;
		} else {
			bs[i] = BUNsize(b[i]);
		}
		cur[i] = BUNfirst(b[i]);
		idx[i] = 0;
		if (i&1) {
			cnt[i] = BATcount(b[b1]);
		} else {
			cnt[i] = BATcount(b[b0]);
		}
	}
@= merged_union_0
	/*  @1: ATOMstorage(b[@3]->ttype) (chr, sht, int, flt, lng, dbl, any=b[@3]->ttype)
	 *  @2: tloc, tvar, tail
	 *  @3: 0, 1
	 *  @5: tail value comparison,
		e.g.,	simple_LE(BUN@2(b[0],cur[0]), BUN@2(b[1],cur[1]), @1)
		or	atom_GT(BUN@2(b[0],cur[0]), BUN@2(b[1],cur[1]), @1)
	 */
	/* copy tails from BAT @3 to the results; 
	   for each BUN, remember in w, whether it came from BAT 0 or BAT 1 */
	while ((idx[@3] < cnt[@3]) && (@4)) {
		void@1_bunfastins_nocheck_noinc(bn[0],dst[0],0,BUN@2(b[@3],cur[@3]));
		idx[@3]++;
		cur[@3] += bs[@3];
		dst[0] += bns[0];
		w[h++] = (chr)@3;
	}
@= merged_union_1
	/*  @1: ATOMstorage(b[0]->ttype) (chr, sht, int, flt, lng, dbl, any=b[0]->ttype)
	 *  @2: tloc, tvar, tail (for BAT 0)
	 *  @3: tloc, tvar, tail (for BAT 1)
	 *  @4: simple, atom
	 */
	/* merge-union the first two BATs; regard and preserve tail-order */
	h = 0;
	concat = (BATcount(b[0])==0 || BATcount(b[1])==0);
	if (!concat) {
		concat = ( BATtordered(b[0])&BATtordered(b[1])&1 && \
		           @4_LE(BUN@2(b[0],BUNlast(b[0])-BUNsize(b[0])),BUN@3(b[1],cur[1]),@1) );
	}
	if (!concat) {
		while ((idx[0] < cnt[0]) && (idx[1] < cnt[1])) {
			@:merged_union_0(@1,@2,0,@4_LE(BUN@2(b[0],cur[0]),BUN@3(b[1],cur[1]),@1))@
			if (idx[0] < cnt[0]) {
				@:merged_union_0(@1,@3,1,@4_GT(BUN@2(b[0],cur[0]),BUN@3(b[1],cur[1]),@1))@
			}
		}
	}
	/* get remaining BUNs */
	@:merged_union_0(@1,@2,0,TRUE)@
	@:merged_union_0(@1,@3,1,TRUE)@
@= merged_union_2
	/*  @1: ATOMstorage(b[0]->ttype) (chr, sht, int, flt, lng, dbl, any=b[0]->ttype)
	 *  @2: tloc, tvar, tail (for BAT 0)
	 *  @3: simple, atom
	 */
	@:merged_union_1(@1,@2,@2,@3)@
	break;
@= merged_union_3
	/*  @1: ATOMstorage(b[@3]->ttype) (chr, sht, int, flt, lng, dbl, any=b[0]->ttype)
	 *  @2: tloc, tvar, tail
	 */
	/* merge-union each of the remaining BAT-pairs; 
	   w tell us, from which BAT we need to get the next BUN */
	for (h=0; h<sze; h++) {
		j = i + (int)w[h];
		void@1_bunfastins_nocheck_noinc(bn[k],dst[k],0,BUN@2(b[j],cur[j]));
		idx[j]++;
		cur[j] += bs[j];
		dst[k] += bns[k];
	}
@= merged_union_4
	/*  @1: ATOMstorage(b[@3]->ttype) (chr, sht, int, flt, lng, dbl, any=b[0]->ttype)
	 *  @2: tloc, tvar, tail
	 */
	@:merged_union_3(@1,@2)@
	break;
@c
	/* merge-union the first two BATs */
/* HACK(?): compare [v]oid (unsigned) as int/lng (signed) to get nil's first... */
#if SIZEOF_OID == SIZEOF_INT
	if (b[0]->ttype==TYPE_void && b[1]->ttype==TYPE_void) {
		@:merged_union_1(int,tvar,tvar,simple)@
	} else if (b[0]->ttype==TYPE_void && b[1]->ttype==TYPE_oid) {
		@:merged_union_1(int,tvar,tloc,simple)@
	} else if (b[0]->ttype==TYPE_oid && b[1]->ttype==TYPE_void) {
		@:merged_union_1(int,tloc,tvar,simple)@
	} else if (b[0]->ttype==TYPE_oid && b[1]->ttype==TYPE_oid) {
		@:merged_union_1(int,tloc,tloc,simple)@
#else
	if (b[0]->ttype==TYPE_void && b[1]->ttype==TYPE_void) {
		@:merged_union_1(lng,tvar,tvar,simple)@
	} else if (b[0]->ttype==TYPE_void && b[1]->ttype==TYPE_oid) {
		@:merged_union_1(lng,tvar,tloc,simple)@
	} else if (b[0]->ttype==TYPE_oid && b[1]->ttype==TYPE_void) {
		@:merged_union_1(lng,tloc,tvar,simple)@
	} else if (b[0]->ttype==TYPE_oid && b[1]->ttype==TYPE_oid) {
		@:merged_union_1(lng,tloc,tloc,simple)@
#endif
	} else {
		any = b[0]->ttype;
		switch(ATOMstorage(b[0]->ttype)) {
		case TYPE_chr:	@:merged_union_2(chr,tloc,simple)@
		case TYPE_sht:	@:merged_union_2(sht,tloc,simple)@
		case TYPE_int:	@:merged_union_2(int,tloc,simple)@
		case TYPE_flt:	@:merged_union_2(flt,tloc,simple)@
		case TYPE_lng:	@:merged_union_2(lng,tloc,simple)@
		case TYPE_dbl:	@:merged_union_2(dbl,tloc,simple)@
		default:
			if (b[0]->tvarsized) {
				@:merged_union_2(any,tvar,atom)@
			} else {
				@:merged_union_2(any,tloc,atom)@
			}
		}
	}
	/* merge-union each of the remaining BAT-pairs */
	for (k=1; k<npairs; k++) {
		i = (k<<1);
		j = i+1;
/* HACK(?): compare [v]oid (unsigned) at int/lng (signed) to get nil's first... */
#if SIZEOF_OID == SIZEOF_INT
		if (b[i]->ttype==TYPE_void || b[j]->ttype==TYPE_void) {
			@:merged_union_3(int,tail,simple)@
		} else if (b[i]->ttype==TYPE_oid && b[j]->ttype==TYPE_oid) {
			@:merged_union_3(int,tloc,simple)@
#else
		if (b[i]->ttype==TYPE_void || b[j]->ttype==TYPE_void) {
			@:merged_union_3(lng,tail,simple)@
		} else if (b[i]->ttype==TYPE_oid && b[j]->ttype==TYPE_oid) {
			@:merged_union_3(lng,tloc,simple)@
#endif
		} else {
			any = b[i]->ttype;
			switch(ATOMstorage(b[i]->ttype)) {
			case TYPE_chr:	@:merged_union_4(chr,tloc)@
			case TYPE_sht:	@:merged_union_4(sht,tloc)@
			case TYPE_int:	@:merged_union_4(int,tloc)@
			case TYPE_flt:	@:merged_union_4(flt,tloc)@
			case TYPE_lng:	@:merged_union_4(lng,tloc)@
			case TYPE_dbl:	@:merged_union_4(dbl,tloc)@
			default:
				if (b[i]->tvarsized) {
					@:merged_union_4(any,tvar)@
				} else {
					@:merged_union_4(any,tloc)@
				}
			}
		}
	}

	/* set BAT properties */

	for (k=0; k<npairs; k++) {
		BAT *b0 = b[2*k], *b1 = b[(2*k)+1];
		BATseqbase(bn[k], (oid)0);
		bn[k]->batBuns->free = dst[k] - bn[k]->batBuns->base;
		BATsetcount(bn[k], bn[k]->batBuns->free/BUNsize(bn[k]));
		if (!bn[k]->batDirty) bn[k]->batDirty = TRUE;
		BATkey(bn[k],TRUE);
		BATkey(BATmirror(bn[k]),FALSE);
		bn[k]->hsorted = GDK_SORTED;
		if (k==0 || (BATcount(b0)==0 && BATcount(b1)==0)) {
			bn[k]->tsorted = GDK_SORTED;
		} else
		  if (BATcount(b0)==0) {
			bn[k]->tsorted = (BATtordered(b1)&1 ? GDK_SORTED : FALSE);
		} else
		  if (BATcount(b1)==0) {
			bn[k]->tsorted = (BATtordered(b0)&1 ? GDK_SORTED : FALSE);
		} else {
			bn[k]->tsorted = ( ( concat && \
			                     BATtordered(b0)&BATtordered(b1)&1 && \
			                     atom_LE(BUNtail(b0,BUNlast(b0)-BUNsize(b0)),BUNtail(b1,BUNfirst(b1)),b0->ttype) ) \
			                  ? GDK_SORTED \
			                  : FALSE );
		}
		bn[k]->hdense = TRUE;
		bn[k]->tdense = FALSE;
	}

	/* insert bn[] BATs in BN BAT */

	DST = BUNlast(BN);
	BS = BUNsize(BN);
	BATseqbase(BN, (oid)0);
	for (k=0; k<npairs; k++) {
		voidany_bunfastins_nocheck_noinc(BN,DST,0,&bn[k]->batCacheid);
		BBPunfix(bn[k]->batCacheid);
		DST += BS;
	}
	BN->batBuns->free = DST - BN->batBuns->base;
	BATsetcount(BN, BN->batBuns->free/BS); 
	if (!BN->batDirty) BN->batDirty = TRUE;
	BATkey(BN,TRUE);
	BATkey(BATmirror(BN),TRUE);
	BN->hsorted = GDK_SORTED;
	BN->tsorted = FALSE;
	BN->hdense = TRUE;
	BN->tdense = FALSE;

	*res = BN;

	GDKfree(w);

	return GDK_SUCCEED;
bunins_failed:
	GDKerror("merged_union: bunins failed.\n");
cleanup:
	BBPreclaim(BN);
	for (k=0; k<npairs; k++) {
		BBPreclaim(bn[k]);
	}
	return GDK_FAIL;
}

int CMDmerged_union( BAT** res, ptr L, int ltpe, ptr R, int rtpe, ... )
{
	int i, tpe, nbats = 0, ret = GDK_SUCCEED;
	BAT *b[MAXPARAMS];
	va_list ap;
        ptr p;

	/* first convert any constant parameters to fake projects */
	if (CMDfakeProject(b+nbats, L, ltpe) == GDK_SUCCEED) {
		nbats++;
		if (CMDfakeProject(b+nbats, R, rtpe) == GDK_SUCCEED) {
			nbats++;
			va_start(ap,rtpe);
			while((p = va_arg(ap, ptr)) != NULL) {
        		        tpe = va_arg(ap, int);
				if (CMDfakeProject(b+nbats, p, tpe) == GDK_SUCCEED) {
					nbats++;
				} else {
					ret = GDK_FAIL;
					break;
				}
			}
			va_end(ap);
		}
	}
	if (ret == GDK_SUCCEED) {
		ret = merged_union(res, nbats, b);
	}
	/* unfix all bats; this destroys any created fake projects */
	for(i=0; i<nbats; i++) 
		BBPunfix(b[i]->batCacheid);
	return ret;
}

int
CMDll_strSplit(BAT **res, BAT *strs, BAT *seps)
{
        BAT *bn;
        BUN p_str, p_sep, last_str_row;
        int bs_str, bs_sep;
        size_t cnt, seplen;
        oid base;
        char *actual_str;
        bit triv_prop;

        /* check arguments */

        BATcheck(strs, "ll_strSplit");
        BATcheck(seps, "ll_strSplit");

        cnt = BATcount(strs);
        base = strs->hseqbase;
        ERRORcheck(!BAThdense(strs) || !BAThdense(seps), 
                "ll_strSplit: input BATs (strs, seps) must be void-headed with non-nil seqbase.\n");
        ERRORcheck(BATcount(seps)!=cnt || seps->hseqbase!=base,
                "ll_strSplit: input BATs (strs, seps) must be head-aligned.\n");

        /* create result BAT */

        bn = BATnew(TYPE_oid, TYPE_str, 2*cnt);
        if (bn == NULL) {
                GDKerror("ll_strSplit: BATnew(TYPE_oid, TYPE_str, %d) failed.\n", 2*cnt);
                return GDK_FAIL;
        }

        /* do the ll_strSplit */

        bs_str = BUNsize(strs);
        bs_sep = BUNsize(seps);

        p_str = BUNfirst(strs);
        p_sep = BUNfirst(seps);

        for (last_str_row = BUNlast(strs) ;
             p_str < last_str_row ;
             p_str += bs_str, p_sep += bs_sep) {

                str sep = (str)BUNtvar(seps, p_sep);
                seplen = strlen(sep);
                actual_str = GDKstrdup((str)BUNtvar(strs, p_str));

                if (!seplen)
                {
                        bunfastins(bn, &base, actual_str);
                        base++;
                        continue;
                }
  
                while (actual_str) {
                        char *e = strstr(actual_str, sep);
  
                        if (!e)
                                break;
  
                        *e = 0;
                        bunfastins(bn, &base, actual_str);
                        actual_str = e + seplen;
                }
 
                if (actual_str && *actual_str)
                        bunfastins(bn, &base, actual_str);
                base++;
        }

        /* set result properties */

        if (!bn->batDirty) bn->batDirty = TRUE;
        triv_prop = (BATcount(bn) < 2);
        BATkey(bn,triv_prop);
        BATkey(BATmirror(bn),triv_prop);
        bn->hsorted = GDK_SORTED;
        bn->tsorted = triv_prop;
        bn->hdense = triv_prop;
        bn->tdense = FALSE;
        if (BATcount(bn) == 0) {
                BATseqbase(bn, (oid)0);
        } else if (BATcount(bn) == 1) {
                BATseqbase(bn, *(oid*)BUNhloc(bn,BUNfirst(bn)));
        }
        *res = bn;
        return GDK_SUCCEED;
bunins_failed:
        GDKerror("ll_strSplit: bunins failed.\n");
        return GDK_FAIL;
}


int
CMDnormSpace(str *res, str string)
{
        char *ws, *cur, *pointer;
        size_t n;

        pointer = GDKstrdup(string);
        if (pointer == NULL) {
                GDKerror("normSpace: GDKmalloc(" SZFMT ") failed.\n",
                         strlen (string) + 1);
                return GDK_FAIL;
        }

        *res = pointer;

        cur = string;
        ws = " \f\n\r\t\v";
        n = strspn (cur, ws);
        if (n)
        {
            *pointer = ' ';
            pointer++;
            cur += n;
        }

        while ((n = strcspn (cur, ws))) {
            while (n > 0)
            {
                *pointer = *cur;
                pointer++;
                cur++;
                n--;
            }
            n = strspn (cur, ws);
            if (n)
            {
                *pointer = ' ';
                pointer++;
                cur += n;
            }
        }
        *pointer = '\0';

        return GDK_SUCCEED;
}

int
math_unary_up_ROUND(dbl *res, dbl *x)
{
        if (*x == dbl_nil) {
                *res = dbl_nil;
        } else {
                double integral;
                double tmp = modf(*x, &integral);

                tmp = floor(tmp + 0.5);
                tmp += integral;

                *res = tmp;
        }

        return (GDK_SUCCEED);
}




#define KIND_NODE (oid)0
#define KIND_TEXT (oid)1
#define KIND_STR  (oid)2

int CMDcombine_text_string( BAT** res, BAT *iter, BAT *kind, BAT *str_value, int *result_size )
{
	BAT *bn;
	BUN qi, pi, pk, ps;
	int bsi, bsk, bss;
	size_t cnt, len, strsize = 1024;
	oid base0, base, i0, k0;
	str actual_str = NULL;
	bit triv_prop;
	
	*res = NULL;

	/* check arguments */

	BATcheck(iter, "combine_text_string");
	BATcheck(kind, "combine_text_string");
	BATcheck(str_value, "combine_text_string");

	cnt = BATcount(iter);
	base = iter->hseqbase;
	ERRORcheck(!BAThdense(iter) || !BAThdense(kind) || !BAThdense(str_value), 
		"combine_text_string: all input BATs (iter, kind, str_value) must be void-headed with non-nil seqbase.\n");
	ERRORcheck(BATcount(kind)!=cnt || BATcount(str_value)!=cnt || kind->hseqbase!=base || str_value->hseqbase!=base,
		"combine_text_string: all input BATs (iter, kind, str_value) must be head-aligned.\n");
	ERRORcheck(!(BATtordered(iter)&1),
		"combine_text_string: input BAT iter must be sorted on tail.\n");

	/* create result BAT */

	bn = BATnew(TYPE_oid, TYPE_str, *result_size);
	if (bn == NULL) {
		GDKerror("combine_text_string: BATnew(TYPE_oid, TYPE_str, %d) failed.\n", *result_size);
		return GDK_FAIL;
	}

	/* do the combine_text_string */

	bsi = BUNsize(iter);
	bsk = BUNsize(kind);
	bss = BUNsize(str_value);

	pi = BUNfirst(iter);
	pk = BUNfirst(kind);
	ps = BUNfirst(str_value);

	/* allocate str buffer */
	actual_str = (str)GDKmalloc(strsize);
	if (actual_str == NULL) {
		GDKerror("combine_text_string: GDKmalloc(" SZFMT ") failed.\n", strsize);
		goto cleanup;
	}
	len = 0;
	actual_str[0] = '\0';
	k0 = oid_nil;
	i0 = *(oid*)BUNtail(iter,pi); /* FIXME: "tvar" (void) vs. "tloc" (oid) */
	base0 = oid_nil;

	for (qi = BUNlast(iter) ; pi < qi ; pi += bsi, pk += bsk, ps += bss) {
		oid i = *(oid*)BUNtail(iter,pi); /* FIXME: "tvar" (void) vs. "tloc" (oid) */
		oid k = *(oid*)BUNtail(kind,pk); /* FIXME: "tvar" (void) vs. "tloc" (oid) */
		str s = (str)BUNtvar(str_value,ps);
		size_t l = strlen(s) + 1;
		if ( i0 < i || k == KIND_NODE ) {
			/* new iter or new node */
			if (len > 0) {
				/* actual_str of (previous) iter is not empty => insert it into result */
				bunfastins(bn, &base0, actual_str);
				len = 0;
				actual_str[0] = '\0';
			}
			k0 = oid_nil;
		}
		if (len+l >= strsize) {
			/* extend str buffer */
			do {
				strsize *= 2;
			} while (len+l >= strsize);
			actual_str = GDKrealloc(actual_str, strsize);
			if (actual_str == NULL) {
				GDKerror("combine_text_string: GDKrealloc(" SZFMT ") failed.\n", strsize);
				goto cleanup;
			}
		}
		if (k0 == KIND_STR && k == KIND_STR) {
			/* insert ' '-separator between adjacent STRs */
			actual_str[len++] = ' ';
			actual_str[len] = '\0';
		}
        if (k != KIND_NODE)
        {
		    strcpy(actual_str + len, s); /* we know it fits */
		    len += l - 1;	/* compensate for +1 earlier on */
        }
		i0 = i;
		k0 = k;
		base0 = base++;
	}

	if (len > 0) {
		bunfastins(bn, &base0, actual_str);
	}

	/* set result properties */

	if (!bn->batDirty) bn->batDirty = TRUE;
	triv_prop = (BATcount(bn) < 2);
	BATkey(bn,TRUE);
	BATkey(BATmirror(bn),triv_prop);
	bn->hsorted = GDK_SORTED;
	bn->tsorted = triv_prop;
	bn->hdense = triv_prop;
	bn->tdense = FALSE;
	if (BATcount(bn) == 0) {
		BATseqbase(bn, (oid)0);
	} else if (BATcount(bn) == 1) {
		BATseqbase(bn, *(oid*)BUNhloc(bn,BUNfirst(bn)));
	}
	*res = bn;

	return GDK_SUCCEED;
bunins_failed:
	GDKerror("combine_text_string: bunins failed.\n");
cleanup:
	if (actual_str) GDKfree(actual_str);
	BBPreclaim(bn);
	return GDK_FAIL;
}

int CMDstring_join ( BAT** res, BAT *iter_str, BAT *separator  )
{
	BAT *bn;
	BUN bun_iter_str, bun_sep, last_iter_str, last_sep;
	int bs_iter_str, bs_sep;
	size_t len, sep_len, strsize = 1024;
	oid i, i0, sep_oid, sep0;
	str s, sep, actual_str = NULL;
	bit triv_prop, first_string;
	
	*res = NULL;

	/* check arguments */

	BATcheck(iter_str, "string_join");
	BATcheck(separator, "string_join");

	ERRORcheck(!(BAThordered(iter_str)&1),
		"string_join: input BAT iter_str must be sorted on head.\n");
	ERRORcheck(!(BAThordered(separator)&1),
		"string_join: input BAT separator must be sorted on head.\n");

	/* create result BAT */

	bn = BATnew(TYPE_oid, TYPE_str, BATcount(separator));
	if (bn == NULL) {
		GDKerror("string_join: BATnew(TYPE_oid, TYPE_str, %d) failed.\n", BATcount(separator));
		return GDK_FAIL;
	}

	/* do the string_join */

	bs_iter_str = BUNsize(iter_str);
	bs_sep = BUNsize(separator);

	bun_iter_str = BUNfirst(iter_str);
	last_iter_str = BUNlast(iter_str);
	bun_sep = BUNfirst(separator);
	last_sep = BUNlast(separator);

	/* handling the empty cases */

	if (bun_iter_str == last_iter_str && bun_sep == last_sep) {
		/* ... head */
		BATkey (bn, TRUE);
                bn->hsorted = GDK_SORTED;
		bn->hdense = TRUE;
		BATseqbase (bn, (oid)0); /* does not really matter */
		/* ... tail */
		BATkey (BATmirror(bn), TRUE);
                bn->tsorted = GDK_SORTED;
		bn->tdense = FALSE;
		*res = bn;
 	       	return GDK_SUCCEED;
	}
	else if (bun_sep == last_sep) {
		GDKerror("string_join: expected oid %i@0 in iter_str "
                         "is missing in separator (0 rows).",
                         *(oid*)BUNhead(iter_str,bun_iter_str)); /* FIXME: "hvar" (void) vs. "hloc" (oid) */
		return GDK_FAIL;
	}
	else if (bun_iter_str == last_iter_str) {
		sep0 = oid_nil;
		sep_oid = *(oid*)BUNhead(separator,bun_sep); /* FIXME: "hvar" (void) vs. "hloc" (oid) */
		@:append_sep_and_set_props@
 	       	return GDK_SUCCEED;
	}

	/* allocate str buffer */
	actual_str = (str)GDKmalloc(strsize);
	if (actual_str == NULL) {
		GDKerror("string_join: GDKmalloc(" SZFMT ") failed.\n", strsize);
		goto cleanup;
	}
	len = 0;
	actual_str[0] = '\0';

	i0 = *(oid*)BUNhead(iter_str,bun_iter_str); /* FIXME: "hvar" (void) vs. "hloc" (oid) */
	first_string = 1;
	sep0 = oid_nil;

@= get_next_separator
	/* - goes to the next row in the separator bat
	     to get the separator for the next iter value
	   - produces an error if oids are not aligned */
	sep_oid = *(oid*)BUNhead(separator,bun_sep); /* FIXME: "hvar" (void) vs. "hloc" (oid) */

	while (i0 > sep_oid && bun_sep != last_sep) {
		if (sep0 == sep_oid) {
			GDKerror("string_join: the head of separator has to be keyed.");
			return GDK_FAIL;
		}
		bunfastins(bn, &sep_oid, "");
		sep0 = sep_oid;
		bun_sep += bs_sep;
	        sep_oid = *(oid*)BUNhead(separator,bun_sep); /* FIXME: "hvar" (void) vs. "hloc" (oid) */
	}
	if (i0 == sep_oid && bun_sep != last_sep) {
		sep = (str)BUNtvar(separator,bun_sep);
		sep_len = strlen(sep);
	}
	else {
		GDKerror("string_join: expected oid %i@0 in iter_str "
			 "is missing in separator.",
			 i0);
		return GDK_FAIL;
	}
@c
	@:get_next_separator@

	for (; bun_iter_str < last_iter_str ; bun_iter_str += bs_iter_str) {
		i = *(oid*)BUNhead(iter_str,bun_iter_str); /* FIXME: "hvar" (void) vs. "hloc" (oid) */
		s = (str)BUNtvar(iter_str,bun_iter_str);

		size_t l;

		if (i0 < i) {
			bunfastins(bn, &i0, actual_str);
			len = 0;
			actual_str[0] = '\0';
			i0 = i;
			first_string = 1;

			sep0 = sep_oid;
			bun_sep += bs_sep;
			@:get_next_separator@
		}

		l = strlen(s) + sep_len + 1;

		if (len+l >= strsize) {
			/* extend str buffer */
			do {
				strsize *= 2;
			} while (len+l >= strsize);
			actual_str = GDKrealloc(actual_str, strsize);
			if (actual_str == NULL) {
				GDKerror("string_join: GDKrealloc(" SZFMT ") failed.\n", strsize);
				goto cleanup;
			}
		}

		/* adds the separator (starting before the second string) */

		if (first_string) {
			first_string = 0;
		}
		else {
			strcpy(actual_str+len, sep); /* we know it fits */
			len += sep_len;
		}

		strcpy(actual_str + len, s); /* we know it fits */
		len += l - sep_len - 1;	/* just strlen(s) */
	}

	/* inserts last row */

	if (len > 0) {
		bunfastins(bn, &i0, actual_str);
		sep0 = sep_oid;
		bun_sep += bs_sep;
	}

@= append_sep_and_set_props
	while (bun_sep != last_sep) {
	        sep_oid = *(oid*)BUNhead(separator,bun_sep); /* FIXME: "hvar" (void) vs. "hloc" (oid) */
		if (sep0 == sep_oid) {
			GDKerror("string_join: the head of separator has to be keyed.");
			return GDK_FAIL;
		}
		bunfastins(bn, &sep_oid, "");
		sep0 = sep_oid;
		bun_sep += bs_sep;
	}

	GDKfree(actual_str);

	/* set result properties */

	if (!bn->batDirty) bn->batDirty = TRUE;
	triv_prop = (BATcount(bn) < 2);
	BATkey(bn,TRUE);
	BATkey(BATmirror(bn),triv_prop);
	bn->hsorted = GDK_SORTED;
	bn->tsorted = triv_prop;
	bn->hdense = triv_prop;
	bn->tdense = FALSE;
	if (BATcount(bn) == 0) {
		BATseqbase(bn, (oid)0);
	} else if (BATcount(bn) == 1) {
		BATseqbase(bn, *(oid*)BUNhloc(bn,BUNfirst(bn)));
	}
	*res = bn;
@c
	@:append_sep_and_set_props@

	return GDK_SUCCEED;
bunins_failed:
	GDKerror("string_join: bunins failed.\n");
cleanup:
	if (actual_str) GDKfree(actual_str);
	BBPreclaim(bn);
	return GDK_FAIL;
}

int CMDenumerate ( BAT** res, BAT *startval, BAT *length )
{
        BAT *bn;
        BUN cur_bun, length_bun, bun_last;
        lng bs_startval, bs_length, number, counter, result_size;
        size_t cnt;
        oid base, head_oid;
        bit triv_prop;

        /* check arguments */

        BATcheck(startval, "enumerate");
        BATcheck(length, "enumerate");

        cnt = BATcount(startval);
        base = startval->hseqbase;
        ERRORcheck(!BAThdense(startval) || !BAThdense(length), 
                "enumerate: input BATs (startval, length) must be void-headed with non-nil seqbase.\n");
        ERRORcheck(BATcount(length)!=cnt || length->hseqbase!=base,
                "enumerate: input BATs (startval, length) must be head-aligned.\n");

        /* create result BAT */
        if (CMDsum_lng_lng(&result_size, length) == GDK_FAIL) {
                GDKerror("enumerate: summing up 'length' failed.\n");
                return GDK_FAIL;
        }

        bn = BATnew(TYPE_oid, TYPE_lng, result_size);
        if (bn == NULL) {
                GDKerror("enumerate: BATnew(TYPE_oid, TYPE_lng, %d) failed.\n", result_size);
                return GDK_FAIL;
        }

        /* do the enumerate */

        for (cur_bun = BUNfirst(startval), length_bun = BUNfirst(length),
             bun_last = BUNlast(startval),
             bs_startval = BUNsize(startval), bs_length = BUNsize(length);
             cur_bun < bun_last;
             cur_bun += bs_startval, length_bun += bs_length)
        {
	        head_oid = *(oid*)BUNhead(startval,cur_bun); /* FIXME: "hvar" (void) vs. "hloc" (oid) */
                number = *(lng*) BUNtloc (startval, cur_bun);
                counter = *(lng*) BUNtloc (length, length_bun);
                while (counter)
                {
		        bunfastins(bn, &head_oid, &number);
                        number++;
                        counter--;
                }
        }

	if (!bn->batDirty) bn->batDirty = TRUE;
	triv_prop = (BATcount(bn) < 2);
	BATkey(bn,triv_prop);
	BATkey(BATmirror(bn),triv_prop);
	bn->hsorted = GDK_SORTED;
	bn->tsorted = triv_prop;
	bn->hdense = triv_prop;
	bn->tdense = FALSE;
	if (BATcount(bn) == 0) {
		BATseqbase(bn, (oid)0);
	} else if (BATcount(bn) == 1) {
		BATseqbase(bn, *(oid*)BUNhloc(bn,BUNfirst(bn)));
	}
	*res = bn;

	return GDK_SUCCEED;
bunins_failed:
	GDKerror("enumerate: bunins failed.\n");
	return GDK_FAIL;
}

int CMDmposjoin ( BAT** res, BAT* pre, BAT* cont, BAT* ws_item )
{
	BAT *bn, **batlist = NULL, *the_cont_bat = NULL;
	BUN q, pp, pf, pw, dst;
	int bs, bsp, bsf, ii = 0, tt = 0;
	size_t cnt, len;
	oid base, wl, wh;
	bit triv_prop;
	bit fake_cont = FALSE;
	bit fake_ws_item = FALSE;
	
	*res = NULL;

	/* check arguments */

	BATcheck(pre, "mposjoin");
	BATcheck(cont, "mposjoin");
	BATcheck(ws_item, "mposjoin");

	len = BATcount(ws_item);
	cnt = BATcount(pre);
	base = pre->hseqbase;
	fake_cont = is_fake_project(cont);
	
	if (fake_cont) {
		ERRORcheck(!BAThdense(pre), 
			"mposjoin: input BAT pre must have a dense head.\n");
		ERRORcheck(!BAThdense(ws_item), 
			"mposjoin: input BAT ws_item must have a dense head.\n");
	} else {
		ERRORcheck(!BAThdense(pre) || !BAThdense(cont) || !BAThdense(ws_item), 
			"mposjoin: all input BATs (pre, cont, ws_item) must have a dense head.\n");
		ERRORcheck(BATcount(cont)!=cnt || cont->hseqbase!=base,
			"mposjoin: first two input BATs (pre & cont) must be head-aligned.\n");
	}
	ERRORcheck(len==0,
		"mposjoin: third input BAT (ws_item) must not be empty.\n");

	the_cont_bat = BATdescriptor(*(bat*)BUNtloc(ws_item, BUNfirst(ws_item)));
	tt = the_cont_bat->ttype;
	BBPunfix(the_cont_bat->batCacheid);
	the_cont_bat = NULL;

	if (cnt==0) {
		@:mpos_res_empty@
	}

	ii = 0;
	
	if (fake_cont) {
		oid the_cont_id = *(oid*)BUNtail(cont, BUNfirst(cont));
		len = 1;
		batlist = &the_cont_bat;
		BUNfndVOID(pw, ws_item, &the_cont_id);
		if (pw==NULL) {
			@:mpos_res_empty@
		}

		@:mpos_init_batlist@
		if (!fake_ws_item) {
			*res = bn = BATleftfetchjoin(pre, batlist[0], oid_nil);
			@:mpos_free_batlist@
			if (bn == NULL) {
				GDKerror("mposjoin: BATleftfetchjoin(pre, ws_item["SZFMT"]) failed.\n",
					 the_cont_id);
				return GDK_FAIL;
			}
			return GDK_SUCCEED;
		}
	
	} else {
		batlist = (BAT**)GDKmalloc(len * sizeof(BAT*));
		if (batlist == NULL) {
			GDKerror("mposjoin: GDKmalloc(" SZFMT ") failed.\n", len * sizeof(BAT*));
			return GDK_FAIL;
		}
		BATloopFast(ws_item, pw, q, bs) {
			@:mpos_init_batlist@
		}
	}

@= mpos_init_batlist
{
		bit fake_item = FALSE;
		bat bid = *(bat*)BUNtloc(ws_item, pw);
		batlist[ii] = BATdescriptor(bid);
		fake_item = is_fake_project(batlist[ii]);
		fake_ws_item |= fake_item;
		if (!(fake_item || BAThdense(batlist[ii]))) {
			GDKerror("mposjoin: all BATs in the tail of the third input BAT (ws_item) must have a dense head.\n");
			ii++;
			@:mpos_free_batlist@
			return GDK_FAIL;
		}
		if (ATOMtype(batlist[0]->ttype) != ATOMtype(batlist[ii]->ttype)) {
			GDKerror("mposjoin: all BATs in the tail of the third input BAT (ws_item) must have the same tail type (%d: %d != %d).\n",
				ii, batlist[ii]->ttype, batlist[0]->ttype);
			ii++;
			@:mpos_free_batlist@
			assert(0);
			return GDK_FAIL;
		}
		ii++;
}	
@
@= mpos_res_empty
	cnt = 0;
	@:mpos_res_create@
	@:mpos_res_prop@

	return GDK_SUCCEED;
@
@= mpos_res_create
	/* create result BAT */

	bn = BATnew(TYPE_void, ATOMtype(tt), cnt);
	if (bn == NULL) {
		GDKerror("mposjoin: BATnew(TYPE_void, %s, " SZFMT ") failed.\n", ATOMname(ATOMtype(tt)), cnt);
		@:mpos_free_batlist@
		return GDK_FAIL;
	}
	BATseqbase(bn, base);
@c
	@:mpos_res_create@
	bs = BUNsize(bn);
	dst = BUNlast(bn);

	/* do the mposjoin */

	wl = ws_item->hseqbase;
	wh = wl + len - 1;

	bsp = BUNsize(pre);
	if (fake_cont) {
		bsf = 0;
	} else {
		bsf = BUNsize(cont);
	}

	pp = BUNfirst(pre);
	pf = BUNfirst(cont);

@= mposjoin
	/*  @1: ATOMstorage(ATOMtype(batlist[0]->ttype)) (chr, sht, int, flt, lng, dbl, any)
	 *  @2: tloc, tvar, tail
	 */
	 if (fake_cont) {
	 	/* !fake_ws_item handled above */
	 	@:mposjoin_fake_fake(@1,@2)@
	 } else {
		if (fake_ws_item) {
			@:mposjoin_(@1,@2,is_fake_project(b))@
		} else {
			@:mposjoin_(@1,@2,FALSE)@
		}
	}
	break;
@
@= mposjoin_fake_fake
	/*  @1: ATOMstorage(ATOMtype(batlist[0]->ttype)) (chr, sht, int, flt, lng, dbl, any)
	 *  @2: tloc, tvar, tail
	 */
	BAT *b = batlist[0];
	ptr  w = BUN@2(b, BUNfirst(b));
	for (q = BUNlast(pre) ; pp < q ; pp += bsp) {
		void@1_bunfastins_nocheck_noinc(bn,dst,0,w);
		dst += bs;
	}
@
@= mposjoin_
	/*  @1: ATOMstorage(ATOMtype(batlist[0]->ttype)) (chr, sht, int, flt, lng, dbl, any)
	 *  @2: tloc, tvar, tail
	 *  @3: FALSE / is_fake_project(b)
	 */
	for (q = BUNlast(pre) ; pp < q ; pp += bsp, pf += bsf) {
		oid p = *(oid*)BUNtail(pre,pp);  /* FIXME: "tvar" (void) vs. "tloc" (oid) */
		oid f = *(oid*)BUNtail(cont,pf); /* FIXME: "tvar" (void) vs. "tloc" (oid) */
		if (f >= wl && f <= wh) {
			BAT *b = batlist[f - wl];
			if (@3) {
				void@1_bunfastins_nocheck_noinc(bn,dst,0,BUN@2(b,BUNfirst(b)));
				dst += bs;
			} else {
				oid l = b->hseqbase;
				oid h = l + BATcount(b) - 1;
				if (p >= l && p <= h) {
					oid b0 = BUNindex(b,BUNfirst(b));
					void@1_bunfastins_nocheck_noinc(bn,dst,0,BUN@2(b,BUNptr(b,p-l+b0)));
					dst += bs;
				}
			}
		}
	}
@c

	switch(ATOMstorage(ATOMtype(batlist[0]->ttype))) {
	case TYPE_chr:	@:mposjoin(chr,tloc,simple)@
	case TYPE_sht:	@:mposjoin(sht,tloc,simple)@
#if SIZEOF_OID == SIZEOF_INT
	/* cannot use tloc on oid(void) */
	case TYPE_int:	@:mposjoin(int,tail,simple)@
#else
	case TYPE_int:	@:mposjoin(int,tloc,simple)@
#endif
	case TYPE_flt:	@:mposjoin(flt,tloc,simple)@
#if SIZEOF_OID == SIZEOF_LNG
	/* cannot use tloc on oid(void) */
	case TYPE_lng:	@:mposjoin(lng,tail,simple)@
#else
	case TYPE_lng:	@:mposjoin(lng,tloc,simple)@
#endif
	case TYPE_dbl:	@:mposjoin(dbl,tloc,simple)@
	default:
		if (batlist[0]->tvarsized) {
			@:mposjoin(any,tvar,atom)@
		} else {
			@:mposjoin(any,tloc,atom)@
		}
	}
	bn->batBuns->free = dst - bn->batBuns->base;
	BATsetcount(bn, bn->batBuns->free/BUNsize(bn));

@= mpos_res_prop
    /* check result size */
    if (BATcount(pre) > BATcount(bn)) {
		GDKerror("mposjoin: missing matches. The result requires the "
                 "same number of tuples as the first two input arguments.");
		@:mpos_free_batlist@
		return GDK_FAIL;
	}
    if (BATcount(pre) < BATcount(bn)) {
		GDKerror("mposjoin: more than one match per input tuple. "
                 "seqbase does not match anymore.");
		@:mpos_free_batlist@
		return GDK_FAIL;
	}

	/* set result properties */

	if (!bn->batDirty) bn->batDirty = TRUE;
	triv_prop = (BATcount(bn) < 2);
	BATkey(bn,TRUE);
	BATkey(BATmirror(bn),triv_prop);
	bn->hsorted = GDK_SORTED;
	bn->tsorted = triv_prop;
	bn->hdense = TRUE;
	bn->tdense = FALSE;

	*res = bn;
@c
	@:mpos_res_prop@
	@:mpos_free_batlist@

	return GDK_SUCCEED;
bunins_failed:
	GDKerror("mposjoin: bunins failed.\n");
	BBPreclaim(bn);
@= mpos_free_batlist
	while (ii > 0) {
		BBPunfix(batlist[--ii]->batCacheid);
	}
	if (batlist && !fake_cont) {
		GDKfree(batlist);
	}
@c
	@:mpos_free_batlist@
	return GDK_FAIL;
}


int CMDmvaljoin ( BAT** res, BAT* pre, BAT* cont, BAT* ws_item )
{
	BAT *bn, **batlist = NULL, *the_cont_bat = NULL;
	BUN q, pp, pf, pw;
	int bsp, bsf, bsw, ii = 0;
	size_t cnt, len, sze;
	oid base, wl, wh;
	bit triv_prop, all_hash, all_sort, some_hash, some_sort, all_key, fake_cont = FALSE;
	
	*res = NULL;

	/* check arguments */

	BATcheck(pre, "mvaljoin");
	BATcheck(cont, "mvaljoin");
	BATcheck(ws_item, "mvaljoin");

	len = BATcount(ws_item);
	cnt = BATcount(pre);
	base = pre->hseqbase;
	fake_cont = is_fake_project(cont);
	
	if (fake_cont) {
		ERRORcheck(!BAThdense(pre) || !BAThdense(ws_item), 
			"mvaljoin: input BATs pre & ws_item must have a dense head.\n");
	} else {
		ERRORcheck(!BAThdense(pre) || !BAThdense(cont) || !BAThdense(ws_item), 
			"mvaljoin: all input BATs (pre, cont, ws_item) must have a dense head.\n");
		ERRORcheck(BATcount(cont)!=cnt || cont->hseqbase!=base,
			"mvaljoin: first two input BATs (pre & cont) must be head-aligned.\n");
	}
	ERRORcheck(len==0,
		"mvaljoin: third input BAT (ws_item) must not be empty.\n");

	sze = cnt;
	ii = 0;
	all_hash = all_sort = all_key = TRUE;
	some_hash = some_sort = FALSE;
	
	if (sze == 0) {
		@:mval_res_empty@
	}
	if (fake_cont) {
		oid the_cont_id = *(oid*)BUNtail(cont, BUNfirst(cont));
		len = 1;
		batlist = &the_cont_bat;
		BUNfndVOID(pw, ws_item, &the_cont_id);
		if (pw==NULL) {
			@:mval_res_empty@
		}

		@:mval_init_batlist@
		*res = bn = BATleftjoin(pre, BATmirror(batlist[0]), oid_nil);
		@:mval_free_batlist@
		if (bn == NULL) {
			GDKerror("mvaljoin: BATleftjoin(pre, BATmirror(ws_item["SZFMT"])) failed.\n",
				 the_cont_id);
			return GDK_FAIL;
		}
		return GDK_SUCCEED;

	} else {
		batlist = (BAT**)GDKmalloc(len * sizeof(BAT*));
		if (batlist == NULL) {
			GDKerror("mvaljoin: GDKmalloc(" SZFMT ") failed.\n", len * sizeof(BAT*));
			return GDK_FAIL;
		}
		BATloopFast(ws_item, pw, q, bsw) {
			@:mval_init_batlist@
		}
	}
	if (all_key) {
		sze = cnt;
	}

@= mval_init_batlist
{
		bit hsh, srt;
		bat bid = *(bat*)BUNtloc(ws_item, pw);
		batlist[ii] = BATdescriptor(bid);
		if (batlist[ii]->ttype != TYPE_oid &&
		    (batlist[ii]->ttype != TYPE_void || batlist[ii]->tseqbase == oid_nil)) {
			GDKerror("mvaljoin: all BATs in the tail of the third input BAT (ws_item) must have tail type OID.\n");
			ii++;
			@:mval_free_batlist@
			return GDK_FAIL;
		}
		hsh = (BAThash(BATmirror(batlist[ii]), 0) != NULL);
		srt = (BATtordered(batlist[ii])&1);
		all_hash &= hsh;
		all_sort &= srt;
		some_hash |= hsh;
		some_sort |= srt;
		all_key &= (batlist[ii]->tkey!=0);
		sze = MAX(sze, BATcount(batlist[ii]));
		ii++;
}	
@
@= mval_res_empty
	sze = 0;
	@:mval_res_create@
	@:mval_res_prop@

	return GDK_SUCCEED;
@
@= mval_res_create
	/* create result BAT */

	bn = BATnew(TYPE_oid, TYPE_oid, sze);
	if (bn == NULL) {
		GDKerror("mvaljoin: BATnew(TYPE_oid, TYPE_oid, " SZFMT ") failed.\n", sze);
		@:mval_free_batlist@
		return GDK_FAIL;
	}
@c
	@:mval_res_create@

	/* do the mvaljoin */

	wl = ws_item->hseqbase;
	wh = wl + len - 1;

	bsp = BUNsize(pre);
	bsf = BUNsize(cont);

	pp = BUNfirst(pre);
	pf = BUNfirst(cont);

@= hash_only
	hash_t h;
	BUN r;
	b = BATmirror(b);
	HASHloop_oid(b, b->hhash, h, (ptr)(&p), r) {
		oidoid_bunfastins(bn,&base,BUNtail(b,r)); /* FIXME: "tvar" (void) vs. "tloc" (oid) */
	}
@= sort_only
	BUN rp, rq;
	int bs;
	SORTloop_oid(b, rp, rq, (ptr)(&p), (ptr)(&p), bs) {
		oidoid_bunfastins(bn,&base,BUNhead(b,rp)); /* FIXME: "hvar" (void) vs. "hloc" (oid) */
	}
@= scan_only
	BUN rp, rq;
	int bs;
	BATloopFast(b, rp, rq, bs) {
		if (p == *(oid*)BUNtail(b,rp)) { /* FIXME: "tvar" (void) vs. "tloc" (oid) */
			oidoid_bunfastins(bn,&base,BUNhead(b,rp)); /* FIXME: "hvar" (void) vs. "hloc" (oid) */
		}
	}
@= hash_scan
	if (b->thash) {
		@:hash_only@
	} else {
		@:scan_only@
	}
@= sort_scan
	if (BATtordered(b)&1) {
		@:sort_only@
	} else {
		@:scan_only@
	}
@= hash_sort_scan
	if (b->thash) {
		@:hash_only@
	} else if (BATtordered(b)&1) {
		@:sort_only@
	} else {
		@:scan_only@
	}
@= mvaljoin
	for (q = BUNlast(pre) ; pp < q ; pp += bsp, pf += bsf) {
		oid p = *(oid*)BUNtail(pre,pp); /* FIXME: "tvar" (void) vs. "tloc" (oid) */
		oid f = *(oid*)BUNtail(cont,pf); /* FIXME: "tvar" (void) vs. "tloc" (oid) */
		if (f >= wl && f <= wh) {
			BAT *b = batlist[f - wl];
			@1
		}
		base++;
	}
@c

	if (all_hash) {
		@:mvaljoin(@:hash_only@)@
	} else if (all_sort) {
		@:mvaljoin(@:sort_only@)@
	} else if (some_hash && some_sort) {
		@:mvaljoin(@:hash_sort_scan@)@
	} else if (some_hash) {
		@:mvaljoin(@:hash_scan@)@
	} else if (some_sort) {
		@:mvaljoin(@:sort_scan@)@
	} else {
		@:mvaljoin(@:scan_only@)@
	}

@= mval_res_prop
	/* set result properties */

	if (!bn->batDirty) bn->batDirty = TRUE;
	triv_prop = (BATcount(bn) < 2);
	BATkey(bn,triv_prop||all_key);
	BATkey(BATmirror(bn),triv_prop);
	bn->hsorted = GDK_SORTED;
	bn->tsorted = triv_prop;
	bn->hdense = triv_prop;
	bn->tdense = triv_prop;
	if (BATcount(bn) == 0) {
		BATseqbase(bn, (oid)0);
		BATseqbase(BATmirror(bn), (oid)0);
	} else if (BATcount(bn) == 1) {
		BATseqbase(bn, *(oid*)BUNhloc(bn,BUNfirst(bn)));
		BATseqbase(BATmirror(bn), *(oid*)BUNtloc(bn,BUNfirst(bn)));
	}

	*res = bn;
@c
	@:mval_res_prop@
	@:mval_free_batlist@

	return GDK_SUCCEED;
bunins_failed:
	GDKerror("mvaljoin: bunins failed.\n");
	BBPreclaim(bn);
@= mval_free_batlist
	while (ii > 0) {
		BBPunfix(batlist[--ii]->batCacheid);
	}
	if (batlist && !fake_cont) {
		GDKfree(batlist);
	}
@c
	@:mval_free_batlist@
	return GDK_FAIL;
}



/*
 * Worker for the ebv() function.
 */
BAT *
BATebv (BAT *b)
{
    BAT *ret = NULL;    /* return value */
    BUN p = 0, q = 0;   /* BUN variables for iteration */
    int bunsz;          /* BUN size used for iteration (BATloopFast) */
    oid old;            /* Last head value we had seen */
    bit val;            /* Boolean result value that belongs to `old' */
    size_t cnt = 0;     /* "guess" of result cardinality */
    bit trivial;        /* indicator for "trivial" result properties */

    /* Just in case BATebv might be called from elsewhere than CMDebv:
     * check, that b in not NULL.
     */
    BATcheck(b, "BATebv");
    /* Input must be sorted by head value, tail must be boolean */
    ERRORcheck (!(BAThordered(b)&1), "BATebv: head of BAT must be sorted.\n");
    /* Needed only, if you want to disallow TYPE_void, 
     * which also matches the oid requirement of the signature;
     * or if BATebv could be called from somewhere/one else than CMDebv.
     */
    ERRORcheck (!(b->htype == TYPE_oid),
                "BATebv: head of BAT must have oid type.\n");
@(
    /* Not needed, if BATebv is only called from CMDebv,
     * since the signature only allows bit-tailed BATs.
     */
    ERRORcheck (!(b->ttype == TYPE_bit),
                "BATebv: tail of BAT must have bit type.\n");
@)

    /* Try to "guess" the result cardinality:
     * on the one hand, we don't want too allocate (far) too much memory;
     * on the other hand, we want to avoid BATextends (i.e., (large) memcpy's),
     * that occur if we initially allow too little space ... 
     * Obviously, BATcount(b) is the upper limit;
     * lower limit is just a "wild guess"...
     */
    if (BAThkey (b))
        cnt = BATcount (b);
    else
        cnt = MIN (200, BATcount (b));

    /* Create return BAT */
    ret = BATnew (b->htype, TYPE_bit, cnt);
    if (!ret)
        return ret;

    /*
     * Iterate over the input BAT.
     * Whenever we see a head value the first time, we record its tail
     * value in val. If we see the same head value a second (third,...)
     * time, we re-set val to false. When we reach the next head
     * value, (old, val) will be the correct BUN for the last group.
     */

    /* Initialize, ... */
    bunsz = BUNsize (b);
    p = BUNfirst (b);
    old = *(oid *) BUNhloc (b, p);
    val = *(bit *) BUNtloc (b, p);
    /* ... skip first, ... */
    p += bunsz;
    /* ... and process the rest. */
    for(q = BUNlast(b); p < q; p += bunsz) {
    	oid *head = (oid *) BUNhloc (b, p);
        if (*head == old)
            val = FALSE;
        else {
            bunfastins (ret, &old, &val);
            old = *head;
            val = *(bit *) BUNtloc (b, p);
        }
    }
    /* Don't forget to produce the last BUN. */
    bunfastins (ret, &old, &val);
    
    /* Set result properties ... */
    cnt = BATcount (ret);
    trivial = (cnt < 2) ? TRUE : FALSE;
    /* ... head ... */
    BATkey (ret, TRUE);
    ret->hsorted = GDK_SORTED;
    ret->hdense = trivial;
    if (trivial == TRUE) {
        if (cnt == 0)
            BATseqbase (ret, (oid)0); /* does not really matter */
        else /* (cnt == 1) */
            BATseqbase (ret, old);
    }
    /* ... tail */
    BATkey (BATmirror(ret), trivial);
    ret->tsorted = trivial;
    ret->tdense = FALSE;

    return ret;

/* required by bunfastins macro */
bunins_failed:
    BBPreclaim(ret);
    return NULL;
}

/*
 * Implementation of ebv(). Basically just calls BATebv().
 */
int
CMDebv (BAT **result, BAT *b)
{
    return (*result = BATebv (b)) ? GDK_SUCCEED : GDK_FAIL;
}

int
CMDinvalid_qname(str *ret, BAT *b) 
{
        str s = ATOMnilptr(TYPE_str);
	BUN p, q;
	int xx;

	BATloopFast(b,p,q,xx) {
            char *r = BUNtail(b,p);
	    if ((*r >= 'a' && *r <= 'z') || (*r >= 'A' && *r <= 'Z') || *(unsigned char*) r >= 128) {
                r++;
                while((*r >= 'a' && *r <= 'z') || (*r >= 'A' && *r <= 'Z') || (*(unsigned char*) r >= 128) ||
                      (*r == '_') || (*r == '.') || (*r == '-') || (*r >= '0' && *r <= '9')) r++;
                if (*r == 0) continue; /* ok */
            }
	    s = (str) BUNtail(b,p); break;
	}
	*ret = GDKstrdup(s);
        return GDK_SUCCEED;

}


MT_Lock pf_runtime_lock[4];

int CMDpflock(ptr *ret, int* nr) {
    *ret = (ptr) &pf_runtime_lock[(*nr)&3];
    return GDK_SUCCEED;
}

int
CMDlastmod_time(timestamp *ret, str filename) {
	struct stat st;
	*(lng*) ret = lng_nil;
	if (stat(filename, &st) == 0) {
		lng msecs = 1000*st.st_mtime;
		int year = 1970, one = 1, zero = 0;
		timestamp ts;
        	daytime dt;
		date d;
		tzone tz;
        	return date_create(&d, &year, &one, &one) &&
             	       daytime_create(&dt, &zero, &zero, &zero, &zero) &&
	               tzone_create(&tz, &zero) &&
                       timestamp_create(&ts, &d, &dt, &tz) &&
                       timestamp_add(ret, &ts, &msecs);
        }
	return GDK_SUCCEED;
}


typedef struct stack_item si;

struct stack_item {
	int *sze;	/* size to be updated */
	oid pre;	/* pre-order rank of subtree root (without holes) */
	oid limit;	/* pre-order rank of last node in subtree (with holes) */
};

#define PUSH(stack,s,p,l) \
	stack_top++;\
	if (stack_top >= stack_size) {\
		stack_size *= 2;\
		stack = (si*) GDKrealloc(stack, stack_size*sizeof(si));\
		if (stack == NULL) {\
			GDKerror("correct_sizes: could not re-allocate stack of size %d.\n", stack_size*sizeof(si));\
	 		return GDK_FAIL;\
		}\
	}\
	stack[stack_top].sze = s;\
	stack[stack_top].pre = p;\
	stack[stack_top].limit = l;

#define POP(stack,s) \
	si s = stack[stack_top];\
	stack_top--;

/* StM:
 * Open: Does the following still work properly even if we're dealing with
 * multiple fragments in function map2NODE_interface() in
 * compiler/mil/milprint_summer.c ?
 */
int
CMDcorrect_sizes(BAT **ret, BAT *bat_iter, BAT *bat_item, BAT *bat_size) {
	BUN cur_iter, cur_item, cur_size;
	BUN fst_size, lst_size;
	int bs_iter, bs_item, bs_size;
	size_t cnt;
	oid base;
	oid prev_iter, prev_item, pre;
	bit fake_iter;
	si *stack = NULL;
	int stack_top = -1, stack_size = 128;
	
	/* check arguments */

	BATcheck(bat_iter, "correct_sizes");
	BATcheck(bat_item, "correct_sizes");
	BATcheck(bat_size, "correct_sizes");

	cnt = BATcount(bat_size);
	base = bat_size->hseqbase;
	fake_iter = is_fake_project(bat_iter);
	
	ERRORcheck(!((fake_iter || BAThdense(bat_iter)) && BAThdense(bat_item) && BAThdense(bat_size)), 
		"correct_sizes: all input BATs (iter, item, size) must have a dense head.\n");
	ERRORcheck(!((fake_iter || BATcount(bat_iter)==cnt) && BATcount(bat_item)==cnt),
		"correct_sizes: all input BATs (iter, item, size) must have the same size.\n");
	ERRORcheck(!((fake_iter || bat_iter->hseqbase==base) && bat_item->hseqbase==base),
		"correct_sizes: all input BATs (iter, item, size) must have the same seqbase.\n");

	stack = (si*)GDKmalloc(stack_size*sizeof(si));
	if (stack == NULL) {
		GDKerror("correct_sizes: could not allocate stack of size %d.\n", stack_size*sizeof(si));
	 	return GDK_FAIL;
	}
	stack_top = -1;

	bs_iter = (fake_iter?0:BUNsize(bat_iter));
	bs_item = BUNsize(bat_item);
	bs_size = BUNsize(bat_size);
	cur_iter = BUNfirst(bat_iter);
	cur_item = BUNfirst(bat_item);
	fst_size = BUNfirst(bat_size);
	lst_size = BUNlast(bat_size);

	prev_iter = oid_nil;
	prev_item = oid_nil;
	pre = oid_nil;
	for (cur_size = fst_size ; cur_size < lst_size ; cur_size += bs_size, cur_item += bs_item, cur_iter += bs_iter) {
		oid iter = *(oid*)BUNtail(bat_iter, cur_iter);
		oid item = *(oid*)BUNtail(bat_item, cur_item);
		int *sze =  (int*)BUNtail(bat_size, cur_size);
		int size = *sze;
		    pre  = *(oid*)BUNhead(bat_size, cur_size);
		while (stack_top >= 0 && ( iter != prev_iter || item > stack[stack_top].limit || item < prev_item )) {
			POP(stack, s);
			if (s.limit > prev_item) {
				*s.sze = pre - s.pre;
			} else {
				*s.sze = pre - s.pre - 1;
			}
		}
		if (size > 0) {
			PUSH(stack, sze, pre, item+size);
		}
		prev_iter = iter;
		prev_item = item;
	}
	while (stack_top >= 0) {
		POP(stack, s);
		if (s.limit > prev_item) {
			*s.sze = pre - s.pre + 1;
		} else {
			*s.sze = pre - s.pre;
		}
	}
	GDKfree(stack);

	if (!bat_size->batDirty) bat_size->batDirty = TRUE;

	BBPfix(bat_size->batCacheid);
	*ret = bat_size;
	return GDK_SUCCEED;
}


int
CMDSplitBat(BAT **res, BAT *b, str sep)
{
	BAT **bn;
	size_t nbats = 0;
	size_t maxbats = 16;
	BUN p, q, r;
	str s, e;
	size_t seplen = strlen(sep);
	char *buf = GDKmalloc(BUFSIZ);
	size_t buflen = BUFSIZ;
	size_t l;
	size_t i;
	size_t bs = BATcount(b);
	oid base, o;

	if (buf == NULL)
		return GDK_FAIL;

	ERRORcheck(seplen == 0, "splitbat: separator must not be empty.\n");

	o = base = b->hseqbase;
	bn = GDKmalloc(maxbats * sizeof(BAT *));
	if (bn == NULL)
		goto bunins_failed;
	memset(bn, 0, maxbats * sizeof(BAT *));
	BATloop(b, p, q) {
		s = (str) BUNtail(b, p);
		l = strlen(s);
		if (l >= buflen) {
			while (l >= (buflen += BUFSIZ))
				;
			buf = GDKrealloc(buf, buflen);
			if (buf == NULL)
				goto bunins_failed;
		}
		strcpy(buf, s);
		s = buf;
		i = 0;
		while (s) {
			if ((e = strstr(s, sep)) != NULL)
				*e = 0;
			if (i >= nbats) {
				size_t j;

				if (nbats >= maxbats) {
					bn = GDKrealloc(bn, maxbats + 16);
					if (bn == NULL)
						goto bunins_failed;
					memset(&bn[maxbats], 0, 16 * sizeof(BAT *));
					maxbats += 16;
				}
				bn[i] = BATnew(TYPE_void, TYPE_str, bs);
				if (bn[i] == NULL)
					goto bunins_failed;
				bn[i] = BATseqbase(bn[i], base);
				BATkey(BATmirror(bn[i]), FALSE);
				bn[i]->tsorted = 0;
				for (j = 0; j < bs; j++)
					bunfastins(bn[i], NULL, str_nil);
				nbats++;
			}
			BUNfndVOID(r, bn[i], &o);
			ATOMreplace(TYPE_str, bn[i]->theap, BUNtloc(bn[i], r), s);
			i++;
			s = e ? e + seplen : NULL;
		}
		o++;
	}
	GDKfree(buf);
	*res = BATnew(TYPE_void, TYPE_bat, nbats);
	if (*res == NULL)
		goto bunins_failed;
	*res = BATseqbase(*res, 0);
	BATkey(BATmirror(*res), FALSE);
	(*res)->tsorted = 0;
	for (i = 0; i < nbats; i++) {
		bunfastins(*res, NULL, &bn[i]->batCacheid);
		BBPunfix(bn[i]->batCacheid);
	}
	GDKfree(bn);
	return GDK_SUCCEED;

  bunins_failed:
	if (bn) {
		for (i = 0; i < nbats; i++)
			if (bn[i])
				BBPreclaim(bn[i]);
		GDKfree(bn);
	}
	if (buf)
		GDKfree(buf);
	return GDK_FAIL;
}

#define MAXKIND 5
int
CMDSplitKind(BAT **res, BAT *b)
{
	size_t i, n = BATcount(b);
	BAT *bn[MAXKIND];
	oid *cur[MAXKIND];

	for (i = 0; i < MAXKIND; i++)
		bn[i] = NULL;

	for (i = 0; i < MAXKIND; i++) {
		bn[i] = BATnew(TYPE_oid, TYPE_void, n);
		if (bn[i] == NULL) goto bunins_failed;

		/* inherit sortedness and keyness */
		bn[i]->tsorted = 0;
		bn[i]->hsorted = b->hsorted;
		BATkey(bn[i], b->hkey & 1);
		cur[i] = (oid*) BUNfirst(bn[i]);
	}
	if (BAThdense(b) && BUNsize(b) == sizeof(chr)) {
		/* fast split-select with direct oid-inserts and predication */
		chr *v = ((chr*) BUNfirst(b)) - b->hseqbase;	
		for(i=b->hseqbase, n+=b->hseqbase; i<n; i++) {
			int val = v[i];
			if ((val >= 0) & (val < MAXKIND))
				*cur[val]++ = i;
		}
	} else {
		BUN p, q;
		BATloopFast(b, p, q, i) {
			int val = *(chr*) BUNtloc(b, p);
			if ((val >= 0) & (val < MAXKIND))
				*cur[val]++ = *(oid*) BUNhead(b,p);
		}
	}
	for(i=0; i<MAXKIND; i++) {
		bn[i]->batBuns->free = ((BUN) cur[i]) - bn[i]->batBuns->base;
		BATsetcount(bn[i], bn[i]->batBuns->free/sizeof(oid));
	}
	*res = BATnew(TYPE_void, TYPE_bat, MAXKIND);
	if (*res == NULL)
		goto bunins_failed;
	*res = BATseqbase(*res, 0);
	BATkey(BATmirror(*res), FALSE);
	(*res)->tsorted = 0;
	for (i = 0; i < MAXKIND; i++) {
		bunfastins(*res, NULL, &bn[i]->batCacheid);
		BBPunfix(bn[i]->batCacheid);
	}
	return GDK_SUCCEED;
bunins_failed:
	for (i = 0; i < MAXKIND; i++)
		if (bn[i]) BBPreclaim(bn[i]);
	return GDK_FAIL;
}

@= nilarithC
int
CMDnil@1(int *res, int *v1, int *v2)
{
	*res = *v1 @2 *v2;
	return GDK_SUCCEED;
}
@c
@:nilarithC(and,&)@
@:nilarithC(or,|)@
@:nilarithC(plus,+)@

bat* pf_support_prelude() {
    MT_init_lock(pf_runtime_lock[0]);
    MT_init_lock(pf_runtime_lock[1]);
    MT_init_lock(pf_runtime_lock[2]);
    MT_init_lock(pf_runtime_lock[3]);
    return NULL;
}

void pf_support_epilogue() {
    MT_destroy_lock(pf_runtime_lock[0]);
    MT_destroy_lock(pf_runtime_lock[1]);
    MT_destroy_lock(pf_runtime_lock[2]);
    MT_destroy_lock(pf_runtime_lock[3]);
}

@- PROCs required by the algebraic translation ###
@mil
PROC doc_tbl (BAT[void, BAT] ws, BAT[void, str] item) : BAT[void,BAT]
{
    # load all requested documents into the working set
    var r := ws_opendoc(ws, item);

    # pick the according cont value for each document requested
    var ret_cont := r.tmark(0@0);

    # pick the according root-pre value for each document requested
    var ret_item := r.hmark(0@0);

    # return result as a BAT of BATs
    return new (void, BAT).append(ws)
                          .append(ret_item)
                          .append(ret_cont)
                          .seqbase(0@0);
}

ADDHELP("doc_tbl", "teubner", "Aug 2005",
                "PARAMETERS:\n\
ws    current working set; will be modified\n\
item  list of documents to add to the working set\n\
DESCRIPTION:\n\
Implementation of the algebra operator `doc_tbl' that\n\
loads persistent documents into the working set.\n\
Input is a list of document names. Output is a BAT of\n\
BATs with the components\n\
(a) the modified working set,\n\
(b) an `item' column with the pre values of the\n\
document roots, and\n\
(c) a `cont' column that encodes document\n\
container (within the working set) according to our\n\
working set representation.",
                "pf_support");

# primitive for supporting highly specific XQuery functionality
PROC merge_adjacent_text_nodes (BAT[void,oid] iter,
                                BAT[void,oid] pre,
                                BAT[void,oid] pcont,
                                BAT[void,BAT] ws) : BAT[void,oid]
{
    var map := pre.ord_uselect(oid_nil,oid_nil).hmark(0@0);
    iter := map.leftfetchjoin(iter);
    pre := map.leftfetchjoin(pre);
    pcont := map.leftfetchjoin(pcont);

    var kind := mposjoin (pre, pcont, ws.fetch(PRE_KIND));
    var text := kind.[=](TEXT);
    var text_sel := text.select(true).hmark(0@0);
    var text_pre := text_sel.leftfetchjoin(pre).tmark(0@0);
    var text_cont := text_sel.leftfetchjoin(pcont).tmark(0@0);

    var text_prop := mposjoin (mposjoin (text_pre, text_cont, ws.fetch(PRE_PROP)),
                               mposjoin (text_pre, text_cont, ws.fetch(PRE_CONT)),
                               ws.fetch(PROP_TEXT));
    text_pre := nil;
    text_cont := nil;

    var pre_prop := pre.mirror()
                       .outerjoin(text_prop.reverse()
                                           .leftfetchjoin(text_sel)
                                           .reverse());
    var pre_enum := [oid](text);
    var res_size := (iter.tunique().count() 
                  + text.count() + 1)
                  - text_sel.count();

    var res_strs := combine_text_string (iter.chk_order(),
                                         pre_enum,
                                         pre_prop,
                                         res_size);
    iter := nil;
    pre_enum := nil;
    pre_prop := nil;
    res_size := nil;
    var res_texts := text_constr (res_strs.tmark(0@0), ws);
    ws := res_texts.fetch(0);
    var textnodes := res_texts.fetch(1);
    res_texts := nil;
    
    text_pre := pre.mirror()
                   .outerjoin(res_strs.mark(0@0)
                                      .leftfetchjoin(textnodes));
    text_cont := pre.mirror()
                    .outerjoin(res_strs.project(WS));
    res_strs := nil;
    textnodes := nil;
    pre := map.reverse()
              .leftfetchjoin([ifthenelse](text,text_pre,pre));
    pcont := map.reverse()
                .leftfetchjoin([ifthenelse](text,text_cont,pcont));

    # return result as a BAT of BATs
    return new (void, BAT).append (ws)
                          .append (pre)
                          .append (pcont)
                          .seqbase (0@0);
}
ADDHELP("merge_adjacent_text_nodes", "tsheyar", "Oct 2005",
        "PARAMETERS:\n\
BAT[void,str] iter : prefix of qname\n\
BAT[void,str] pre  : URI of the qname\n\
BAT[void,str] cont : local part of the qname\n\
BAT[void,BAT] ws   : working set that stores the qname\n\
DESCRIPTION:\n\
merge_adjacent_text_nodes takes an iter|pre|cont schema and\n\
combines within each iteration all adjacent text nodes.\n\
(Note that the order is given by the input order.)\n\
New textnodes are added into the working set ws and the result is\n\
a bat of bats (ws, modified_pres, modified_conts). The heads of the\n\
pre and cont are aligned to the input relations.",
        "pf_support");
                                
# add_qnames changes the working set as side effect
# without a 'prefix:uri:local' index this could be quite expensive
#
# it basically does:
# [ifthenelse]([isnil](local),local.project(nil),[add_qname](prefix,uri,local,local.project(ws)));
PROC add_qnames (BAT[void,str] prefix,
                 BAT[void,str] uri,
                 BAT[void,str] local,
                 BAT[void,BAT] ws) : BAT[void,oid]
{
    var pref_uri_loc := pref.[+](":").[+](uri).[+](":").[+](local); # [void,str]
    pref_uri_loc := [isnil](local).ord_uselect(false).mirror().leftfetchjoin(pref_uri_loc); # [oid,str] (sorted subset)
    return mirror(local).outerjoin(find_qn_bulk(ws, WS, pref_uri_loc, true)).tmark(seqbase(local)); # [void,oid]
}
ADDHELP("add_qnames", "tsheyar", "Oct 2005",
        "PARAMETERS:\n\
BAT[void,str] prefix : prefix of qname\n\
BAT[void,str] uri    : URI of the qname\n\
BAT[void,str] local  : local part of the qname\n\
BAT[void,BAT] ws     : working set that stores the qname\n\
DESCRIPTION:\n\
add_qnames adds qnames consisting of the three strings prefix,\n\
uri, and local to the working set (ws). The return value is the\n\
identifier that corresponds to the qname in the qname container\n\
of the transient nodes.\n\
NOTE: the working set 'ws' is changed as side effect!",
        "pf_support");

# add_qname changes the working set as side effect
PROC add_qname (str prefix, str uri, str local, BAT[void,BAT] ws) : oid
{
    var props := ws.fetch(QN_PREFIX_URI_LOC).fetch(WS);
    var key := prefix + ":" + uri + ":" + local;
    var itemID := oid(count(props));
    if (not(isnil(CATCH(itemID := reverse(props).find(key))))) {
        props.insert(itemID, key);
        ws.fetch(QN_URI_LOC).fetch(WS).insert(itemID, local + ":" + uri);
        ws.fetch(QN_URI).fetch(WS).insert(itemID, uri);
        ws.fetch(QN_PREFIX).fetch(WS).insert(itemID, prefix);
        ws.fetch(QN_LOC).fetch(WS).insert(itemID, local);
    }
    return itemID;
}
ADDHELP("add_qname", "tsheyar", "Oct 2005",
        "PARAMETERS:\n\
str           prefix : prefix of qname\n\
str           uri    : URI of the qname\n\
str           local  : local part of the qname\n\
BAT[void,BAT] ws     : working set that stores the qname\n\
DESCRIPTION:\n\
add_qname adds a qname consisting of the three strings prefix,\n\
uri, and local to the working set ws. The return value is the\n\
identifier that corresponds to the qname in the qname container\n\
of the transient nodes.\n\
NOTE: the working set 'ws' is changed as side effect!",
        "pf_support");

PROC text_constr (BAT[void, str] item, BAT[void, BAT] ws) : BAT[void,BAT]
{
    # find all strings that are not already in the working set ...
    var ws_prop_text := ws.fetch(PROP_TEXT).fetch(WS);
    var unq_str := item.tunique().hmark(0@0);
    var str_unq := unq_str.reverse().kdiff(ws_prop_text.reverse());
    unq_str := nil;
    # ... and add them to the PROP_TEXT container
    var seqb := oid(int(ws_prop_text.seqbase()) + ws_prop_text.count());
    unq_str := str_unq.hmark(seqb);
    str_unq := nil;
    ws_prop_text := ws_prop_text.insert(unq_str);
    unq_str := nil;

    # get the property values of the strings;
    # we invest in sorting ws_prop_text &  X_strings/item on the TYPE_str 
    # join columns as the mergejoin proved to be faster and more robust with
    # large BATs than a hashjoin
    var ws_text_prop := ws_prop_text.reverse().sort();
    var X_item := item.mark(0@0);
    var X_strings := item.tmark(0@0).tsort();
    var X_prop := X_strings.leftjoin(ws_text_prop);
    X_strings := nil;
    ws_text_prop := nil;
    var newProp := X_item.leftjoin(X_prop);
    X_item := nil;
    X_prop := nil;

    # add new text nodes to the working set
    var seqb := oid(count(ws.fetch(PRE_KIND).fetch(WS)) +
                    int(ws.fetch(PRE_KIND).fetch(WS).seqbase()));
    var newPre_prop := newProp.tmark(seqb).chk_order();
    newProp := nil;
    ws.fetch(PRE_PROP).fetch(WS).insert(newPre_prop);
    ws.fetch(PRE_SIZE).fetch(WS).insert(newPre_prop.project(0));
    ws.fetch(PRE_LEVEL).fetch(WS).insert(newPre_prop.project(chr(0)));
    ws.fetch(PRE_KIND).fetch(WS).insert(newPre_prop.project(TEXT));
    ws.fetch(PRE_CONT).fetch(WS).insert(newPre_prop.project(WS));
    ws.fetch(PRE_NID).fetch(WS).append(newPre_prop.mirror());
    ws.fetch(NID_RID).fetch(WS).append(newPre_prop.mirror());

    newPre_prop := nil;
    item := item.mark(seqb);
    seqb := nil;

    # return result as a BAT of BATs
    var res := new (void, BAT).append (ws)
                              .append (item)
                              .append (item.project(WS))
                              .seqbase (0@0);

    { # adding new fragments to the FRAG_ROOT bat
        reverse(ws.fetch(FRAG_ROOT).fetch(WS)).insert(reverse(item).project(oid_nil));
    }

    return res;
}
ADDHELP("text_constr", "tsheyar", "Oct 2005",
        "PARAMETERS:\n\
BAT[void,str] item : content of the text nodes\n\
BAT[void,BAT] ws   : working set that stores the document representations\n\
DESCRIPTION:\n\
text_constr is a generic text constructor that creates for each\n\
item a new textnode. These textnodes are added to the working\n\
set ws. Output is a BAT of BATs with the following components:\n\
(a) the modified working set,\n\
(b) the pre values of the textnodes, and\n\
(c) the cont values of the textnodes",
        "pf_support");

PROC attr_constr (BAT[void, oid] qn, BAT[void, str] item, BAT[void, BAT] ws) : BAT[void,BAT]
{
    # find all strings that are not already in the working set ...
    var ws_prop_val := ws.fetch(PROP_VAL).fetch(WS);
    var unq_str := item.tunique().hmark(0@0);
    var str_unq := unq_str.reverse().kdiff(ws_prop_val.reverse());
    unq_str := nil;
    # ... and add them to the PROP_VAL container
    var seqb := oid(int(ws_prop_val.seqbase()) + ws_prop_val.count());
    unq_str := str_unq.hmark(seqb);
    str_unq := nil;
    ws_prop_val := ws_prop_val.insert(unq_str);
    unq_str := nil;

    # get the property values of the strings;
    # we invest in sorting ws_prop_val &  X_strings/item on the TYPE_str 
    # join columns as the mergejoin proved to be faster and more robust with
    # large BATs than a hashjoin
    var ws_val_prop := ws_prop_val.reverse().sort();
    var X_item := item.mark(0@0);
    var X_strings := item.tmark(0@0).tsort();
    var X_prop := X_strings.leftjoin(ws_val_prop);
    X_strings := nil;
    ws_val_prop := nil;
    var newProp := X_item.leftjoin(X_prop);
    X_item := nil;
    X_prop := nil;

    # add new text nodes to the working set
    var seqb := oid(count(ws.fetch(ATTR_OWN).fetch(WS)) +
                    int(ws.fetch(ATTR_OWN).fetch(WS).seqbase()));
    var newAttr_prop := newProp.tmark(seqb);
    newProp := nil;
    ws.fetch(ATTR_PROP).fetch(WS).insert(newAttr_prop);
    ws.fetch(ATTR_OWN).fetch(WS).insert(newAttr_prop.project(oid_nil));
    ws.fetch(ATTR_QN).fetch(WS).insert(qn.tmark(seqb));
    ws.fetch(ATTR_CONT).fetch(WS).insert(newAttr_prop.project(WS));

    newAttr_prop := nil;
    item := item.mark(seqb);
    seqb := nil;

    # return result as a BAT of BATs
    var res := new (void, BAT).append (ws)
                              .append (item)
                              .append (item.project(WS))
                              .seqbase (0@0);

    return res;
}
ADDHELP("attr_constr", "tsheyar", "Oct 2005",
        "PARAMETERS:\n\
BAT[void,oid] qn   : names of the attributes\n\
BAT[void,str] item : values of the attributes\n\
BAT[void,BAT] ws   : working set that stores the document representations\n\
DESCRIPTION:\n\
attr_constr is a generic attribute constructor that creates for\n\
each aligned qn|item pair a new attribute. These attributes are\n\
added to the working set ws. Output is a BAT of BATs with the\n\
following components:\n\
(a) the modified working set,\n\
(b) the attribute ids, and\n\
(c) the cont values of the attributes",
        "pf_support");

PROC elem_constr_empty (BAT[void, oid] qn, BAT[void, BAT] ws) : BAT[void,BAT]
{
    # add new element nodes to the working set
    var seqb := oid(count(ws.fetch(PRE_KIND).fetch(WS)) +
                    int(ws.fetch(PRE_KIND).fetch(WS).seqbase()));
    var newPre_prop := qn.tmark(seqb).chk_order();
    ws.fetch(PRE_PROP).fetch(WS).insert(newPre_prop);
    ws.fetch(PRE_SIZE).fetch(WS).insert(newPre_prop.project(0));
    ws.fetch(PRE_LEVEL).fetch(WS).insert(newPre_prop.project(chr(0)));
    ws.fetch(PRE_KIND).fetch(WS).insert(newPre_prop.project(ELEMENT));
    ws.fetch(PRE_CONT).fetch(WS).insert(newPre_prop.project(WS));
    ws.fetch(PRE_NID).fetch(WS).append(newPre_prop.mirror());
    ws.fetch(NID_RID).fetch(WS).append(newPre_prop.mirror());

    newPre_prop := nil;
    qn := qn.mark(seqb);
    seqb := nil;

    # return result as a BAT of BATs
    var res := new (void, BAT).append (ws)
                              .append (qn)
                              .append (qn.project(WS))
                              .seqbase (0@0);

    { # adding new fragments to the WS_FRAG bat
        reverse(ws.fetch(FRAG_ROOT).fetch(WS)).insert(reverse(qn).project(oid_nil));
    }

    return res;
}
ADDHELP("elem_constr_empty", "tsheyar", "Oct 2005",
        "PARAMETERS:\n\
BAT[void,oid] qn   : names of the elements\n\
BAT[void,BAT] ws   : working set that stores the document representations\n\
DESCRIPTION:\n\
elem_constr_empty is a generic element constructor for empty\n\
elements that creates for each qname qn a new element. These\n\
elements are added to the working set ws. Output is a BAT of\n\
BATs with the following components:\n\
(a) the modified working set,\n\
(b) the pre values, and\n\
(c) the cont values of the elements",
        "pf_support");

PROC elem_constr (BAT[void, oid] qn_iter,
                  BAT[void, oid] qn_item,
                  BAT[void, oid] iter,
                  BAT[oid, oid] pre,
                  BAT[oid, oid] pcont,
                  BAT[void, oid] attr,
                  BAT[void, oid] acont,
                  BAT[void, BAT] ws) : BAT[void,BAT]
{
    var root_iter;
    var root_size;
    var root_prop;
    var root_kind;
    var root_cont;
    var root_level;
    # attr
        var root_pre;
        var root_pre_cont;
        
    # throw out nil values and generate iter|item|cont representation
    # for attributes
    var selected := pre.select(oid_nil,oid_nil);
    var piter := selected.hmark(0@0).leftfetchjoin(iter).tmark(0@0); # make it void
    pre := selected.tmark(0@0);
    pcont := pcont.select(oid_nil,oid_nil).tmark(0@0);
    selected := nil;

    # throw out nil values and generate iter|item|cont representation
    # for attributes
    selected := attr.select(oid_nil,oid_nil);
    var aiter := selected.hmark(0@0).leftfetchjoin(iter).tmark(0@0); # make it void
    attr := selected.tmark(0@0);
    acont := acont.select(oid_nil,oid_nil).tmark(0@0);
    selected := nil;

    if (pre.count() != 0) {

        # use head to avoid elimination of duplicates
        # (this is additionally used in the content level determination
        var iter_unq := piter.mirror();
        # get all subtree copies
        var res_scj := loop_lifted_descendant_or_self_step 
                           (iter_unq, pre, pcont, ws, 0);
        iter_unq := nil;

        # variables for the result of the scj 
        var res_iter := res_scj.fetch(0);
        var res_item := res_scj.fetch(1);
        # !be aware that res_cont is only a fake_project!
        var res_cont := res_scj.fetch(2);
        # !avoid being res_iter a fake_project!
        res_iter := materialize (res_iter, res_item);
        res_scj := nil;
            
        # create content_iter as sorting argument for the merged union
        var content_iter := res_iter.leftfetchjoin(piter).chk_order();
        # create subtree copies for all bats
        var content_size := mposjoin(res_item, res_cont, ws.fetch(PRE_SIZE));
        var content_prop := mposjoin(res_item, res_cont, ws.fetch(PRE_PROP));
        var content_kind := mposjoin(res_item, res_cont, ws.fetch(PRE_KIND));
        var content_cont := mposjoin(res_item, res_cont, ws.fetch(PRE_CONT));
        var content_level := mposjoin(res_item, res_cont, ws.fetch(PRE_LEVEL));
        # change the level of the subtree copies
        content_level := content_level.[+](chr(1));
        var contentRoot_level := mposjoin(pre, pcont, ws.fetch(PRE_LEVEL));
        # map Root_level to the result of the scj 
        #using the faked iteration values
        contentRoot_level := res_iter.leftfetchjoin(contentRoot_level);
        content_level := content_level.[-](contentRoot_level);
        content_level := content_level.tmark(0@0);
        contentRoot_level := nil;
            
        # attr
        # content_pre is needed for attribute subtree copies
        var content_pre := res_item;

        # as well as content_pre_cont
        var content_pre_cont := res_cont;
            
        root_iter := qn_iter.chk_order();
        # calculate the sizes for the root nodes
        root_size := {count}(content_iter.reverse(), qn_iter.reverse(), FALSE).tmark(seqbase(qn_iter));
        root_prop := qn_item;
        root_kind := constant2bat(ELEMENT);
        root_cont := constant2bat(WS);
        root_level := constant2bat(chr(0));

        # attr
            # root_pre is a dummy needed for merge union with content_pre 
            root_pre := constant2bat(oid_nil);
            # as well as root_cont_pre
            root_pre_cont := constant2bat(oid_nil);

        # merge union root and nodes
        {
        var merged_result := merged_union (
                                 root_iter, content_iter,
                                 root_size, content_size,
                                 root_level, content_level,
                                 root_kind, content_kind,
                                 root_prop, content_prop,
                                 root_cont, content_cont,
        # attr
                                 root_pre, content_pre,
                                 root_pre_cont, content_pre_cont);
        root_iter := nil;
        content_iter := nil;
        content_size := nil;
        content_level := nil;
        content_kind := nil;
        content_prop := nil;
        content_cont := nil;
        # attr
            content_pre := nil;
            content_pre_cont := nil;
        root_size := merged_result.fetch(1);
        root_level := merged_result.fetch(2);
        root_kind := merged_result.fetch(3);
        root_prop := merged_result.fetch(4);
        root_cont := merged_result.fetch(5);
        # attr
            root_pre := merged_result.fetch(6);
            root_pre_cont := merged_result.fetch(7);

        merged_result := nil;

        # printing output for debugging purposes
            # print("merged (root & content)");
            # print(root_size, [int](root_level), [int](root_kind), root_prop);
        }

    } else { # end of ``if (pre.count() != 0)''

        root_size := qn_iter.project(0);
        root_prop := qn_item; # !the seqbase of qn_item is later modified
        root_kind := qn_iter.project(ELEMENT);
        root_cont := qn_iter.project(WS);
        root_level := qn_iter.project(chr(0));
        # attr
            root_pre := qn_iter.project(oid_nil);
            root_pre_cont := qn_iter.project(oid_nil);

    }  # end of else in ``if (pre.count() != 0)''
        
    # set the offset for the new created trees
    {
        var seqb := oid(count(ws.fetch(PRE_SIZE).fetch(WS))
                        + int(ws.fetch(PRE_SIZE).fetch(WS).seqbase()));
        root_size := root_size.seqbase(seqb);
        root_prop := root_prop.seqbase(seqb);
        root_kind := root_kind.seqbase(seqb);
        root_cont := root_cont.seqbase(seqb);
        root_level := root_level.seqbase(seqb);
        # attr
            # get the new pre values
            root_pre := root_pre.seqbase(seqb);
            root_pre_cont := root_pre_cont.seqbase(seqb);
        seqb := nil;
    }

    # insert the new trees into the working set
    ws.fetch(PRE_SIZE).fetch(WS).insert(root_size);
    ws.fetch(PRE_KIND).fetch(WS).insert(root_kind);
    ws.fetch(PRE_PROP).fetch(WS).insert(root_prop);
    ws.fetch(PRE_CONT).fetch(WS).insert(root_cont);
    ws.fetch(PRE_LEVEL).fetch(WS).insert(root_level);
    ws.fetch(PRE_NID).fetch(WS).append(root_kind.mirror());
    ws.fetch(NID_RID).fetch(WS).append(root_kind.mirror());

    # save the new roots for creation of the intermediate result
    var roots := root_level.ord_uselect(chr(0));
    # (note that all operations are order preserving and ``mark''
    # aligns the key with the qn_iter input 
    roots := roots.hmark(0@0);

    # resetting the temporary variables
    root_size := nil;
    root_prop := nil;
    root_kind := nil;
    root_cont := nil;
    root_level := nil;
        
    # adding the new constructed roots to the WS_FRAG bat of the
    # working set, that a following (preceding) step can check
    # the fragment boundaries
    {
        reverse(ws.fetch(FRAG_ROOT).fetch(WS)).insert(reverse(roots).project(oid_nil));
    }

    # ----------------------------------
    # ----- ATTRIBUTE TRANSLATION ------
    # ----------------------------------
    # 1. step: add subtree copies of attributes
    if (pre.count() != 0) { # but only if there are any subtree nodes
        # lookup the affected attributes using the old pre values
        var preNew_attr := mvaljoin(root_pre, 
                                    root_pre_cont,
                                    ws.fetch(ATTR_OWN));
        # lookup the first free attr value
        var seqb := oid(ws.fetch(ATTR_QN).fetch(WS).count());
        # split up result of mvaljoin and mark them with the correct seqbase
        var attrNew_preNew := preNew_attr.mark(seqb).reverse();
        var attrNew_attrOld := preNew_attr.reverse().mark(seqb).reverse();
        preNew_attr := nil;
        var attrNew_pre_cont := attrNew_preNew.leftfetchjoin(root_pre_cont);
        # help MIL to keep head void
        attrNew_pre_cont := attrNew_pre_cont.reverse().mark(seqb).reverse();
        seqb := nil;

        # get the values of the QN/OID offsets for the reference to the
        # string values
        var attrNew_qn := mposjoin(attrNew_attrOld,
                                   attrNew_pre_cont,
                                   ws.fetch(ATTR_QN));
        var attrNew_prop := mposjoin(attrNew_attrOld,
                                     attrNew_pre_cont,
                                     ws.fetch(ATTR_PROP));
        # get container where values are stored (not where attribute is stored)
        var attrNew_cont := mposjoin(attrNew_attrOld,
                                     attrNew_pre_cont,
                                     ws.fetch(ATTR_CONT));
        attrNew_attrOld := nil;
        attrNew_pre_cont := nil;

        ws.fetch(ATTR_QN).fetch(WS).insert(attrNew_qn);
        ws.fetch(ATTR_PROP).fetch(WS).insert(attrNew_prop);
        ws.fetch(ATTR_OWN).fetch(WS).insert(attrNew_preNew);
        ws.fetch(ATTR_CONT).fetch(WS).insert(attrNew_cont);
        attrNew_qn := nil;
        attrNew_prop := nil;
        attrNew_preNew := nil;
        attrNew_cont := nil;
    }

    # 2. step: add attribute binding for new elements
    if (attr.count() != 0) { # but only if there are any top level attributes
        
        # use iter, qn and cont to find unique combinations
        var attr_qn := mposjoin(attr, acont, ws.fetch(ATTR_QN));
        var attr_cont := mposjoin(attr, acont, ws.fetch(ATTR_CONT));
        var sorting := aiter.tsort();
        sorting := sorting.CTrefine(mposjoin(attr_qn,
                                             attr_cont,
                                             ws.fetch(QN_URI_LOC)));
        var unq_attrs := sorting.tunique();
        sorting := nil;
        # test uniqueness
        if (unq_attrs.count() != aiter.count())
        {
           if (qn_item.count() > 0) {
               ERROR ("err:XQDY0025: attribute names are not unique in constructed element '%s'.",
                      qn_item.leftfetchjoin(ws.fetch(QN_LOC).fetch(WS))
                             .fetch(0));
           } else {
               ERROR ("err:XQDY0025: attribute names are not unique in constructed element.");
           }
        }
        unq_attrs := nil;

        var seqb := oid(ws.fetch(ATTR_QN).fetch(WS).count());
        attr_qn := attr_qn.seqbase(seqb);
        var attr_own := aiter.leftjoin(qn_iter.reverse())
                             .leftfetchjoin(roots)
                             .reverse().mark(seqb).reverse();
        var attr_prop := mposjoin(attr, acont, ws.fetch(ATTR_PROP));
        attr_prop := attr_prop.seqbase(seqb);
        attr_cont := attr_cont.seqbase(seqb);
        seqb := nil;

        ws.fetch(ATTR_QN).fetch(WS).insert(attr_qn);
        ws.fetch(ATTR_PROP).fetch(WS).insert(attr_prop);
        ws.fetch(ATTR_OWN).fetch(WS).insert(attr_own);
        ws.fetch(ATTR_CONT).fetch(WS).insert(attr_cont);
        attr_qn := nil;
        attr_prop := nil;
        attr_own := nil;
        attr_cont := nil;
    }

    # create result as a BAT of BATs
    var res := new (void, BAT).append (ws)
                              .append (roots)
                              .append (roots.project(WS))
                              .seqbase (0@0);
    roots := nil;

    return res;
}
ADDHELP("elem_constr", "tsheyar", "Oct 2005",
        "PARAMETERS:\n\
BAT[void, oid] qn_iter : iteration values of the qnames\n\
BAT[void, oid] qn_item : names of the elements\n\
BAT[void, oid] iter    : iteration values of the content\n\
BAT[oid, oid] pre      : pre values of the content (heads aligned with head of iter)\n\
BAT[oid, oid] pcont    : node cont values of the content (heads aligned with head of iter)\n\
BAT[void, oid] attr    : attribute ids of the content (heads aligned with head of iter)\n\
BAT[void, oid] acont   : attribute container-ids of the content (heads aligned with head of iter)\n\
BAT[void, BAT] ws      : working set that stores the document representations\n\
DESCRIPTION:\n\
elem_constr is a full featured element constructor that requires\n\
qn|iter pairs for the name part and iteration, attribute, and node\n\
information for the content. These elements are added to the working\n\
set ws. Output is a BAT of BATs with the following components:\n\
(a) the modified working set,\n\
(b) the pre values, and\n\
(c) the containder-ids of the elements",
        "pf_support");
