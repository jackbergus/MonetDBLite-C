@' pathfinder.mx
@'
@' XQuery runtime environment
@'
@' Copyright Notice:
@' -----------------
@'
@' The contents of this file are subject to the Pathfinder Public License
@' Version 1.1 (the "License"); you may not use this file except in
@' compliance with the License.  You may obtain a copy of the License at
@' http://monetdb.cwi.nl/Legal/PathfinderLicense-1.1.html
@'
@' Software distributed under the License is distributed on an "AS IS"
@' basis, WITHOUT WARRANTY OF ANY KIND, either express or implied.  See
@' the License for the specific language governing rights and limitations
@' under the License.
@'
@' The Original Code is the Pathfinder system.
@'
@' The Original Code has initially been developed by the Database &
@' Information Systems Group at the University of Konstanz, Germany and
@' is now maintained by the Database Systems Group at the Technische
@' Universitaet Muenchen, Germany.  Portions created by the University of
@' Konstanz and the Technische Universitaet Muenchen are Copyright (C)
@' 2000-2005 University of Konstanz and (C) 2005-2006 Technische
@' Universitaet Muenchen, respectively.  All Rights Reserved.
@'
@' $Id$
@'

@f pathfinder
@a Torsten Teggy Grust
@a Maurice van Keulen
@a Henning Rode
@a Jan Flokstra
@a Jens Teubner
@a Stefan Manegold
@a Peter Boncz 
@a Ying Zhang
@a Niels Nes

@t Runtime Support for the Pathfinder XQuery Compiler

@m
.MODULE pathfinder;

.USE pf_support;

.COMMAND xquery_frontend() : ptr = xquery_frontend;
 "create/return the xquery_frontend callback interface to pass to mapi register. "

.BUILTIN xquery(mode str, xquery str, is_url bit) : str = CMDxquery;
 "xquery execution. parameters: mode, query, is_url (optional)
 usage:  var result := xquery(\"xml\", \"1+1\", false); printf(result);
 or:  printf(xquery(\"xml\", \"1+1\"));"

.COMMAND xquery_start_query_cache(lng maxsize) : void = CMDxquery_start_query_cache; 
 "Cached xquery clients use the query plan cache (also flushes the cache when called). if nonzero, the parameter is a per-connection size limit to the plan cache in bytes"

.PRELUDE = xquery_prelude;
.EPILOGUE = xquery_epilogue;

.END pathfinder;
@mil
if (clientid() != 0) {
    ERROR("pathfinder module must be loaded in Mserver console first.");
}
module(mapi);       # remote client access
module(pf_support);
module(logger);

# standoff extensions
var standoff := false;
if (monet_environment.exist("standoff")) {
     standoff := =(monet_environment.find("standoff"),"enabled"); 
}

if (standoff) {
    module("pf_standoff");
}

# The XML Meta-Database #############################################################
#
# Global information on persistent stored XML collections:
# - collection_name   BAT[oid,name]             coll-ID / collection name 
# - collection_size   BAT[oid,lng]              coll-ID / size in bytes
# - collection_zombie BAT[oid,lng]              coll-ID / ws-ID that blocked its deletion (TRANSIENT) 
#
# A collection may contain one ore more XML documents:
# - doc_collection    BAT[oid,oid]          document-ID / coll-ID 
# - doc_name          BAT[oid,str]          document-ID / document name
# - doc_location      BAT[oid,str]          document-ID / document URI
# - doc_timestamp     BAT[oid,timestamp]    document-ID / end-of-cache-time (nil if none)
# - doc_undo          BAT[oid,lng]          document-ID / ws-ID that created it (TRANSIENT) 
#
# some runtime (TRANSIENT) information is also kept on collections, by name: 
# - colname_shredlock BAT[str,lock]     collection name / append-lock
# - colname_runtime   BAT[str,bat]      collection name / index+locking structures 
# - colname_pins      BAT[str,lng]      collection name / ws-ID using it 
# - colname_locks     BAT[str,lng]      collection name / ws-ID having it locked
#
# Meta-information on running transactions (table only contains still active queries Y)
# - ws_overlaps_ws    BAT[lng,lng]                ws-ID / ws-ID 
#   X/Y means execution of X overlapped that of Y (and both used the same collection)
#
# Meta-information controlling the cache:
# - uri_lifetime      BAT[str,lng]          URI prefix  / time-to-live (seconds), 
#                                                         nil if not to be cached 
# these tables are protected by the pf_short lock.

# Document Containers ##############################################################
#
# Each imported XML-document (collection) is stored in a series of persistent 
# BATs (columns) whose name starts with the collection ID and ends with the 
# column name. The full set of these bats is called a 'document container'.
# Thus, each document collection maps on a single persistent document container
# (a set of bats). At run-time, multiple isolated copies (containers) for a certain
# collection may be open. Each query also creates a temporary 'transient document
# container' consisting of transient BATs, which holds only nodes that are
# constructed in the query.
#
# Each document container contains the following rid_* BATs from which the pre_* 
# BATs are derived:
# - map_pid            BAT[void,oid] 64K tuple page-id / its page index in the rid_table
# - nid_rid            BAT[void,oid]        stable NID / RID 
# - rid_size           BAT[void,int]               RID / #descendants,
# - rid_level          BAT[void,chr]               RID / distance from root,
# - rid_prop           BAT[void,oid]               RID / property-ID,
# - rid_kind           BAT[void,chr]               RID / node kind (determins prop_* column)
# - rid_nid            BAT[void,oid]               RID / stable NID 
# - frag_root          BAT[oid,oid]        document-ID / root NID
#                              
# NOTE: read-only collections have NID_RID and MAP_PID as BAT[void,void] views. 
#       For them RID=PRE=NID in all cases, the RID-PRE-NID transformations (leftfetchjoin/ 
#       siwzzle) are zero-cost. This is also true for the transient document container. 
#
# NOTE: MAP_PID page indices start at oid(0). by putting the rid_* phyisical pages 
#       in the order specified by MAP_PID we get the original pre_* tables back.
#
# qn_* tables contain qualified names (elements, attributes). 
# They are double-eliminated on (prefix_uri_loc) and we keep a histogram statistic 
# on them, that is used for indexing only 'relatively infrequent' qnames:
# - qn_prefix_uri_loc: BAT[void,str]          qname-ID / prefix:uri:loc
# - qn_uri_loc         BAT[void,str]          qname-ID / uri:loc only
# - qn_prefix          BAT[void,str]          qname-ID / prefix
# - qn_ns              BAT[void,str]          qname-ID / namespace URI
# - qn_loc             BAT[void,str]          qname-ID / local name (e.g. element name)
# - qn_histogram       BAT[void,lng]          qname-ID / occurence count (estimate)
#
# the prop_* bats are independent (varying sizes for each kind) and keep UTF-8 string data
# - prop_text          BAT[void,str]       property-ID / text,
# - prop_com           BAT[void,str]       property-ID / comment,
# - prop_ins           BAT[void,str]       property-ID / processing instruction,
# - prop_tgt           BAT[void,str]       property-ID / processing instruction target,
# - prop_val           BAT[void,str]       property-ID / string value of attribute node
#
# the attr_* bats contain attribute data:
# - attr_own           BAT[void,oid]      attribute-ID / NID of owner
# - attr_qn            BAT[void,oid]      attribute-ID / and qname-ID
# - attr_prop          BAT[void,oid]      attribute-ID / property-ID (for prop_val)
#
# attr_prop stores the values separately to allow "shallow copying", where in a transient 
# document container, an attribute is both defined (qname) and its value stored (prop_val) 
# in a different collection (see PRE_CONT and ATTR_CONT below).


# The Working Set #################################################################
#
# A "working set" contains all XML data currently accessible to a running query;
# each running XQuery has its own working set. 
#
# Thus, for each bat in a document container, the working set contains a bat-of-bats.
# It contains one entry for each loaded container.
#
# For updatable collections, the  bats in the working set used for query execution 
# are *views* on the persistent bats, to provide isolation.
# - for the pre/post table pages from the rid_* are remapped into isolate pre_* bats
# - all other container bats are copy-on-write mmap views on the masters
#   (mmap is only used for big heaps; small heaps are malloced copies)
# - the working set also contains all masters. Update queries need access
#   to the masters when they commit. The master column of "X" is called "_X".
# - for read-only collections (including all documents shredded on-the-fly)
#   there is no difference between the queryable bats and the masters.
#
# The working set can have multiple documents open. Those multiple documents
# may stem from a single, or multiple collections. The code is optimized to deal
# with huge numers of (small) documents from s single collection efficiently. 
#
# Each open collection has a corresponding container in the working set,
# administered in a table:
# - CONT_COLL          BAT[void,oid]      container-ID / collection-ID 
# - CONT_NAME          BAT[void,str]      container-ID / collection-ID 
#                                                       (both nil for transient container)
# - CONT_RUNTIME       BAT[void,bat]      container-ID / index bat
#                                                       (empty for transient container)
# the idea behind having NAME and RUNTIME (from collection_name and colname_runtime) 
# replicated inside the ws besides the collection -ID (with which those could be looked up)
# is that during the query we want to limit taking the pf_short lock to do that each time.
#
# since each container can contain multiple documents, these are in a separate table:
# - OPEN_CONT          BAT[void,oid]        open-docid / container-ID 
# - OPEN_NAME          BAT[void,str]        open-docid / document name
# - OPEN_DOCID         BAT[void,oid]        open-docid / persistent document-ID 
#
# NOTE: when the query starts, a first, empty container is created, the
#       'transient document container'. It has container-ID (cont) 0.
#
# NOTE: open temporary shredded documents that are not cached have both 
#       _COLL and _DOCID fields set to an "artificial" doc_oid == open-docid.
#       These are values < DOCID_MIN (1 billion). It is only unique within the ws.
#       Persistent documents and container have globally unique keys that 
#       point into the doc_* and collection_* tables.
#
# For each container, the working set contains two extra virtual bats:
# - PRE_CONT           BAT[void,BAT[void,oid]] 
#                      list of bats with containers oids for each pre value 
#                      (copied in element construction)
# - ATTR_CONT          BAT[void,BAT[void,oid]] 
#                      list of bats with containers oids for each attr value 
#                      (copied in element/attribute construction)
#
# These bats are *constant* (i.e. have an identical value for each tuple)
# for all shredded documents, hence they are not stored on disk (we create a
# view when they are loaded instead). Their function is to allow shallow copying 
# in the transient document container.  i.e. for the transient container, these 
# bats are not views, and their CONT values refer to other containers.


@- ws definition

This macro is used for the MIL const defs, the C const defs,
but also in the MIL procs for creating, filling and destroying
a working set.

We define a table with the column name, its number,
the type of data (typically again a bat), and if
so the head and tail type of that bat.

actually the field 'tpe' is taken to be bat *always*, 
EXCEPT when (child-T == void)

('tpe' = void means it is a view; without persistent name)

All ws entries starting with '_' are master bats, whereas 
their versions with '_' copies/views. The latter ones
are used for querying, as they provide isolation against
concurrent updates.

         name           number  htp  ttp  col[H,T]    col-seqbase 
         ========       ======  ===  ===  ==========  ===========
@= ws
@:ws_@1(MAP_PID,            0, void, bat, void,  oid, PRE_BASE)@
@:ws_@1(PRE_SIZE,           1, void, bat, void,  int, PRE_BASE)@
@:ws_@1(PRE_LEVEL,          2, void, bat, void,  chr, PRE_BASE)@
@:ws_@1(PRE_PROP,           3, void, bat, void,  oid, PRE_BASE)@
@:ws_@1(PRE_KIND,           4, void, bat, void,  chr, PRE_BASE)@
@:ws_@1(PRE_NID,            5, void, bat, void,  oid, PRE_BASE)@
@:ws_@1(NID_RID,            6, void, bat, void,  oid, PRE_BASE)@
@:ws_@1(FRAG_ROOT,          7, void, bat,  oid,  oid, oid_nil)@
@:ws_@1(QN_HISTOGRAM,       8, void, bat, void,  lng, PRE_BASE)@
@:ws_@1(QN_PREFIX_URI_LOC,  9, void, bat, void,  str, PRE_BASE)@
@:ws_@1(QN_URI_LOC,        10, void, bat, void,  str, PRE_BASE)@
@:ws_@1(QN_PREFIX,         11, void, bat, void,  str, PRE_BASE)@
@:ws_@1(QN_URI,            12, void, bat, void,  str, PRE_BASE)@
@:ws_@1(QN_LOC,            13, void, bat, void,  str, PRE_BASE)@
@:ws_@1(PROP_TEXT,         14, void, bat, void,  str, PRE_BASE)@
@:ws_@1(PROP_COM,          15, void, bat, void,  str, PRE_BASE)@
@:ws_@1(PROP_INS,          16, void, bat, void,  str, PRE_BASE)@
@:ws_@1(PROP_TGT,          17, void, bat, void,  str, PRE_BASE)@
@:ws_@1(PROP_VAL,          18, void, bat, void,  str, PRE_BASE)@
@:ws_@1(ID_NID,            19, void, bat,  str,  oid, oid_nil)@
@:ws_@1(IDREF_NID,         20, void, bat,  str,  oid, oid_nil)@
@:ws_@1(ATTR_OWN,          21, void, bat, void,  oid, PRE_BASE)@
@:ws_@1(ATTR_QN,           22, void, bat, void,  oid, PRE_BASE)@
@:ws_@1(ATTR_PROP,         23, void, bat, void,  oid, PRE_BASE)@

@:ws_@1(QN_NID,            24, void, bat, void,  oid, PRE_BASE)@
@:ws_@1(QN_NID_DEL,        25, void, bat, void,  oid, PRE_BASE)@
@:ws_@1(QN_NID_INS,        26, void, bat, void,  oid, PRE_BASE)@

@:ws_@1(PID_MAP,           27, void, bat, void,  oid, PRE_BASE)@
@:ws_@1(PRE_CONT,          28, void, void,void,  oid, PRE_BASE)@
@:ws_@1(ATTR_CONT,         29, void, void,void,  oid, PRE_BASE)@
@:ws_@1(OPEN_NAME,         30, void, str, void, void, oid_nil)@
@:ws_@1(OPEN_DOCID,        31, void, oid, void, void, oid_nil)@
@:ws_@1(OPEN_CONT,         32, void, oid, void, void, oid_nil)@
@:ws_@1(CONT_COLL,         33, void, oid, void, void, oid_nil)@
@:ws_@1(CONT_NAME,         34, void, str, void, void, oid_nil)@
@:ws_@1(CONT_RUNTIME,      35, void, bat, void, void, oid_nil)@
@:ws_@1(CONT_LOCKED,       36, void, lock,void, void, oid_nil)@

@:ws_@1(_MAP_PID,          37, void, bat, void,  oid, PRE_BASE)@
@:ws_@1(_RID_SIZE,         38, void, bat, void,  int, PRE_BASE)@
@:ws_@1(_RID_LEVEL,        39, void, bat, void,  chr, PRE_BASE)@
@:ws_@1(_RID_PROP,         40, void, bat, void,  oid, PRE_BASE)@
@:ws_@1(_RID_KIND,         41, void, bat, void,  chr, PRE_BASE)@
@:ws_@1(_RID_NID,          42, void, bat, void,  oid, PRE_BASE)@
@:ws_@1(_NID_RID,          43, void, bat, void,  oid, PRE_BASE)@
@:ws_@1(_FRAG_ROOT,        44, void, bat,  oid,  oid, oid_nil)@
@:ws_@1(_QN_HISTOGRAM,     45, void, bat, void,  str, PRE_BASE)@
@:ws_@1(_QN_PREFIX_URI_LOC,46, void, bat, void,  str, PRE_BASE)@
@:ws_@1(_QN_URI_LOC,       47, void, bat, void,  str, PRE_BASE)@
@:ws_@1(_QN_PREFIX,        48, void, bat, void,  str, PRE_BASE)@
@:ws_@1(_QN_URI,           49, void, bat, void,  str, PRE_BASE)@
@:ws_@1(_QN_LOC,           50, void, bat, void,  str, PRE_BASE)@
@:ws_@1(_PROP_TEXT,        51, void, bat, void,  str, PRE_BASE)@
@:ws_@1(_PROP_COM,         52, void, bat, void,  str, PRE_BASE)@
@:ws_@1(_PROP_INS,         53, void, bat, void,  str, PRE_BASE)@
@:ws_@1(_PROP_TGT,         54, void, bat, void,  str, PRE_BASE)@
@:ws_@1(_PROP_VAL,         55, void, bat, void,  str, PRE_BASE)@
@:ws_@1(_ID_NID,           56, void, bat,  str,  oid, oid_nil)@
@:ws_@1(_IDREF_NID,        57, void, bat,  str,  oid, oid_nil)@
@:ws_@1(_ATTR_OWN,         58, void, bat, void,  oid, PRE_BASE)@
@:ws_@1(_ATTR_QN,          59, void, bat, void,  oid, PRE_BASE)@
@:ws_@1(_ATTR_PROP,        60, void, bat, void,  oid, PRE_BASE)@
@-
The bottom segment are the master copies of the top segment.
The middle segment is private to the query.

BEWARE: WS_SIZE (below) should *always* be the size of ws (above)

BEWARE: the logger version number below needs to be incremented whenever the working set schema is changed.

@= ws_decl
@:ws_@1_decl(WS_SIZE, 61)@
@:ws_@1_decl(QNAME,    2)@
@:ws_@1_decl(BOOL,     3)@
@:ws_@1_decl(INT,      4)@
@:ws_@1_decl(DEC,      5)@
@:ws_@1_decl(DBL,      6)@
@:ws_@1_decl(STR,      7)@
@:ws_@1_decl(U_A,      8)@
@:ws_@1_decl(ATOMIC,  31)@
@:ws_@1_decl(NODE,    32)@
@:ws_@1_decl(ATTR,    33)@
@:ws_@1_decl(ELEM,    34)@

@= ws_mil_decl
const @1 := @2;
@mil
@:ws(mil_decl)@
@:ws_decl(mil)@

# logger version number, needs to be incremented whenever the working set schema is changed
const LOGGER_VERSION := 1;

# KIND constants, carefully chosen
# atomic value items can be retrieved with 'kind.select(int_nil,ATOMIC)'
# NODE is not a type but all node types can be retrieved with 'kind.select(NODE,int_nil)'
const ELEMENT          := chr(0);
const TEXT             := chr(1);
const COMMENT          := chr(2);
const PI               := chr(3);
const DOCUMENT         := chr(4);
const COLLECTION       := chr(5);

# zero
const WS               := 0@0; # first container in ws = transient doc container
const PRE_BASE         := 0@0; # all our PRE bats start at 0 (the super-root)
const TEMP_DOC         := 0@0; # doc/coll key that is never used for persistent docs
const DOCID_MIN        := 1000000000@0; # persistent doc-ids start here
const DOCID_MAX        := 2000000000@0; # and end here
const WS_MAXID         := 1LL << 62;

# slots in the col_runtime bats
const RT_LOCK_FREELIST := 0;
const RT_NID_FREELIST  := 1;
const RT_PAGE_WS       := 2;
const RT_ATTR_WS       := 3;
const RT_QN_NID        := 4;
const RT_QN_NID_INS    := 5;
const RT_QN_NID_DEL    := 6;
const RT_QN_NID_UNQ    := 7;
const RT_REGION_PRE    := 8;
const RT_REGION_START  := 9;
const RT_REGION_END    := 10;

const WSID_UPDATE := (3LL << 30);
const WSID_EXCLUSIVE := (1LL << 31);

# dirty solution (proposed by Peter ;) to be able to locate (and replace) the
# bats inside the colname_runtime-bat.
const RT_REGION_PRE_LOCK    := lock(RT_REGION_PRE);
const RT_REGION_START_LOCK  := lock(RT_REGION_START);
const RT_REGION_END_LOCK    := lock(RT_REGION_END);

# these constants are used by the update code
# the values should remain in this order and be consecutive with the indices from the working set
const MAP_PID_UPDATE := _ATTR_PROP + 1; # assume _ATTR_PROP is the last entry in the working set
const RID_SIZE_UPDATE := MAP_PID_UPDATE + 1;
const RID_LEVEL_UPDATE := RID_SIZE_UPDATE + 1;
const RID_KIND_UPDATE := RID_LEVEL_UPDATE + 1;
const RID_PROP_UPDATE := RID_KIND_UPDATE + 1;
const RID_NID_UPDATE := RID_PROP_UPDATE + 1;
const NID_RID_UPDATE := RID_NID_UPDATE + 1;
const ATTR_QN_UPDATE := NID_RID_UPDATE + 1;
const ATTR_PROP_UPDATE := ATTR_QN_UPDATE + 1;
const ATTR_OWN_UPDATE := ATTR_PROP_UPDATE + 1;
const PROP_VAL_UPDATE := ATTR_OWN_UPDATE + 1;
const PROP_TEXT_UPDATE := PROP_VAL_UPDATE + 1;
const PROP_COM_UPDATE := PROP_TEXT_UPDATE + 1;
const PROP_INS_UPDATE := PROP_COM_UPDATE + 1;
const PROP_TGT_UPDATE := PROP_INS_UPDATE + 1;
const QN_LOC_UPDATE := PROP_TGT_UPDATE + 1;
const QN_URI_UPDATE := QN_LOC_UPDATE + 1;
const QN_PREFIX_UPDATE := QN_URI_UPDATE + 1;
const QN_URI_LOC_UPDATE := QN_PREFIX_UPDATE + 1;
const QN_PREFIX_URI_LOC_UPDATE := QN_URI_LOC_UPDATE + 1;
const QN_HISTOGRAM_UPDATE := QN_PREFIX_URI_LOC_UPDATE + 1;
const UPDATED_TEXT := QN_HISTOGRAM_UPDATE + 1;
const NID_QN_INS_UPDATE := UPDATED_TEXT + 1; # note, NID_QN and not QN_NID
const NID_QN_DEL_UPDATE := NID_QN_INS_UPDATE + 1;
const MODIFIED_NID := NID_QN_DEL_UPDATE + 1;
const ANCESTOR_NID := MODIFIED_NID + 1;
const MODIFIED_ATTR := ANCESTOR_NID + 1;
const MODIFIED_PAGE := MODIFIED_ATTR + 1;
const NEW_PAGE := MODIFIED_PAGE + 1;

@= ws_nme
    .append(toLower("@1"))
@= ws_tpe
    .append(@4)
@= ws_htp
    .append(@5)
@= ws_ttp
    .append(@6)
@= ws_seq
    .append(@7)
@mil
# get a handle to the global locks
var pf_short := pflock_get(0); # *NOTE* all PROCs _X() (starting with underscore) hold pf_short
var pf_free  := pflock_get(1); # lock held while freeing ws-es
var pf_wal   := pflock_get(2); # lock that must be held while writing into the WAL

# initialize the logger
var pf_logger := logger_create(0, "xquery", monet_environment.find("xquery_logdir"), 
                                            monet_environment.find("gdk_dbname"), LOGGER_VERSION);

# the list of bats that get changed using the logger in case of updates 
# (i.e. these are the ones that need to be registered in the logger)
const logger_bats := new(void, str, 21).seqbase(0@0)
	.append("_map_pid")
	.append("_rid_size")
	.append("_rid_level")
	.append("_rid_prop")
	.append("_rid_kind")
	.append("_rid_nid")
	.append("_nid_rid")
	.append("_attr_own")
	.append("_attr_qn")
	.append("_attr_prop")
	.append("_prop_val")
	.append("_prop_text")
	.append("_prop_com")
	.append("_prop_ins")
	.append("_prop_tgt")
	.append("_qn_loc")
	.append("_qn_uri")
	.append("_qn_prefix")
	.append("_qn_uri_loc")
	.append("_qn_prefix_uri_loc")
	.append("_qn_histogram");

PROC pf_checkpoint(BAT[void,str] commitBAT) : bit 
{
    if (count(commitBAT) = 0) return false;
    commitBAT := commitBAT.access(BAT_WRITE);
    commitBAT.append("xquery_catalog");
    commitBAT.append("xquery_seqs");
    commitBAT.append("xquery_snapshots");
    commitBAT.append("collection_name");
    commitBAT.append("collection_size");
    commitBAT.append("doc_name");
    commitBAT.append("doc_location");
    commitBAT.append("doc_collection");
    commitBAT.append("doc_timestamp");
    commitBAT.append("uri_lifetime");
    var ok := false;
    lock_set(pf_wal);
    CATCH(ok := subcommit(commitBAT));
    lock_unset(pf_wal);
    if (not(ok)) ERROR("XQDY0062: checkpoint failed, query aborted.\n");
    return true;
}

# the logger background thread
PROC pf_logmanager() : void {
    var cnt := 0;
    while(true) {
        if ((logger_changes(pf_logger) > 100000) and ((cnt :+= 1) <= 10)) { 
            lock_set(pf_wal);
            logger_restart(pf_logger);
            lock_unset(pf_wal);
            logger_cleanup(pf_logger);
            cnt := 0;
        } 
        sleep(90);  
    }
}
# synchronize the starting of the log
fork(pf_logmanager());

# the set of document collections (may only be accessed holding pf_short)
var collection_name;  # bat[oid,str] collection name 
var collection_size;  # bat[oid,lng] collection size in bytes
var collection_zombie := bat(oid,lng).rename("collection_zombie"); 
                      # bat[oid,lng] contains ws still using the now defunct collection (TRANSIENT)

var doc_collection;   # bat[oid,oid] collection-id 
var doc_name;         # bat[oid,str] document name
var doc_location;     # bat[oid,str] document URI
var doc_timestamp;    # bat[oid,timestamp] caching limit (nil if none)
var doc_undo := bat(oid,lng).rename("doc_undo"); 
                      # bat[oid,lng] contains ws that created this document (TRANSIENT)

var uri_lifetime;     # caching rules

# initialize persistent bats (use BBP as global mechanism to discover initialization)
if (isnil(CATCH(bat("doc_name").count()))) {
    collection_name  := bat("collection_name");
    collection_size  := bat("collection_size");
    doc_collection   := bat("doc_collection");
    doc_name         := bat("doc_name");
    doc_location     := bat("doc_location");
    doc_timestamp    := bat("doc_timestamp");
    uri_lifetime     := bat("uri_lifetime");
} else {
    # create doc_name table in case it does not exist
    collection_name := new(oid,str).persists(true).rename("collection_name");
    collection_size := new(oid,lng).persists(true).rename("collection_size");
    doc_collection  := new(oid,oid).persists(true).rename("doc_collection");
    doc_name        := new(oid,str).persists(true).rename("doc_name");
    doc_location    := new(oid,str).persists(true).rename("doc_location");
    doc_timestamp   := new(oid,timestamp).persists(true).rename("doc_timestamp");
    uri_lifetime    := new(str,lng).persists(true).rename("uri_lifetime");
    doc_collection.insert(TEMP_DOC, DOCID_MIN); # hack: store next oid as in invalid TEMP_DOC tuple
    pf_checkpoint(bat(void,str).append("uri_lifetime"));
}

# runtime collection acccess control (TRANSIENT)
var colname_runtime  := bat(str,bat).rename("colname_runtime"); 
                        # bat[str,bat] runtime index/lock bat-of-bat 
var colname_pins     := bat(str,lng).rename("colname_pins"); 
                        # bat[str,lng] queries that are using a collection (negative numbers are shreds)
var colname_shredlock:= bat(str,lock).rename("colname_shredlock"); 
                        # bat[str,lng] query that is shredding into a collection 
var colname_locks    := bat(str,lng).rename("colname_locks"); 
                        # bat[str,lng] queries that are using a collection 

var ws_overlaps_ws := bat("ws_overlaps_ws"); 
                        # bat[lng,lng] execution of query X overlapped query Y and they used a common collection

var empty_bat        := bat(void,oid).seqbase(0@0).access(BAT_READ).rename("empty_bat"); 
var empty_runtime    := bat(lock,bat).insert(lock_nil,empty_bat).rename("empty_runtime"); 
var empty_page       := bat(void,int,REMAP_PAGE_SIZE).rename("empty_page"); 
                        # empty pages to append onto rid_* master bats
{   # bat[void,int] of size REMAP_PAGE_SIZE counting down from REMAP_PAGE_SIZE-1
    var m := int_nil, i := int(REMAP_PAGE_SIZE);
    var bak := debugmask();
    debugmask(0);
    while((i :-= 1) >= 0) { empty_page.append(nilor(i, m)); }
    debugmask(bak);
    empty_page.seqbase(0@0).access(BAT_READ);
}

# the ws_* bats contain a recipe for creating a new ws
var ws_nme := bat(void,str,WS_SIZE)@:ws(nme)@.seqbase(0@0).access(BAT_READ).rename("ws_nme");
              # name (prefix) of ws entry as persistent bat
var ws_tpe := bat(void,int,WS_SIZE)@:ws(tpe)@.seqbase(0@0).access(BAT_READ).rename("ws_tpe");
              # type of ws entry (often bat)
var ws_htp := bat(void,int,WS_SIZE)@:ws(htp)@.seqbase(0@0).access(BAT_READ).rename("ws_htp");
              # (if tpe=bat) head-type of nested bat
var ws_ttp := bat(void,int,WS_SIZE)@:ws(ttp)@.seqbase(0@0).access(BAT_READ).rename("ws_ttp");
              # (if tpe=bat) tail-type of nested bat
var ws_seq := bat(void,oid,WS_SIZE)@:ws(seq)@.seqbase(0@0).access(BAT_READ).rename("ws_seq");
              # (if tpe=bat) seqbase of nested bat
var ws_col := ws_tpe.ord_uselect(bat).mirror().leftfetchjoin(ws_nme).rename("ws_col");
              # all ws entries that are real bats, and their names
var ws_dsk := ws_nme.reverse().ord_select(oid(_MAP_PID), oid_nil).reverse().rename("ws_dsk");
              # of those, all persistent bats on disk for a document container , and their names
var ws_mem := [oid]([int](mirror(ws_dsk)).[-](_RID_SIZE - PRE_SIZE));
              # of those, all master non-rid_* bats, and their (copy-on-write) updatable views 
var ws_rid := ws_mem.slice(PRE_SIZE, PRE_NID).rename("ws_rid");
              # of those, all master rid_* bats, and their (remapped) pre_* views
    ws_mem := ws_mem.slice(NID_RID, INT_MAX).rename("ws_mem");

# silently clean up the repository
collection_cleanup(_collection_cleanup());

# start the background processes 
xquery_start_query_cache(lng(monet_environment.find("xquery_procMB")) * 1024LL * 1024LL);
mapi_register(xquery_frontend());


# scans for empty collections, and produces a list of kill-bats (fast - done inside the short lock)
PROC _collection_cleanup() : BAT[str,str]
{
    var commitBAT := bat(str,str);
    var cnt := {count_no_nil}(reverse(doc_collection).leftjoin(doc_name), collection_name);
    var del := cnt.uselect(0).mirror().join(collection_name);
    collection_zombie.delete();
    del@batloop() {
        var coll_oid := $h;
        var doc_oids := doc_collection.uselect(coll_oid);

        # only do something if this collection is not pinned!!
        var users := reverse(colname_pins).uselect($t);
        if (count(users) = 0) {
            # delete all documents from the collection
            doc_collection.delete(doc_oids);
            doc_name.delete(doc_oids);
            doc_location.delete(doc_oids);
            doc_timestamp.delete(doc_oids);

            # delete empty collection 
            if (colname_runtime.exist($t)) {
                var runtime := colname_runtime.find($t);
                var coll_lock := reverse(runtime).fetch(RT_LOCK_FREELIST);
                coll_lock.lock_destroy();
                colname_runtime.delete($t);
            }
            colname_shredlock.reverse().select($t)@batloop() lock_destroy($h);
            colname_shredlock.delete($t);
            colname_pins.delete($t);
            colname_locks.delete($t);

            collection_name.delete(coll_oid); 
            collection_size.delete(coll_oid);
            commitBAT.insert([+](str(int(coll_oid)), ws_dsk.reverse().mirror()));
         } else {
            # recall the ws-ids that blocked deletion of a collection 
            collection_zombie.append([abs](reverse(project(users,$h))));
         }
    }
    return commitBAT.access(BAT_READ); # return a list of garbage bats
}

# make a list of victim bats transient, the commit (slow - done outside the short lock)
PROC collection_cleanup(BAT[str,str] delBAT) : void
{
    var cnt := count(delBAT);
    if (bit(cnt)) {
        var commitBAT := bat(void,str,cnt);
        var logger_delBAT := logger_bats.join(delBAT);
        if (logger_delBAT.count() > 0) {
            lock_set(pf_wal);
            log_trans_start(pf_logger);
            [log_bat_transient](pf_logger, logger_delBAT);
            [logger_del_bat](pf_logger, [logger_find_bat](pf_logger, logger_delBAT));
            log_trans_end(pf_logger);
            lock_unset(pf_wal);
        }
        delBAT.kdiff(reverse(logger_bats))@batloop() {
            if (isnil(CATCH(persists(bat($t), false)))) commitBAT.append($t); 
        }
        pf_checkpoint(commitBAT);
    }
}

@+ locking approach
@T
MonetDB/XQuery uses optimistic concurrency control with snapshot
isolation, so updates do not use locks as such. Instead, conflicting 
queries are aborted at commit time (see later in "Query Types"). 

Still, some locking still needs to be done, to prevent crashes.
Monet BATs may never be modified (e.g. from MIL) while other  
concurrent queries are reading them (e.g. from MIL). This holds
both from the meta-bats, as well as the data bats.

The goal is to allow as much concurrency as possible (after all, the
strength of optimistic CC).

@- short lock

There is a short lock (pf_short) that protects access to the collection_*,
doc_* and colname_* meta-tables. Note that the fn:add_doc(), fn:del_doc()
as well as the fn:doc() function (which does implicit shredding and caching)
modify these tables. All types of queries read them. Thus all reads and
writes to these tables need to be locked, with the short lock. 

It is good practice to carry out all work while holding the short lock inside 
a CATCH(). Otherwise a run-time error may leave the short lock taken and the 
whole system blocked forever.  Thus, all MIL PROCs X() that need the lock, 
have a worker function _X() that is called inside the locked execution:

PROC X() : void {
    lock_set(pf_short);
    var err := CATCH(_X());
    lock_unset(pf_short);
    if (not(isnil(err))) ERROR(err);
}

As a general convention all MIL PROCs _X(), i.e. whose name starts with an
underscore, assume the pf_short lock is taken.

@- collection lock 

Apart from the short lock, each XML collection (i.e. document container) has 
its own lock. These locks can be found via the colname_runtime BAT[str,bat]. 
Its head contains collection names. Its tail a so-called 'runtime' BAT[lock,bat]. 
The first entry (named RT_LOCK_FREELIST ) in this runtime-BAT is 
[coll_lock,pagefree], where 'coll_lock' is the collection lock and 
'pagefree' is a BAT[oid,void] that contains a list of free pages.

The other entries in the runtime-BAT relate to indices on the collection.
More information can be found in the QN_NID section. Also, the StandOff
extensions use entries in the runtime-BAT.

The collection lock can be used to get exclusive access to the master
bats of a collection. This is required when:

- a collection is opened and isolated copies of the master bats need to 
  be made. This includes the time taken for any nsloc index construction,
  which must be done on the master copies.

- while an incremental shred operation is *extending* the bat collection 
  -- though it is not needed while shredding in general.

- while playing the update tape, and determining which updates
  to make, certain append-only tables are extended (qn_*,  prop_*).
  These extensions must also take the coll_lock, temporarily.

- while applying the updates of a committed query to the master bat.
  note that in a commit, first all locks of all documents must be acquired
  (in ascending order - to prevent deadlock), then all changes commited. 

Similar to the short_doc PROC naming convention, __X() PROCs, i.e.
with double underscore are those that execute while holding a collection
lock.

@- shred lock 

Note that we will not use the collection lock while shredding (fn:add_doc())
continuously, only when extending the master bats. The code of shredding is 
carefully screened only to touch *new* parts of the BATs thus not affecting 
the master copies in places that are shared with ongoing queries. BAT-extends 
must be locked with the collection lock, as these may lead to base-relocations,
that affect other users of the master bats.

However, we must ensure that only one shred into the same collection is
happening at a time, as both need exclusive append access. For this
purpose, an extra "shred-lock" in the colname_shredlock BAT[str,lock] is taken 
by shred operations.

This "shred-lock" thus protects the process of making the data bats longer.
As such, also the insert operations that allocate a new page (ws_newpage) 
or a new set of NIDs (ws_newnids) must acquire this lock. These two operations
always request a karger batch of (pages, NIDs) in one go, adding them to a 
free-list. Thus, many insert actions will actually not need to take the 
shred-lock (as they can get theire new pages/NIds from a freelist).

@- deleting documents 

Deleting documents simply marks them as unused by changing document and
collection names to nil. This ensures that newly entering queries will
never find and thus use those documents. When the last document in a 
collection is deleted, the collection should be removed. Only then, 
the BAT resources may be freed.

Deleting documents is separated in two phases, where the setting 
to nil of the name is the critical part. This action does not throw
away any data, so can be easily rolled back. A single query can
delete many documents and shred many new ones, but should commit
actomically. If some action fails, everything is rolled back.

After a succesful document management query, empty document collections 
are pruned. That is, they are removed from the meta-tables, and 
their data tables physically removed.  This may not be possible if there
are concurrent users of documents in the collections (these 
transactions must have started before the document name was 
set to nil, or will shred a new document into the now empty collection).
Those collections are not pruned, but when the transaction that
blocked it finishes, it retries empty collection pruning in its 
ws_destroy() sequence.

@- collection pins and ws-IDs

To detect concurrent use of collections, all document-using functions 
(fn:doc() but also fn:add_doc()) put a so-called 'pin' on the collection 
they are intending to manipulate.  These pins are gathered in the BAT[str,lng] 
colname_pins (it contains document names and ws-IDs). 
This BAT is also used for recording which queries currently hold 
a shred-lock. This is marked by storing the *negated* ws-id. 

ws-ID: a transaction (query) is characterized by its ws-id. The 
ws-id is a unique OID, and is kept as the name of the working set 
bat[void,bat]. ws-IDs are globally aned temporally unique, i.e. 
we can talk about a ws-ID even after the transaction has finished.

The collection pins record which transactions (wsids) are using 
which bats. This information is deleted only at the end of
the transaction. 

@- conflict detection & isolation 

This relates to the ws_precommit() function. 

From the collection pins we also derive a 'ws_overlaps_ws'
BAT that captures which update transactions executed concurrently
and had some common XML collection open (in common). These
transactions potentially conflict with each other (which
may lead to an abort on one of them).

For conflict detection, we remember all page-ids in the rid_* 
table that a transaction modified, as well as all attribute 
oids (the other tables, qn_* and prop_* are append-only so
never cause any conflicts).

(note that for structural updates in a page, all pages containing 
 ancestors (whoise size field will be affected by the update) 
 are *not* considered modified. Concurrent ancestor size-changes 
 are compensated at commit time by keeping track of the difference 
 in size, caused by a transaction, rather than absolute values.)

A related issue is isolation. At commit time, changes from
the update list (that were succesfully logged in the WAL) are
applied to the master BATs. Concurrent queries should be
isolated from these changes in the masters. For this purpose, 
we touch the affected pages in their copy-on-write memory maps
first. 

To establish which transactions (working sets) need to be 
isolated, we again use the colname_pins.
The isolating may take significant time, therefore it
is done outside the short lock, but inside a free-lock.
This free-lock is also taken during the ws_destroy.

@- WAL versus subcommit 

For committing, queries write into the WAL. The WAL is therefore also
protected by a separate WAL lock (similar but separate to the short lock).

However, for shredding, we use checkpoints. A partial checkpoint 
causes certain BATs to be saved to disk; all WAL entries for that BAT
before the subcommit time can be ignored.

Besides, there is a checkpoint background thread in the logger, that 
performs periodical checkpoints, and flushes the old logfiles.  


@+ Query types

Besides read-only queries, there are two other typed: updaing
queries (that rely on a WAL commit) and documnent management
queries that shred/delete documents (and rely on a checkpoint).

Because of their relience on different commit mechanism, updating
queries cannot do document management. Otherwise we would not be
able to provide an atomic commit. 

@- Updating Queries

An update query goes through the following phases:
(0) ws_create(1), indicating an updating query. If the paraneter value 
    is 2, it is a rerun of an aborted transaction (in serial mode). 
(1) query execution. this produces an update tape.
(2) ordering and playing the update tape for each kind of update
    (delete, insert, renam). This produces intentional updates
    aka "delta bats" to the (rid_*, nid_* and attr_* master tables),
    but *directly* carries out modifications to the qn_* and prop_* 
    masters.  For the latter direct modifications coll_lock's are used
    short-term (i.e. lock, modify, unlock). 
    Also, while the update tape is played, all (intended or direct)
    updates are logged in the WAL.
(3) ws_precommit(). The main function is conflict detection:
    it will trigger a MIL ERROR, which will result in an abort.
    In case of no error, ws_precommit() isolates all concurrent
    transactions from the intended updates (VM shadow paging).
    ws_precommit() also obtains the coll_lock of an affected
    container and does not release it (to prevent deadlock, the 
    order of the affected containers for which ws_precommit() 
    is called, should be consistent).
(4) commit in the WAL. Reaching this point determines transaction commit/abort.
    Afterwards, update all rid_*, nid_* and attr_* masters with the 
    intentional updates (delta bats) produced in phase 2.
    Note that applying the deltas to the size column are special,
    because we keep not the new value, but the difference. So, when
    apllying size deltas, we read the current value in the master, 
    apply the difference kept in the delta-bat, and write back the result.
    Thanks to this, we can keep the ancestor-sizes out of the 
    modified-page administration (otherwise, the page containing 
    the root node would always be modified, inhibiting any concurrency).
(5) ws_postcommit(). It maintains the index structures, and 
    releases the coll_lock. It should be called for each 
    affected container in consistent order.
(6) ws_destroy(). In case of an error in any of the stages >0, 
    we get here.  It releases all locks (these actions are protected 
    by pf_short, the only lock that must never remain taken when 
    an error occurs)

Optimistic CC may suffer from high abort rates, if many updating queries 
modify the same page. With our page-wise deadlock detection (and pages
being rather large), this is a serious threat to update throughput.

This threat is reduced somewhat by adaptively handling transaction aborts.
When a transaction aborts (due to concurrent conflict only), we immediately 
reschedule the transaction it and run it in serial mode.

We actually schedule a "serial convoy" of e.g. size 5.  This serial convoy 
means that the next 5 incoming update transactions will be executed in 
serial mode.  This policy ensures that conflict aborts never bother the user, and
highly "conflicting" query loads avoid putting the system in "thrashing" mode.

(see the pflock_* COMMANDS in pf_support.mx)

@- Document Management Queries 
A read-only query executes the following phases:
(0) ws_create(false)
(1) query execution. this produces an statement tape.
(2) ordering and playing the statement tape for each kind of 
    statement (first del_doc, then add_doc).
(3) pf_checkpoint. All affected document containers, plus the
    meta bats (collection_*, doc_*) are flushed to disk.
(4) ws_destroy()

@- Read-only Queries 
A read-only query just executes the following phases:
(0) ws_create(false)
(1) query execution. 
(2) ws_destroy()

Note that for all types of queries, phase (1) "query execution"  
may also trigger checkpoints. That is, each occurrence of a fn:doc() 
function may trigger a checkpoint, if the document (identified by URI) 
was not in the database and the caching policy indicates that 
the document should be cached. 

Note that we loop-lifted fn:doc() (ws_opendoc), in the sense that 
each fn:doc() application will construct exactly one single collection 
with all documents that had to be shredded in the loop. A checkpoint
is done only if these documents are exported visibly (to other queries) 
in the database as cached URIs. This is determined by the caching rules. 
This is only done if *all* documents in the loop are cachable. Otherwise, 
the shredded collection is a temporary collection that does not need a 
checkpoint. 

@mil
PROC _shredlock_set(str colname, 
                    lng wsid) : void
{
    # xlocks use a string collection key as it may not yet exist in the table
    if (not(colname_shredlock.exist(colname))) 
        colname_shredlock.insert(colname, lock_create());

    var shred_lock := colname_shredlock.find(colname);
    lock_unset(pf_short);
    lock_set(shred_lock); # can take a long time, do so with short lock released 
    lock_set(pf_short);
    colname_pins.insert(colname, -(wsid));
}

PROC _shredlock_unset(str colname, 
                      lng wsid) : void
{
    # xlocks use a string collection key as it may not yet exist in the table
    var shred_lock := colname_shredlock.find(colname);
    lock_unset(shred_lock);
    colname_pins.delete(colname, -(wsid));
}

PROC coll_lock_set(BAT[void,bat] ws, 
                   oid cont) : void
{
    if (bit(cont)) {
        var coll_lock := reverse(ws.fetch(CONT_RUNTIME).fetch(cont)).fetch(RT_LOCK_FREELIST);
        ws.fetch(CONT_LOCKED).append(coll_lock);
        lock_set(coll_lock);
    }
}

PROC coll_lock_unset(BAT[void,bat] ws, 
                     oid cont) : void
{
    if (bit(cont)) {
        var coll_lock := reverse(ws.fetch(CONT_RUNTIME).fetch(cont)).fetch(RT_LOCK_FREELIST);
        ws.fetch(CONT_LOCKED).reverse().delete(coll_lock);
        lock_unset(coll_lock);
    }
}

@+ working sets and ws-IDs

The working set is the runtime context of a query. For each collection, two
sets of bats are visible: updatable bats and masters. The masters
have names in the working set that start with an underscore.

When a working-set is destroyed, we take care to release all
collection locks and pins. These may be open as the query may have terminated
early with an error (these are caught and ws_destroy() is executed always).

ws-IDs are persistent refererences to working sets. As a working set is
a BAT that is freed and recycled after commit, is is not persistent.
The combination of a *unique* ID (int) with a working-set ID (bat) is
fit into a lng and is used as the ws-ID.
@mil
PROC ws_new(oid id, 
            int tpe, 
            int htp, 
            int ttp, 
            oid seq) : BAT[void,any]
{
    if ((ttp != void) and (int(id) < _RID_SIZE)) { # a bat of bats (persistent or view)
        var b := bat(htp,ttp,10000);
        if (not(isnil(seq))) b.seqbase(seq); 
        return bat(void,bat).seqbase(PRE_BASE).append(b);
    } 
    return bat(void,tpe).seqbase(PRE_BASE); # a constant bat
}

PROC ws_create(int update) : BAT[void,bat]
{
    # only instantiates the default views of the ws-bats (not the master bats)
    var ws := [ws_new](mirror(ws_tpe), ws_tpe, ws_htp, ws_ttp, ws_seq);
    ws.fetch(PID_MAP).fetch(WS).append(ws.fetch(MAP_PID).fetch(WS));

    # the temporary document container has some bogus values here
    ws.fetch(CONT_COLL).seqbase(0@0).insert(0@0,oid_nil);
    ws.fetch(CONT_NAME).seqbase(0@0).insert(0@0,str_nil);
    ws.fetch(CONT_RUNTIME).seqbase(0@0).insert(0@0,empty_runtime);

    # add a (bogus) collection root pre=0@0 to the temporary document container
    ws.fetch(PRE_SIZE).fetch(WS).append(int_nil);
    ws.fetch(PRE_LEVEL).fetch(WS).append(chr(-2));
    ws.fetch(PRE_PROP).fetch(WS).append(oid_nil);
    ws.fetch(PRE_KIND).fetch(WS).append(COLLECTION);
    ws.fetch(PRE_NID).fetch(WS).append(oid_nil);
    ws.fetch(FRAG_ROOT).fetch(WS).insert(WS,1@0); # first root is 1@0

    # add identical bat references as 'master' bats just to make the transient container complete  
    mirror(ws_rid).leftfetchjoin(ws).[insert](0@0, [fetch](ws_rid.leftfetchjoin(ws), 0));
    mirror(ws_mem).leftfetchjoin(ws).[insert](0@0, [fetch](ws_mem.leftfetchjoin(ws), 0));

    # wsid = 1bit(0) | 31bits(unique-id) | 2bits(update) | 30bits(batid)
    var wsid := <<(and(lng(newoid(1)), 2147483647LL), 32) + (lng(update) << 30) + lng(ws);
    ws.access(BAT_READ).rename(str(wsid));
    pflock_begin(wsid);
    return ws;
}

PROC ws_create() : BAT[void,bat]
{
    return ws_create(0);
}

# retrieve wsid from name of BAT ws 
PROC ws_id(BAT[void,bat] ws) : lng
{
    return lng(bbpname(ws));
}

# retrieve BAT ws that belongs to wsid; note that you must be sure that it is still alive
PROC ws_bat(lng wsid) : BAT[void,bat] 
{
    return bat(and(wsid, 1073741823LL));
}

PROC _ws_free(lng wsid) : BAT[void,any]
{
    # handle update queries
    if (and(wsid,WSID_UPDATE) != 0LL) {
        pflock_end(wsid);
        ws_overlaps_ws.delete(wsid); # remove the dependencies of this query 
    }
   
    # check for failed doc_adds (should happen infrequently - we don't care about performance)
    var del := doc_undo.uselect(wsid).project(str_nil);
    if (count(del) > 0) _del_doc_replace(del, del); # delete them again

    # release all claimed locks (error recovery)
    colname_pins.uselect(-(wsid))@batloop() _shredlock_unset($h, wsid);
    reverse(colname_pins).delete(wsid);
 
    # determine whether a cache flush is desired (only count cached bats, those with a timestamp)
    var cursize := sum(doc_timestamp.select(timestamp_nil,timestamp_nil).mirror().join(collection_size));
    var maxsize := (1024LL * 1024LL) * lng(monet_environment.find("xquery_cacheMB"));
    if (cursize > maxsize) del_doc_base(true, doc_name, false);

    # try to flush the document collection, if we held up removal of a now empty collection
    if (count(collection_zombie.uselect(wsid)) > 0)
        return _collection_cleanup(); # garbage collect empty collections

    return new(str,str);
}

PROC ws_free(lng wsid) : void
{
    # always make sure not to cause errors while holding the lock
    lock_set(pf_free);
    lock_set(pf_short);
    var commitBAT, err := CATCH(commitBAT := _ws_free(wsid));
    lock_unset(pf_short);
    lock_unset(pf_free);
    if (not(isnil(err))) {
        printf("%s\n!ERROR: ws_free: query cleanup failed, Mserver must be restarted.\n", err);
        exit(); # ws_free *must must* succeed, it frees all hanging locks etc
    }
    CATCH(collection_cleanup(commitBAT)); 
}

PROC ws_destroy(BAT[void,bat] ws) : void
{
    ws.fetch(CONT_LOCKED)@batloop() lock_unset($t);
    ws_free(ws_id(ws));
}

# add a collection to the working set
PROC __ws_opencoll(BAT[void,bat] ws, 
                   BAT[lock,bat] runtime, 
                   BAT[str,bat] docBAT, 
                   str colname, 
                   oid coll_oid) : oid
{
    # get map, pre and mem from the master bats
    var dsk := docBAT.tmark(oid(_MAP_PID));
    var map_pid := dsk.fetch(MAP_PID);
    var pid_map := map_pid;
    var pre, mem, isolate := (ttype(map_pid) = oid);
    
    if (isolate) {
        # on each document load, we update the free page list (i.e. garbage collection)
        var free_pages := map_pid.ord_uselect(oid_nil).access(BAT_WRITE); # list of free pages
        if ((free_pages.count() = 0) and (free_pages.htype() = void)) free_pages.seqbase(0@0); # give it a non-nil head
        var coll_lock := reverse(runtime).fetch(RT_LOCK_FREELIST);
        runtime.replace(coll_lock, free_pages);

        # sort the non-nil entries to get used-page-list (avoids sorting using positional insert trick)
        pid_map := map_pid.slice(0,count(map_pid)-(1+count(free_pages))).copy().access(BAT_WRITE);
        pid_map.replace(map_pid.reverse()).access(BAT_READ);

        # use the map to get transaction isolation: pre's are remapped logical views, and mem are rcopy logical views
        pre := [remap](reverse(ws_rid).leftjoin(dsk), const pid_map, false);
        mem := [rcopy](reverse(ws_mem).leftjoin(dsk)); 
    } else {
        # read-only doc; no isolation needed 
        pre := reverse(ws_rid).leftjoin(dsk);     # pre_*'s are identical to rid_*
        mem := reverse(ws_mem).leftjoin(dsk);     # other bats are also just the same bats
    }

    # register new container in ws, and append all bats to it
    var cont := oid(count(ws.fetch(CONT_COLL)));
    var cont_bat := constant2bat(cont);
    ws.fetch(MAP_PID).append(map_pid);
    ws.fetch(PID_MAP).append(pid_map);
    ws.slice(PRE_SIZE,PRE_NID).[append](pre);
    ws.slice(NID_RID,ATTR_PROP).[append](mem);
    ws.fetch(PRE_CONT).append(cont_bat);
    ws.fetch(ATTR_CONT).append(cont_bat);
    ws.fetch(CONT_COLL).append(coll_oid);
    ws.fetch(CONT_NAME).append(colname);
    ws.fetch(CONT_RUNTIME).append(runtime);
    mirror(ws_dsk).leftfetchjoin(ws).[append](dsk);

    # initialize runtime on first load (this involves full table scans and may cost)
    var idx, ins, del;
    if (count(runtime) > RT_QN_NID) {
        idx := runtime.fetch(RT_QN_NID);
        ins := runtime.fetch(RT_QN_NID_INS);
        del := runtime.fetch(RT_QN_NID_DEL);
    } else {
        # create the QN_NID index
        var cnt := ws.fetch(QN_HISTOGRAM).fetch(cont);
        var nid := ws.fetch(PRE_NID).fetch(cont);
        var knd := ws.fetch(PRE_KIND).fetch(cont);
        var prp := ws.fetch(PRE_PROP).fetch(cont);
        var unq := ord_uselect([*](cnt,[log]([dbl](cnt))), dbl_nil, dbl(count(knd)));
        var page_ws := empty_bat;
        var attr_ws := empty_bat;
        idx := __runtime_index(nid, knd, prp, unq, 0@0, isolate);
        ins := empty_bat;
        del := empty_bat;
        if (runtime != empty_runtime) { # a non temporary document
            var free_nids := empty_bat;
            if (isolate) { # new writable empty bats
                free_nids := dsk.fetch(PRE_NID).uselect(oid_nil).access(BAT_WRITE);
                if ((free_nids.count() = 0) and (free_nids.htype() = void)) {
                  free_nids.seqbase(0@0);
                }
                ins := bat(oid,oid);
                del := bat(oid,oid);
                page_ws := bat(oid,lng);
                attr_ws := bat(oid,lng);
            }
            # insert new index
            runtime.insert(lock_nil,free_nids);
            runtime.insert(lock_nil,page_ws);
            runtime.insert(lock_nil,attr_ws);
            runtime.insert(lock_nil,idx);
            runtime.insert(lock_nil,ins);
            runtime.insert(lock_nil,del);

            # we retain the index sizes for cache control
            # it must be part of the runtime structure, protected by coll_lock
            # but where to store such a number?
            # the hack is to misuse the (unused) tail seqbase of unq
            reverse(unq).seqbase(oid(batsize(idx))); 
            runtime.insert(lock_nil,unq);
        }
    }
    if (isolate) { # copy ins/del for isolation
        ins := ins.copy().access(BAT_WRITE);
        del := del.copy().access(BAT_WRITE);
    }
    ws.fetch(QN_NID).append(idx);
    ws.fetch(QN_NID_INS).append(ins);
    ws.fetch(QN_NID_DEL).append(del);

    return cont;
}

# returns all other queries that have this collection open
PROC _ws_pinnedcoll(lng wsid,
                    str colname) : BAT[lng,lng]
{
    return colname_pins.reverse().ord_uselect(colname).reverse() # get the basic list of pins
                       .[abs]()                                  # shreds have negated numbers here, normalize
                       .ord_select(0LL,WS_MAXID).reverse()       # exclude artificial ws-es (MIL invoked commands)
                       .access(BAT_WRITE).delete(wsid)           # do not report self
                       .project(wsid).reverse();                           
}


PROC _ws_opencoll(lng wsid, 
                  oid coll_oid) : BAT[lock,bat]
{
    var colname := collection_name.find(coll_oid);
    var runtime := _runtime_get(colname);

    if (and(wsid,WSID_UPDATE) != 0LL) {
        # clean up the query change lists (pages, attributes) by removing no longer overlapping queries
        if (count(runtime) > RT_ATTR_WS) {
            var page_ws := runtime.fetch(RT_PAGE_WS);
            if (bit(count(page_ws))) {
                page_ws.delete(tdiff(page_ws, ws_overlaps_ws));
            }
            var attr_ws := runtime.fetch(RT_ATTR_WS);
            if (bit(count(attr_ws))) {
                attr_ws.delete(tdiff(attr_ws, ws_overlaps_ws));
            }
        }

        # all other queries using colname now constitute new dependencies
        var dep := _ws_pinnedcoll(wsid, colname);
        ws_overlaps_ws.insert(dep);           # A overlaps B
        ws_overlaps_ws.insert(reverse(dep));  # B overlaps A (overlapping is reflexive)
    }

    # index memory control, done when a persistent collection is opened for the first time  
    if ((coll_oid >= DOCID_MIN) and (count(runtime) <= RT_QN_NID)) {
        # check sizes of all indices, stuffed in the seqbase of the UNQ bats
        var indices := [count](reverse(colname_runtime).mirror()).ord_uselect(RT_QN_NID_UNQ, int_nil);
        if (bit(count(indices))) {
            var totsize := [fetch](reverse(indices), RT_QN_NID_UNQ).[reverse]().[seqbase]().[lng]().sum();
            if (totsize > (mem_maxsize()/4LL)) {
                colname_runtime.delete(); # flush everything!
                runtime := _runtime_get(colname);
            }
        }
    }
    return runtime;
}


PROC ws_opencoll(BAT[void,BAT] ws,
                 BAT[str,bat] docBAT, 
                 str name, oid coll_oid) : oid
{
    var err, cont, coll_lock, runtime := empty_runtime;

    if (coll_oid >= DOCID_MIN) {
         lock_set(pf_short);
         err := CATCH(coll_lock := reverse(runtime := _ws_opencoll(ws_id(ws), coll_oid)).fetch(RT_LOCK_FREELIST));
         lock_unset(pf_short);
         if (not(isnil(err))) ERROR(err);

         lock_set(coll_lock); # never lock a collection inside the short lock
    }
    err := CATCH(cont := __ws_opencoll(ws, runtime, docBAT, name, coll_oid));
    if (coll_oid >= DOCID_MIN) {
        lock_unset(coll_lock); # release lock acquired for updatable bats
    }
    if (not(isnil(err))) ERROR(err);

    return cont;
}


@+ Collection Free-Lists and Indexing

These run-time structures are available in the colname_runtime meta 
BAT[str,bat]. For non-loaded collections, this BAT does not contain
any data. It only gets an entry the first time a collection is loaded.
Currently, this entry remains RAM resident from then on.

The runtime-BATs are BAT[lock,bat]s, in which order does matter. We fetch
BUNs by position using RT_* constants. The idea is to store per
collection a number of specific locks and index structures (BATs).

  fetch constant   runtime tuple 
  ================ ==========
0 RT_LOCK_FREELIST [lock,bat] 
                   the lock and a BAT with a list of free page ids.
1 RT_NID_FREELIST  [lock,bat] 
                   nil lock and a BAT with a list of free NIDs
2 RT_QN_NID        [nil, bat] 
                   the main BAT[oid,oid] object shared by all concurrent queries
3 RT_QN_NID_INS    [nil, bat] 
                   a private BAT[oid,oid] with all nodes that got this QN  during this query
4 RT_QN_NID_DEL    [nil, bat] 
                   a private BAT[oid,oid] with all nodes that no longer have this QN since this query.
5 RT_QN_NID_UNQ    [nil, bat] 
                   a BAT[oid,void] list of QNs which are interesting to index (i.e. MlogM < N).

The first entry head holds a collection lock (coll_lock, in much of the
MIL code). It is used to guard the master BAT images, while isolated
copies are created for read-queries. Update-queries and shred-docs
acquire this lock when committing resp. extending these master bats. 

The first entry tail holds a page-free list.
The second entry tail holds a NID-free list.
Both are used when a document is being extended by an update query.

@- QN_NID index

The QN_NID index uses the collection lock for all its maintenance and
query actions. The bulk of the data is in the shared QN_NID master bat (thus 
taking coll_lock is required when accessing it).  The QN_NID index does not 
use any additional locks, so the other head values are nil.

The QN_NID index is a dynamic, adaptive non-persistent index on NSLOC that
can deliver NID candidate lists. These NIDs must be translated into RIDs
(leftfetchjoin), then swizzled, then (finally) sorted, in order to serve
as input for loop-lifted staircase join (SCJ).

As sorting is on the menu always, the length of the candidate list M
should be small wrt the document size N (i.e. MlogM < N), otherwise the whole
purpose of indexing is defeated and a loop-lifted staircase join that does
a full O(N) scan is more efficient.

Thus, the idea is to solely index those QN items that are small. For this
purpose the shredder now keeps statistics on M in QN_HISTOGRAM.
Notice that in incremental shreds, the decision which qnames to index 
is made on the first document. With incremental shreds, qnames that were 
kept out of the index will stay out, even if they turn out to be frequent 
in ater shredded documents. Thi is necessary because *if* the index
contains info about a qn, it should be complete info.

The index is non-persistent as in update scenarios it may be big and is 
not ordered, which would make checkpointing it expensive. Now our checkpoint
costs are in the order of the updated volume (the checkpointed index cost
would be  in the order of the document collection, instead).
Therefore, it is stored in the runtime-BAT, reachable for new queries
via the colname_runtime meta-BAT.

Isolation in the QN_NID index is provided by committing in the _INS and _DEL 
master bats, which are not seen by any concurrent queries. If there are no 
concurrent queries, _INS and _DEL are flushed with the new changes into the 
QN_NID master.
@mil
# get a handle to the runtime-BAT (and create it if not there yet)
PROC _runtime_get(str colname) : BAT[lock,bat] 
{
    if (not(colname_runtime.exist(colname)))
        colname_runtime.insert(colname, bat(lock,bat).insert(lock_create(),empty_bat));
    return colname_runtime.find(colname);
}


# double-underscore __X() means we must have the RT_LOCK_FREELIST of this collection

# this computes a new QN_NID index for a suffix of the PRE-table
PROC __runtime_index(BAT[void,oid] nid, 
                     BAT[void,chr] knd, 
                     BAT[void,oid] prp, 
                     BAT[oid,void]  unq, 
                     oid pre, bit updatable) : BAT[oid,oid] 
{
    # compute the index bat for all nodes of the document from 'pre' on
        knd := knd.reverse().ord_select(pre,oid_nil).reverse(); # limit to a certain pre-range
    var idx := knd.ord_uselect(ELEMENT).mirror();   # get [pre,pre] (some false non-ELEM hits)
        idx := idx.leftfetchjoin(prp);              # get [pre,qn], in pre-order
        idx := reverse(idx.leftjoin(unq.mirror())); # get [qn,pre], in pre-order
        idx := idx.leftfetchjoin(nid);              # [qn,nid] still in pre-order
    if (updatable) 
        (idx := idx.access(BAT_WRITE)).accbuild("hash");
    else
        idx := idx.ssort().access(BAT_READ);        # [qn,nid] now lexico-ordered (thanks to stable-sort)
    return idx; # [qn,nid]
}

# worker function to handle inserts and deletes in the index
PROC __runtime_maintain(lng wsid, 
                        str colname, 
                        BAT[lock,bat] runtime, 
                        BAT[oid,oid] ins, 
                        BAT[oid,oid] del,
                        BAT[void,oid] delpages) : void
{
    var others := colname_pins.reverse().ord_uselect(colname).access(BAT_WRITE).delete(wsid);
    var totsize;
    if (count(others) > 0) {
        totsize := lng(runtime.fetch(RT_QN_NID_UNQ).reverse().seqbase()) + batsize(ins) + batsize(del);
        runtime.fetch(RT_QN_NID_INS).insert(ins);
        runtime.fetch(RT_QN_NID_DEL).insert(del);
    } else {
        # coast is clear, unite als ins, all del and apply them to the master
        ins := runtime.fetch(RT_QN_NID_INS).insert(ins);
        del := runtime.fetch(RT_QN_NID_DEL).insert(del);
        var idx := runtime.fetch(RT_QN_NID);
        idx.insert(ins).deleteBuns(del);
        ins.delete();
        del.delete();
        totsize := batsize(idx);
    }
    # store the new size in the UNQ seqbase
    runtime.fetch(RT_QN_NID_UNQ).reverse().seqbase(oid(totsize));
    
    # mark the region index invalid
    # for now, we don't try to maintain it over updates
    # any subsequent queries need to first recreate the index
    runtime.replace(RT_REGION_PRE_LOCK, empty_bat);
    runtime.replace(RT_REGION_START_LOCK, empty_bat);
    runtime.replace(RT_REGION_END_LOCK, empty_bat);

    runtime.fetch(RT_LOCK_FREELIST).reverse().append(delpages);
}

# used by shred: incremental shred on an already index document must maintain it (i.e. add new nodes)
PROC __runtime_addchunk(lng wsid, 
                        str colname, 
                        BAT[lock,bat] runtime, 
                        BAT[void,oid] nid, 
                        BAT[void,chr] knd, 
                        BAT[void,oid] prp, 
                        oid pre,
                        bit updatable) : void 
{
    if (count(runtime) > RT_QN_NID) { # only maintain if the index is instantiated now anyway
        var idx := __runtime_index(nid, knd, prp, runtime.fetch(RT_QN_NID_UNQ), pre, updatable);
        __runtime_maintain(wsid, colname, runtime, idx, empty_bat, empty_bat);
    }
}


PROC __runtime_lookup(BAT[lock,bat] runtime,
                      BAT[oid,oid] qn_ids) : bat[void,oid] 
{
    var res, valid := false;
    if (count(runtime) > RT_QN_NID) { 
        # do lookup using the index
        var ins, del, idx := runtime.fetch(RT_QN_NID).reverse();
        if (count(qn_ids) = 1) {
            var qn_id := qn_ids.fetch(0);
            res := idx.select(qn_id);
            ins := runtime.fetch(RT_QN_NID_INS).select(qn_id);
            del := runtime.fetch(RT_QN_NID_DEL).select(qn_id);
            valid := bit(count(res) + count(ins) + count(del));
        } else {
            res := idx.join(qn_ids);
            ins := runtime.fetch(RT_QN_NID_INS).join(qn_ids);
            del := runtime.fetch(RT_QN_NID_DEL).join(qn_ids);
            valid := (count(qn_ids.tdiff(res).tdiff(ins).tdiff(del)) = 0);
        }
        if (bit(count(ins) + count(del))) {
            # avoid doing this when ins/del are empty: res maybe a view on idx (readonly case)
            res := res.access(BAT_WRITE).insert(ins).deleteBuns(del).access(BAT_READ);
        } 
    }
    if (not(valid)) ERROR("index_lookup: qn_nid not indexed");
    return res;
}

PROC __runtime_newpage(BAT[lock,bat] runtime) : oid 
{
    var free_pages := runtime.fetch(RT_LOCK_FREELIST);
    var i := count(free_pages);
    
    # re-use a page from the list; or -if empty- append a new page
    if (i > 0) {
        last_pid := reverse(free_pages).fetch(i - 1);
        free_pages.delete(last_pid);
        return last_pid;
    }
    return oid_nil;
}

PROC __runtime_newnids(BAT[lock,bat] runtime, int cnt) : BAT[oid,void]
{
    var free_nids := runtime.fetch(RT_NID_FREELIST);
    var i := count(free_nids);
    
    # re-use a page from the list; or -if empty- append a new page
    if (i > 0) {
        var ret := free_nids.slice(i - cnt, i - 1).copy();
        free_nids.delete(ret);
        return ret;
    }
    return bat(oid,void);
}


@- exported runtime support API 

ws_lookup     - lookup nids by qn id
ws_precommit  - detect conflicts with overlapping queries that committed already, isolate concurrent queries
ws_postcommit - maintain indices after updates
ws_newpage    - allocate a new page, during an update
ws_newnids    - allocate a new nids, during an update
@mil
# proc to call from the SCJ with nsloc test: acquire locks and get a candidate list using the index
PROC ws_lookup(BAT[void,bat] ws, 
               oid cont, 
               BAT[oid,oid] qn_ids) : bat[void,oid] 
{
    if (count(qn_ids) = 0) return empty_bat; # unknown qnames => empty result

    var colname := ws.fetch(CONT_NAME).fetch(cont);
    var runtime := ws.fetch(CONT_RUNTIME).fetch(cont);
    var coll_lock := reverse(runtime).fetch(RT_LOCK_FREELIST);

    # get the lock and runtime inside the short lock
    lock_set(coll_lock);
    var res, err := CATCH(res := __runtime_lookup(runtime, qn_ids));
    lock_unset(coll_lock);
    if (not(isnil(err))) ERROR(err);

    # SCJ must catch error and use sequential post-filter instead.
    return res.hmark(oid_nil);
}

# find node pre numbers by ID (/NID) or IDREF.
# currently does not use a shared index (that needs locking), but in the future may do so
#
# INPUT TABLE oid iter |oid  item|int kind|int cont|str tokens
#             a single-shaped table, but each of them (except iter) may be constant 
#
# OUTPUT [key,NID], where key is the key of the input table     
PROC ws_findnodes(BAT[void,bat] ws, 
                  int ws_attr, 
                  BAT[void,oid] iter, any item, any kind, any cont, any tokens) : BAT[oid,oid] 
{
    # get root nids, which identify the XML fragment in which we must look
    var root := get_root(ws, item, kind, cont).mposjoin(cont, ws.fetch(PRE_NID));

    # expand the token list by splitting on spaces, and expand split_root and split_cont with it
    var split_tokens := tokens.[normSpace]().materialize(iter).ll_tokenize(iter.project(" "));
    var base_map     := split_tokens.hmark(0@0);
        split_tokens := split_tokens.tmark(0@0);
    var split_root   := base_map.leftfetchjoin(root); # may stay constant
    var split_cont   := base_map.leftfetchjoin(cont).materialize(base_map);

    # separate numbers (i.e. nids) from string-tokens (only for ID lookups)
    var bak_tokens   := split_tokens;
    var split_nids   := bat(oid,oid);
    if (ws_attr = ID_NID) {
        split_nids   := [oid](bak_tokens);
        var split_sel:= split_nids.ord_uselect(oid_nil).mirror();
        split_tokens := split_sel.leftfetchjoin(split_tokens);
        split_root   := split_sel.leftfetchjoin(split_root); # may stay constant
        split_nids   := split_nids.ord_select(oid_nil,oid_nil);
    }

    # prefix string-tokens with the root nid (for correct treatment of multi-document collections)
    split_tokens := [+]([+]([str](split_root), "_"),  split_tokens);

    # process all containers one-by-one, putting [split,pre]-s into the result 
    var result   := bat(oid,oid,count(split_tokens));
    var cont_unq := cont.tunique();
    cont_unq@batloop () {
        var idX_nid := ws.fetch(ws_attr).fetch($h);
        var nid_rid := ws.fetch(NID_RID).fetch($h);
        var map_pid := ws.fetch(MAP_PID).fetch($h);
        var part := reverse(split_cont.ord_uselect($h).mirror().leftfetchjoin(base_map));

        result.insert(part.leftjoin(split_tokens).leftjoin(idX_nid).leftfetchjoin(nid_rid).[swizzle](map_pid));
        if (ws_attr = ID_NID) 
            result.insert(part.leftjoin(split_nids).leftfetchjoin(nid_rid).[swizzle](map_pid));
    }

    # sort on iter|cont|pre and eliminate duplicates
    var srt_base:= result.access(BAT_READ).hmark(0@0).tsort(); 
    var id_srt  := srt_base.hmark(0@0);
    var id_base := srt_base.tmark(0@0);
    var id_pre  := id_srt.leftfetchjoin(result.tmark(0@0));
    var id_cont := id_base.leftfetchjoin(cont);
    var id_iter := id_base.leftfetchjoin(iter);
    assert_order(id_iter); # base was ordered and iter was ordered 
    var id_num  := id_iter.CTrefine(id_cont).CTrefine(id_pre);
    var id_unq  := reverse(kunique(reverse(id_num))); # merge double-elim
    var srt_unq := reverse(reverse(id_unq).leftfetchjoin(id_srt));

    return result.fetch(srt_unq); # map back to [base,pre] result
}

PROC _ws_coll_isolate(BAT[void,bat] ws,
                      str colname,
                      BAT[void,oid] ancestor_nid,
                      BAT[void,oid] modified_nid,
                      BAT[void,oid] modified_page,
                      BAT[void,oid] modified_attr) : void 
{
    # get columns of a concurrent query (ws)
    var cont      := ws.fetch(CONT_NAME).reverse().find(colname);
    var attr_own  := ws.fetch(ATTR_OWN).fetch(cont);
    var attr_qn   := ws.fetch(ATTR_QN).fetch(cont);
    var attr_prop := ws.fetch(ATTR_PROP).fetch(cont);
    var pre_size  := ws.fetch(PRE_SIZE).fetch(cont);
    var pre_level := ws.fetch(PRE_LEVEL).fetch(cont);
    var pre_prop  := ws.fetch(PRE_PROP).fetch(cont);
    var pre_kind  := ws.fetch(PRE_KIND).fetch(cont);
    var pre_nid   := ws.fetch(PRE_NID).fetch(cont);
    var nid_rid   := ws.fetch(NID_RID).fetch(cont);
    var map_pid   := ws.fetch(MAP_PID).fetch(cont);

    # translate nid-s to that query's pre-s
    var ancestor_pre := ancestor_nid.leftfetchjoin(nid_rid).[swizzle](map_pid);
    var modified_pid := modified_page.leftfetchjoin(map_pid);

    # isolate the affected positions
    pre_size.isolate(ancestor_pre, false);
    pre_size.isolate(modified_pid, true);
    pre_level.isolate(modified_pid,true);
    pre_prop.isolate(modified_pid, true);
    pre_kind.isolate(modified_pid, true);
    if (map_pid.ttype() = oid) {
        pre_nid.isolate(modified_pid, true);
        nid_rid.isolate(modified_nid, false);
    }
    attr_own.isolate(modified_attr, false);
    attr_qn.isolate(modified_attr, false);
    attr_prop.isolate(modified_attr, false);
}


PROC ws_precommit(BAT[void,BAT] ws,
                  oid cont,
                  BAT[void,oid] modified_page,
                  BAT[void,oid] ancestor_nid,
                  BAT[void,oid] modified_nid,
                  BAT[void,oid] modified_attr) : void
{
    var wsid := ws_id(ws);
    var colname := ws.fetch(CONT_NAME).fetch(cont);
    var runtime := ws.fetch(CONT_RUNTIME).fetch(cont);
    var page_ws := runtime.fetch(RT_PAGE_WS);
    var attr_ws := runtime.fetch(RT_ATTR_WS);
 
    # thanks to coll_lock, no new cont users will appear for the moment
    # also get pf_free, to block processing of ending queries, to achieve total stability
    coll_lock_set(ws, cont); 
    lock_set(pf_free);

    # concurrency control: abort conflicting queries
    var conflict1 := join(modified_page,page_ws);
    if (bit(count(conflict1))) 
        ERROR("conflicting update at page %d from ws=%d (%d such errors in total)", 
              modified_page.find(reverse(conflict1).fetch(0)), 
              conflict1.fetch(0), count(conflict1));

    var conflict2 := join(modified_attr,attr_ws);
    if (bit(count(conflict2))) 
        ERROR("conflicting update at page %d from ws=%d (%d such errors in total)", 
              modified_attr.find(reverse(conflict2).fetch(0)), 
              conflict2.fetch(0), count(conflict2));

    # insert pages in modified page list (similar for attr ids)
    page_ws.insert(reverse(modified_page).project(wsid));
    attr_ws.insert(reverse(modified_attr).project(wsid));

    # let's now establish the current set of queries (ws-s) that were already using this collection
    lock_set(pf_short);
    var other_ws, err := CATCH(other_ws := [ws_bat](_ws_pinnedcoll(wsid, colname)).tmark(0@0));

    # isolate these working sets against our intended updates. 
    # copying pages can take time, thus we introduced pf_free: it allows to do the isolation without claiming pf_short
    lock_unset(pf_short);
    if (isnil(err)) {
        if (other_ws.count() > 0) {
            err := CATCH([_ws_coll_isolate](other_ws, colname, 
                                            const ancestor_nid, 
                                            const modified_nid, 
                                            const modified_page, 
                                            const modified_attr));
        }
    }
    lock_unset(pf_free);
    if (not(isnil(err))) ERROR(err);
}


# proc to call from the update code: acquire locks and add new nodes and remove deleted ones
PROC ws_postcommit(BAT[void,BAT] ws,
                   oid cont,  
                   BAT[oid,oid] ins, 
                   BAT[oid,oid] del,
                   BAT[void,oid] delpages) : void 
{
    var colname := ws.fetch(CONT_NAME).fetch(cont);
    var runtime := ws.fetch(CONT_RUNTIME).fetch(cont);

    # maintain the index while holding the collection lock
    var err := CATCH(__runtime_maintain(ws_id(ws), colname, runtime, ins, del, delpages));
    if (not(isnil(err))) ERROR(err);

    coll_lock_unset(ws, cont); # release X-access to the masters (after the commit phase)
}


# append a new page. when the page is at the end; we 
PROC ws_newpage(BAT[void,BAT] ws,
                oid cont) : oid 
{
    var wsid := ws_id(ws);
    var runtime := ws.fetch(CONT_RUNTIME).fetch(cont);
    var coll_lock := reverse(runtime).fetch(RT_LOCK_FREELIST);

    # if there is a free page, then this is easy
    lock_set(coll_lock);
    var page_id := 0@0, err := CATCH(page_id := __runtime_newpage(runtime));
    lock_unset(coll_lock);

    if (isnil(err) and isnil(page_id)) {
        # no free page: we must physically extend the rid_* table 
        var colname := ws.fetch(CONT_NAME).find(cont);

        # get the shredlock, as we need append-exclusive access 
        lock_set(pf_short);
        err := CATCH(_shredlock_set(colname, wsid));
        lock_unset(pf_short);

        if (isnil(err)) {
            var rid_size  := ws.fetch(_RID_SIZE).find(cont);
            var rid_level := ws.fetch(_RID_LEVEL).find(cont);
            var rid_prop  := ws.fetch(_RID_PROP).find(cont);
            var rid_kind  := ws.fetch(_RID_KIND).find(cont);
            var rid_nid   := ws.fetch(_RID_NID).find(cont);
            var map_pid   := ws.fetch(_MAP_PID).find(cont);
            var rid_cnt   := count(rid_size);
            var new_pid   := 1 + ((rid_cnt - 1) >> REMAP_PAGE_BITS);
            var last_pid  := new_pid + (new_pid/16);

            var empty_page_chr := empty_page.project(chr_nil);
            var empty_page_oid := empty_page.project(oid_nil);

            # take care to fill out the last page (should happen only for small documents)
            var lastpage_size := and(lng(rid_cnt),REMAP_PAGE_MASK);
            if (lastpage_size > 0LL) {
                rid_size.append(empty_page.slice(lastpage_size,REMAP_PAGE_SIZE), true);
                rid_level.append(empty_page_chr.slice(lastpage_size,REMAP_PAGE_SIZE), true);
                rid_kind.append(empty_page_chr.slice(lastpage_size,REMAP_PAGE_SIZE), true);
                rid_prop.append(empty_page_oid.slice(lastpage_size,REMAP_PAGE_SIZE), true);
                rid_nid.append(empty_page_oid.slice(lastpage_size,REMAP_PAGE_SIZE), true);
            }
            page_id := oid(new_pid);

            # append (possibly multiple) new pages. We directly allocate 6% (1/16) free space
            while(new_pid <= last_pid) {
                rid_size.append(empty_page, true);
                rid_level.append(empty_page_chr, true);
                rid_kind.append(empty_page_chr, true);
                rid_prop.append(empty_page_oid, true);
                rid_nid.append(empty_page_oid, true);
                map_pid.append(oid_nil); # add page as unused to map_pid
                new_pid :+= 1;
            }

            lock_set(pf_short);
            err := CATCH(_shredlock_unset(colname, wsid));
            lock_unset(pf_short);

            # add extra created pages to the freelist
            new_pid := int(page_id);
            if (isnil(err) and (new_pid < last_pid)) {
                var pages_free := reverse(runtime.fetch(RT_LOCK_FREELIST));
                var newpids := bat(void,oid);
                while((new_pid :+= 1) < last_pid) newpids.append(oid(new_pid)); 
                revert(newpids); # put in reverse order to give the pages out in order 
                lock_set(coll_lock);
                err := CATCH(pages_free.insert(newpids));
                lock_unset(coll_lock);
            }
        }
    }
    if (not(isnil(err))) ERROR("ws_newpage: " + err);
    return page_id;
} 

# return free NID values in the head
PROC ws_newnids(BAT[void, BAT] ws,
                oid cont,
                int cnt) : BAT[oid,void]
{
    var wsid := ws_id(ws);
    var runtime := ws.fetch(CONT_RUNTIME).fetch(cont);
    var coll_lock := reverse(runtime).fetch(RT_LOCK_FREELIST);

    lock_set(coll_lock);
    var newnids := empty_bat, err := CATCH(newnids := __runtime_newnids(runtime, cnt));
    lock_unset(coll_lock);

    if (isnil(err) and bit(cnt :-= count(newnids))) {
        # not enough free nids page: we must physically extend the nid_rid table 
        var colname := ws.fetch(CONT_NAME).find(cont);

        # get the shredlock, as we need append-exclusive access  
        lock_set(pf_short);
        err := CATCH(_shredlock_set(colname, wsid));
        lock_unset(pf_short);

        if (isnil(err)) {
            var nid_rid := ws.fetch(_NID_RID).find(cont);
            var nid_cnt := count(nid_rid);
            var nid_tgt := nid_cnt + cnt + (nid_cnt/16);
            var nid_off := nid_cnt;
            var empty_page_oid := empty_page.project(oid_nil);
            var pgsz := int(REMAP_PAGE_SIZE);
            if (nid_tgt < pgsz) {
                # extend nid column of small documents by the amount needed, not more
                nid_rid.append(empty_page_oid.slice(1, nid_tgt - nid_cnt), true);
                nid_cnt := nid_tgt;
            } else while(nid_cnt < nid_tgt) {
                # append a whole number of pages
                nid_rid.append(empty_page_oid, true);
                nid_cnt :+= pgsze;
            }
            newnids := newnids.access(BAT_WRITE);
            reverse(newnids).append(reverse(nid_rid.slice(nid_off,(nid_off :+= cnt) - 1)));

            lock_set(pf_short);
            err := CATCH(_shredlock_unset(colname, wsid));
            lock_unset(pf_short);

            if (isnil(err) and (nid_cnt > nid_off)) {
                var delta := reverse(nid_rid.slice(nid_off,nid_cnt - 1));
                # put nids in reverse order in the freelist, so they are given out in order
                delta := delta.copy().access(BAT_WRITE).revert(); 

                # add extra created NIDs to the freelist
                lock_set(coll_lock);
                err := CATCH(reverse(runtime.fetch(RT_NID_FREELIST)).append(delta));
                lock_unset(coll_lock);
            }
        }
    }
    if (not(isnil(err))) ERROR("ws_newpage: " + err);
    return newnids;
} 




@- adding documents

The XQuery call fn:doc() is translated into ws_doc() MIL proc. It is optimized
to be able to handle a large collection of document names that all reside
in the same collection very quickly, i.e. in loop-lifted, bulk fashion.
When multiple collections are involved, things go one-at-a-time, thus more slowly. 

The decision process which documents are new and must be shredded (and x-locked)
and which are available (and need only pinning) is done inside the locked phase of
wd_doc(). Care was taken to allow large sets of documents that reside in a single
collection to be opened quickly (i.e. using the proper bulk primitives).
@mil
PROC _ws_open(lng wsid,
              BAT[void,str] idx_names, 
              BAT[void,str] idx_filenames, 
              BAT[void,timestamp] idx_timestamps, # inout param
              BAT[void,str] idx_colname,    # out param  
              BAT[void,oid] idx_coll,       # out param
              BAT[void,oid] idx_doc) : void # out param
{
    # get all the doc-id, coll-id's and collection names of known documents. The ones with nil-tail are unknown.
    idx_doc.append(idx_names.outerjoin(reverse(doc_name)));
    idx_doc.replace(idx_doc.ord_uselect(oid_nil).mirror().leftfetchjoin(idx_names).join(reverse(doc_location)));
    idx_coll.append(idx_doc.outerjoin(doc_collection));
    idx_colname.append(idx_coll.outerjoin(collection_name));

    # of the non-nil doc-ids, try to get non-nil timestamps
    var idx_lim := idx_doc.ord_select(oid_nil,oid_nil).leftjoin(doc_timestamp).ord_select(timestamp_nil,timestamp_nil);
    var sel_lim := idx_lim.tmark(0@0);
    var sel_idx := idx_lim.hmark(0@0);

    # check the timestamps
    var sel_del := [>](sel_idx.leftfetchjoin(idx_timestamps), sel_lim).ord_uselect(true);
    if (count(sel_del) > 0) # delete stale documents
	del_doc_base(bit_nil,mirror(sel_del).leftfetchjoin(sel_idx).leftfetchjoin(idx_names),false);

    # for not-yet-cached URIs: get lifetime from uri_lifetime BAT
    var idx_idx := idx_doc.ord_uselect(oid_nil).mirror();
    var idx_ts := idx_idx.leftfetchjoin(idx_filenames).ord_uselect(str_nil).mirror().leftfetchjoin(idx_timestamps);
    idx_ts@batloop() { # URI (filename = nil)
        var b := [startsWith](idx_names.find($h), mirror(uri_lifetime)).uselect(true);
        var lifetime := lng(nil);
        if (b.count() > 0) {
            var matchlen := [length](mirror(b));
            lifetime :=  *(1000LL, uri_lifetime.find(matchlen.reverse().find(matchlen.max())));
        }
        # this may set ts to nil; such URIs are never cached (and thus do not need to be persistent)
        idx_timestamps.replace($h, add($t,lifetime));
    }

    # pin all collections of already available documents (once)
    colname_pins.insert(idx_doc.join(doc_collection).join(collection_name).tunique().project(wsid)); 
}

# this function processes only URIs still unknown to this ws; returns OPEN ids (point into OPEN_* ws entries) 
PROC ws_open(BAT[void,BAT] ws,
             BAT[void,str] idx_names) : BAT[void,oid]
{
    var idx_filenames := copy(idx_names).access(BAT_WRITE);
    var open_docid    := ws.fetch(OPEN_DOCID);
    var open_name     := ws.fetch(OPEN_NAME);
    var open_cont     := ws.fetch(OPEN_CONT);
    var wsid := ws_id(ws);

    # create filenames from URIs (str_nil if not a filename-URI)
    { var selidx_isurl  := [search](idx_names, "://").ord_select(0,int_nil);
      var selidx_match  := selidx_isurl.ord_uselect(4).mirror().leftfetchjoin(idx_names);
      var selidx_isfile := [startsWith](selidx_match, "file").ord_uselect(true).mirror().leftfetchjoin(idx_names).[string](7);
      var selidx_isFILE := [startsWith](selidx_match, "FILE").ord_uselect(true).mirror().leftfetchjoin(idx_names).[string](7);
      idx_filenames.replace(selidx_isurl.project(str_nil)).replace(selidx_isfile).replace(selidx_isFILE).access(BAT_READ); }

    # get the actual timestamp of the document cached in the database. 
    var idx_timestamps := idx_filenames.project(current_timestamp()).access(BAT_WRITE);
    idx_timestamps.replace([lastmod_time](idx_filenames.select(str_nil,str_nil)).select(timestamp_nil,timestamp_nil));

    # get the lock and pin all existing documents; return info from meta tables in (idx_colname, idx_coll, idx_doc)
    var idx_colname := bat(void,str).seqbase(0@0);
    var idx_coll    := bat(void,oid).seqbase(0@0);
    var idx_doc     := bat(void,oid).seqbase(0@0);
    lock_set(pf_short);
    var err := CATCH(_ws_open(wsid, idx_names, idx_filenames, idx_timestamps, idx_colname, idx_coll, idx_doc));
    lock_unset(pf_short);
    if (not(isnil(err))) ERROR(err);

    # add all available but not-yet-present collections to the ws
    var coll_colname := reverse(idx_coll.select(oid_nil,oid_nil).tdiff(ws.fetch(CONT_COLL))).kunique().leftfetchjoin(idx_colname);
    coll_colname@batloop() {
        var docBAT := [bat]([+](str(int($h)), ws_dsk).reverse().mirror()); # get master bats
        ws_opencoll(ws, docBAT, $t, $h); # collections are loaded one-by-one
    }
    var idx_cont := idx_coll.outerjoin(reverse(ws.fetch(CONT_COLL))).access(BAT_WRITE);

    # all still unknown documents (if any) are shredded one-by-one into separate temporary collections
    var selidx_names := idx_doc.ord_uselect(oid_nil);
    if (bit(count(selidx_names))) {
        selidx_names  := selidx_names.mirror().leftfetchjoin(idx_names);
        var selidx_unq:= selidx_names.reverse().kunique().reverse();
        var commitBAT := bat(void,str);
        var docBAT    := bat(str,bat,count(selidx_unq));
        var locations := selidx_unq.tmark(0@0);
        var names     := [+]("::" + str(wsid) + "::",  locations);
        var colname   := names.fetch(0);
        var min_ts    := selidx_unq.mirror().leftfetchjoin(idx_timestamps).min();
        var docid_base:= oid(count(open_docid));
        var doCommit  := not(isnil(min_ts));
        var coll_oid  := shred_into_docBAT(docBAT, locations, names, colname, 
                                           oid_nil,       # create new collection
                                           empty_runtime, # no index to maintain 
                                           docid_base,    # transient docid
                                           lng(0),        # read-only (freespace=0)
                                           min_ts,        # until when to cache it
                                           doCommit,      # cache it persistently? 
                                           stream_nil, wsid); 
        var cont      := ws_opencoll(ws, docBAT, colname, coll_oid);
        if (doCommit) # persistent? (probably -- could have backed off -- should not matter)
            commitBAT.append([bbpname](docBAT).tmark(0@0));
        
        # commit the new collections 
        pf_checkpoint(commitBAT);
        lock_set(pf_short);
        doc_undo.delete(doc_undo.select(wsid)); # if these remain, ws_destroy() would remove the new documents
        lock_unset(pf_short);

        # set new colname, cont, and doc_oid
        idx_cont.replace(selidx_names.project(cont));
        idx_doc.replace(selidx_names.leftjoin(locations.seqbase(coll_oid).reverse()));
    }

    # add in bulk all documents to the ws (could be thousands of them!!)
    var selidx_doc   := idx_doc.tdiff(open_docid).reverse().kunique().reverse();
    var selidx_cont  := selidx_doc.mirror().leftfetchjoin(idx_cont);
    var selidx_names := selidx_doc.mirror().leftfetchjoin(idx_names);
    open_docid.append(selidx_doc);
    open_cont.append(selidx_cont);
    open_name.append(selidx_names);
    open_name.reverse().accbuild("hash");

    return idx_doc.leftjoin(reverse(open_docid)).tmark(0@0);
}

# fn:doc() support, optimized for loop-lifted execution (e.g. quickly open thousands of documents from a few collections)
PROC ws_opendoc(BAT[void,BAT] ws,
                BAT[void,str] idx_names) : BAT[oid,oid]
{
    var idx_open  := idx_names.outerjoin(reverse(ws.fetch(OPEN_NAME))).tmark(0@0);
    var new_names := idx_open.uselect(oid_nil).mirror().leftfetchjoin(idx_names.tmark(0@0));
    var new_open  := new_names.mark(0@0).leftfetchjoin(ws_open(ws, new_names.tmark(0@0)));
    idx_open := idx_open.copy().access(BAT_WRITE).replace(new_open).access(BAT_READ);

    # return the resulting [rootpre,cont] combinations
    var idx_cont := idx_open.leftfetchjoin(ws.fetch(OPEN_CONT));
    var idx_doc  := idx_open.leftfetchjoin(ws.fetch(OPEN_DOCID));
    var idx_root := idx_cont.project(oid_nil).access(BAT_WRITE);
    tunique(idx_cont)@batloop() {
        var frag_root  := ws.fetch(FRAG_ROOT).fetch($h);
        var nid_rid    := ws.fetch(NID_RID).fetch($h);
        var map_pid    := ws.fetch(MAP_PID).fetch($h);
        var selidx_nid := mirror(idx_cont.ord_uselect($h)).leftfetchjoin(idx_doc).leftjoin(frag_root);
        idx_root.replace(selidx_nid.leftfetchjoin(nid_rid).[swizzle](map_pid));
    }
    return reverse(idx_root).leftfetchjoin(idx_cont);
}

# fn:collection(), get document nodes of all documents in a collection
PROC ws_collection(BAT[void,BAT] ws, BAT[any,str] nms, BAT[void,oid] map) : BAT[oid,oid]
{
    pflock_meta(ws_id(ws)); # stop all concurrent shred_doc/del_doc activities
    lock_set(pf_short);
    var idx_names, err := CATCH(idx_names := nms.tmark(0@0).leftjoin(reverse(collection_name)).leftjoin(reverse(doc_collection)).leftjoin(doc_name)); 
    lock_unset(pf_short);
    if (not(isnil(err))) ERROR(err);
    map.append(idx_names.hmark(0@0)); # map = SECOND RESULT VALUE
    return ws_opendoc(ws, idx_names.tmark(0@0)); 
}

# fn:collections(), get all collection *names*
PROC ws_collections(BAT[void,BAT] ws) : BAT[oid,str]
{
    pflock_meta(ws_id(ws)); # stop all concurrent shred_doc/del_doc activities
    lock_set(pf_short);
    var res, err := CATCH(res := reverse(reverse(collection_name).project(0@0)));
    lock_unset(pf_short);
    if (not(isnil(err))) ERROR(err);
    return res;
}

# fn:documents(), get all document *names* in a collection
PROC ws_documents(BAT[void,BAT] ws, BAT[any,str] coll_nme) : BAT[void,str]
{
    pflock_meta(ws_id(ws)); # stop all concurrent shred_doc/del_doc activities
    lock_set(pf_short);
    var res, err := CATCH(res := coll_nme.tmark(0@0).leftjoin(reverse(collection_name)).leftjoin(reverse(doc_collection)).leftjoin(doc_name));
    lock_unset(pf_short);
    if (not(isnil(err))) ERROR(err);
    return res;
}

# fn:documents(), get all document *names* in a collection
PROC ws_documents(BAT[void,BAT] ws) : BAT[void,str]
{
    pflock_meta(ws_id(ws)); # stop all concurrent shred_doc/del_doc activities
    lock_set(pf_short);
    var res, err := CATCH(res := doc_name.tmark(0@0));
    lock_unset(pf_short);
    if (not(isnil(err))) ERROR(err);
    return res;
}


@- shredding documents

Documents are shredded one-at-a-time, even if we must shred a sequence of documents into the same
collection. It is implemented by shred_url(). Note that shred_url() adds the resulting
new document container to the BAT-of-BATs that is passed in as first parameter. If this
BAT-of-BATs already contains a document container, the XML document is added to this collection.

Some care is taken to give out unique document oids. The collection-oid is that of the first document
that belongs to it. The number is stored persistently (HACK) in a special bun in doc_collection.

The shred_doc_base() operator it depends on is made atomic by adding all new documents to a "doc_undo"
bat. Only if everything succeeds, the entries are removed from there. Otherwise, in ws_destroy(), 
all documents mentioned in "doc_undo" are deleted again. 
@mil
# update the doc_* and collection_* tables while holding the short lock
PROC _shred_into_docBAT(BAT[str,bat] docBAT, 
                        BAT[void,str] idx_location, 
                        BAT[void,str] idx_name, 
                        str colname, 
                        oid coll_oid, 
                        timestamp ts, 
                        lng wsid) : oid
{
    # get a new persistent doc id
    var docid_base := doc_collection.find(TEMP_DOC);
    var docid      := lng(docid_base);
    var docid_new  := docid + lng(count(idx_location));
    if (docid_new > lng(DOCID_MAX)) 
        ERROR("_shred_doc: out of document id's. Export all documents, and shred them into a new database\n");
    doc_collection.replace(TEMP_DOC, oid(docid_new));

    if (bit(count(doc_name.tintersect(idx_name)))) 
        ERROR("_shred_doc: document names should be globally unique\n");

    # determine the collection id for this doc
    if (isnil(coll_oid)) {
        coll_oid := docid_base;
        if (collection_name.texist(colname)) ERROR("_shred_doc: collection name should be globally unique\n");
        collection_name.insert(coll_oid, colname);
        collection_size.insert(coll_oid, sum([batsize](docBAT)));
        [persists]([rename](docBAT, [+](str(int(coll_oid)), mirror(docBAT))), true);
    } else {
        collection_size.replace(coll_oid, sum([batsize](docBAT)));
    }

    # all documents to the doc_* table
    var docid_location := idx_location.tmark(docid_base);
    var docid_name     := idx_name.tmark(docid_base);
    doc_name.insert(docid_name);
    doc_location.insert(docid_location);
    doc_timestamp.insert(docid_name.project(ts));
    doc_collection.insert(docid_name.project(coll_oid));
    if (not(colname.startsWith("::"))) doc_undo.insert(docid_name.project(wsid));

    return docid_base;
}

# finish the master bats while holding the collection lock
PROC __shred_into_docBAT(BAT[str,bat] docBAT, 
                         str colname, 
                         oid docid_base, 
                         BAT[lock,bat] runtime,
                         oid pre, 
                         bit updatable, 
                         lng wsid) : void
{
    # finish shred by setting the new (densely ascending doc_oids in FRAG_ROOT (in order)
    var root_frag := reverse(docBAT.fetch(FRAG_ROOT));
    root_frag.replace(root_frag.ord_uselect(TEMP_DOC).mark(docid_base), true);

    # index the new document(s)
    if (runtime != empty_runtime) 
      __runtime_addchunk(wsid, colname, runtime, docBAT.fetch(PRE_NID), docBAT.fetch(PRE_KIND), docBAT.fetch(PRE_PROP), pre, updatable);
}


# main shredder may shred many documents into a single collection
PROC shred_into_docBAT(BAT[str,bat] docBAT, 
                       BAT[void,str] location, 
                       BAT[void,str] name, 
                       str colname, 
                       oid coll_oid, 
                       BAT[lock,bat] runtime,
                       oid docid_base, 
                       lng pageFree, 
                       timestamp ts, 
                       bit doCommit, 
                       Stream s,
                       lng wsid) : oid
{
    var err := str_nil;
    var coll_lock := reverse(runtime).fetch(RT_LOCK_FREELIST);
    var pre := 0@0;
    if (count(docBAT) > 0) pre := oid(count(docBAT.fetch(PRE_SIZE))); 

    if (isnil(s)) { 
        # shred multiple documents into a single collection (maybe empty at first)
        [shred_url](const docBAT, location, pageFree, coll_lock);
    } else {
        # shred from a stream (a single document assumed here)
        shred_stream(docBAT, s, pageFree, coll_lock);
    }

    if (doCommit) {
      [save](docBAT); # make persistent documents clean on disk outside the locks

      lock_set(pf_short);

      # possibly back off if auto-caching documents gets us into meta-data locking trouble
      if (colname.startsWith("::")) doCommit := pflock_free(doCommit); 

      # add doc to the database locked
      if (doCommit) err := CATCH(docid_base := _shred_into_docBAT(docBAT, location, name, colname, coll_oid, ts, wsid));

      lock_unset(pf_short);
      if (not(isnil(err))) ERROR(err);
    }
    if (isnil(coll_oid)) 
        coll_oid := docid_base; # new collection got oid of first doc in it 

    # finish the shred (set doc_oids in FRAG_ROOT, and maintain the nsloc index)
    var protect := not(isnil(coll_lock));
    if (protect) lock_set(coll_lock); # never lock a collection inside the short lock
    err := CATCH(__shred_into_docBAT(docBAT, colname, docid_base, runtime, pre, >(pageFree,0LL), wsid));
    if (protect) lock_unset(coll_lock);
    if (not(isnil(err))) ERROR(err);

    return coll_oid;
}


PROC _shred_doc_base(BAT[oid,str] selidx_coll,
                     BAT[void,str] idx_names, 
                     BAT[void,str] idx_colnames, 
                     lng wsid) : BAT[oid,bat]
{
    # claim exclusive access to all collections
    var selidx_coll := reverse(reverse(idx_colnames).kunique().sort());
    [_shredlock_set](selidx_coll, wsid); 

    # now that we have access, check consistency
    var conflicts := mirror(reverse(idx_names)).join(reverse(doc_name));
    if (count(conflicts) > 0) {
        conflicts := conflicts.outerjoin(doc_collection).outerjoin(collection_name);
        ERROR("shred_doc: document %s already exists in collection %s (%d such errors)!\n", 
            reverse(conflicts).fetch(0), conflicts.fetch(0), count(conflicts));
    }

    # look up the locks and coll_oids while inside the short lock, and return these for later use
    [_runtime_get](selidx_coll);
    return reverse(mirror(reverse(idx_colnames)).outerjoin(reverse(collection_name))).outerjoin(colname_runtime);
}

PROC _shred_doc_cleanup(lng wsid, bit cleanup) : BAT[any,any]
{
    doc_undo.delete(doc_undo.select(wsid));
    if (cleanup) return _collection_cleanup(); # garbage collect empty collections
    return empty_bat;
}

PROC shred_doc_base(BAT[void,str] commitBAT,
                    BAT[void,str] idx_locations, 
                    BAT[void,str] idx_names, 
                    BAT[void,str] idx_colnames, 
                    BAT[void,lng] pageFrees, 
                    Stream s,
                    lng wsid) : void
{
    var pivot, err, nr := 0, cleanup := bit(count(commitBAT));
    var selidx_colname := idx_colnames;
    if (count(selidx_colname) > 0)
        selidx_colname := reverse(reverse(idx_colnames).kunique().sort());


    lock_set(pf_short);
    err := CATCH(pivot := _shred_doc_base(selidx_colname, idx_names, idx_colnames, wsid));
    lock_unset(pf_short);
    if (not(isnil(err))) ERROR(err);
    var idx_runtime := pivot.tmark(0@0);
    var idx_colloid := pivot.hmark(0@0);

    # collect IDs of new collections for the logger
    var newcoll := new(void, str, count(selidx_colname) * count(logger_bats)).seqbase(0@0);

    selidx_colname@batloop(){
        # process collections one-by one
        var colname  := $t;
        var coll_oid := idx_colloid.find($h);
        var runtime  := idx_runtime.find($h);
        var idx      := idx_colnames.ord_uselect(colname).hmark(0@0);  
        var percentage := pageFrees.find($h);
        var docBAT;

        if (isnil(coll_oid)) {
            docBAT := bat(str,bat,count(idx)); # new collection
        } else {
            docBAT := [bat]([+](str(int(coll_oid)), ws_dsk).reverse().mirror()); # append to existing 

        }
        # now shred all documents for one collection
        shred_into_docBAT(docBAT, 
                          idx.leftfetchjoin(idx_locations),
                          idx.leftfetchjoin(idx_names),
                          colname, coll_oid, runtime, oid_nil, percentage, timestamp_nil, true, s, wsid);

	if (isnil(coll_oid)) {
            # register new bats with the logger
	    newcoll.append([bbpname](logger_bats.join(docBAT)));
	}
        commitBAT.insert([bbpname](docBAT.tmark(oid_nil)));
    }
    # checkpoint the new bats
    if (pf_checkpoint(commitBAT)) {
        # remove the in-memory undo log; and trim collection
        lock_set(pf_short);
        err := CATCH(commitBAT := _shred_doc_cleanup(wsid, cleanup));
        lock_unset(pf_short);
        if (isnil(err)) CATCH(collection_cleanup(commitBAT)); 
    }

    if (count(newcoll) > 0) {
        lock_set(pf_wal);
        log_trans_start(pf_logger);
        [logger_add_bat](pf_logger, [bat](newcoll), newcoll);
        [log_bat_persists](pf_logger, [bat](newcoll), newcoll);
        log_trans_end(pf_logger);
        lock_unset(pf_wal);
    }
}


PROC shred_stream(Stream s,
                  str name,
                  str colname,
                  lng pageFree) : void
{
    var names := bat(void,str).append(name).access(BAT_READ).seqbase(0@0);
    var wsid := WS_MAXID + lng(clientid() + 1);
    var err := CATCH(shred_doc_base(bat(void,str), names, names, names.project(colname), names.project(pageFree), s, wsid));
    ws_free(wsid); 
    if (not(isnil(err))) ERROR(err);
}

@- deleting documents

To make document deletes atomic, we first just set the document names to nil in the
administrative interface and commit that (using a partial checkpoint). 

Collections without any non-nil document names are garbage-collected periodically.
This happens at start-up and at times when the system detects that no queries are 
running (this is triggered by the last leaving query in ws_destroy()).
@mil
PROC _del_doc_replace(BAT[oid,str] bak_locations, 
                      BAT[oid,str] bak_names) : void 
{
    doc_location.replace(bak_locations);
    doc_name.replace(bak_names);
}

PROC _del_doc(bit cachedOnly,  
              BAT[any,str] names, # dummy param iff not(isnil(cachedOnly)) 
              BAT[oid,str] bak_locations, 
              BAT[oid,str] bak_names) : void
{
    var del := doc_timestamp; # select all at first
    if (isnil(cachedOnly)) {
        del := reverse(names.outerjoin(reverse(doc_name)));
        if (del.exist(oid_nil)) {
            ERROR("_del_doc(%s): document not found in database (%d such errors)!\n", 
                                 names.find(del.find(oid_nil)), 
                                 count(reverse(del).uselect(oid_nil)));
        }
        del := kunique(del);
    } else if (cachedOnly) {
        del := del.uselect(timestamp_nil,timestamp_nil);
    } 
    del := del.project(str_nil);
    bak_locations.insert(mirror(del).join(doc_location));
    bak_names.insert(mirror(del).join(doc_name));
    _del_doc_replace(del, del);
}

PROC del_doc(bit cachedOnly, 
             BAT[any,str] names,
             bit pf_short_req) : BAT[void,str]
{
    var bak_locations := bat(oid,str);
    var bak_names := bat(oid,str);

    if (pf_short_req) lock_set(pf_short);
    var err := CATCH(_del_doc(cachedOnly, names, bak_locations, bak_names));
    if (not(isnil(err))) {
        var fatal := CATCH(_del_doc_replace(bak_locations, bak_names));
        if (not(isnil(fatal))) {
             printf("%s\n!ERROR: del_doc: in-memory recovery failed, Mserver must be restarted.\n", fatal);
             exit(); # recover *must must* succeed
        }
    }
    if (pf_short_req) lock_unset(pf_short);
    if (not(isnil(err))) ERROR(err);

    return bat(void,str).append("doc_name").append("doc_location");
}

PROC del_doc_base(bit cachedOnly, 
                  BAT[any,str] names,
                  bit pf_short_req) : void
{
    # do the work in memory
    var commitBAT := del_doc(cachedOnly, names, pf_short_req);

    # now here is our commit: checkpoint 2 bat descs and BBP.dir
    var ok := false;
    lock_set(pf_wal);
    CATCH(ok := subcommit(commitBAT));
    lock_unset(pf_wal);
    if (not(ok)) ERROR("XQDY0062: checkpoint failed, query aborted.\n");
   
    if (pf_short_req) {
        # try to remove empty collections (non-critical)
        lock_set(pf_short);
        var err := CATCH(commitBAT := _collection_cleanup());
        lock_unset(pf_short);
        if (isnil(err)) CATCH(collection_cleanup(commitBAT));
    }
}


@+ Document Management Interfaces

The fn:add_doc, fn:del_doc XQuery builtin functions are implemented
in loop-lifted form by the following MIL PROCs.

Note that ws_doc (previous) is similarly called from XQuery for fn:doc()
and may also lead to on-the-fly document shredding.

@- XQuery Document Management Interface

The play_doc_tape() is a loop-lifted document management function. It may only occur in read-only
queries (i.e. not intermingled with updates). This is because we use checkpointing for
shredding (and not the WAL). We cannot use both mechanisms and still have an atomic operation.
@mil
PROC play_doc_tape(BAT[void,BAT] ws,
                   BAT[void,oid] item, 
                   BAT[void,int] kind, 
                   BAT[void,lng] int_values, 
                   BAT[void,str] str_values) : void
{
    var locations   := [and]([lng](item.mirror()), 3LL).ord_uselect(0LL).mirror().leftfetchjoin(item).leftfetchjoin(str_values);
    var names       := [+](locations.mirror().[lng](), 1).[oid]().leftfetchjoin(item).leftfetchjoin(str_values).tmark(0@0);
    var colnames    := [+](locations.mirror().[lng](), 2).[oid]().leftfetchjoin(item).leftfetchjoin(str_values).tmark(0@0);
    var percentages := [+](locations.mirror().[lng](), 3).[oid]().leftfetchjoin(item).leftfetchjoin(int_values).tmark(0@0);
    var del_doc     := percentages.ord_uselect(-1LL).hmark(0@0); 
    var add_doc     := percentages.ord_uselect(0LL,lng_nil).hmark(0@0); 
    shred_doc_base(del_doc(bit_nil, del_doc.leftfetchjoin(names), true),
                   stream_nil,
                   add_doc.leftfetchjoin(locations), 
                   add_doc.leftfetchjoin(names), 
                   add_doc.leftfetchjoin(colnames), 
                   add_doc.leftfetchjoin(percentages), ws_id(ws));
}

@- MIL Document Management Interface

This is the old MIL administrative interface, now superseded by the 
new {fn:add_doc(),fn:del_doc()} XQuery built-ins. It can continue to exist.

The shred_doc() operation is the MIL document management interface. It uses a "phony" working
set identifier derived from the MIL client-id.
@mil
PROC shred_doc(BAT[void,str] locations, 
               BAT[void,str] names, 
               BAT[void,str] colnames, 
               BAT[void,lng] pageFrees) : void
{
    var us := usec();
    var wsid := WS_MAXID + lng(clientid() + 1);
    var err := CATCH(shred_doc_base(bat(void,str), 
                                    locations.tmark(0@0), 
                                    names.tmark(0@0), 
                                    colnames.tmark(0@0), 
                                    pageFrees.tmark(0@0), 
                                    stream_nil, wsid));
    ws_free(wsid); 
    if (not(isnil(err))) ERROR(err);
    var ms := (us := usec() - us) / 1000;
    var nr := count(locations);
    if (nr = 1)
        printf("%c Shredded 1 XML document (%s), total time after commit=%lld.%03llds\n",
               chr(35), names.fetch(0), /(ms,1000),%(ms,1000));
    else
        printf("%c Shredded %d XML documents, total time after commit=%lld.%03llds\n",
               chr(35), nr, /(ms,1000),%(ms,1000));
}
ADDHELP("shred_doc", "rittinge", "Oct 2006",
"PARAMETERS:\n\
- BAT[void,str] locations: URIs refering to the xml documents to be shredded)\n\
- BAT[void,str] names:     document names ('alias') in the database\n\
- BAT[void,str] colnames:  collection names ('alias') in the database\n\
- BAT[void,lng] pageFrees: percentage of pages left free in the database\n\
DESCRIPTION:\n\
Shred multiple xml documents to the internal Pathfinder format.",
"pathfinder");

PROC shred_doc(str location, 
               str name, 
               str colname, 
               lng percentage) : void
{
    shred_doc(bat(void,str).append(location).seqbase(0@0), 
              bat(void,str).append(name).seqbase(0@0), 
              bat(void,str).append(colname).seqbase(0@0), 
              bat(void,lng).append(percentage).seqbase(0@0)); 
}
ADDHELP("shred_doc", "rittinge", "Oct 2006",
"PARAMETERS:\n\
- str location: URI refering to the xml documents to be shredded)\n\
- str name:     document name ('alias') in the database\n\
- str colname:  collection name ('alias') in the database\n\
- lng pageFree: percentage of pages left free in the database\n\
DESCRIPTION:\n\
Shred single xml documents to the internal Pathfinder format.",
"pathfinder");

PROC shred_doc(str location, 
               str name) : void
{
    shred_doc(location, name, name, 0LL);
}
ADDHELP("shred_doc", "rittinge", "Oct 2006",
"PARAMETERS:\n\
- str location: URI containing the xml document to be shredded)\n\
- str name:     document name ('alias') in database\n\
DESCRIPTION:\n\
Shred single xml document to the internal Pathfinder format.\n\
(Leave no free pages and do not relate it to a collection.)",
"pathfinder");

PROC delete_doc(BAT[void,str] name) : void
{
    del_doc_base(bit_nil, name, true);
}
PROC delete_doc(str name) : void
{
    delete_doc(bat(void,str).append(name).seqbase(0@0));
}
ADDHELP("delete_doc", "tsheyar", "July 2004",
"PARAMETERS:\n\
str document name\n\
DESCRIPTION:\n\
delete the persistent BATS that store the document.",
"pathfinder");

PROC delete_all_docs(bit cachedOnly) : void
{
    del_doc_base(cachedOnly, doc_name, true);
}
ADDHELP("delete_all_docs", "tsheyar", "July 2004",
"DESCRIPTION:\n\
deletes all persistent document BATs that store xml documents;\n\
with parameter TRUE, only the (implicitely) cached documents are deleted,\n\
with parameter FALSE, also the (explicitely) shredded documents are deleted.",
"pathfinder");



@- MIL Interface for the Document Cache

When fn:doc() is used with a previously unseen URI, it is shredded on the fly and placed into 
the xml document cache (see text below). A number of procs are provided to monitor
and control the behavior of the cache.
@mil
const xmlcache_help := 
"The XML document cache keeps indexed copies of documents that where recently\n\
used in the fn:doc(URI) xquery function.\n\
\n\
The size of the cache is controlled using the 'xquery_cacheMB' setting in\n\
the 'MonetDB.conf' file.\n\
\n\
For file URIs, the cache looks at the last-modification-time of the file on disk\n\
to guarantee that the cached document is still up-to-date for answering queries from.\n\
\n\
For other URIs, *lifetime rules* determine how long documents can stay in the cache.\n\
Each lifetime rule consists of a URI prefix and the registered seconds of lifetime.\n\
\n\
The rule with longest prefix that matches an URI counts. Specifying a lifetime\n\
of 'int_nil' seconds means that the URI will *not* be cached at all.\n\
This is also the default if no prefix matches an URI.\n\
\n\
The name of a cached document is the same as its location (URI). For explicitly\n\
shredded documents (with 'shred_doc(location,name)'), the name is an 'alias' and\n\
may differ from the URI. Explicitly shredded documents fall outside the XML document\n\
cache; documents are only removed at explicit user request (with 'delete_doc(name)').";

PROC xmlcache_add_rule(str uri, 
                       any lifetime) : void 
{
    xmlcache_add_rule(uri, lng(lifetime)); 
}

PROC xmlcache_add_rule(str uri, 
                       lng lifetime) : void 
{
    lock_set(pf_short);
    var err := CATCH({ uri_lifetime.delete(uri); uri_lifetime.insert(uri, lifetime); });
    lock_unset(pf_short);
    if (not(isnil(err))) ERROR(err);
}
ADDHELP("xmlcache_add_rule", "boncz", "May 2005",
"DESCRIPTION:\nadd a new URI lifetime rule.\n\n" + xmlcache_help,  "pathfinder");

PROC xmlcache_del_rule(str uri) : void 
{
    lock_set(pf_short);
    var err := CATCH(uri_lifetime.delete(uri));
    lock_unset(pf_short);
    if (not(isnil(err))) ERROR(err);
}
ADDHELP("xmlcache_del_rule", "boncz", "May 2005",
"DESCRIPTION:\ndeletes an existing URI lifetime rule.\n\n" + xmlcache_help,  "pathfinder");

PROC xmlcache_print_rules() : void 
{
    lock_set(pf_short);
    var err := CATCH({  table(uri_lifetime.hmark(0@0).col_name("URI-prefix"), uri_lifetime.tmark(0@0).col_name("liftime-secs")); });
    lock_unset(pf_short);
    if (not(isnil(err))) ERROR(err);
}
ADDHELP("xmlcache_print_rules", "boncz", "May 2005",
"DESCRIPTION:\nshows all URI lifetime rules.\n\n" + xmlcache_help,  "pathfinder");

PROC xmlcache_print() : void 
{
    lock_set(pf_short);
    var err := CATCH({  table( doc_name.col_name("alias"), doc_location.col_name("URI"), collection_size.col_name("size"), doc_timestamp.select(timestamp_nil,timestamp_nil).col_name("valid-thru")); });
    lock_unset(pf_short);
    if (not(isnil(err))) ERROR(err);
}
ADDHELP("xmlcache_print", "boncz", "May 2005",
        "DESCRIPTION:\nshows the actual content of the XML document cache.\n\n" + xmlcache_help,  "pathfinder");

PROC xmldb_print() : void 
{
    lock_set(pf_short);
    var err := CATCH({  table( tsort(mirror(doc_timestamp.uselect(timestamp_nil)).join(doc_collection).join(collection_name)).col_name("collection"), doc_name.col_name("alias"), doc_location.col_name("URI")); });
    lock_unset(pf_short);
    if (not(isnil(err))) ERROR(err);
}
ADDHELP("xmldb_print", "boncz", "May 2005",
"DESCRIPTION:\nshows the actual content of the persistent XML document database (not the XML document cache).\n\nThis consists of all documents explicitly shredded with shred_doc(URI, alias).",  "pathfinder");


@= ws_c_decl
#define @1 @2
@h
#ifndef PATHFINDER_H
#define PATHFINDER_H

#define XML_DEPTH_MAX 128

#include <monet.h>
#include <monettime.h>
#include <lock.h>
#include <monet_context.h>
#include <monet_interpreter.h>
#include <streams.h>
#include <mapi.h>
#include <sys.h>
#include <pathfinder.proto.h>
#include <pf_support.proto.h>

#define is_fake_project(b) (((b)->htype==TYPE_void) && (BATcount(b)==1) && ((b)->hseqbase==oid_nil))

@:ws(c_decl)@
@:ws_decl(c)@

#define XTRACT_KIND(X)     (X & 63)
#define XTRACT_CONT(X)     (X >> 6)
#define SET_CONT_KIND(X,Y) (X << 6 | Y)

/* xquery_method : execute a loop-lifted xquery function
 *
 * argc          = #params
 * itercnt       = #iterations
 * argcnt[iter]  = #items per param 
 * argtpe[]      = xquery type of each parameter (as string, e.g. 'xs:integer')
 * argval[]      = str representation of item (e.g. '42')
 *
 * shredBAT   = optional shredded document table, that is added to working set
 *              params of type xs:anyNode are represented as int pre-numbers.
 *
 * we return an error string, or NULL iff everything went A-OK  
 */
pathfinder_export char *
xquery_method(stream *out, 
              int rpctiming,
              char* module, 
              char* uri, 
              char *method, 
              int argc, 
              int itercnt, 
              int** argcnt, 
              str* argtpe, 
              str* argval, 
              BAT* shredBAT);

#endif
@c
#include "pathfinder.h"
#include "shredder.h"

#define XQUERY_BUFSIZE 16364

/* the xquery builtin type hierarchy */
typedef struct {
    int parent;
    int monet_tpe;
    int kind;
    char* name;
} xquery_type;

#define DOCBAT (ELEM | (1<<6))
#define XQUERY_TYPES 15
#define XQUERY_ABSTRACT 6

xquery_type xquery_types[XQUERY_TYPES+1] =
{ {  5, TYPE_bit, BOOL,   "xs:boolean"  },  
  {  2, TYPE_lng, INT,    "xs:integer" },
  {  4, TYPE_dbl, DEC,    "xs:decimal" },
  {  4, TYPE_dbl, DBL,    "xs:float" },
  {  5, TYPE_dbl, DBL,    "xs:double" },
  {  7, TYPE_str, STR,    "xs:string" },
  {  8, TYPE_str, STR,    "xs:untypedAtomic" },
  {  8, TYPE_str, STR,    "xdt:anyAtomicType" },
  {  9, TYPE_str, STR,    "xs:anySimpleType" },
  { 14, TYPE_str, STR,    "xs:anyType" },
  { 14, TYPE_str, STR,    "xdt:untypedAny" },
  { 13, TYPE_oid, DOCBAT, "xs:anyElement" },
  { 13, TYPE_oid, DOCBAT, "xs:anyAttribute" },
  { 14, TYPE_oid, DOCBAT, "xs:anyNode" },
  { 15, TYPE_oid, DOCBAT, "xs:anyItem" },
  {  0, TYPE_oid, DOCBAT, "illegal type" } };

/*
 * return xquery type number, given a type string
 */
static int
xquery_typenr(char* tpe) 
{
    int i;
    for(i=0; i<XQUERY_TYPES; i++) 
        if (strcmp(tpe, xquery_types[i].name) == 0) break;
    return i;
}

/*
 * find the common ancestor of two xquery types
 */
static int
xquery_type_common_ancestor(int t1, int t2) 
{
    if (t1 < 0 || t1 >= XQUERY_TYPES) return t2;
    if (t2 < 0 || t2 >= XQUERY_TYPES) return t1;
    while(t1 != t2) {
        if (t1 < t2) t1 = xquery_types[t1].parent;  
        else         t2 = xquery_types[t2].parent;  
    }
    return t1;
} 

/* representation of a xquery function signature */
typedef struct {
    int update;                   /* is an updating function? */
    int argc;                     /* number of params */
    unsigned int zero;            /* bit-mask that indicates whether param (bit) i can be the empty sequence */
    unsigned int multiple;        /* bit-mask that indicates whether param (bit) i can be a sequence */
    unsigned char tpe[MAXPARAMS]; /* xquery type number (point into above xquery_types table) */
    char name[1];                 /* method name */
} xquery_sig;


/* xquery functions */
typedef struct _xquery_function {
    struct _xquery_function *next;
    oid vid;                      /* vid of first param */
    lng size;                     /* byte size of prepared tree */
    xquery_sig *sig;              /* method signature */
    char* mil;                    /* generated MIL */
    char  proc[1];                /* MIL procname */
} xquery_function;


/* xquery modules */
typedef struct _xquery_module {
    struct _xquery_module *next;
    char* prologue;               /* MIL procs defined in this module */
    char* epilogue;               /* MIL procs undefs for this module */
    xquery_function *functions;   /* functions declared in this module */
    char *nsurl;                  /* module namespace definition */
    char url[1];                  /* module url */
} xquery_module;

/* global list of known modules and their function declarations */
xquery_module *xquery_compiled_modules = NULL;


/* cached functions */
typedef struct _xquery_prepared_function {
    struct _xquery_prepared_function *next;
    xquery_function *def;         /* function definition */
    YYSTREE lt;                   /* cached MIL tree */
    unsigned int lru;             /* least recently used stamp */
} xquery_prepared_function;

unsigned int xquery_lru = 0;

/* loaded modules */
typedef struct _xquery_loaded_module {
    struct _xquery_loaded_module *next;
    xquery_module* def;           /* module definition */
    char* ns;                     /* namespace under which the module was loaded */
    int nslen;
} xquery_loaded_module;

/* cached MIL client + Xquery specific context */
typedef struct {
    bit initialized;

    Cntxt stk; /* stack to execute module prologues and non-cacheable queries in */  
    /* MIL child context of ctx->stk; it is marked as a reusable stack frame so variable records are kept */
    Cntxt repeat_stk; /* stk to execute the prepared function trees in  for fast reuse */ 

    /* value parsing buffer reuse */
    int vallen;
    ptr val;

    /* query buffer reuse */
    size_t buflen;
    char *buf;
    int cacheid;        /* only reuse from the same cache */
        
    /* error stream (normally fderr=GDKerr=GDKout) */
    stream *fderr;

    /* live BAT handles (note we gave them a memory refcount in BBP) */
    BAT *proc_vid, *var_usage;
    BAT *dbl_values, *int_values, *str_values;
    BAT *fun_vid000, *fun_iter000, *fun_item000, *fun_kind000, *loop000;

    /* pointers into MIL variable records (to set values) */
    int *shredBAT; 
    lng *time_compile; 
    lng *time_shred; 
    lng *time_exec; 
    lng *time_print; 
    char **genType;

    /* counts used to remove query (non-module) procs and stacks after execution */
    size_t var_usage_size; 
    size_t proc_vid_size;

    int mode; /* XQ bitmasks */ 

    /* size of the cached procs */
    size_t cachesize;

    xquery_prepared_function* prepared_functions;
    xquery_loaded_module *loaded_modules; 
} xquery_client;

/* bitmasks for mode */
#define XQ_DEBUG 1
#define XQ_MAPI  2 

size_t xquery_client_bytes = 64<<20; /* 64MB of procs should be enough for anyone */
int xquery_cacheid = 0;

MT_Lock pf_compiler_lock;
MT_Lock pf_module_lock;
MT_Lock pf_cache_lock;

#include "compile_interface.h"

/*
 * =================== MIL execution ================================
 *
 * int     
 * xquery_tree_exec(xquery_client *ctx, YYSTREE t, int repeat) { 
 * - execute parsed MIL tree
 *
 * YYSTREE 
 * xquery_mil2tree(xquery_client *ctx, char* buf) { 
 * - parse MIL buffer into a tree
 *
 * int
 * xquery_mil_exec(xquery_client *ctx, char* buf) { 
 * - execute MIL buffer (parse & execute)
 *
 * int
 * xquery_compile_exec(xquery_client *ctx, char* xquery, int is_url, 
 *                     char** prologue, char** query, char** epilogue, char* nsurl) 
 * - translate xquery to MIL and execute
 *
 * all int-returning functions return error(0)/ok(1)
 */

/*
 * execute parsed MIL tree, return error(0)/ok(1)
 */
static int 
xquery_tree_exec(xquery_client *ctx, 
                 YYSTREE t, 
                 int repeat) 
{ 
    ValRecord res;
    int ret = interpret(repeat?ctx->repeat_stk:ctx->stk, t, &res);
    if (ret == -TOK_RETURN) {
        /* ignore return value here */
        VALclear(&res);
        ret = 1;
    } else if (ret >= 0) {
        ret = 1;
    } else {
        ret = 0;
    }
    CLEANUP(t);
    return ret;
}

/*
 * parse MIL buffer into a tree
 */
static YYSTREE 
xquery_mil2tree(xquery_client *ctx, 
                char* buf) 
{ 
    Client c = monet_clients + ctx->stk;
    YYSTREE ret = NULL, treebak = c->tree;
    char* bufbak = c->input;
    int listing_bak = c->listing;
    c->listing = 0;
    c->input = buf;
    c->tree = NULL;
    if (parseClient(c, FALSE))
        ret = c->tree;
    c->tree = treebak;
    c->input = bufbak;
    c->listing = listing_bak;
    return ret;
}

/*
 * execute MIL buffer (parse & execute), return error(0)/ok(1)
 */
static int 
xquery_mil_exec(xquery_client *ctx,  
                char* buf) 
{
    int ret = 0;
    YYSTREE t;

    if (ctx->mode&XQ_DEBUG)
        stream_write(ctx->fderr, buf, strlen(buf), 1);

    t = xquery_mil2tree(ctx, buf); 
    if (t) {
        ret = xquery_tree_exec(ctx, t, 0);
        Myyfree(t);
    }
    return ret;
}

static char* xquery_parse_ident(char* p); 
static char* xquery_parse_space(char* p); 
static char* xquery_parse_string(char* p, char *buf, int len); 

/*
 * translate xquery to MIL and execute, return error(0)/ok(1)
 * We collect the MIL scripts in three sections (prologue,query,epilogue).
 * The query may be NULL, in which case we mean that it should be ignored. 
 */
#define PFURLCACHE(fcn, query, cache) {\
    char *url = query;\
    query = PFurlcache(url, cache);\
    if (query == NULL) {\
        err = (char*) alloca(strlen(url)+80);\
        sprintf(err, "%s(%s): could not retrieve query\n", fcn, url);\
}    }
static int
xquery_compile_exec(xquery_client *ctx, 
                    char* xquery, 
                    int is_url, 
                    char** prologue, 
                    char** query, 
                    char** epilogue,
                    char* nsurl)
{
    int is_mil = 0, len=0, ret = 0;
    char *err = NULL;

    int options = 0;
    /* Setting the StandOff flag based on runtime settings */
    if ((GDKgetenv("standoff") != NULL) && (strcmp(GDKgetenv("standoff"),"enabled") == 0))
        options |= COMPILE_OPTION_STANDOFF;

    MT_set_lock(pf_compiler_lock, "xquery_compile_exec");
    if (is_url) {
        int l = strlen(xquery);
        is_mil = (l > 4 && xquery[l-4] == '.' && xquery[l-3] == 'm' && xquery[l-2] == 'i' && xquery[l-1] == 'l');
        PFURLCACHE("xquery_compile_exec", xquery, !is_mil);
    }
    if (err == NULL) {
        char *del = NULL;
        if (is_mil && query == NULL) {
            *prologue = xquery; *epilogue = NULL;
        } else {
            err = PFcompile_MonetDB(xquery, prologue, &del, epilogue, options);
            if (err == NULL && nsurl != NULL){
                /* get the module namespace URL Y from pattern: "module namespace X = Y" */
                char *p0 = xquery_parse_space(xquery); 
                err = "xquery_compile_exec: cannot parse module namespace.\n";
                if (strncmp(p0, "module", 6) == 0) {
                    char *p1 = xquery_parse_space(p0+=6); 
                    if (p1 > p0 && strncmp(p1, "namespace", 9) == 0) {
                        char *p2 = xquery_parse_space(p1+=9); 
                        if (p2 > p1) {
                            char* p3 = xquery_parse_ident(p2);
                            if (p3 > p2) {
                                char *p4 = xquery_parse_space(p3); 
                                if (p4 >= p3 && *p4++ == '=') {
                                    char *p5 = xquery_parse_space(p4); 
                                    if (p5 >= p4 && xquery_parse_string(p5, nsurl, 1024) > p5) {
                                        err = NULL; /* success! */
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
        if (err == NULL || (prologue && *prologue) || (del && *del)) {
            ret = 1; /* no errors, or some MIL script came out still */
        }
        if (query) {
            *query = del;
        } else if (del) {
            free(del); /* we are ignoring the query part apparently */
        }
    }
    if (err) {
        len = strlen(err);
        if (ctx->mode&XQ_MAPI) {
            /* put ! before error lines */
            char *p = err, *q = err;

            while (*p) {
                if (*p++ == '\n')
                    len++;
            }
            err = (char*) alloca(len+3);
            *err = '!'; 
            for (p = err + 1; *q; q++) {
                *p++ = *q;
                if (*q == '\n')
                    *p++ = '!'; 
            }
            /* guard against errors that do not terminate in a newline */
            if (q > err && q[-1] != '\n')
                *p++ = '\n';
            else if (p[-1] == '!')
                p--;
            *p = 0;
            len = p - err;
        }
    }
    MT_unset_lock(pf_compiler_lock, "xquery_compile_exec");
    
    /* write errors and debug info on client stream */
    if (err && *err) stream_write(ctx->fderr, err, len, 1);

    /* execute the three MIL sections */
    if (ret && *prologue && **prologue)
        ret = xquery_mil_exec(ctx, *prologue);

    if (ret && query) {
        if (*query && **query)
            ret = xquery_mil_exec(ctx, *query);

        if (ret && *epilogue && **epilogue)
            ret = xquery_mil_exec(ctx, *epilogue);
    }
    return ret?ret+is_mil:0;
}

/*
 * =================== function admin ================================
 *
 * xquery_sig*
 * xquery_sig_init(char *proc)
 * - infer the xquery function signature from the mangled MIL procname (return NULL on error)
 *
 * int
 * xquery_sig_match(xquery_sig *sig, int argc, int* mincnt, int* maxcnt, int *argtpe)
 * - check whether sig can match the actual parameters (return true/false)
 *
 * xquery_function* 
 * xquery_resolve(xquery_client *ctx, char *ns, char *method, int argc, int *mincnt, int* maxcnt, int* argtpe)
 * - resolve a method call in the current xquery context (return NULL if not resolved)
 *
 * char*
 * xquery_function_call(xquery_client *ctx, lng usec, char *ns, char *method, 
 *                      int argc, int itercnt, int** argcnt, char** argtpe, char** argval, BAT *shredBAT)
 * - call a function ns:method(). try to use the function cache (ie re-use a cached MIL tree).
 *   otherwise generate MIL yourself, interpret it (and cache it). Returns error string (NULL if ok).
 */

/*
 * infer the xquery function signature from the mangled MIl procname (return NULL on error)
 */
static xquery_sig* 
xquery_sig_init(char *proc) 
{
    char *cur = (char*) alloca(strlen(proc)); 
    xquery_sig* sig;
    int update = 0, len = 0;

    /* proc names string with 'up' are updating functions */
    if (proc[0] == 'u' && proc[1] == 'p') {
        update = 1;
    } else if (proc[0] != 'f' || proc[1] != 'n') {
        return NULL;
    }

    proc = strchr(proc, '_'); /* skip fnXXXXXXXX_' */
    if (proc == NULL) return NULL;
    strcpy(cur, ++proc);
    sig = (xquery_sig*) GDKmalloc(sizeof(xquery_sig)+strlen(proc)); 
    if (sig == NULL) return NULL;
    sig->update = update;
    sig->argc = sig->zero = sig->multiple = 0;

    /* get method name */
    while(cur[0]) {
        if (cur[0] == '_' && cur[1] == '_') {
            cur++; /* unescape '_' */
        } else if (cur[0] == '_' && (cur[1] == '4' || cur[1] == '5') && cur[2] == '_') {
            sig->name[len++] = (cur[1] == '4')?'-':'.'; cur += 3; continue;
        } else if (cur[0] == '_') {
            break; /* unescaped '_' => end of function name */
        }
        sig->name[len++] = *cur++;
    }
    sig->name[len] = 0;
    while(*cur++ == '_') {
        char *tpe = cur;
                
        /* parse namespace part */
        for(len=0; cur[0]; cur++) {
            if (cur[0] == '_' && cur[1] == '_') {
                tpe[len++] = '_';
                cur++; /* unescape '_' */
            } else if (cur[0] != '_') {
                tpe[len++] = cur[0];
            } else {
                tpe[len++] = ':';
                cur++; break;
            }
        }
        /* parse type part */
        for(; cur[0]; cur++) {
            if (cur[0] == '_' && cur[1] == '_') {
                tpe[len++] = '_';
                cur++; /* unescape '_' */
            } else if (cur[0] != '_') {
                tpe[len++] = cur[0];
            } else {
                break;
            }
        }
        if (cur[-1] == '0') {
            sig->zero |= 1<<sig->argc; 
        } else if (cur[-1]  == '2') {
            sig->zero |= 1<<sig->argc; 
            sig->multiple |= 1<<sig->argc; 
        } else if (cur[-1]  == '3') {
            sig->multiple |= 1<<sig->argc; 
        }
        cur[-1] = 0;
        if ((sig->tpe[sig->argc++] = xquery_typenr(tpe)) >= XQUERY_TYPES) {
            /* unknown type: don't cache this function */
            GDKfree(sig);
            return NULL;
        }
    }
    return sig;
}


/*
 * check whether sig can match the actual parameters (return true/false)
 */
static int
xquery_sig_match(xquery_sig *sig, int argc, int* mincnt, int* maxcnt, int *argtpe) 
{
    int i, tpe[MAXPARAMS];
    for(i=0; i < argc; i++) {
        if (mincnt[i] == 0 && !(sig->zero & (1<<i))) return 0; 
        if (maxcnt[i] > 1 && !(sig->multiple & (1<<i))) return 0; 
        /* If (argtpe[i] == -1), then the actual value of this parameter
         * is an empty sequence.
         * If the actual value of this parameter is an empty sequence,
         * and this parameter can be an empty sequence, we _should not_
         * check the parameter type, instead, we copy the type
         * information from the function signature into 'tpe' */
        if (argtpe[i] == -1 && (sig->zero & (1<<i))) {
            tpe[i] = sig->tpe[i];
        } else {
            tpe[i] = argtpe[i];
            while(sig->tpe[i] != tpe[i]) {
                if (tpe[i] >= XQUERY_TYPES) return 0;
                tpe[i] = xquery_types[tpe[i]].parent;
            }
        }
    }
    for(i=0; i< argc; i++) {
        argtpe[i] = tpe[i];
    }
    return 1;
}

/*
 * resolve a method call in the current xquery context (return NULL if nonresolved)
 */
static xquery_function*
xquery_resolve(xquery_client *ctx, char *ns, char *method, int argc, int *mincnt, int* maxcnt, int* argtpe) 
{
    xquery_loaded_module *mod = ctx->loaded_modules;
    int nslen = strlen(ns);

    /* look up ns and method */
    while(mod) {
        if (mod->nslen == nslen && strncmp(mod->ns, ns, nslen) == 0) {
            xquery_function *fun = mod->def->functions;
            while(fun) {
                if (argc == fun->sig->argc && strcmp(method, fun->sig->name) == 0) {
                    if (xquery_sig_match(fun->sig, argc, mincnt, maxcnt, argtpe)) return fun;
                }
                fun = fun->next;
            }
        }
        mod = mod->next;
    }
    return NULL;
}


@= seqbase
    BATseqbase(ctx->@1, @2);
    if (ctx->mode&XQ_DEBUG) m += snprintf(mil+m, XQUERY_BUFSIZE-l, "@1.seqbase(" @3 ");\n");
@= bunins
    if (BUNins(ctx->@1, @2, @3, FALSE) == NULL) return "xquery_method: allocation error while inserting in @1";
    if (ctx->mode&XQ_DEBUG) m += snprintf(mil+m, XQUERY_BUFSIZE-l, "@1.append(" @5 @6 ");\n", @4 @3);
@= bunappend
    if (BUNappend(ctx->@1, @2, FALSE) == NULL) return "xquery_method: allocation error while inserting in @1";
    if (ctx->mode&XQ_DEBUG) m += snprintf(mil+m, XQUERY_BUFSIZE-l, "@1.append(" @4 @5 ");\n", @3 @2);
@c
/*
 * call a function ns:method(). try to use the function cache (ie re-use a cached MIL tree).
 * otherwise generate MIL yourself, interpret it (and cache it). Returns error string (NULL if ok).
 */
static char xquery_function_error[80] = "xquery_method: error during execution.\n";
static char* 
xquery_function_call(xquery_client *ctx, 
                     lng usec, 
                     char *ns, 
                     char *method, 
                     int argc, 
                     int itercnt, 
                     int** argcnt, 
                     char** argtpe, 
                     char** argval, 
                     BAT *shredBAT) 
{
    xquery_prepared_function *prepfun = ctx->prepared_functions;
    xquery_function *fun;
    int i, j, k, l, m=0, tpe[MAXPARAMS], mincnt[MAXPARAMS], maxcnt[MAXPARAMS];
    char mil[XQUERY_BUFSIZE], *src, *cur = mil, *end = mil + XQUERY_BUFSIZE-1;

    /* determine minimum and maximum sequence of the parameters, and the common ancestor type of each sequence  */
    for(j=0; j<argc; j++) {
        mincnt[j] = maxcnt[j] = argcnt[0][j];
        tpe[j] = -1;
    }
    for(l=i=0; i<itercnt; i++) {
        for(j=0; j<argc; j++) {
            if (argcnt[i][j] > maxcnt[j]) maxcnt[j] = argcnt[i][j];
            if (argcnt[i][j] < mincnt[j]) mincnt[j] = argcnt[i][j];
            for(k=0; k<argcnt[i][j]; k++,l++) {
                int t = xquery_typenr(argtpe[l]);
                if (t >= XQUERY_TYPES) 
                    return (char*) -1; /* can't make a quick function resolution if unknown types are involved */
                tpe[j] = xquery_type_common_ancestor(tpe[j],t);
            }
        }
    }

    /* try to resolve the parameters */
    fun = xquery_resolve(ctx, ns, method, argc, mincnt, maxcnt, tpe);
    if (fun == NULL)
        return (char*) -1; /* no such udf. but it may be a built-in, actually */

    /* create a prepared function record for this MIL client */
    while(prepfun && prepfun->def != fun) prepfun = prepfun->next;
    if (prepfun == NULL) {
        prepfun = (xquery_prepared_function*) GDKmalloc(sizeof(xquery_prepared_function));
        if (prepfun == NULL)
            return "xquery_function_call: allocation failed.\n";
        prepfun->def = fun;
        prepfun->lt = NULL;
        prepfun->next = ctx->prepared_functions;
        ctx->prepared_functions = prepfun;
    }
        
    /* generate small MIL query that calls the function PROC */
    if (fun->mil == NULL) {
        MT_set_lock(pf_cache_lock, "xquery_function_call");
        if (fun->mil == NULL) {
            /* create working set */
            int ret;
  
            src = (char*) PFstartMIL(fun->sig->update);
            while(*src && cur < end) *cur++ = *src++;

            if (shredBAT) {
                /* add shredded RPC request message to the working set */
                src = (char*) PFdocbatMIL();
                while(*src && cur < end) *cur++ = *src++;
            }

            /* call UDF */
            ret = snprintf(cur, XQUERY_BUFSIZE-(cur-mil), 
                           PFudfMIL(), 
                           fun->proc, 0, 0, 0,0, 0, 0, 0, 0, fun->sig->name, fun->sig->name, 0, 0, 0, 0);
            if (ret > 0) cur += ret;

            /* destroy working set */
            ret = snprintf(cur, XQUERY_BUFSIZE-(cur-mil), PFstopMIL(fun->sig->update));
            if (ret > 0) cur += ret;

            /* done! execute the script */
            if (cur >= end) {
                return "xquery_function_call: generated MIL query exceeds buffer size.\n";
            }
            *cur = 0;
            fun->mil = GDKstrdup(mil);
        }
        MT_unset_lock(pf_cache_lock, "xquery_function_call");
    }
    if (fun->mil == NULL)
       return "xquery_function_call: malloc failed.\n";

    /* if no MIL tree is available, create it now */
    if (prepfun->lt == NULL) {
        prepfun->lt = xquery_mil2tree(ctx, fun->mil);
        if (prepfun->lt == NULL) {
            GDKfree(prepfun);
            return "xquery_function_call: error during parsing .\n";
        }
    }

    /* put the actual parameters into the fun_* bats (and *_values containers) */
    @:seqbase(fun_vid000, oid_nil, "oid_nil")@
    @:seqbase(fun_iter000, oid_nil, "oid_nil")@
    @:seqbase(fun_kind000, oid_nil, "oid_nil")@
    @:seqbase(fun_item000, oid_nil, "oid_nil")@
    @:seqbase(loop000, oid_nil, "oid_nil")@

    for(l=j=0; j<itercnt; j++) {
        for(i=0; i<argc; i++) {
            oid item, vid = i + fun->vid, iter = j+1;
            if (i == 0 && j > 0) {
                @:bunappend(loop000, &iter, (size_t) *(oid*), SZFMT, "@0")@
            }
            for(k=0; k<argcnt[j][i]; k++,l++) {
                int t = xquery_typenr(argtpe[l]);
                char c;

                /* 'hack': perform simple atomic casts using Monet's ATOMfromstr */
                if (fun->sig->tpe[i] < XQUERY_ABSTRACT)
                    t = fun->sig->tpe[i]; /* just parse the value string as if it was from the desired type */ 
                /* it is doubtful how well pathfinder supports other
                 * casts and what we should do here in those cases.
                 */
                c = xquery_types[t].name[3];

                if (ATOMfromstr(xquery_types[t].monet_tpe, &ctx->val, &ctx->vallen, argval[l]) <= 0)
                    return "xquery_function_call: illegal parameter value.\n";

                @:bunappend(fun_vid000, &vid, (size_t) *(oid*), SZFMT, "@0")@
                @:bunappend(fun_iter000, &iter, (size_t) *(oid*), SZFMT, "@0")@
                @:bunappend(fun_kind000, &xquery_types[t].kind, *(int*), "%d")@
                if (c == 'i') { /* xs:integer */
                    @:bunappend(int_values, ctx->val, *(lng*), LLFMT, "LL")@
                    item = *(oid*) BUNhead(ctx->int_values, BUNfnd(BATmirror(ctx->int_values), ctx->val));
                    @:bunappend(fun_item000, &item, (size_t) *(oid*), SZFMT, "@0")@
                } else if (c == 'd') { /* xs:double or xs:decimal */
                    @:bunappend(dbl_values, ctx->val, *(dbl*), "%g")@
                    item = *(oid*) BUNhead(ctx->dbl_values, BUNfnd(BATmirror(ctx->dbl_values), ctx->val));
                    @:bunappend(fun_item000, &item , (size_t) *(oid*), SZFMT, "@0")@
                } else if (c == 's') { /* xs:string */
                    @:bunappend(str_values, ctx->val, (str), "\"%s\"")@
                    item = *(oid*) BUNhead(ctx->str_values, BUNfnd(BATmirror(ctx->str_values), ctx->val));
                    @:bunappend(fun_item000, &item, (size_t) *(oid*), SZFMT, "@0")@
                } else if (shredBAT == NULL) { 
                    return "xquery_function_call: node parameter without shredBAT.\n";
                } else {
                    @:bunappend(fun_item000, ctx->val, (size_t) *(oid*), SZFMT, "@0")@
                }
            }
        }
    }
    @:seqbase(loop000, 0, "0@0")@
    @:seqbase(fun_vid000, 0, "0@0")@
    @:seqbase(fun_iter000, 0, "0@0")@
    @:seqbase(fun_kind000, 0, "0@0")@
    @:seqbase(fun_item000, 0, "0@0")@

    /* for debugging purposes, we simulate a full MIL on the log; even if parts are cached */
    if (ctx->mode&XQ_DEBUG) { 
        /* MIL corresponding to BUNins calls we made from C */
        stream_write(ctx->fderr, mil, strlen(mil), 1);
        /* MIL corresponding to UDF call sequence (even if we already have it cached) */
        stream_write(ctx->fderr, fun->mil, strlen(fun->mil), 1);
    }

    /* set the MIL shredBAT and getType variables to the actual values */
    ctx->shredBAT[0] = shredBAT?shredBAT->batCacheid:0;
    *(ctx->time_compile) = GDKusec() - usec;
    
    /* Done preparing the query. Time to (re-)execute the MIL tree */
    prepfun->lru = xquery_lru++;
    if (xquery_tree_exec(ctx, prepfun->lt, 1)) {
/*
        if (strstr(*(ctx->genType), "rpcdtime") != NULL) {
           printf("\nServer_Application: %.3f msec\n", (*ctx->time_compile + *ctx->time_exec) / 1000.0 );
           printf("\tTrans: %.3f msec\n", (*ctx->time_compile) / 1000.0 );
           printf("\tShred: %.3f msec\n", (*ctx->time_shred) / 1000.0 );
           printf("\tQuery: %.3f msec\n", (*ctx->time_exec - *ctx->time_shred) / 1000.0 );
           printf("Server_Serialisation + Network_Server_2_Client: %.3f msec\n", (*ctx->time_print) / 1000.0 );
        }
*/

        size_t dummy;
        if (fun->size == 0)
            fun->size = Myysize(prepfun->lt, &dummy);

        /* keep the prepared function cache within a certain size */
        ctx->cachesize += fun->size;
        while (ctx->cachesize > xquery_client_bytes) {
             xquery_prepared_function *kill=NULL,*cur;
             unsigned int lru = xquery_lru;
             for(cur=ctx->prepared_functions; cur; cur=cur->next)
                 if (cur->lt && cur->lru < lru) { kill = cur; lru = cur->lru; }
             if (kill) {
                 Myyfree(kill->lt);
                 kill->lt = NULL;
                 ctx->cachesize -= kill->def->size; 
             }
        }

        return NULL;
    }
    return xquery_function_error;
}


/*
 * =================== module admin ================================
 *
 * void
 * xquery_module_free(xquery_module *mod)
 * - free module structure 
 *
 * xquery_module* 
 * xquery_module_compile(xquery_client *ctx, char *url)
 * - get an xquery module, compile it and cache it (return NULL on error)
 *
 * char*
 * xquery_module_load(xquery_client *ctx, char *ns, char *url)
 * - check whether we already loaded the module, or if we already 
 *   have it cached. If not, fetch&compile. Returns error string or NULL if ok.
 */

/* 
 * free module structure 
 */
static void 
xquery_module_free(xquery_module *mod) 
{
    xquery_function *fun = mod->functions;
    while(fun) {
        xquery_function *del = fun;
        fun = fun->next;
        if (del->mil) GDKfree(del->mil);
        GDKfree(del);
    }
    if (mod->epilogue) free(mod->epilogue);
    if (mod->prologue) free(mod->prologue);
    GDKfree(mod);
}

/*
 * get an xquery module, compile it and cache it (return NULL on error)
 */
xquery_module*
xquery_module_compile(xquery_client *ctx, 
                      char *url) 
{
    xquery_module *mod = NULL;
    BAT *b = ctx->proc_vid;
    int xx = BUNsize(b);
    int cnt = BUNindex(b, BUNlast(b));
    int ret, url_len = strlen(url)+1;
    BUN p, q;

    mod = GDKmalloc(sizeof(xquery_module)+url_len+1024);
    if (mod == NULL) return NULL;
    memset(mod, 0, sizeof(xquery_module)+url_len+1024);
    strcpy(mod->url, url);
    mod->nsurl = mod->url + url_len;

    ret = xquery_compile_exec(ctx, url, 1, &mod->prologue, NULL, &mod->epilogue, mod->nsurl);
    if (!ret) {
        xquery_module_free(mod);
        return NULL;
    } 
    if (ret == 2) mod->nsurl = NULL; /* for MIL modules (ret == 2), mod->nsurl == NULL (we don't know it :-( )*/

    for(p = BUNptr(b,cnt), q = BUNlast(b); p < q; p += xx) {
        char *proc = (char*) BUNhead(b,p);
        xquery_function *fun = (xquery_function*) GDKmalloc(sizeof(xquery_function)+strlen(proc));
        if (fun == NULL) {
            xquery_module_free(mod);
            return NULL;
        }
        strcpy(fun->proc, proc);
        fun->vid = *(lng*) BUNtail(b,p);
        fun->sig = xquery_sig_init(fun->proc);
        fun->mil = NULL;
        fun->size = 0;
        if (fun->sig == NULL) {
            GDKfree(fun);
        } else {
            fun->next = mod->functions;
            mod->functions = fun;
        }
    }
    mod->next = xquery_compiled_modules;
    xquery_compiled_modules = mod;
    return mod;
}

/*
 * check whether we already loaded the module, or if we already have it cached. 
 * If not, fetch&compile. Returns error string or NULL if ok.
 */
static char* 
xquery_module_load(xquery_client *ctx, 
                   char *ns, 
                   char *module,
                   char *url) 
{
    xquery_loaded_module *mod, *prev = NULL;
    int nslen = strlen(ns);

    /* check whether it was already loaded in this query */
    for(mod = ctx->loaded_modules; mod; prev = mod, mod = mod->next) {
        if (strcmp(mod->def->url, url) == 0) {
            if (mod->nslen == 0) {
                if (prev) prev->next = mod->next;
                else ctx->loaded_modules = NULL;
                break; /* put module at front of list */
            }
            if (mod->def->nsurl && module && strcmp(mod->def->nsurl, module)) 
                return "xquery_module_load: import module statement does not match module namespace declaration.\n";
        }
    }
    if (mod == NULL) {
        xquery_module *def;
        mod = (xquery_loaded_module*) GDKmalloc(sizeof(xquery_loaded_module));
        if (mod == NULL) 
            return "xquery_module_load: could not allocate.\n";
        mod->def = NULL;

        MT_set_lock(pf_module_lock, "xquery_module_load");
        for(def = xquery_compiled_modules; def; def = def->next) 
            if (strcmp(def->url, url) == 0) break;

        if (def == NULL){
            mod->def = xquery_module_compile(ctx, url);
        }
        MT_unset_lock(pf_module_lock, "xquery_module_load");

        /* if a compiled module was found, we still need to execute it */
        if (def && xquery_mil_exec(ctx, def->prologue))
            mod->def = def; /* TODO: find a way to share PROC defs between MIL sessions */

        if (mod->def == NULL) {
            GDKfree(mod);
            return "xquery_module_load: could not load module.\n";
        }
        ctx->var_usage_size = BATcount(ctx->var_usage);
        ctx->proc_vid_size = BATcount(ctx->proc_vid);
    } else if (ctx->mode&XQ_DEBUG) {
        stream_write(ctx->fderr, mod->def->prologue, strlen(mod->def->prologue), 1);
    }
    mod->ns = ns;
    mod->nslen = nslen;
    mod->next = ctx->loaded_modules;
    ctx->loaded_modules = mod;

    if (mod->def->nsurl && module && strcmp(mod->def->nsurl, module)) 
        return "xquery_module_load: import module statement does not match module namespace declaration.\n";
    return NULL;
}

/*
 * wait for all queries to finish; free all clients; clear PF url cache
 * freeing the cached YYTREEs in the xquery clients is done lazily 
 * (postponed to the next initialization of the record)
 */
static void
xquery_client_flushall()
{
    int i, wait = 100;
    while(wait) {
        MT_set_lock(pf_cache_lock, "xquery_client_flushall");
        i = active_clients("xquery");
        if (i == 0) {
            /* ok, no xquery clients are active */
            xquery_module *mod = xquery_compiled_modules;
            while(mod) {
                xquery_module *del = mod;
                mod = mod->next;
                xquery_module_free(del);
            }
            xquery_compiled_modules = NULL;
            PFurlcache_flush();
            wait = 0;
        }
        MT_unset_lock(pf_cache_lock, "xquery_client_flushall");
        MT_sleep_ms(wait);
    }
}

/*
 * flush the cache. 
 */
int
CMDxquery_start_query_cache(lng *maxsize)
{
    xquery_client_flushall();
    if (*maxsize > 0) xquery_client_bytes = *maxsize;
    xquery_cacheid++; /* old clients need to clean up their resources */
    return GDK_SUCCEED;
}


/*
 * =================== client session management ================================
 *
 * xquery_client *
 * xquery_client_alloc(mapi_client *fc);
 * - allocate a new xquery client, returns error message (NULL on success)
 *
 * char*
 * xquery_client_init(mapi_client *fc);
 * - initialize a new xquery cache context, returns error string (NULL if ok)
 *
 * void
 * xquery_client_free(mapi_client *fc);
 * - free a xquery cache context (terminate)
 *
 * void
 * xquery_client_end(xquery_client *ctx, char *err);
 * - end of xquery execution (struct stays alive for reuse). 
 */

@= find_var
    v = VARfind(&ctx->stk, "@1");
    if (v == NULL) 
        return "xquery_client_alloc_: failed to lookup @1 variable.\n"; 
    if (v->binding.vtype != TYPE_@2) 
        return "xquery_client_alloc_: @1 variable has wrong type != int.\n"; 
    ctx->@1 = &v->binding.val.@3; 

@= find_bat
{   Variable v = VARfind(&ctx->stk, "@1");
    ctx->@1 =  NULL;
    if (v && v->binding.vtype == TYPE_bat)
        ctx->@1 = BATdescriptor(v->binding.val.bval);
    if (ctx->@1 == NULL) return "xquery_client_alloc: failed to lookup @1 variable.\n"; }
@c

static xquery_client*
xquery_client_new(Cntxt stk) {
    xquery_client *ctx = (xquery_client*)GDKmalloc(sizeof(xquery_client));
    if (ctx) {
        memset(ctx, 0, sizeof(xquery_client));
        ctx->stk = stk; 
        ctx->fderr = GDKerr;
    }
    return ctx; 
}

static char *
xquery_client_alloc_(xquery_client *ctx)
{
    Variable v;

    if (!xquery_mil_exec(ctx, (char*) PFinitMIL()))
        return "xquery_client_alloc: failed to execute init script.\n"; 

    @:find_var(shredBAT,int,ival)@
    @:find_var(genType,str,sval)@
    @:find_var(time_compile,lng,lval)@
    @:find_var(time_exec,lng,lval)@
    @:find_var(time_print,lng,lval)@
    @:find_var(time_shred,lng,lval)@

    @:find_bat(proc_vid)@
    @:find_bat(var_usage)@
    @:find_bat(dbl_values)@
    @:find_bat(int_values)@
    @:find_bat(str_values)@
    @:find_bat(fun_vid000)@
    @:find_bat(fun_iter000)@
    @:find_bat(fun_item000)@
    @:find_bat(fun_kind000)@
    @:find_bat(loop000)@

    ctx->var_usage_size = BATcount(ctx->var_usage);
    ctx->proc_vid_size = BATcount(ctx->proc_vid);
    ctx->cachesize = 0;
    ctx->loaded_modules = NULL;
    ctx->prepared_functions = NULL;
    ctx->buflen = XQUERY_BUFSIZE;
    ctx->cacheid = xquery_cacheid;
    ctx->buf = GDKmalloc(ctx->buflen+1);
    ctx->val = GDKmalloc(ctx->vallen = 128);
    if (ctx->val == NULL || ctx->buf == NULL) {
            if (ctx->buf) GDKfree(ctx->buf);
            if (ctx->val) GDKfree(ctx->val);
            ctx->buflen = 0;
            return "xquery_client_alloc: failed to allocate.\n";
    }
    ctx->repeat_stk = CNTXTnew(ctx->stk);
    ctx->initialized = 0;
    CNTXTuse(ctx->repeat_stk);
    monet_cntxt[ctx->repeat_stk].reuse = TRUE;

    return NULL;
}

/* 
 * allocate a new xquery client, returns client cntxt (0 on error)
 */
static char* 
xquery_client_alloc(mapi_client *fc)
{
    xquery_client *ctx = xquery_client_new(fc->stk);

    fc->fc = ctx;
    if (!ctx) {
        return "!ERROR: no space to allocate xquery client\n";
    } else {
        return xquery_client_alloc_(ctx);
    }
}

/*
 * initialize a new xquery cache context, returns error string (NULL if ok)
 */ 
static char *
xquery_client_init_(xquery_client *ctx )
{
    ctx->mode = 0;
    if (!ctx->initialized) {
        ctx->initialized = 1;
        if (!xquery_mil_exec(ctx, (char*) PFvarMIL()))
            return "xquery_client_init: failed to execute variable declarations.\n"; 
    }
    return NULL;
}

/*
 * free all cached subtrees and all proc definitions for all xquery modules
 * (the epilogue contains UNDEF procs) 
 */ 
void
xquery_client_free_cached_modules(xquery_client *ctx)
{
    xquery_prepared_function *fun= ctx->prepared_functions; 
    xquery_loaded_module *mod= ctx->loaded_modules; 

    while(fun) {
        xquery_prepared_function *del = fun;
        fun = fun->next;
        if (del->lt) Myyfree(del->lt);
        GDKfree(del);
    }
    while(mod) {
        xquery_loaded_module *del = mod;
        mod = mod->next;
        /* free all modules */
        if (del->def->epilogue && !xquery_mil_exec(ctx, del->def->epilogue))
            fprintf(stderr, "xquery_client_free: client %d error dropping %s\n", ctx->stk, del->def->url);
        GDKfree(mod);
    }
    ctx->loaded_modules = NULL;
    ctx->prepared_functions = NULL;

    /* free the query buffer */
    if (ctx->buf) GDKfree(ctx->buf);
    ctx->buf = NULL;
    ctx->buflen = 0;
}

static char* 
xquery_client_init(mapi_client *fc) 
{ 
    xquery_client *ctx = fc->fc;
    char* err = xquery_client_init_(ctx);

    ctx->fderr = fc->c->fdout;

    if (!err && ctx->cacheid != xquery_cacheid) {
        xquery_client_free_cached_modules(ctx);

        ctx->buflen = XQUERY_BUFSIZE;
        ctx->cacheid = xquery_cacheid;
        ctx->buf = GDKmalloc(ctx->buflen+1);
        if (ctx->buf == NULL) {
            if (ctx->buf) GDKfree(ctx->buf);
            ctx->buflen = 0;
            err = "xquery_client_init: failed to allocate.\n";
        }
    }
    if (err)
        fprintf(stderr, "xquery_client_init: client %d %s\n", fc->stk, err);
    return err;
}


@= unfix
    if (ctx->@1) BBPunfix(ctx->@1->batCacheid);
    ctx->@1 = NULL;
@c
/* 
 * free a xquery cache context (terminate).
 */
static void
xquery_client_free_(xquery_client *ctx)
{
    xquery_client_free_cached_modules(ctx);

    ctx->shredBAT = NULL;

    /* free the value buffer */
    if (ctx->val) GDKfree(ctx->val);
    ctx->val = NULL;
    ctx->vallen = 0;
    
    /* unfix the BAT handles */
    @:unfix(int_values)@
    @:unfix(dbl_values)@
    @:unfix(str_values)@
    @:unfix(fun_vid000)@
    @:unfix(fun_iter000)@
    @:unfix(fun_item000)@
    @:unfix(fun_kind000)@
    @:unfix(loop000)@

    /* close the MIL client session */
    monet_cntxt[ctx->repeat_stk].reuse = FALSE;
    CNTXTclear(ctx->repeat_stk);
    CNTXTfree1(ctx->repeat_stk);
    CNTXTdelete(ctx->repeat_stk);
}

static void 
xquery_client_free(mapi_client *fc) 
{
    xquery_client_free_(fc->fc);
}

/* 
 * end of xquery execution (struct stays alive for reuse).
 */
static void 
xquery_client_end(xquery_client *ctx, char *err) 
{
    oid zero = 0, one = 1;

    /* undo any inserts by the query into the var_usage bats */
    size_t delta_var_usage = BATcount(ctx->var_usage) - ctx->var_usage_size;
    size_t delta_proc_vid = BATcount(ctx->proc_vid) - ctx->proc_vid_size;
    BATsetcount(ctx->var_usage, ctx->var_usage_size);
    ctx->var_usage->batBuns->free -= delta_var_usage*BUNsize(ctx->var_usage);
    BATsetcount(ctx->proc_vid, ctx->proc_vid_size);
    ctx->proc_vid->batBuns->free -= delta_proc_vid*BUNsize(ctx->proc_vid);

    /* empty all bats (static variables) */
    BATclear(ctx->loop000);
    BUNins(ctx->loop000, &zero, &one, FALSE);

    BATclear(ctx->fun_vid000);
    BATclear(ctx->fun_iter000);
    BATclear(ctx->fun_kind000);
    BATclear(ctx->fun_item000);
    BATclear(ctx->dbl_values);
    BATclear(ctx->int_values);
    BATclear(ctx->str_values);
    BUNappend(ctx->str_values, (ptr)str_nil, FALSE);
    *ctx->shredBAT = int_nil; 

    MT_set_lock(pf_cache_lock, "xquery_client_end");
    /* only deactivate the loaded modules */
    xquery_loaded_module *mod= ctx->loaded_modules; 
    while(mod) {
            mod->nslen = 0;
            mod->ns = NULL; 
            mod = mod->next;
    }
    MT_unset_lock(pf_cache_lock, "xquery_client_end");

    if (err) 
        fprintf(stderr, "xquery_server: client %d %s\n", ctx->stk, err);
}


/*
 * ========== parse xquery to identify 'import module's and function calls ==========
 *
 * char*
 * xquery_parse_ident(char* p) 
 * - parse an identifier; accept any UTF-8 characters in it (is that correct?)
 *
 * char*
 * xquery_parse_comment(char* p)
 * - parse an xquery (: .. :)  comment. Note it may be nested.
 *
 * char*
 * xquery_parse_space(char* p)
 * - parse xquery space, which may include comments 
 *
 * char*
 * xquery_parse_string(char* p, char *buf, int len)
 * - parse an XML datamodel string. Deliver an unescaped version as a result 
 *
 * char*
 * xquery_parse_numeric(char* p, char **tpe)
 * - parse an XML datamodel numeric, and determine its minimal type (xs:integer, xs:decimal or xs:double) 
 *
 * all above functions return the new pointer in the xquery after parsing.
 *
 * char*
 * xquery_prepare(xquery_client *ctx, lng usec, char* xquery)
 * - parse xquery; chop off module imports, and recognize single method calls. These are re-executed
 *   from a cached MIL tree. Otherwise use pathfinder to compile. Returns error string (NULL if ok).
 */

/* 
 * parse an identifier; accept any UTF-8 characters in it (is that correct?)
 */
static char* 
xquery_parse_ident(char* p) 
{
    if ((*p >= 'a' && *p <= 'z') || (*p >= 'A' && *p <= 'Z') || *(unsigned char*) p >= 128) {
        p++;
        while((*p >= 'a' && *p <= 'z') || (*p >= 'A' && *p <= 'Z') || (*(unsigned char*) p >= 128) ||
              (*p == '_') || (*p == '.') || (*p == '-') || (*p >= '0' && *p <= '9')) p++;
    }
    return p;
}

/* 
 * parse an xquery (: .. :)  comment. Note it may be nested.
 */
static char* 
xquery_parse_comment(char* p) 
{
    int nesting;
    for(nesting=1; *p; p++) {
        if (p[0] == ':' && p[1] == ')' && --nesting == 0) return p+2;
        if (p[0] == '(' && *(++p) == ':') nesting++;
    }
    return p;
}

/* 
 * parse xquery space, which may include comments 
 */
#define ISSPACE(c) ((c) == ' ' || (c) == '\t' || (c) == 10 || (c) == 13) 
static char* 
xquery_parse_space(char* p) 
{
    while(*p) {
        while(ISSPACE(*p)) p++;
        if (p[0] != '(' || p[1] != ':') break; 
        p = xquery_parse_comment(p+2);
    }
    return p;
}

/* 
 * parse an XML datamodel string. Deliver an unescaped version as a result 
 */
static char* 
xquery_parse_string(char *src, 
                    char *buf, 
                    int len) 
{
    char *p = src, *q = buf, *r = buf+len-1;
    int sep1 = *p++;
    int sep2 = (sep1=='"')?'\'':'"';
    int escape = 0;
    if (sep1 != '\'' && sep1 != '"') return src;
    while(*p) {
        if (escape) {
            if (p[0] == sep2) escape = 0;
            if (q+1 > r) return src; /* no room */
            *q++ = *p; p++;
        } else {
            if (p[0] == sep1) break;
            if (q+1 > r) return src; /* no room */
            if (p[0] == sep2) {
                if (p[1] == sep1 && p[2] == sep1 && p[3] == sep2) {
                    *q++ = sep1; p += 4;
                } else {
                    *q++ = *p; p++;
                    escape = 1;
                }
            } else if (p[0] == '&') {
                if (p[1] == '#' && p[2] == 'x') {
                    unsigned long v = 0; 
                    for(p+=3; *p; p++) {
                        if (*p >= '0' && *p <= '9') {
                            v = (v << 4) + (*p - '0');
                        } else if (*p >= 'a' && *p <= 'f') {
                            v = (v << 4) + (*p - 'a');
                        } else if (*p >= 'A' && *p <= 'F') {
                            v = (v << 4) + (*p - 'A');
                        } else {
                            break;
                        }
                    }
                    *q++ = (char) v;
                } else if (p[1] == '#') {
                    unsigned long v = 0; 
                    for(p+=2; *p; p++) {
                        if (*p >= '0' && *p <= '9') {
                            v = (v * 10) + (*p - '0');
                        } else {
                            break;
                        }
                    }
                    /* UTF8 generation */
                    if (v < 0x80) {
                        *q++ = v; /* ahh! ascii */
                    } else if (v < 0x800) {
                        if (q+2 > r) return src; 
                        *q++ = 0xC0 | (v >> 6);
                        *q++ = 0x80 | (v & 0x3F);
                    } else if (v < 0x10000) {
                        if (q+3 > r) return src; 
                        *q++ = 0xE0 | (v >> 12);
                        *q++ = 0x80 | ((v >> 6) & 0x3F);
                        *q++ = 0x80 | (v & 0x3F);
                    } else if (v < 0x200000) {
                        if (q+4 > r) return src; 
                        *q++ = 0xF0 | (v >> 18);
                        *q++ = 0x80 | ((v >> 12) & 0x3F);
                        *q++ = 0x80 | ((v >> 6) & 0x3F);
                        *q++ = 0x80 | (v & 0x3F);
                    } else if (v < 0x4000000) {
                        if (q+5 > r) return src; 
                        *q++ = 0xF8 | (v >> 24);
                        *q++ = 0x80 | ((v >> 18) & 0x3F);
                        *q++ = 0x80 | ((v >> 12) & 0x3F);
                        *q++ = 0x80 | ((v >> 6) & 0x3F);
                        *q++ = 0x80 | (v & 0x3F);
                    } else /* if (v < 0x80000000) */ {
                        if (q+6 > r) return src; 
                        *q++ = 0xFC | (v >> 30);
                        *q++ = 0x80 | ((v >> 24) & 0x3F);
                        *q++ = 0x80 | ((v >> 18) & 0x3F);
                        *q++ = 0x80 | ((v >> 12) & 0x3F);
                        *q++ = 0x80 | ((v >> 6) & 0x3F);
                        *q++ = 0x80 | (v & 0x3F);
                    }
                } else if (p[1] == 'l' && p[2] == 't' && p[3] == ';') {
                    *q++ = '<'; p += 4;
                } else if (p[1] == 'g' && p[2] == 't' && p[3] == ';') {
                    *q++ = '<'; p += 4;
                } else if (p[1] == 'a' && p[2] == 'm' && p[3] == 'p' && p[4] == ';') {
                    *q++ = '&'; p += 5;
                } else if (p[1] == 'q' && p[2] == 'u' && p[3] == 'o' && p[4] == 't' && p[5] == ';') {
                    *q++ = '"'; p += 6;
                } else if (p[1] == 'a' && p[2] == 'p' && p[3] == 'o' && p[4] == 's' && p[5] == ';') {
                    *q++ = '\''; p += 6;
                }
            } else {
                *q++ = *p++; /* just copy a byte */
            }
        }
    }
    if (*p++ != sep1) return src;
    *q = 0;
    return p;
}

/* 
 * parse an XML datamodel numeric, and determine its minimal type (xs:integer, xs:decimal or xs:double) 
 */
static char* 
xquery_parse_numeric(char* p, 
                     char **tpe) 
{
    *tpe = "xs:integer";
    if (p[0] == '-' || p[0] == '+') p++;
    while(p[0] >= '0' && p[0] <= '9') p++;
    if (p[0] == '.' && (p[1] >= '0' && p[1] <= '9')) {
        p++;
        while(p[0] >= '0' && p[0] <= '9') p++;
        *tpe = "xs:decimal";
    }
    if (p[0] == 'e' || p[0] == 'E') {
        char *q = p+1;
        if (q[0] == '-' || q[0] == '+') q++;
        if (q[0] >= '0' && q[0] <= '9') {
           while(q[0] >= '0' && q[0] <= '9') q++;
           p = q;
           *tpe = "xs:double";
        }
    }
    return p;
}

/* 
 * parse xquery; chop off module imports, and recognize single method calls. These are re-executed
 * from a cached MIL tree. Otherwise use pathfinder to compile. Returns error string (NULL if ok).
 */
static char xquery_too_complex[80] = "xquery_prepare: xquery is too complex for cached execution.\n";
#define xquery_nondescriptive_error ((char*) -1)
static char*
xquery_prepare(xquery_client *ctx, 
               lng usec, 
               char* query) 
{
    int nsbuf = 0, loaded_modules = 0, len;
    char *ns = (char*)&nsbuf, *nsend = ns, *locend, *loc = NULL, *q, *p = query;
    char val[256], url1[256], url2[256];
    char *err = NULL;

    if (ctx->mode&XQ_DEBUG) {
        /* for debugging purposes, we simulate a full MIL on the log; even if parts are cached */
        char *prologue = (char*) PFinitMIL();
        stream_write(ctx->fderr, prologue, strlen(prologue), 1);
        prologue = (char*) PFvarMIL();
        stream_write(ctx->fderr, prologue, strlen(prologue), 1);
    }

    /* handle optional xquery version string */
    p = xquery_parse_space(p);
    if (strncmp(p, "xquery", 6) == 0 && ISSPACE(p[6])) {
        err = "xquery_prepare: illegal xquery version or encoding";
        p = xquery_parse_space(p+6);
        if (strncmp(p, "version", 7) == 0 && ISSPACE(p[7])) {
            q = xquery_parse_space(p+7);
            p = xquery_parse_string(q, val, 256);
            if (p > q && strcmp(val,"1.0") == 0) {
                p = xquery_parse_space(p);
                if (strncmp(p, "encoding", 8) == 0 && ISSPACE(p[8])) {
                    q = xquery_parse_string(p+8, val, 256);
                    if (q > p+8 && strcmp(val, "UTF-8") == 0) 
                        p = xquery_parse_space(q);
                }
                if (*p++ == ';') err = NULL; /* ok! */
            }
        }
    }
   
    /* parse one ore more import module statements */  
    while(*p && err == NULL) {
        p = xquery_parse_space(p);
        if (strncmp(p, "import", 6) || !ISSPACE(p[6])) {
            break;
        } else {
            /* e.g. import module namespace xmark = "/cygwin/tmp/" at "/cygwin/tmp/mod1.xq" */
            p = xquery_parse_space(p+6);
            if ( strncmp(p, "module", 6) == 0 && ISSPACE(p[6])) {
                len = p[0] == 'm' ? 6 : 10;
                p = xquery_parse_space(p+len);
                if (strncmp(p, "namespace", 9) == 0 && ISSPACE(p[9])) {
                    ns = xquery_parse_space(p+9);
                    nsend = xquery_parse_ident(ns);
                    p = xquery_parse_space(nsend);
                    if (*p == '=') {
                        p = xquery_parse_space(p+1);
                    } else {
                        err = "xquery_prepare: expecting '=' after namespace declaration";
                        break;
                    }
                }
                q = xquery_parse_string(p, url1, 256);
                if (q == p) {
                    err = "xquery_prepare: expecting URI after namespace declaration";
                    break;
                }
                p = xquery_parse_space(q);
                if (*p == 'a' && *(++p) == 't' && ISSPACE(p[1])) do {
                    char bak = *nsend;
                    loc = xquery_parse_space(p+1);
                    locend = xquery_parse_string(loc, url2, 256);
                    if (locend == loc) {
                        err = "xquery_prepare: expecting URI after at-hint in module import";
                        break; 
                    }
                    p = xquery_parse_space(locend);

                    /* cut off module import from the query, and load it here (to have it cached later) */
                    *nsend = 0;

                    err = xquery_module_load(ctx, ns, url1, url2);
                    *nsend = bak; 
                    if (err) break;
                    loaded_modules++;
                } while (*p == ',');

                if (*p == ';') {
                    p++;
                } else if (err == NULL) {
                    err = "xquery_prepare: missing ';' after module import.\n";
                }
            } else {
                err = xquery_too_complex; /* we understand only no other imports than module */
                break;
            }
        }
    }

    if (loaded_modules == 0) {
        err = xquery_too_complex; /* must at least load one module to be able to just execute a function */
    } else if (err == NULL) {
        /* detect queries that consist of a single method call only */
        nsend = ns = (char*) &nsbuf; 
        loc = p; 
        locend = xquery_parse_ident(loc);
        p = xquery_parse_space(locend);
        if (*p == ':') {
            ns = loc; nsend = locend; 
            loc = ++p; 
            locend = xquery_parse_ident(p);
            p = xquery_parse_space(locend);
        }
        if (*p != '(' || ((locend-loc) == 2 && loc[0] == 'i' && loc[1] == 'f')) {
            err = xquery_too_complex; /* this was not a function call, but an if-statement */
        } else {
            int cnt[MAXPARAMS];
            char* tpe[MAXPARAMS];
            char* param[MAXPARAMS];
            int argc = 0;
    
            /* e.g. ns:function(1,2,3) */
            p = xquery_parse_space(p+1);
            if (*p == ')') {
               p++;
            } else do {
                param[argc] = p;
                tpe[argc] = "xs:string";
                cnt[argc] = 1;
                if (*param[argc] == '"' || *param[argc] == '\'') {
                    p = xquery_parse_string(param[argc], val, 256);
                    if (p <= param[argc]) {
                        err = "xquery_prepare: could not parse string literal.\n";
                        break;
                    }
                } else if (*p == '-' || *p == '+' || *p == '.' || (*p >= '0' && *p <= '9')) {
                    p = xquery_parse_numeric(param[argc], tpe+argc);
                    if (p <= param[argc]) {
                        err = "xquery_prepare: could not parse numeric literal.\n";
                        break;
                    }
                } else {
                    /* complex parameter */
                    err = xquery_too_complex; 
                    break;
                }
                if (++argc >= MAXPARAMS) {
                    err = "xquery_prepare: too many parameters.\n";
                    break;
                }
                p = xquery_parse_space(p);
                if (*p == ')') {
                    p++; 
                    break;
                } else if (*p != ',') {
                    err = "xquery_prepare: expecting a ',' between function parameters.\n";
                    break;
                }
                p = xquery_parse_space(p+1);
            } while(*p);
    
            if (err == NULL) {    
                p = xquery_parse_space(p);
                if (*p == '/') {
                    err = xquery_too_complex;  /* what was this case?? */
                } else if (*p) {
                    err = "xquery_prepare: unexpected characters after ';'.\n";
                } else {
                    /* all set: make the call */
                    int* cnt_ptr = cnt;    
                    char nsbak = *nsend, locbak = *locend;
                    *nsend = 0; *locend = 0;
                    err = xquery_function_call(ctx, usec, ns, loc, argc, 1, &cnt_ptr, tpe, param, NULL);
                    *nsend = nsbak; *locend = locbak;
                }
            }
        }
    }
    /* if (err != NULL) we could return that error here, but it is more consistent 
     * to let the PF compiler give out all error messages ("why make error queries fast?").
     *
     * we can re-enable immediate return if we (ever) decide to create a low-resource XQ
     * implementation that only supports prepared queries and lacks a linked PF compiler.  
     */
    if (err == xquery_function_error) /* MIL execution failed, do not generate error in PF compiler */
       return xquery_nondescriptive_error;
    if (err) {
        char *sec1 = NULL;
        char *sec2 = NULL;
        char *sec3 = NULL;
        /* compile and execute the query (minus module imports) */
        err = xquery_nondescriptive_error;
        if (xquery_compile_exec(ctx, query, 0, &sec1, &sec2, &sec3, NULL)) 
                err = NULL;
        if (sec1) free(sec1);
        if (sec2) free(sec2);
        if (sec3) free(sec3);
    } 
    return err; 
}

/*
 * =================== exported functions ================================
 *
 * see MIL module definition (top of file)
 */

@= builtin_operand
{
    int _k = interpret(stk, arg(lt, @1), res);
    if (_k < 0) {
        return _k;
    }
    @3 = VALconvert(@2, res);
    if ((@3 == ILLEGALVALUE)  || (@2 == TYPE_bat && !@3)) {
        return handle_paramerror(res,@1,res->vtype,@2);
    }
}
@c
static char* 
xquery_change_genType(xquery_client *ctx, char* magic_string) {
    if (strcmp(*(ctx->genType), magic_string)) { 
        char* newmode = GDKstrdup(magic_string);
        if (newmode == NULL) return "xquery_change_genType: malloc failure";
        GDKfree(*(ctx->genType));
        (*ctx->genType) = newmode;
    }
    return NULL;
}

static void
xquery_client_engine(mapi_client *fc )
{
    ssize_t n;
    size_t curlen;
    xquery_client *ctx = fc->fc;
    stream *in = fc->c->fdin, *out = fc->c->fdout;
    char *p, *xquery, *err = (char*) -1;

    /* buf is the mode string that is available during execution in the MIL genType var */
    char buf[113], *genType, *output; 
    strcpy(buf, "timing-mapi-xml");
    genType = buf+7; /* initially skis over  over "timing-" */
    output = buf+12; /* place to overwrite with alternatives to "xml" */
    output[100] = 0; /* max 100 characters in output string, ensure zero at end */

    ctx->mode = XQ_MAPI;
    while (1) {
        /* use the MAPI protocol to read as much xquery buffer as possible */
        if (!fc->c->blocked && 
                stream_write(out, PROMPT1, sizeof(PROMPT1) - 1, 1) < 0) {
            xquery_client_end(ctx, "could not write prompt"); 
            return;
        }
        if (stream_flush(out)) {
            xquery_client_end(ctx, "could not flush prompt"); 
            return;
        }

        for (p = ctx->buf, curlen = 0; p; ) {
            n = stream_read(in, p + curlen, 1, ctx->buflen - curlen);
            if (n < 0) {
                xquery_client_end(ctx, NULL); 
                return;
            }
            if (n == 0)
                break;

            curlen += n;
            if (curlen == ctx->buflen) {
                p = GDKrealloc(ctx->buf, ctx->buflen + 1025);
                if (p) {
                    ctx->buflen += 1024;
                    ctx->buf = p;
                }
            }
        }
        if (curlen == 0 || !p)
                break;
        p[curlen] = 0;        /* terminate (we know there is space) */
        if (*p == 'X') {
                /* remove newline */
                if (p[curlen - 1] == '\n') p[curlen - 1] = 0;  
                p++;
                switch(*p) {
                case 'p': /* profile */
                        genType = buf; /* now includes "timing-" prefix */
                        break;
                case 'o': /* output format */
                        p += sizeof("output ") - 1;
                        strncpy(output, p, 100); /* 'output' has room for 100 chars */
                        if (strncmp(output, "debug", 5) == 0)
                            ctx->mode |= XQ_DEBUG;
                        break;
                case 'c': { /* shred from stream */
                        int i, perc=0;
                        char *dname, *cname;
                        p += sizeof("copy ")-1;

                        /* start shredder (first character should be skipped) */
                        if (!fc->c->blocked && 
                                stream_write(out, PROMPT1, sizeof(PROMPT1) - 1, 1) < 0) {
                                xquery_client_end(ctx, "could not write prompt"); 
                                return;
                        }
                        if (stream_flush(out)) {
                                xquery_client_end(ctx, "could not flush prompt"); 
                                return;
                        }
                        dname = GDKstrdup(p);
                        if (dname == NULL) {
                                xquery_client_end(ctx, "malloc failure"); 
                                return;
                        }
                        cname = strchr(dname, ',');
                        if (cname == NULL)  { 
                                /* default collection name is the document name */
                                cname = dname; 
                        } else {
                                char *percStr = strchr(cname+1, ',');
                                *cname++ = 0;
                                if (percStr) perc=atoi(percStr+1);
                        }

                        /* insert into document collection (p is name)*/
                        snprintf(ctx->buf, ctx->buflen, "shred_stream(Stream(" SZFMT "LL), \"%s\", \"%s\", lng(%d));\n", (size_t) in, dname, cname, perc);
                        i = xquery_mil_exec(ctx, ctx->buf); /* use MIL to add it to the repository */
                        GDKfree(dname);
                        if (i < 0) {
                                xquery_client_end(ctx, "shred_stream failed"); 
                                return;
                        }
                        break;
                    }
                }
                continue; 
        } else if (*p == 'S' || *p == 's') {
            /* execute query */
            lng usec = GDKusec();
            xquery = p+1;
            err = xquery_change_genType(ctx, genType);
            if (err == NULL) 
                err = xquery_prepare(ctx, usec, xquery);
            if (err && err != xquery_nondescriptive_error) {
                /* report errors back to client */
                stream_write(ctx->fderr, err, strlen(err), 1);
            }
            if (ctx->mode&XQ_DEBUG) {
                /* memory debugging */
                xquery_prepared_function *fun = ctx->prepared_functions;
                BAT *b = NULL;
                view_client_size(&b, &fc->stk);
                if (b) {
                   while(fun) {
                      BUNins(b, fun->def->proc, &fun->def->size, FALSE);
                      fun = fun->next;
                   } 
                   BATprintf(GDKstdout, b);
                   BBPreclaim(b);
                } 
            }
        }
        /* second and on queries also need a cleared context */
        xquery_client_end(ctx, NULL); 
    }
    xquery_client_end(ctx, NULL); 
}

int
xquery_frontend( ptr *F)
{
    char *m_clients = GDKgetenv("mapi_clients"); 
    int nr = (m_clients)?strtol(m_clients, NULL, 10):1;
    mapi_frontend *f = (mapi_frontend*)GDKmalloc(sizeof(mapi_frontend));
    if (f) {
        f->name = GDKstrdup("xquery");
        if (f->name) {
            *F = f;
            f->cache_limit = nr;
	    f->f_alloc = xquery_client_alloc;
	    f->f_init  = xquery_client_init;
	    f->f_free  = xquery_client_free;
	    f->f_engine  = xquery_client_engine; /* read/parse/execute loop */
	    return GDK_SUCCEED;
        }
        GDKfree(f);
    }
    return GDK_FAIL;
}


/*
 * execute xquery and return the result in a string.
 */
int
CMDxquery(Cntxt stk, 
          YYSTREE lt, 
          ValPtr res)
{
    lng usec = GDKusec();
    char *mode = "xml", *xquery = NULL, *err = NULL;
    bit no=0, *is_url=&no;
    Client c = NULL;
    xquery_client *ctx;

    /* this is a BUILTIN because we must obtain the client context (and
     * thus the streams) */
    if (lt->cnt > 4)
        return handle_argerror(res, lt->cnt, 3);
    if (lt->cnt == 1) {
        @:builtin_operand(0,TYPE_str,xquery)@
    } else {
        @:builtin_operand(0,TYPE_str,mode)@
        @:builtin_operand(1,TYPE_str,xquery)@
    }
    if (lt->cnt == 3) {
        @:builtin_operand(2,TYPE_bit,is_url)@
    }
    CNTXTclient(stk, &c);
    ctx = xquery_client_new(c->stk);
    ctx->fderr = GDKerr;
    MT_set_lock(pf_cache_lock, "CMDxquery");
    err = xquery_client_alloc_(ctx);
    if (!err)
        err = xquery_client_init_(ctx);
    MT_unset_lock(pf_cache_lock, "CMDxquery");

    if (err == NULL && *is_url == TRUE) { 
        MT_set_lock(pf_compiler_lock, "CMDxquery");
        PFURLCACHE("CMDxquery", xquery, 1);
        MT_unset_lock(pf_compiler_lock, "CMDxquery");
    }
    err = xquery_change_genType(ctx, mode);
    if (err == NULL) {
        buffer *b = buffer_create(XQUERY_BUFSIZE);
        if (b) {
            stream *s = buffer_wastream(b, "CMDxquery");
            if (s) {
                /* run the query, but collect all output in a buffer */
                stream *bak = GDKout;
                THRsetdata(0,s);
                err = xquery_prepare(ctx, usec, xquery);
                if (err == NULL || err == xquery_nondescriptive_error) {
                    res->val.sval = GDKmalloc(b->pos+1);
                    if (res->val.sval) {
                        memcpy(res->val.sval, b->buf, b->pos);
                        res->val.sval[b->pos] = 0;
                        res->vtype = TYPE_str;
                    } else {
                        err = "CMDxquery: failed to allocate buffer";
                    }
                }
                THRsetdata(0,bak);
                stream_close(s);
            } else {
                err = "CMDxquery: failed to create stream";
            }
            buffer_destroy(b);
            stream_destroy(s);
        } else {
            err = "CMDxquery: failed to allocate streambuffer";
        }
    }
    MT_set_lock(pf_cache_lock, "CMDxquery");
    xquery_client_free_(ctx);
    MT_unset_lock(pf_cache_lock, "CMDxquery");
    if (err) {
	GDKerror((err==xquery_nondescriptive_error)?res->val.sval:err);
	VALclear(res);
        return GDK_FAIL;
    } 
    /* stream_printf(GDKout,"RES = %s\n",res->val.sval); */
    return GDK_SUCCEED;
}

/*
 * call a method in a temporary xquery client context
 */  
char*
xquery_method(stream *out,
              int rpctiming,
              char* module,
              char* uri,
              char *method,
              int argc,
              int itercnt,
              int** argcnt,
              str* argtpe,
              str* argval,
              BAT* shredBAT)
{
    lng usec = GDKusec();
    MT_Id XQthread_id = THRgettid(), old_tid;
    Thread XQthread = THRget(XQthread_id), old_thread;
    char *err, *ns = "fn", *mode = "xml-noheader-soap-root-iter";
    stream *s = NULL;
    mapi_client *mc = MAPIclient(GDKin, out, "xquery" );
    xquery_client *ctx;

    if (mc == NULL || mc->fc == NULL)
        return "xquery_method: out of client slots.\n";

    ctx = mc->fc;
    ctx->fderr = GDKerr;
    ctx->mode = 0;

    if (rpctiming){
        mode = "timing-rpcdtime-xml-noheader-soap-root-iter";
    }
    err = xquery_change_genType(ctx, mode);
    if (err) return err;

    old_tid = mc->t;
    old_thread = mc->thread;
    mc->t = XQthread_id;
    mc->thread = XQthread;
    monetSetChannel(XQthread, GDKin, out);
    if (argc > 1000) {
        /* hack: pass argc+1000 and you get debug output */
        s = open_wstream("/tmp/xrpc.mil");
        char *prologue = (char*) PFinitMIL();
        if (s) {
            ctx->fderr = s;
            ctx->mode |= XQ_DEBUG;
        }
        stream_write(ctx->fderr, prologue, strlen(prologue), 1);
        argc = argc % 1000;
    }
    if (err == NULL && module){
        err = xquery_module_load(ctx, ns="xrpc", module, uri); 
    }

    if (err == NULL) { 
        err = xquery_function_call(ctx, usec, ns, method, argc, itercnt, argcnt, argtpe, argval, shredBAT);
        if (err == (char*) -1) err = "xquery_method: function could not be resolved.\n";
    }

    if (s) {
        stream_close(ctx->fderr);
        stream_destroy(ctx->fderr);
    }
    monetSetChannel(XQthread, GDKin, GDKout);

    xquery_client_end(ctx, NULL);
    mc->t = old_tid;
    mc->thread = old_thread;
	mc->c->fdin = NULL;
	mc->c->fdout = NULL;

    mc->inuse = 0;
    return err;
}

/*
 * module initialization
 */
extern void xmlInitThreads(void);
bat *
xquery_prelude(void)
{
    MT_init_lock(pf_compiler_lock);
    MT_init_lock(pf_module_lock);
    MT_init_lock(pf_cache_lock);

    xmlInitThreads();
   
    xquery_compiled_modules = NULL;
    return NULL;
}

/*
 * module cleanup
 */
void
xquery_epilogue(void)
{
    xquery_client_flushall();
    MT_destroy_lock(pf_compiler_lock);
    MT_destroy_lock(pf_cache_lock);
}
/* vim:set shiftwidth=4 expandtab: */
