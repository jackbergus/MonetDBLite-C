@' Copyright Notice:
@' -----------------
@'
@' The contents of this file are subject to the Pathfinder Public License
@' Version 1.1 (the "License"); you may not use this file except in
@' compliance with the License.  You may obtain a copy of the License at
@' http://monetdb.cwi.nl/Legal/PathfinderLicense-1.1.html
@'
@' Software distributed under the License is distributed on an "AS IS"
@' basis, WITHOUT WARRANTY OF ANY KIND, either express or implied.  See
@' the License for the specific language governing rights and limitations
@' under the License.
@'
@' The Original Code is the Pathfinder system.
@'
@' The Original Code has initially been developed by the Database &
@' Information Systems Group at the University of Konstanz, Germany and
@' the Database Group at the Technische Universitaet Muenchen, Germany.
@' It is now maintained by the Database Systems Group at the Eberhard
@' Karls Universitaet Tuebingen, Germany.  Portions created by the
@' University of Konstanz, the Technische Universitaet Muenchen, and the
@' Universitaet Tuebingen are Copyright (C) 2000-2005 University of
@' Konstanz, (C) 2005-2008 Technische Universitaet Muenchen, and (C)
@' 2008-2010 Eberhard Karls Universitaet Tuebingen, respectively.  All
@' Rights Reserved.
@'
@' $Id$
@f ll_upwards
@a Peter Boncz 
@t loop-lifted upwards staircase steps

Previously, we used upwards steps that depended on the 'level' column.
These where non-loop-lifted. As opposed to XPath, XQuery produces query
plans with path steps *nested* in for-loops. Loop-lifted staircase join
algorithms deal with all iterations in a single document scan, whereas
non-loop-lifted algorithms can only be used repetitively (once for every
iteration).

The new loop-lifted variants depend on the 'size' column which allows
for skipping. Using  'level', this is not possible.

During the traversals, various per-iter bounds are needed. We heavily
exploit the fact that iter numbers are from a dense domain, and use
bound-arrays to store them, giving us O(1) access cost for this.

The upwards axes must see the full size_bat[void,int] (starting at 0@0), 
of which the first BUN must be a dummy (i.e. the collection root).

@verbatim
(time in msec)          10MB            100MB           1GB
    STEP                single  multi   single  multi   single  multi
    =================================================================
old parent                   5    646       12  45344       79    DNF
new parent                   5      7       10     27       72    249
old ancestor                 5    452       11  44962       66    DNF
new ancestor                 5      7       15     37      114    376 
old ancestor-or-self         6    454       19  44653      132    DNF
new ancestor-or-self         5      9       19     47      167    480

single: count(doc("auctionsX.xml")/descendant::person/STEP::*)
multi:  count(for $x in doc("auctionsX.xml")/descendant::person return $x/STEP::*)
@end verbatim

Experiments were performed on db2.cwi.nl (optimized 64-bits oid32 icc compile) 
on XMark datasets of various sizes with two query variants (single and multi)
for each step, one that executes the steps on a single sequence of N persons, 
and the other on N sequences of size 1. The latter variant takes the form of 
a for-loop and in the old non-loop-lifted implementation leads to 
repetitive execution.

We conclude the following from these experiments:
@itemize
@item loop-lifting is very effective, the loop-lifted variant is less
than twice slower on the multi-variant, whereas in the older variant
we observe quadratic degradation, causing the performance difference
to grow very large.
@item in case of parent on a single context sequence, the new variant is 
slightly faster than the old implementation. 
@item in case of ancestor-or-self on a single context sequence, 
performance is identical.
@item in case of ancestor on a single context sequence, the 
new algorithm is slower (up to a factor 2).
@end itemize
The new ancestor is 'optimal' in the sense that it only touches the
result nodes (plus the preceding siblings). However, it touches them 
twice, and the algorithm is more jumpy than the old level scan, and the 
size column is wider than level. These factors may explain why on single 
node sequences it is slower.

Taking into account that in single-iterations the performance loss
is limited, but is huge on multiple iterations, the new loop-lifted 
algorithms for the upwards XPath axes seem a profitable addition for the 
pathfinder runtime.

@h
#ifndef LL_UPWARDS_H
#define LL_UPWARDS_H
#define PF_SIBLING_PROBES 64

#define SKIPHOLES(pre, pre_size) {                \
    while(pre_size[pre] & (1U<<31))               \
        pre += 1 + (pre_size[pre] & ~(1U<<31));   \
}

oid speculate_skip(oid, oid, oid, int, unsigned int*, unsigned char*);

#endif /* LL_UPWARDS_H */

@c
#include "pf_config.h"
#include <gdk.h>
#include "shredder.h" /* for XML_DEPTH_MAX */
#include "ll_upwards.h"

static char LL_UPWARDS_PARENT[] = "parent";
static char LL_UPWARDS_ANCESTOR[] = "ancestor";
static char LL_UPWARDS_ANCESTOR_SELF[] = "ancestor-or-self";

typedef struct {
 oid iter;
 oid pre; 
} duple;

@= found_parent

    /* parent pass: generate the parent as a result 
     */
    oid idx = iter - min_iter;
    oid pos = bounds[idx]++;                    /* position to write result to */  
    oid parent = stack[depth-1];                /* parent is top-of-stack */ 
    oid iter_parent = iter_stack[depth-1][idx]; /* last parent at this level for this iter */

    if (pos >= result_size) break; /* SANITY */

    iter_stack[depth-1][idx] = parent;
    if (iter_parent > parent) tail_sorted = 0;
    result_pre[pos] = (iter_parent == parent)?oid_nil:parent; /* nils are later filtered out */
    result_iter[pos] = iter;

@= found_ancestor_cnt

    /* anc pass1: count how many nodes are on the stack (that we haven't seen before in this iter) 
     */
    int i = depth;
    while(i > 0 && stack[i-1] > bounds[iter-min_iter]) i--;
    bounds[iter-min_iter] = stack[depth-1]; /* biggest ancestor so far for this iter */
    result_iter[cur] = depth-i;             /* #new ancestors generated for this context node */

@= found_ancestor_gen

    /* anc pass2: generate the precomputed number of (unique) ancestors for this iter 
     */
    oid* final_result_iter = bounds; /* HACK, result was passed as bounds  */
    oid* final_result_pre  = bounds_t; /* HACK, result was passed as bounds  */
    int hitcnt = (int) result_iter[cur]; 
    oid pos = result_pre[cur];
    if (pos > result_size || hitcnt > depth) break; /* SANITY */
    while(hitcnt > 0) {
        final_result_pre[pos] = stack[depth-hitcnt];    
        final_result_iter[pos] = iter;
        hitcnt--; pos++;
    }

@= upwards_core
static int 
ll_upwards_@1(                            /* OUTPUT: */
        oid *result_iter,
        oid *result_pre, 
        oid result_size,   /* - pre-allocated result array */
        oid* bounds, oid *bounds_t,
        oid** iter_stack,    /* - per iter bound */ 
                                          /* DOCUMENT: */
        unsigned int* pre_size,           /* - pre_size column */
        unsigned char* pre_level,         /* - pre_level column */
        oid limit,                        /* - valid range of pre ids in the document */
                                          /* INPUT: */
        oid min_iter,                     /* - minimum iter */      
        duple* context, oid context_size) /* - the context array and its size */
{  
    oid buf[XML_DEPTH_MAX+1], *stack=buf; /* STACK CONTAINS pre NUMBERS */ 
    oid root = 1; /* 0=collection node, 1=root of first fragment */  
    oid pre = root;  
    oid cur = 0;  
    int depth = 0;  
    int tail_sorted = 2;  

    *stack++ = oid_nil; /* bogus parent, filtered out later */
   (void) bounds_t;
   (void) result_pre;
   (void) result_size;
   (void) min_iter;
   (void) iter_stack;

    /* if the collection node is passed in, skip it */
    while(cur < context_size && context[cur].pre == 0) cur++;

    /* we perform a forwards scan with skipping, that carries out an *optimal* 
     * depth-first DOM tree traversal (where we visit nodes only if needed)
     */ 
    while(cur < context_size) { /* while still context nodes active */

        if (context[cur].pre == pre) { 

            /* generate result for each iteration */
            while(context[cur].pre == pre) { /* can disregard cur<context_size, thanks to sentinel */         
                oid iter = context[cur].iter;      
                 @:found_@1@
                cur++;
            }

        } else if (context[cur].pre <= pre + pre_size[pre]) {

            /* next context node is in the descendants: go find it */
            stack[depth++] = pre;
            pre = pre+1;
            SKIPHOLES(pre, pre_size);
              if (depth == XML_DEPTH_MAX || pre > limit) break; /* SANITY */

        } else if (depth == 0 || context[cur].pre <= stack[depth-1] + pre_size[stack[depth-1]]) {
            oid off = pre;
            int budget = PF_SIBLING_PROBES;
            int cnt = 0;

            /* in the branch that is on the stack, but in some sibling that we need to find */
            while(pre + pre_size[pre] < context[cur].pre) {
                pre = pre + pre_size[pre] + 1;
                SKIPHOLES(pre, pre_size); /* skip from sibling to sibling */
                  if (pre > limit) break; /* SANITY */
                  if (++cnt == budget) {
                    oid old = pre;
                    pre = speculate_skip(pre, context[cur].pre, pre-off, budget, pre_size, pre_level); 
                    if (pre == old) { 
                        budget += budget; /* skip failed: wait longer next time */
                    }
                    off = pre; cnt = 0;
                }
            }
            if (depth == 0)
                    root = pre;
        } else {

            /* pop the stack */
            pre = stack[--depth];
        }
   }
   return (cur == context_size) + tail_sorted;
}

@c

/* If an XML is regularly structured (contains "list" or "table" like data) such that we have
 * a subtree with very many siblings, the upwards steps will have to touch all the preceding
 * siblings, if some context node is in that subtree. In some trees, there may be O(N) preceding
 * siblings. Given that the expected parent/ancestor result for such trees is very small (<= O(log(N))), 
 * this is far from optimal.
 *
 * Thus, we added code that after traversing some number of siblings, speculatively tries
 * to skip siblings. To recognize such speculative siblings, we also need the level column.
 * We take care not to waste more time speculating than we already did traversing preceding siblings. 
 */
oid
speculate_skip(oid pre, oid dst, oid skip, int budget, unsigned int* pre_size, unsigned char* pre_level) {

    skip = skip << 6;
    if (pre + skip < dst) {
        oid cur = pre + skip;
        int cnt = 0, depth = pre_level[pre];
        SKIPHOLES(cur, pre_size);
        while(cur < dst) {
            if (pre_level[cur] == depth) {
                pre = cur; /* we found a sibling, without seeing all intermediate siblings!! */
                /* now go for more.. double skip distance, speculation budget */
                skip += skip; skip += skip; 
                budget += budget; budget += budget;
                cur += skip; 
                cnt = 0;
                if (cur >= dst) break;
            } else {
                cur += pre_size[cur] + 1; /* skip over this deeper node */
            }
            SKIPHOLES(cur, pre_size);
            if (cnt++ >= budget) return pre; /* could not find it quickly */
        }
    }
    return pre;
}

@:upwards_core(parent)@
@:upwards_core(ancestor_cnt)@
@:upwards_core(ancestor_gen)@

static int
ll_upwards(               /* RESULT: */
        BAT **ret,        /* - [oid,oid] bat sorted on [iter,pre] */
                          /* INPUT: */
        BAT *iter_bat,    /* - [void,oid] bat, no order assumed */
        BAT *ctx_bat,     /* - [void,oid] bat, synced with iter_bat */
                          /* DOCUMENT: */
        BAT *size_bat,    /* - [void,int] bat, doc representation with holes */ 
        BAT *level_bat,   /* - [void,chr] bat, doc representation with holes */ 
        str axis) 
{ 
    oid killed = (axis == LL_UPWARDS_ANCESTOR_SELF)?oid_nil:1; /* 1=root of first fragment */
    oid *bounds, niters=1, min_iter = LL_CONSTANT(1)<<(8*sizeof(oid)-1), max_iter = 0; 
    oid i=0, n=0, m = BATcount(ctx_bat);
    BUN p = BUNfirst(iter_bat), q = BUNlast(iter_bat), r = BUNfirst(ctx_bat);
    unsigned int *pre_size = (unsigned int*) Tloc(size_bat, BUNfirst(size_bat));
    unsigned char *pre_level = (unsigned char*) Tloc(level_bat, BUNfirst(level_bat));
    duple *context, *prune;
    int status = GDK_FAIL;
    BAT *bn = NULL;
    oid *context_result_pre, *context_result_iter;
    int tail_sorted = 1;

    if (!ALIGNsynced(iter_bat,ctx_bat)) {
        GDKerror("%s: iter and context bat should be in sync.\n", axis);
        return status;
    }
    if (!(BATtordered(ctx_bat) & 1))
    {
        GDKerror("%s: context bat must be ordered on tail.\n", axis);
        return status;
    }
    if (size_bat->hseqbase || !BAThdense(size_bat)) {
        GDKerror("%s: illegal size bat passed in.\n", axis);
        return status;
    }
    if (level_bat->hseqbase || !BAThdense(level_bat)) {
        GDKerror("%s: illegal level bat passed in.\n", axis);
        return status;
    }

    /* context will hold the pruned set of [iter,pre] context nodes */
    context = (duple*) GDKmalloc((m+1)*sizeof(duple));
    if (context == NULL) return status;

    /* gather the context nodes and analyze them (order, min/max iter)  */
@= ll_upwards_min_max
                if (context[i].iter < min_iter) min_iter = context[i].iter;
                if (context[i].iter > max_iter) max_iter = context[i].iter;
@
@= ll_upwards_copy
            while(p < q) {
                context[i].iter = @1;
                context[i].pre  = @2;
                @3
                  i++; p++; r++;
            }
@
@c
    if (p < q) {
        if (!(BATtordered(iter_bat)&1)) {
            if (BATtdense(iter_bat) && BATtdense(ctx_bat)) {
                oid iter = iter_bat->tseqbase;
                oid pre  = ctx_bat->tseqbase;
                @:ll_upwards_copy(iter++, pre++, @:ll_upwards_min_max@)@
            } else
            if (BATtdense(iter_bat) && ctx_bat->ttype == TYPE_oid) {
                oid iter = iter_bat->tseqbase;
                @:ll_upwards_copy(iter++, *(oid*) Tloc(ctx_bat,r), @:ll_upwards_min_max@)@
            } else
            if (iter_bat->ttype == TYPE_oid && BATtdense(ctx_bat)) {
                oid pre  = ctx_bat->tseqbase;
                @:ll_upwards_copy(*(oid*) Tloc(iter_bat,p), pre++, @:ll_upwards_min_max@)@
            } else
            if (iter_bat->ttype == TYPE_oid  && ctx_bat->ttype == TYPE_oid) {
                @:ll_upwards_copy(*(oid*) Tloc(iter_bat,p), *(oid*) Tloc(ctx_bat,r), @:ll_upwards_min_max@)@
            } else {
                assert(0); /* should never happen */
            }
        } else {
            /* ordered iters, so we know min and max */
            if (BATtdense(iter_bat) && BATtdense(ctx_bat)) {
                oid iter = iter_bat->tseqbase;
                oid pre  = ctx_bat->tseqbase;
                @:ll_upwards_copy(iter++, pre++,)@
            } else
            if (BATtdense(iter_bat) && ctx_bat->ttype == TYPE_oid) {
                oid iter = iter_bat->tseqbase;
                @:ll_upwards_copy(iter++, *(oid*) Tloc(ctx_bat,r),)@
            } else
            if (iter_bat->ttype == TYPE_oid && BATtdense(ctx_bat)) {
                oid pre  = ctx_bat->tseqbase;
                @:ll_upwards_copy(*(oid*) Tloc(iter_bat,p), pre++,)@
            } else
            if (iter_bat->ttype == TYPE_oid && ctx_bat->ttype == TYPE_oid) {
                @:ll_upwards_copy(*(oid*) Tloc(iter_bat,p), *(oid*) Tloc(ctx_bat,r),)@
            } else {
                assert(0); /* should never happen */
            }
            min_iter = context[0].iter;
            max_iter = context[i-1].iter;
        }
        niters += max_iter - min_iter; /* the size of the per-iter lookup arrays */
    }
    
    /* prune is a temporary array of duples, one duple per iter
     * - duple.pre  contains the pre-bound for pruning the previous node
     * - duple.iter is (mis)used to contain the position in context[] of
     *              the previous node (for that same iter, that is).
     */
    prune = (duple*) GDKmalloc(MAX(1,niters)*sizeof(duple));
    if (prune == NULL) {
        GDKfree(context);
        return status;
    }
    for(i=0; i<niters; i++) {
        prune[i].pre = 1; /* 1 = root of first fragment */
        prune[i].iter = oid_nil; 
    }

    /* we can now do pruning, remember we now see context nodes in pre order */
    for(i=0; i<m; i++) {
        oid pre = context[i].pre;
        oid iter = context[i].iter - min_iter;

        if (pre > 0 && pre < prune[iter].pre) { 
            context[prune[iter].iter].pre = killed; /* prune it */ 
        }
        /* set the new bound */
        prune[iter].iter = i; 
        prune[iter].pre = pre + 1; /* this just removes duplicates */
        if (axis != LL_UPWARDS_PARENT) { 
            prune[iter].pre += pre_size[pre]; /* this prunes ancestors */
        }
    }
    GDKfree(prune);

    /* remove pruned tuples */
    for(n=i=0; i<m; i++) {
        oid pre = context[i].pre;
        oid iter = context[i].iter;
        int inc = (pre != killed); /* also prunes root (of first fragment only) */
        context[n].pre = pre;
        context[n].iter = iter;
        n += inc; /* pruned nodes will be overwritten */
    }
    /* write sentinel record */
    context[n].pre = oid_nil;
    context[n].iter = oid_nil;

    /* bounds is used (mostly) to keep per-iter start positions in the result BAT
     * it allows us to directly generate a [iter,pre] ordered result
     */
    bounds = (oid*) GDKzalloc((niters+1)*sizeof(oid));
    if (bounds == NULL) {
        GDKfree(context);
        return status;
    }

    /* go do the staircase join */
    if (axis == LL_UPWARDS_PARENT) {
        /* iter_stack contains for each depth an array[iter], allocated in bulk */
        oid *iter_stack[XML_DEPTH_MAX];
        oid *buf = (oid*) GDKmalloc(MAX(1,(m=XML_DEPTH_MAX*niters))*sizeof(oid)); 
        if (buf) {
             /* initialize it, filled will all nil */
             for(i=0; i<(size_t) XML_DEPTH_MAX; i++) iter_stack[i] = buf + i*niters;
             for(i=0; i<m; i++) buf[i] = oid_nil;

            /* bounds will contain offsets into the result for each iter */
            for(i=0; i<n; i++) 
                bounds[1+context[i].iter - min_iter]++; /* count by iter */
            for(i=1; i<=niters; i++) 
                bounds[i] += bounds[i-1];  /* running sum produces offsets */

            bn = BATnew(TYPE_oid, TYPE_oid, n);
            if (bn) {
                int r = ll_upwards_parent(
                            context_result_iter = (oid*) Hloc(bn, BUNfirst(bn)),
                            context_result_pre  = (oid*) Tloc(bn, BUNfirst(bn)),
                            n, bounds, NULL, iter_stack+1, 
                            pre_size, pre_level,
                            BATcount(size_bat), 
                            min_iter, context, n);
                 if (r) {
                    /* filter out duplicates and non-existing fragment roots (represented by oid_nils) */
                    for(m=i=0; i<n; i++) {
                        oid pre = context_result_pre[i];
                        oid iter = context_result_iter[i];
                        context_result_pre[m] = pre;
                        context_result_iter[m] = iter;
                        m += (pre != oid_nil);
                    }
                    status = GDK_SUCCEED;

                    /* for each context node, parent gives back 1 or 0 results */ 
                    if (iter_bat->tkey) BATkey(bn, TRUE);
                    tail_sorted = r >> 1;
                } else  {
                    GDKerror("%s: illegal data in size column or context list.\n", axis);
                }
            }
            GDKfree(buf);
        }
    } else if ( (context_result_pre=GDKzalloc(MAX(1,n)*sizeof(oid))) != NULL &&
                (context_result_iter=GDKzalloc(MAX(1,n)*sizeof(oid))) != NULL ) {
        /* in first pass, bounds contains a partitioning bound (=0 < root) */
        if (ll_upwards_ancestor_cnt(
                 context_result_iter, 
                 context_result_pre, 
                 n, 
                 bounds, NULL, NULL,
                 pre_size, pre_level,
                 BATcount(size_bat), 
                 min_iter, context, n))
        {
            /* count the hits per-iter, by examining hitcnt (context_result_iter) of each context node.
             * while doing so, put in context_result_pre the absolute position of self in the result 
             */
            for(i=0; i <= niters; i++)
                bounds[i] = 0; /* reset iter-bounds, now use it for counting again */

            for(i=0; i<n; i++) {
                oid iter = context[i].iter - min_iter; 
                oid hitcnt = context_result_iter[i];
                context_result_pre[i] = bounds[iter+1]; /* offset within the iter block */
                bounds[iter+1] += hitcnt + (axis == LL_UPWARDS_ANCESTOR_SELF); /* per-iter result size */
            }
            for(i=1; i<=niters; i++) 
                bounds[i] += bounds[i-1];  /* running sum to get per-iter offsets */
            m = bounds[niters]; /* this is the size of the result */

            for(i=0; i<n; i++) {
                oid iter = context[i].iter - min_iter; 
                context_result_pre[i] += bounds[iter]; /* add iter-start to get absolute offset */
            }

            /* second pass, generating the results, knowing the final result size m */
            bn = BATnew(TYPE_oid, TYPE_oid, m);
            if (bn) {
                if (axis == LL_UPWARDS_ANCESTOR_SELF) { /* insert the self nodes beforehand */ 
                    oid *result_iter = (oid*) Hloc(bn, BUNfirst(bn));
                    oid *result_pre  = (oid*) Tloc(bn, BUNfirst(bn));
                    for(i=0; i<n; i++) {
                        int hitcnt = (int) context_result_iter[i]; /* hitcnt */
                        oid pos = context_result_pre[i] + hitcnt;
                        result_pre[pos] = context[i].pre;
                        result_iter[pos] = context[i].iter;
                    }
                }
                if (ll_upwards_ancestor_gen(
                        context_result_iter, 
                        context_result_pre, 
                        m,
                        (oid*) Hloc(bn, BUNfirst(bn)), /* HACK, pass result as bounds */ 
                        (oid*) Tloc(bn, BUNfirst(bn)), /* HACK, pass result as bounds */ 
                        NULL,
                        pre_size, pre_level,
                        BATcount(size_bat), 
                        min_iter, context, n)) 
                {
                    status = GDK_SUCCEED;
                } else {
                    GDKerror("%s: illegal data during result generation.\n", axis);
                }
            }
        } else {
            GDKerror("%s: illegal data in size column or context list.\n", axis);
        }
        GDKfree(context_result_pre);
        GDKfree(context_result_iter);
    }
    GDKfree(bounds);
    GDKfree(context);

    if (status == GDK_SUCCEED) {
        BATsetcount(bn, m);
        bn->hsorted = GDK_SORTED;
        if (BATcount(bn) == BATcount(iter_bat)) {
            bn->hdense = BATtdense(iter_bat);
            BATseqbase(bn, iter_bat->tseqbase);
            BATkey(bn, iter_bat->tkey);
        }
        bn->tsorted = 0;
        if (niters == 1) {
            bn->tsorted = tail_sorted;
            BATkey(BATmirror(bn), 1);
        }
        *ret = bn;
    } else if (bn) {
        BBPreclaim(bn);
    }
    return status;
}

int
PFll_parent(BAT **ret, BAT *iter_bat, BAT *ctx_bat, BAT *pre_size, BAT *pre_level) { 
    return ll_upwards(ret, iter_bat, ctx_bat, pre_size, pre_level, LL_UPWARDS_PARENT);
}

int
PFll_ancestor(BAT **ret, BAT *iter_bat, BAT *ctx_bat, BAT *pre_size, BAT *pre_level) { 
    return ll_upwards(ret, iter_bat, ctx_bat, pre_size, pre_level, LL_UPWARDS_ANCESTOR);
}

int
PFll_ancestor_or_self(BAT **ret, BAT *iter_bat, BAT *ctx_bat, BAT *pre_size, BAT *pre_level) { 
    return ll_upwards(ret, iter_bat, ctx_bat, pre_size, pre_level, LL_UPWARDS_ANCESTOR_SELF);
}
