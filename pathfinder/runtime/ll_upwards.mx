@' Copyright Notice:
@' -----------------
@'
@' The contents of this file are subject to the Pathfinder Public License
@' Version 1.1 (the "License"); you may not use this file except in
@' compliance with the License.  You may obtain a copy of the License at
@' http://monetdb.cwi.nl/Legal/PathfinderLicense-1.1.html
@'
@' Software distributed under the License is distributed on an "AS IS"
@' basis, WITHOUT WARRANTY OF ANY KIND, either express or implied.  See
@' the License for the specific language governing rights and limitations
@' under the License.
@'
@' The Original Code is the Pathfinder system.
@'
@' The Original Code has initially been developed by the Database &
@' Information Systems Group at the University of Konstanz, Germany and
@' is now maintained by the Database Systems Group at the Technische
@' Universitaet Muenchen, Germany.  Portions created by the University of
@' Konstanz and the Technische Universitaet Muenchen are Copyright (C)
@' 2000-2005 University of Konstanz and (C) 2005-2006 Technische
@' Universitaet Muenchen, respectively.  All Rights Reserved.
@'
@' $Id$
@f ll_upwards
@a Peter Boncz 
@t loop-lifted upwards staircase steps

Previously, we used upwards steps that depended on the 'level' column.
These where non-loop-lifted. As opposed to XPath, XQuery produces query
plans with path steps *nested* in for-loops. Loop-lifted staircase join
algorithms deal with all iterations in a single document scan, whereas
non-loop-lifted algorithms can only be used repetitively (once for every
iteration).

The new loop-lifted variants depend on the 'size' column which allows
for skipping. Using  'level', this is not possible.

During the traversals, various per-iter bounds are needed. We heavily
exploit the fact that iter numbers are from a dense domain, and use
bound-arrays to store them, giving us O(1) access cost for this.

The upwards axes must see the full size_bat[void,int] (starting at 0@0), 
of which the first BUN must be a dummy (i.e. the collection root).

@verbatim
(time in msec)          10MB            100MB           1GB
    STEP                single  multi   single  multi   single  multi
    =================================================================
old parent                   5    646       12  45344       79    DNF
new parent                   5      7       10     27       72    249
old ancestor                 5    452       11  44962       66    DNF
new ancestor                 5      7       15     37      114    376 
old ancestor-or-self         6    454       19  44653      132    DNF
new ancestor-or-self         5      9       19     47      167    480

single: count(doc("auctionsX.xml")/descendant::person/STEP::*)
multi:  count(for $x in doc("auctionsX.xml")/descendant::person return $x/STEP::*)
@end verbatim

Experiments were performed on db2.cwi.nl (optimized 64-bits oid32 icc compile) 
on XMark datasets of various sizes with two query variants (single and multi)
for each step, one that executes the steps on a single sequence of N persons, 
and the other on N sequences of size 1. The latter variant takes the form of 
a for-loop and in the old non-loop-lifted implementation leads to 
repetitive execution.

We conclude the following from these experiments:
@itemize
@item loop-lifting is very effective, the loop-lifted variant is less
than twice slower on the multi-variant, whereas in the older variant
we observe quadratic degradation, causing the performance difference
to grow very large.
@item in case of parent on a single context sequence, the new variant is 
slightly faster than the old implementation. 
@item in case of ancestor-or-self on a single context sequence, 
performance is identical.
@item in case of ancestor on a single context sequence, the 
new algorithm is slower (up to a factor 2).
@end itemize
The new ancestor is 'optimal' in the sense that it only touches the
result nodes (plus the preceding siblings). However, it touches them 
twice, and the algorithm is more jumpy than the old level scan, and the 
size column is wider than level. These factors may explain why on single 
node sequences it is slower.

Taking into account that in single-iterations the performance loss
is limited, but is huge on multiple iterations, the new loop-lifted 
algorithms for the upwards XPath axes seem a profitable addition for the 
pathfinder runtime.
@c
#include <gdk.h>
#include "pathfinder.h"

static char LL_UPWARDS_PARENT[] = "parent";
static char LL_UPWARDS_ANCESTOR[] = "ancestor";
static char LL_UPWARDS_ANCESTOR_SELF[] = "ancestor-or-self";

typedef struct {
 oid iter;
 oid pre; 
} duple;

static INLINE oid 
skipholes(oid pre, unsigned int *pre_size) {
     while(pre_size[pre] & (1<<31)) 
         pre += 1 + (pre_size[pre] & ~(1<<31)); /* skip over holes */
     return pre; 
}

@= found_parent

    /* parent pass: generate the parent as a result 
     */
    oid idx = iter - min_iter;
    oid pos = bounds[idx]++;                    /* position to write result to */  
    oid parent = stack[depth-1];                /* parent is top-of-stack */ 
    oid iter_parent = iter_stack[depth-1][idx]; /* last parent at this level for this iter */

    if (pos >= result_size) break; /* SANITY */

    iter_stack[depth-1][idx] = parent;
    result[pos].pre = (iter_parent == parent)?oid_nil:parent; /* nils are later filtered out */
    result[pos].iter = iter;

@= found_ancestor_cnt

    /* anc pass1: count how many nodes are on the stack (that we haven't seen before in this iter) 
     */
    int i = depth;
    while(i > 0 && stack[i-1] > bounds[iter-min_iter]) i--;
    bounds[iter-min_iter] = stack[depth-1]; /* biggest ancestor so far for this iter */
    result[cur].iter = depth-i;             /* #new ancestors generated for this context node */

@= found_ancestor_gen

    /* anc pass2: generate the precomputed number of (unique) ancestors for this iter 
     */
    duple* final_result = (duple*) bounds; /* HACK, result was passed as bounds  */
    int hitcnt = (int) result[cur].iter; 
    oid pos = result[cur].pre;
    if (pos > result_size || hitcnt > depth) break; /* SANITY */
    while(hitcnt > 0) {
        final_result[pos].pre = stack[depth-hitcnt];    
        final_result[pos].iter = iter;
        hitcnt--; pos++;
    }

@= upwards_core
static int 
ll_upwards_@1(                            /* OUTPUT: */
        duple* result, oid result_size,   /* - pre-allocated result array */
        oid* bounds, oid** iter_stack,    /* - per iter bound */ 
                                          /* DOCUMENT: */
        unsigned int* pre_size,           /* - pre_size column */
        oid limit,                        /* - valid range of pre ids in the document */
                                          /* INPUT: */
        oid min_iter,                     /* - minimum iter */      
        duple* context, oid context_size) /* - the context array and its size */
{  
    oid buf[XML_DEPTH_MAX+1], *stack=buf; /* STACK CONTAINS pre NUMBERS */ 
    oid root = 1; /* 0=collection node, 1=root of first fragment */  
    oid pre = root;  
    oid cur = 0;  
    int depth = 0;  

    *stack++ = oid_nil; /* bogus parent, filtered out later */
   (void) result_size;
   (void) min_iter;
   (void) iter_stack;

    /* we perform a forwards scan with skipping, that carries out an *optimal* 
     * depth-first DOM tree traversal (where we visit nodes only if needed)
     */ 
    while(cur < context_size) { /* while still context nodes active */

        if (context[cur].pre == pre) { 

            /* generate result for each iteration */
            while(context[cur].pre == pre) { /* can disregard cur<context_size, thanks to sentinel */         
                oid iter = context[cur].iter;      
 	        @:found_@1@
                cur++;
            }

        } else if (context[cur].pre <= pre + pre_size[pre]) {

            /* next context node is in the descendants: go find it */
            stack[depth++] = pre;
            pre = skipholes(pre+1, pre_size);
  	    if (depth == XML_DEPTH_MAX || pre > limit) break; /* SANITY */

        } else if (depth == 0) {

            /* enter another fragment */
            pre = skipholes(pre+1+pre_size[pre], pre_size);
  	    if (pre > limit) break; /* SANITY */
            root = pre;

        } else if (context[cur].pre < stack[depth-1] + pre_size[stack[depth-1]]) {

            /* none of the above, but next context node is in the descendants of the parent */
            pre = skipholes(pre + pre_size[pre] + 1, pre_size); /* go to the next sibling */
  	    if (pre > limit) break; /* SANITY */

        } else {

            /* pop the stack */
            pre = stack[--depth];
        }
   }
   return (cur == context_size);
}

@c
@:upwards_core(parent)@
@:upwards_core(ancestor_cnt)@
@:upwards_core(ancestor_gen)@

static int
ll_upwards(               /* RESULT: */
        BAT **ret,        /* - [oid,oid] bat sorted on [iter,pre] */
                          /* INPUT: */
        BAT *iter_bat,    /* - [void,oid] bat, no order assumed */
        BAT *ctx_bat,     /* - [void,oid] bat, synced with iter_bat */
                          /* DOCUMENT: */
        BAT *size_bat,    /* - [void,int] bat, doc representation with holes */ 
        str axis) 
{ 
    oid killed = (axis == LL_UPWARDS_ANCESTOR_SELF)?oid_nil:1; /* 1=root of first fragment */
    oid *bounds, niters=1, min_iter = LL_CONSTANT(1)<<(8*sizeof(oid)-1), max_iter = 0; 
    oid i=0, k = BUNsize(iter_bat), n = BUNsize(ctx_bat), m = BATcount(ctx_bat);
    BUN p = BUNfirst(iter_bat), q = BUNlast(iter_bat), r = BUNfirst(ctx_bat);
    unsigned int *pre_size = (unsigned int*) BUNfirst(size_bat);
    duple *context, *context_result, *prune;
    int status = GDK_FAIL;
    BAT *bn = NULL;

    if (!ALIGNsynced(iter_bat,ctx_bat)) {
        GDKerror("%s: iter and context bat should be in sync.\n", axis);
        return status;
    }
    if (BUNsize(size_bat) != sizeof(int) || size_bat->hseqbase || !BAThdense(size_bat)) {
        GDKerror("%s: illegal size bat passed in.\n", axis);
        return status;
    }

    /* context will hold the pruned set of [iter,pre] context nodes */
    context = (duple*) GDKmalloc((m+1)*sizeof(duple));
    if (context == NULL) return status;

    /* gather the context nodes and analyze them (order, min/max iter)  */
    if (p < q) {
	if (!(BATtordered(iter_bat)&1)) {
	    while(p < q) {
                context[i].iter = *(oid*) BUNtail(iter_bat,p);
                context[i].pre  = *(oid*) BUNtail(ctx_bat,r);
	        if (context[i].iter < min_iter) min_iter = context[i].iter;
	        if (context[i].iter > max_iter) max_iter = context[i].iter;
  	        i++; p += k; r += n;
            }
        } else {
            /* ordered iters, so we know min and max */
	    while(p < q) {
                context[i].iter = *(oid*) BUNtail(iter_bat,p);
                context[i].pre  = *(oid*) BUNtail(ctx_bat,r);
  	        i++; p += k; r += n;
            }
            min_iter = context[0].iter;
            max_iter = context[i-1].iter;
        }
        niters += max_iter - min_iter; /* the size of the per-iter lookup arrays */
    }
    
    if (!(BATtordered(ctx_bat)&1)) { /* if needed, sort context set on pre-s */
        GDKqsort(context, NULL, m, sizeof(duple), TYPE_oid, sizeof(oid));
    }

    /* prune is a temporary array of duples, one duple per iter
     * - duple.pre  contains the pre-bound for pruning the previous node
     * - duple.iter is (mis)used to contain the position in context[] of
     *              the previous node (for that same iter, that is).
     */
    prune = (duple*) GDKmalloc(niters*sizeof(duple));
    if (prune == NULL) {
        GDKfree(context);
        return status;
    }
    for(i=0; i<niters; i++) {
        prune[i].pre = 1; /* 1 = root of first fragment */
        prune[i].iter = oid_nil; 
    }

    /* we can now do pruning, remember we now see context nodes in pre order */
    for(i=0; i<m; i++) {
        oid pre = context[i].pre;
        oid iter = context[i].iter - min_iter;

        if (pre < prune[iter].pre) { 
            context[prune[iter].iter].pre = killed; /* prune it */ 
        }
        /* set the new bound */
        prune[iter].iter = i; 
        prune[iter].pre = pre + 1; /* this just removes duplicates */
        if (axis != LL_UPWARDS_PARENT) { 
            prune[iter].pre += pre_size[pre]; /* this prunes ancestors */
        }
    }
    GDKfree(prune);

    /* remove pruned tuples */
    for(n=i=0; i<m; i++) {
        oid pre = context[i].pre;
        oid iter = context[i].iter;
        int inc = (pre != killed); /* also prunes root (of first fragment only) */
        context[n].pre = pre;
        context[n].iter = iter;
        n += inc; /* pruned nodes will be overwritten */
    }
    /* write sentinel record */
    context[n].pre = oid_nil;
    context[n].iter = oid_nil;

    /* bounds is used (mostly) to keep per-iter start positions in the result BAT
     * it allows us to directly generate a [iter,pre] ordered result
     */
    bounds = (oid*) GDKzalloc((niters+1)*sizeof(oid));
    if (bounds == NULL) {
        GDKfree(context);
        return status;
    }

    /* go do the staircase join */
    if (axis == LL_UPWARDS_PARENT) {
        /* iter_stack contains for each depth an array[iter], allocated in bulk */
        oid *iter_stack[XML_DEPTH_MAX];
        oid *buf = (oid*) GDKmalloc((m=XML_DEPTH_MAX*niters)*sizeof(oid)); 
        if (buf) {
             /* initialize it, filled will all nil */
             for(i=0; i<(size_t) XML_DEPTH_MAX; i++) iter_stack[i] = buf + i*niters;
             for(i=0; i<m; i++) buf[i] = oid_nil;

            /* bounds will contain offsets into the result for each iter */
            for(i=0; i<n; i++) 
                bounds[1+context[i].iter - min_iter]++; /* count by iter */
            for(i=1; i<=niters; i++) 
                bounds[i] += bounds[i-1];  /* running sum produces offsets */

            bn = BATnew(TYPE_oid, TYPE_oid, n);
            if (bn) {
                if (ll_upwards_parent(
                    context_result = (duple*) BUNfirst(bn), n, 
                    bounds, iter_stack+1, 
                    pre_size,
                    BATcount(size_bat), 
                    min_iter, context, n))
                {
                    /* filter out duplicates and non-existing fragment roots (represented by oid_nils) */
                    for(m=i=0; i<n; i++) {
                        oid pre = context_result[i].pre;
                        oid iter = context_result[i].iter;
                        context_result[m].pre = pre;
                        context_result[m].iter = iter;
                        m += (pre != oid_nil);
                    }
                    status = GDK_SUCCEED;

                    /* for each context node, parent gives back 1 or 0 results */ 
    	            if (iter_bat->tkey) BATkey(bn, TRUE);
                } else  {
                    GDKerror("%s: illegal data in size column or context list.\n", axis);
                }
            }
            GDKfree(buf);
        }
    } else if ((context_result=GDKzalloc(n*sizeof(duple))) != NULL) {
        /* in first pass, bounds contains a partitioning bound (=0 < root) */
        if (ll_upwards_ancestor_cnt(
                 context_result, n, 
                 bounds, NULL,
                 pre_size,
                 BATcount(size_bat), 
                 min_iter, context, n))
        {
            /* count the hits per-iter, by examining hitcnt (context_result.iter) of each context node.
             * while doing so, put in context_result.pre the absolute position of self in the result 
             */
            for(i=0; i <= niters; i++)
                bounds[i] = 0; /* reset iter-bounds, now use it for counting again */

            for(i=0; i<n; i++) {
                oid iter = context[i].iter - min_iter; 
                oid hitcnt = context_result[i].iter;
                context_result[i].pre = bounds[iter+1]; /* offset within the iter block */
                bounds[iter+1] += hitcnt + (axis == LL_UPWARDS_ANCESTOR_SELF); /* per-iter result size */
            }
            for(i=1; i<=niters; i++) 
                bounds[i] += bounds[i-1];  /* running sum to get per-iter offsets */
            m = bounds[niters]; /* this is the size of the result */

            for(i=0; i<n; i++) {
                oid iter = context[i].iter - min_iter; 
                context_result[i].pre += bounds[iter]; /* add iter-start to get absolute offset */
            }

            /* second pass, generating the results, knowing the final result size m */
            bn = BATnew(TYPE_oid, TYPE_oid, m);
            if (bn) {
                if (axis == LL_UPWARDS_ANCESTOR_SELF) { /* insert the self nodes beforehand */ 
                    duple *result = (duple*) BUNfirst(bn);
                    for(i=0; i<n; i++) {
                        int hitcnt = (int) context_result[i].iter; /* hitcnt */
                        oid pos = context_result[i].pre + hitcnt;
                        result[pos].pre = context[i].pre;
                        result[pos].iter = context[i].iter;
                    }
                }
		if (ll_upwards_ancestor_gen(
                        context_result, m,
                        (oid*) BUNfirst(bn), NULL, /* HACK, pass result as bounds */ 
                        pre_size,
                        BATcount(size_bat), 
                        min_iter, context, n)) 
                {
                    status = GDK_SUCCEED;
                } else {
                    GDKerror("%s: illegal data during result generation.\n", axis);
                }
            }
        } else {
            GDKerror("%s: illegal data in size column or context list.\n", axis);
        }
        GDKfree(context_result);
    }
    GDKfree(bounds);
    GDKfree(context);

    if (status == GDK_SUCCEED) {
        BATsetcount(bn, m);
        bn->batBuns->free = m*sizeof(duple);
        bn->hsorted = 1;
        bn->tsorted = 0;
        if (niters == 1) {
            bn->tsorted = 1;
	    BATkey(BATmirror(bn), 1);
        }
	*ret = bn;
    } else if (bn) {
        BBPreclaim(bn);
    }
    return status;
}

int
PFll_parent(BAT **ret, BAT *iter_bat, BAT *ctx_bat, BAT *pre_size) { 
    return ll_upwards(ret, iter_bat, ctx_bat, pre_size, LL_UPWARDS_PARENT);
}

int
PFll_ancestor(BAT **ret, BAT *iter_bat, BAT *ctx_bat, BAT *pre_size) { 
    return ll_upwards(ret, iter_bat, ctx_bat, pre_size, LL_UPWARDS_ANCESTOR);
}

int
PFll_ancestor_or_self(BAT **ret, BAT *iter_bat, BAT *ctx_bat, BAT *pre_size) { 
    return ll_upwards(ret, iter_bat, ctx_bat, pre_size, LL_UPWARDS_ANCESTOR_SELF);
}
