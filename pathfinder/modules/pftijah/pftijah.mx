@/
Copyright Notice:
-----------------

The contents of this file are subject to the PfTijah Public License
Version 1.1 (the "License"); you may not use this file except in
compliance with the License. You may obtain a copy of the License at
http://dbappl.cs.utwente.nl/Legal/PfTijah-1.1.html

Software distributed under the License is distributed on an "AS IS"
basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
License for the specific language governing rights and limitations
under the License.

The Original Code is the PfTijah system.

The Initial Developer of the Original Code is the "University of Twente".
Portions created by the "University of Twente" are
Copyright (C) 2006-2010 "University of Twente".

Portions created by the "CWI" are
Copyright (C) 2008-2010 "CWI".

All Rights Reserved.
@

@f pftijah
@a Jan Flokstra
@a Henning Rode
@t pftijah

@m
.MODULE pftijah;

.COMMAND _run_tijah_query(BAT[str,str] opt, BAT[oid,str] rtag, bit use_startnodes) : void = CMDtijah_query;
 "INCOMPLETE"

.COMMAND tj_checkHashTable(BAT[oid,str]) : void = CMDcheckHashTable;
 "INCOMPLETE"

.COMMAND tj_normalizeTerm(str, str) : str = CMDtj_normalizeTerm;
 "INCOMPLETE"

.COMMAND _tj_throw2collection(BAT[str,bat],BAT[oid,bat],str) : void = CMDtj_throw2collection;
 "INCOMPLETE"

.COMMAND _tj_throw2collection_bat(BAT[str,bat],BAT[oid,bat],BAT[str,str]) : void = CMDtj_throw2collection_bat;
 "INCOMPLETE"

.COMMAND _tj_throw2collection_index(BAT[str,bat],str) : void = CMDtj_throw2collection_index;
 "INCOMPLETE"
 
.COMMAND tijah_tokenize(str) : str = CMDtijah_tokenize;
 "INCOMPLETE"

.COMMAND tijah_tokenize2bat(str) : BAT[void,str] = CMDtijah_tokenize2bat;
 "INCOMPLETE"

.COMMAND tj_chk_dict_hash(BAT[void,str], BAT[void,str]) : void = CMDtj_chk_dict_hash;
"INCOMPLETE"

.COMMAND tj_create_termdb(int, oid) : void = CMDtj_create_termdb;
 "INCOMPLETE"

.COMMAND tj_dispose_termdb() : void = CMDtj_dispose_termdb;
 "INCOMPLETE"

.COMMAND tj_log(str, int) : void = CMDtj_log;
 "DEBUGGING function for difficult IO areas"

.COMMAND tj_setlog(str) : void = CMDtj_setlog;
 "intialize outputfile for tj_log"

.COMMAND left_add(BAT[oid,dbl] l, BAT[oid,dbl] r) : BAT[oid,dbl] = CMDleft_add_dbl;
"Fast in-bat implementation of 2 head sorted bat addition with synchronized oid"
.COMMAND left_sub(BAT[oid,dbl] l, BAT[oid,dbl] r) : BAT[oid,dbl] = CMDleft_sub_dbl;
"Fast in-bat implementation of 2 head sorted bat subtraction with synchronized oid"
.COMMAND left_mul(BAT[oid,dbl] l, BAT[oid,dbl] r) : BAT[oid,dbl] = CMDleft_mul_dbl;
"Fast in-bat implementation of 2 head sorted bat multiplication with synchronized oid"
.COMMAND left_div(BAT[oid,dbl] l, BAT[oid,dbl] r) : BAT[oid,dbl] = CMDleft_div_dbl;
"Fast in-bat implementation of 2 head sorted bat division with synchronized oid"
.COMMAND left_div(BAT[oid,dbl] l, BAT[oid,int] r) : BAT[oid,dbl] = CMDleft_div_dbl_int;
"Fast in-bat implementation of 2 head sorted bat division, right type int with synchronized oid"
.COMMAND left_log(BAT[oid,dbl] l) : BAT[oid,dbl] = CMDleft_log_dbl;
"Fast in-bat implementation of in bat log() with synchronized oid"

.COMMAND union_add(BAT[oid,dbl] l, BAT[oid,dbl] r) : BAT[oid,dbl] = CMDunion_add_dbl;
"Fast union implementation of 2 head sorted bat addition with synchronized oid"
.COMMAND union_sub(BAT[oid,dbl] l, BAT[oid,dbl] r) : BAT[oid,dbl] = CMDunion_sub_dbl;
"Fast union implementation of 2 head sorted bat addition with synchronized oid"
.COMMAND union_mul(BAT[oid,dbl] l, BAT[oid,dbl] r) : BAT[oid,dbl] = CMDunion_mul_dbl;
"Fast union implementation of 2 head sorted bat addition with synchronized oid"
.COMMAND union_div(BAT[oid,dbl] l, BAT[oid,dbl] r) : BAT[oid,dbl] = CMDunion_div_dbl;
"Fast union implementation of 2 head sorted bat addition with synchronized oid"


.COMMAND serialize_tijah_opt(
                      BAT[void,bat] ws,
                      int	    niters,
                      BAT[void,oid] loop,
                      BAT[void,oid] iter,
                      BAT[void,oid] item,
		      BAT[void,int] kind,
                      BAT[void,lng] int_values,
		      BAT[void,dbl] dbl_values,
		      BAT[void,str] str_values)
		       : BAT[str,str] = serialize_pftijah_options_DRIVER;
 "C interface to pftijah option serialize"

.COMMAND pf2tijah_node(
		      bit	   preserve_head,
                      BAT[oid,str] doc_name,
                      BAT[oid,oid] doc_firstpre,
                      BAT[oid,oid] pfpre,
                      BAT[oid,oid] item,
		      BAT[oid,int] kind,
                      BAT[oid,str]  doc_loaded)
		       : BAT[void,oid] = CMDpf2tijah_node;
 "Translate Pathfinder node sequence to tijah node sequence"

.COMMAND offsetindex( BAT[void,oid] offset_tid, wrd res_size)
		: BAT[void,oid] = CMDoffsetindex;

"PARAMETERS:
BAT[void,oid] - the offset index 
ressize       - the result size, equals number of different tids + 1
DESCRIPTION:
creates an offset index.
"

.COMMAND mergeindex( BAT[oid,oid] tid_pre, BAT[void,oid] index, BAT[void, oid] pre, wrd indsize)
		: BAT[void,bat] = CMDmergeindex;
"PARAMETERS:
BAT[oid,oid] - new tid_pre to merge with the old index
BAT[void,oid] - old index bat with value-offset
BAT[void,oid] - old posting lists (pre order lists)
int - size of new (dense) offset index.
DESCRIPTION:
the operation merges a new sorted tid_pre with an existing offset index.
"

.COMMAND mergeindex2( BAT[oid,oid] tid_pre, BAT[oid,int] tid_size, BAT[void,oid] index, BAT[void, oid] pre, BAT[void, int] size, wrd indsize)
		: BAT[void,bat] = CMDmergeindex2;
"PARAMETERS:
BAT[oid,oid] - new tid_pre to merge with the old index
BAT[oid,int] - sizes of new elements to merge with the old index (synched with tid_pre)
BAT[void,oid] - old index bat with value-offset
BAT[void,oid] - old posting lists (pre order lists)
BAT[void,int] - corresponding size lists (pre order lists)
int - size of new (dense) offset index.
DESCRIPTION:
the operation merges a new sorted tid_pre with an existing offset index.
"

.COMMAND indexfetchjoin( BAT[any,oid] tid, BAT[void,oid] index, BAT[void, oid] pre)
		: BAT[void,oid] = CMDindexfetchjoin;
"PARAMETERS:
BAT[any,oid] - bat with tail values which have to be joined (e.g. tid values)
BAT[void,oid] - join index bat with value-offset
BAT[void,oid] - bat with indexed offset and tail values to be returned
DESCRIPTION:
the join algorithm comes down to a repeated slice and insert operation.
"

.COMMAND splitbat( BAT[void,oid] pre_tid, BAT[oid,any] pre_split)
		: BAT[void,bat] = CMDsplitbat;
"PARAMETERS:
BAT[void,oid] - pre_tid: original BAT that should get split according to
BAT[oid,any] - pre_split: OIDs in split bat
DESCRIPTION:
the operation does a kdiff and semijoin at the same time returning the kdiff as result 0 and the semijoin as result 1.
"

.COMMAND set_tailkeysorted(BAT[any,any]) : BAT[any,any] = CMDsettailkeysorted; 
"set bat properties of the tail to key and sorted"

.COMMAND treemergejoin_sort(BAT[oid,oid],BAT[void,int],BAT[oid,oid]) : BAT[oid,oid] = CMDtreemergejoin_sort; 
"Stack tree merge join descendant"

.COMMAND treemergejoin_sort_unnested(BAT[oid,oid],BAT[void,int],BAT[oid,oid]) : BAT[oid,oid] = CMDtreemergejoin_sort_unnested; 
"Stack tree merge join descendant"

.COMMAND treemergejoin_nest_pre(BAT[oid,any],BAT[void,int],BAT[oid,any]) : BAT[oid,oid] = CMDtreemergejoin_pre; 
"Stack tree merge join descendant"

.COMMAND treemergejoin_nest_nid(BAT[oid,oid],BAT[void,int],BAT[oid,oid]) : BAT[oid,oid] = CMDtreemergejoin_nid; 
"Stack tree merge join descendant"

.COMMAND treemergejoin_unnest_pre(BAT[oid,any],BAT[void,int],BAT[oid,any]) : BAT[oid,oid] = CMDtreemergejoin_unnested_pre; 
"Stack tree merge join descendant"

.COMMAND treemergejoin_unnest_nid(BAT[oid,oid],BAT[void,int],BAT[oid,oid]) : BAT[oid,oid] = CMDtreemergejoin_unnested_nid; 
"Stack tree merge join descendant"

.PRELUDE = pftijah_prelude;
.EPILOGUE = pftijah_epilogue;

.END pftijah;
@mil
###
# This file contains implementations of some of the SRA operators 
# to run on the TIJAH Light index.
#
# Based on code by the TIJAH team (Vojkan, Thijs)
#
# Additional retrieval models by Henning Rode and Djoerd Hiemstra
#
# Authors: Roel van Os <roel.van.os@glacimonto.nl>
#          Henning Rode <h.rode@cs.utwente.nl>
#
###

######### TEMPORARY FIX FOR M4 count() limitation #################
# In M4 count returns a 32-bit int: count(BAT b) : int
# The following PROC is a temporary solution until a proper fix in M4 is available.
# It returns a type wrd
PROC count_wrd(BAT b) : wrd {
    return wrd(count(int(b)));
}
###################################################################

const DEBUG     := false;
var trace       := false;
var timing      := false;
var verbose     := false;
var inex        := false;
var verbosefile := "";  # writes to client stdout if empty filename


# locks
var tj_adm_lock     := lock_create(); # tijah top administration lock
var tj_dep_lock     := lock_create(); # tijah top dependency adm lock
var tj_coll_lockbat := new(str,lock).rename("tj_coll_lockbat"); # locks for all active collections

# Comparisons
# const GREATER := 10;
# const LESS := 11;
# const EQUAL := 12;
# const GEQ := 13;
# const LEQ := 14;

# Modifiers
# const NORMAL := 71;
# const PLUS := 72;
# const MINUS := 73;
# const MUST := 74;
# const MUST_NOT := 75;

const ENTITY_NUM := 10000;

#var collHeight := 10;
#var retNum := 100;

const HASH := str(chr(35));

##
# For retrieval models: 
#   true:  return all elements from the context set
#   false: return only elements from the context set that contain one or more query terms
#
# Setting this variable to false has the advantage of smaller intermediate region sets.
# In theory, true has the advantage of better results, since it is possible that
# elements that don't match any term at the beginning of a query, contain descendants
# that do match terms.
##
var returnAllElements := false;

if (isnil(CATCH(bat("tj_collName").count_wrd()))) {
	if (bat("tj_collName").count_wrd() > wrd(0)) {
		var name := bat("tj_collName").fetch(0);
		# tj_setCollName(name);
	}
}

const QENV_FTINAME        := 0@0;
const QENV_FTIBGNAME      := 1@0;
const QENV_SCOREBASE      := 2@0;
const QENV_C_LAMBDA       := 3@0;
const QENV_TERM_PROXIMITY := 4@0;
const QENV_FEEDBACK_DOCS  := 5@0;
const QENV_RECURSIVE_TAGS := 6@0;
const QENV_OKAPI_K1       := 7@0;
const QENV_OKAPI_B        := 8@0;

# create a query environment bat
PROC create_qenv() : BAT[oid,str]
{
    var res := new(oid,str);
    return res;
}

PROC modify_qenv(BAT[oid,str] qenv, oid key, str val) : void
{
    if (qenv.exist(key)) {
       qenv.replace(key, val);
    } else {
       qenv.insert(key, val);
    }
}

# safe bat removal
PROC _tj_safe_remove(str batName) : void {
    var err := CATCH({
        bat(batName).persists(false);
    });
    if (not(isnil(err))) printf("%cIGNORING: " + err, chr(35));
}

#
# Hash utility functions
#

PROC tj_init_termHash(str ftiName) : void {
	tj_checkHashTable(bat(_tj_TermBat(ftiName)));
}

PROC tj_init_tagHash(str ftiName) : void {
	tj_checkHashTable(bat(_tj_TagBat(ftiName)));
}


#####################################################################
#                                                                   #
# Start of the information functions                                #
#                                                                   #
#####################################################################

# tijah:ft-index-info(), get all ft-index-information
PROC ws_ft_index_info(BAT[void,BAT] ws, bit consistent) : BAT[void,oid]
{
    return ws_ft_index_info_base(ws,new(void,str),true);
}

# tijah:ft-index-info(str), get all ft-index-information
PROC ws_ft_index_info(BAT[void,BAT] ws, BAT[any,str] ftiNames, bit consistent) : BAT[void,oid]
{
    return ws_ft_index_info_base(ws,ftiNames,false);
}

# tijah:ft-index-info(str), get all ft-index-information
PROC ws_ft_index_info_base(BAT[void,BAT] ws, BAT[any,str] ftiNames, bit all) : BAT[void,oid]
{
    var chkbat;

    var tjc;

    if (isnil(CATCH(bat("tj_collName").count_wrd()))) {
        tjc := bat("tj_collName");
    } else {
        tjc := new(oid,str);
    }

    if ( all )
        chkbat := tjc;
    else 
        chkbat := ftiNames;

    var res := new(void,str).seqbase(0@0);
    var stm := new(void,str).seqbase(0@0);
    var tok := new(void,str).seqbase(0@0);
    var col := new(void,str).seqbase(0@0);
    chkbat@batloop() {
	if ( or(all,tjc.reverse().exist($t)) ) {
          res.append($t);
          stm.append(bat("tj_" + $t + "_param").find("stemmer"));
          tok.append(bat("tj_" + $t + "_param").find("tokenizer"));
	  var as := "";
	  bat("tj_pfc_fti_dep").reverse().select($t)@batloop() {
	      if ( as = "" )
	          as := $h;
	      else 
	          as := as + "," + $h;
	  }
          col.append(as);
    	}
    }
    return xmltab4(ws, "ftindex", res, "stemmer", stm, "tokenizer", tok, "collections", col);
}

#####################################################################
#                                                                   #
# Start of the new implementation of the interfaces                 #
#                                                                   #
#####################################################################

const dflt_ft_index   := "DFLT_FT_INDEX";
const dflt_bg_index   := "DFLT_FT_INDEX";
const dflt_score_base := "0";

ADDHELP("tj_init_global", "flokstra & rode", "Jan 2007",
"PARAMETERS:\n\
- optional BAT[str,str] param: initialization parameter for global pftijah.\n\
  settings.\n\
DESCRIPTION:\n\
Initialize the global pftijah environment.",
"pftijah");
PROC tj_init_global(BAT[str,str] param) : void 
{
    tj_init_global(param,true);
}

const GLOBAL_TTBAT := false;
const VOID_TTBAT   := true;

PROC _tj_TermBat(str ftiName) : str 
{
    if ( GLOBAL_TTBAT )
        return "tj_globalTerms";
    else
    	return "tj_" + ftiName + "_termdict";
}

PROC _tj_TagBat(str ftiName) : str 
{
    if ( GLOBAL_TTBAT )
        return "tj_globalTags";
    else
    	return "tj_" + ftiName + "_tagdict";
}

PROC _tj_RTagBat(str ftiName) : str 
{
    if ( GLOBAL_TTBAT )
        return "tj_globalRTags";
    else
    	return "tj_" + ftiName + "_rtags";
}

PROC tj_init_global(BAT[str,str] param, bit doLock) : void 
{
    if (doLock) lock_set(tj_adm_lock);
    var err := CATCH({
      if ( verbose ) tj_verbose(HASH +"TJ:tj_init_global() called.\n");
      param@batloop() {
	if ( verbose ) tj_verbose(HASH +"TJ:tj_init_global():param[%s]=\"%s\"\n",$h,$t);
	if ( $h = "term_frag" ) {
	    # incomplete, handle term frag
	} else if ( $h = "term_frag_size" ) {
	    # incomplete, handle term frag
	} else {
	    ERROR(HASH + " tj_init_global() unkonwn parameter [%s].\n",$h);
	}
      }
      if ( GLOBAL_TTBAT ) {
          new(oid,str).persists(true).bbpname(_tj_TermBat(""));
          new(oid,str).persists(true).bbpname(_tj_TagBat(""));
          new(oid,str).persists(true).bbpname(_tj_RTagBat(""));
      }
      new(oid,str).persists(true).bbpname("tj_collName");
      new(str,str).persists(true).bbpname("tj_pfc_fti_dep");
      new(str,str).persists(true).bbpname("tj_pfc_fti_dep_star");
      var globals := new(void,str).seqbase(0@0);
      if ( GLOBAL_TTBAT ) {
          globals.append(_tj_TermBat(""));
          globals.append(_tj_TagBat(""));
          globals.append(_tj_RTagBat(""));
      }
      globals.append("tj_collName");
      globals.append("tj_pfc_fti_dep");
      globals.append("tj_pfc_fti_dep_star");
      subcommit(globals);
    });
    if (doLock) lock_unset(tj_adm_lock);
    if (not(isnil(err))) ERROR(err);
}

PROC tj_init_global() : void 
{
     tj_init_global(new(str,str));
}

ADDHELP("tj_delete_global", "flokstra & rode", "Jan 2007",
"PARAMETERS:\n\
DESCRIPTION:\n\
Delete all pftijah collections and remove the global pftijah settings.",
"pftijah");
PROC tj_delete_global() : void 
{
    lock_set(tj_adm_lock);
    var err := CATCH({
      if ( verbose ) tj_verbose(HASH +"TJ:tj_delete_global() called.\n");
      #
      bat("tj_collName")@batloop(){
  	  tj_delete_collection($t,false);
      }
      if ( GLOBAL_TTBAT ) {
          _tj_safe_remove(_tj_TermBat(""));
          _tj_safe_remove(_tj_TagBat(""));
          _tj_safe_remove(_tj_RTagBat(""));
      }
      _tj_safe_remove("tj_collName");
      _tj_safe_remove("tj_pfc_fti_dep");
      _tj_safe_remove("tj_pfc_fti_dep_star");
      var globals := new(void,str).seqbase(0@0);
      if ( GLOBAL_TTBAT ) {
          globals.append(_tj_TermBat(""));
          globals.append(_tj_TagBat(""));
          globals.append(_tj_RTagBat(""));
      }
      globals.append("tj_collName");
      globals.append("tj_pfc_fti_dep");
      globals.append("tj_pfc_fti_dep_star");
      subcommit(globals);
    });
    lock_unset(tj_adm_lock);
    if (not(isnil(err))) ERROR(err);
}

# protext the lookup/insert of the per-collection-locks

var tj_coll_mutex := lock_create();

PROC tj_get_collection_lock(str colname) : lock
{
    var collection_lock;

    lock_set(tj_coll_mutex);
    var err := CATCH({
      if (tj_coll_lockbat.exist(colname))
        collection_lock := tj_coll_lockbat.find(colname);
      else {
        collection_lock := lock_create();
	tj_coll_lockbat.insert(colname,collection_lock);
      }
    });
    lock_unset(tj_coll_mutex);
    if (not(isnil(err))) ERROR(err);
    return collection_lock;
}

ADDHELP("tj_init_collection", "flokstra & rode", "Jan 2007",
"PARAMETERS:\n\
- str ftiName: the name of the collection
- BAT[str,str] param: initialization parameter for collection.\n\
  possible values are:\n\
  tokenizer = { flex, fast }\n\
  stemmer = { nostemming, snowball-english, snowball-porter, snowball-dutch }\n\
  fragmentSize = [number] == the maximum size of a [pre|item] fragment\n\
  tagFilter = [comma seperated list of tags to be indexed]\n\
  etc.\n\
- BAT[void,str] v_pfc, list of pathfinder collection to index 
DESCRIPTION:\n\
Create a new tijah collection.",
"pftijah");
PROC tj_init_collection(str ftiName, BAT[str,str] param, BAT[void,str] v_pfc) : void 
{
    _tj_init_collection(ftiName,param,v_pfc,FALSE);
}

PROC tj_init_collection(str ftiName, BAT[str,str] param) : void 
{
    _tj_init_collection(ftiName,param,new(void,str),FALSE);
}

PROC tj_rebuild_collection(str ftiName) : void  
{
    # WARNING: not thoroughly tested yet
    _tj_init_collection(ftiName,new(str,str),new(void,str),TRUE);
}

PROC _tj_init_collection(str ftiName, BAT[str,str] param, BAT[void,str] v_pfc, bit rebuild) : void 
{
    var coll_lock;

    #
    # first handle the global administration stuff
    #
    lock_set(tj_adm_lock);
    var err := CATCH({
      if ( verbose ) tj_verbose(HASH +"TJ tj_init_collection(\"%s\") called.\n",ftiName);
      
      # check existence of global index management BATs
      if ( not(view_bbp_name().reverse().exist("tj_pfc_fti_dep")) ) {
    	tj_init_global(new(str,str),false); # just in case 
      }
      # check whether index already exists
      if ( view_bbp_name().reverse().exist("tj_" + ftiName + "_size") ) {
    	if ( not(rebuild) ) {
          # check whether collection is empty
          if (bat("tj_" + ftiName + "_size").count_wrd() = wrd(0)) {
             tj_delete_collection(ftiName, false);
          } else {
	     ERROR("tj_init_collection, pftijah collection already exists: %s\n",ftiName);
          }
        } 
      } else {
        if (rebuild) {
	  ERROR("tj_rebuild_collection, pftijah collection \"%s\" does not exists\n",ftiName);
	}
      }
      #
      if ( not(rebuild) ) {
          var coll_oid;
          if (bat("tj_collName").count_wrd() = wrd(0)) { 
            coll_oid := 0@0;
          } else {
            coll_oid := oid(int(bat("tj_collName").reverse().max()) + 1);
          }
          bat("tj_collName").insert(coll_oid, ftiName);
          #
      }
      coll_lock := tj_get_collection_lock(ftiName);
    });
    lock_unset(tj_adm_lock);
    if (not(isnil(err))) ERROR(err);
    #
    # now the collection stuff 
    #
    var extra_del_bat;
    lock_set(coll_lock);
    var err := CATCH({
      if ( not(GLOBAL_TTBAT) ) {
	  if ( rebuild ) {
	      # INCOMPLETE, not throwing them away is much faster!!!
              bat(_tj_TermBat(ftiName)).delete();
              bat("tj_" + ftiName + "_termfreq").delete();
              bat(_tj_TagBat(ftiName)).delete();
              bat(_tj_RTagBat(ftiName)).delete();
	  } else {
	      if ( VOID_TTBAT) {
                  new(void,str).seqbase(0@0).persists(true).bbpname(_tj_TermBat(ftiName));
                  new(void,int).seqbase(0@0).persists(true).bbpname("tj_" + ftiName + "_termfreq");
                  new(void,str).seqbase(0@0).persists(true).bbpname(_tj_TagBat(ftiName));
	      } else {
                  new(oid,str).persists(true).bbpname(_tj_TermBat(ftiName));
                  new(oid,str).persists(true).bbpname(_tj_TagBat(ftiName));
	      }
              new(oid,str).persists(true).bbpname(_tj_RTagBat(ftiName));
	  }
      }
      extra_del_bat := new(void,str).seqbase(0@0);
      if ( rebuild ) {
          bat("tj_" + ftiName + "_doc_name").delete();
          bat("tj_" + ftiName + "_doc_firstpre").delete();
	  # do not delete the param bat
	  var frag_offset := wrd(2); # we delete all buns in existing 1 frag
	  var frag_last := bat("tj_" + ftiName + "_fragments").count_wrd();
	  while (frag_offset < frag_last)
	  {
		var bn := "tj_" + ftiName + "_tid";
		_tj_safe_remove(bn);
                extra_del_bat.append(bn);
		bn := "tj_" + ftiName + "_size";
		_tj_safe_remove(bn);
                extra_del_bat.append(bn);
		frag_offset :+= 1;
	  }
          bat("tj_" + ftiName + "_tid").delete();
          bat("tj_" + ftiName + "_size").delete();
          bat("tj_" + ftiName + "_path").delete();
          bat("tj_" + ftiName + "_fragments").delete();
          bat("tj_" + ftiName + "_fragments").append(1@0);
          bat("tj_" + ftiName + "_pfpre").delete();
          bat("tj_" + ftiName + "_conceptdict").delete();
          bat("tj_" + ftiName + "_concept_tid").delete();
          bat("tj_" + ftiName + "_concept_elem").delete();
          bat("tj_" + ftiName + "_concept_score").delete();
      } else {
          new(void,str).seqbase(0@0).persists(true).access(BAT_APPEND).bbpname("tj_" + ftiName + "_doc_name");
          new(void,oid).seqbase(0@0).persists(true). access(BAT_APPEND).bbpname("tj_" + ftiName + "_doc_firstpre");
          new(str,str).persists(true).bbpname("tj_" + ftiName + "_param");
          
          new(void,oid).seqbase(1@0).persists(true).access(BAT_APPEND).bbpname("tj_" + ftiName + "_tid");
          new(void,int).seqbase(1@0).persists(true).access(BAT_APPEND).bbpname("tj_" + ftiName + "_size");
          new(oid,str).persists(true).access(BAT_APPEND).bbpname("tj_" + ftiName + "_path");
          # bat contains the start oid of every tid/size frag. Head is postfix
          # string to _tid/_size. Normally "", "2", "3"
          new(void,oid).seqbase(1@0).append(1@0).persists(true).access(BAT_APPEND).bbpname("tj_" + ftiName + "_fragments");
          new(oid,oid).persists(true).access(BAT_APPEND).bbpname("tj_" + ftiName + "_pfpre");
          new(oid,str).persists(true).bbpname("tj_" + ftiName + "_conceptdict");
          new(void,oid).seqbase(0@0).persists(true).access(BAT_APPEND).bbpname("tj_" + ftiName + "_concept_tid");
          new(void,oid).seqbase(0@0).persists(true).access(BAT_APPEND).bbpname("tj_" + ftiName + "_concept_elem");
          new(void,dbl).seqbase(0@0).persists(true).access(BAT_APPEND).bbpname("tj_" + ftiName + "_concept_score");
      }
         
      var parambat := bat("tj_" + ftiName + "_param");
      if ( rebuild ) {
	parambat.replace("status","building");
	parambat.replace("_last_tijahPre","1");
	parambat.replace("_last_finalizedPre","0");
      } else {
        #
        # now read the param file
        #
        var stemmer        := "nostemming";
        var tokenizer      := "flex";
        var tagfilter      := "";
	var whitelist      := "";
	var blacklist      := "";
        var fragsize       := "0";
        var delay_finalize := "0";
  
        param@batloop() {
	  if ( verbose ) tj_verbose(HASH +"TJ:tj_init_collection():param[%s]=\"%s\"\n",$h,$t);
	  if ( $h = "stemmer" ) {
	      stemmer := $t;
	  } else if ( $h = "tokenizer" ) {
	      tokenizer := $t;
	  } else if ( $h = "pf_collection" ) {
              bat("tj_" + ftiName + "_param").insert($h,$t);
          } else if ( $h = "fragmentSize" ) {
	  #fragments are currently not supported
	  #    fragsize := $t;
	  } else if ( $h = "whitelist" ) {
              whitelist := $t;
	  } else if ( $h = "blacklist" ) {
              blacklist := $t;
	  } else if ( $h = "ft-index" ) {
	      # ignore this one here
	  } else if ( $h = "delay-finalize" ) {
	      # the number of pre nodes to delay a finalize
	      delay_finalize := $t;
	  } else {
	      ERROR(HASH + " tj_init_collection() unknown parameter [%s].\n",$h);
	  }
        }
        #
        # now set the parameters for this collection
        #
        parambat.insert("_version","1.01");
        parambat.insert("name",ftiName);
        parambat.insert("tokenizer",tokenizer);
        parambat.insert("stemmer",stemmer);
        parambat.insert("fragmentSize",fragsize);
        parambat.insert("curFragment","-1");
        parambat.insert("preExpansion","4");
        parambat.insert("collectionSize","0");
        parambat.insert("lastStopWord","0");
        parambat.insert("status","building");
        parambat.insert("_last_tijahPre","1");
        parambat.insert("_last_finalizedPre","0");
        parambat.insert("delay_finalize",delay_finalize);
	if( not(whitelist = "") )
            parambat.insert("whitelist",whitelist);
	if( not(blacklist = "") )
            parambat.insert("blacklist",blacklist);
      }
      if ( rebuild  ) {
        # reconstruct the original v_pfc
	v_pfc := bat("tj_pfc_fti_dep").reverse().select(ftiName).reverse();
      } else {
        #
        # now modify the global fti pfc dependency administration. We may ignore
        # the return value because all dependencies for this collection are new.
        modify_pfc_fti(ftiName,v_pfc);
      }
      if ( rebuild ) {
	if (isnil(CATCH(bat("tj_" + ftiName + "_TermIndex").count_wrd()))) {
		_tj_safe_remove("tj_" + ftiName + "_TermIndex");
		_tj_safe_remove("tj_" + ftiName + "_Terms");
		_tj_safe_remove("tj_" + ftiName + "_TagIndex");
		_tj_safe_remove("tj_" + ftiName + "_TagSize");
		_tj_safe_remove("tj_" + ftiName + "_Tags");
		_tj_safe_remove("tj_" + ftiName + "_ConceptIndex");
		_tj_safe_remove("tj_" + ftiName + "_ConceptScore");
		_tj_safe_remove("tj_" + ftiName + "_Concepts");
	}
      }
    });
    if ( rebuild ) {
        subcommit(extra_del_bat);
    }
    #subcommit(_tj_collection_str(ftiName));
    lock_unset(coll_lock);
    #
    if (not(isnil(err))) ERROR(err);
    #
    if ( true ) {
      #
      # Now compute the list of existing docs which need to be added to the 
      # ft-index because of the associations.
      lock_set(pf_short);
      var doclist, err := CATCH({
      if ( verbose ) tj_verbose(HASH +"TJ:tj_init_collection(\"%s\") checking collection to index.\n",ftiName);
      if ( v_pfc.uselect("*").count_wrd() > wrd(0) ) {
         doclist := bat("doc_name").reverse().project(str(nil)).reverse();
      } else {
         doclist := bat("doc_name").reverse().join(bat("doc_collection").join(bat("collection_name").join(v_pfc.reverse())));
         doclist := doclist.project(str(nil)).reverse();
      }});
      lock_unset(pf_short);
      if (not(isnil(err))) ERROR(err);

      if ( verbose ) tj_verbose(HASH +"TJ:tj_init_collection(\"%s\") indexing existing collections.\n",ftiName);
      tj_add2collection(ftiName,doclist,false);
      if ( verbose ) tj_verbose(HASH +"TJ:tj_init_collection(\"%s\") finish indexing existing collections.\n",ftiName);
    }
    if ( verbose ) tj_verbose(HASH +"TJ:tj_init_collection(\"%s\") finished.\n",ftiName);
}

#
# The tj_extend_collection() adds new pf collection dependencies to an existing
# collection.
#
PROC tj_extend_collection(str ftiName, BAT[void,str] v_pfc) : void 
{
    if ( verbose ) tj_verbose(HASH +"TJ:tj_extend_collection(\"%s\") start.\n",ftiName);
    var newdep := modify_pfc_fti(ftiName,v_pfc);

    var doclist := bat("doc_name").reverse().join(bat("doc_collection").join(bat("collection_name").join(newdep.reverse())));
    doclist := doclist.project(str(nil)).reverse();
    if ( doclist.count_wrd() > wrd(0) ) {
        if ( verbose ) tj_verbose(HASH +"TJ:tj_extend_collection(\"%s\") indexing existing collections.\n",ftiName);
        # if ( verbose ) doclist.print();
        # careful wuth the previous print, it may be huge
        if ( verbose ) tj_verbose(HASH +"TJ:tj_extend_collection(\"%s\") doclist is %d docs long.\n",ftiName,int(doclist.count_wrd()));
	tj_add2collection(ftiName,doclist,false);
        if ( verbose ) tj_verbose(HASH +"TJ:tj_extend_collection(\"%s\") finish indexing existing collections.\n",ftiName);
    } else {
        # be sure to commit extend bat changes when no docs are added
        subcommit(_tj_collection_str(ftiName));
    }
    if ( verbose ) tj_verbose(HASH +"TJ:tj_extend_collection(\"%s\") finished.\n",ftiName);
}


#
# End of ft-index / pf-collection dependency module
#

ADDHELP("tj_delete_collection", "flokstra & rode", "Jan 2007",
"PARAMETERS:\n\
- str ftiName: the name of the collection to be deleted.\n
DESCRIPTION:\n\
Delete the collection with name \"ftiName\".",
"pftijah");
PROC tj_delete_collection(str ftiName) : void
{
    tj_delete_collection(ftiName,true);
}

PROC tj_delete_collection(str ftiName, bit doAdmLock) : void
{
    var coll_lock;

    #
    # first handle the global administration stuff
    #
    if ( doAdmLock ) lock_set(tj_adm_lock);
    var err := CATCH({
      if ( verbose ) tj_verbose(HASH +"TJ:tj_delete_collection(\"%s\") called.\n",ftiName);

      if (not(isnil(CATCH(bat("tj_collName").count_wrd())))) {
    	ERROR("tj_delete_collection: pftijah not initialized.\n");
      }
      if (not(bat("tj_collName").reverse().exist(ftiName))) {
    	ERROR("tj_delete_collection, pftijah collection does not exist: %s\n",ftiName);
      }
      #
      var coll_oid := bat("tj_collName").reverse().find(ftiName);
      bat("tj_collName").delete(coll_oid);
      #
      coll_lock := tj_get_collection_lock(ftiName);
    });
    if ( doAdmLock ) lock_unset(tj_adm_lock);
    if (not(isnil(err))) ERROR(err);
    #
    # now remove the collection stuff 
    #
    lock_set(coll_lock);
    var err := CATCH({
        if ( not(GLOBAL_TTBAT) ) {
          _tj_safe_remove(_tj_TermBat(ftiName));
          _tj_safe_remove("tj_" + ftiName + "_termfreq");
          _tj_safe_remove(_tj_TagBat(ftiName));
          _tj_safe_remove(_tj_RTagBat(ftiName));
        }
	_tj_safe_remove("tj_" + ftiName + "_doc_name");
	_tj_safe_remove("tj_" + ftiName + "_doc_firstpre");
	_tj_safe_remove("tj_" + ftiName + "_param");
	_tj_safe_remove("tj_" + ftiName + "_pfpre");
	_tj_safe_remove("tj_" + ftiName + "_conceptdict");
	_tj_safe_remove("tj_" + ftiName + "_concept_tid");
	_tj_safe_remove("tj_" + ftiName + "_concept_elem");
	_tj_safe_remove("tj_" + ftiName + "_concept_score");
	_tj_safe_remove("tj_" + ftiName + "_tid");
	_tj_safe_remove("tj_" + ftiName + "_size");
	bat("tj_" + ftiName + "_fragments").persists(false);
	if (isnil(CATCH(bat("tj_" + ftiName + "_TermIndex").count_wrd()))) {
		_tj_safe_remove("tj_" + ftiName + "_TermIndex");
		_tj_safe_remove("tj_" + ftiName + "_Terms");
		_tj_safe_remove("tj_" + ftiName + "_TagIndex");
		_tj_safe_remove("tj_" + ftiName + "_TagSize");
		_tj_safe_remove("tj_" + ftiName + "_Tags");
		_tj_safe_remove("tj_" + ftiName + "_ConceptIndex");
		_tj_safe_remove("tj_" + ftiName + "_ConceptScore");
		_tj_safe_remove("tj_" + ftiName + "_Concepts");
	}
        delete_pfc_fti(ftiName);
        subcommit(_tj_collection_str(ftiName));
    });
    lock_unset(coll_lock);
    if (not(isnil(err))) ERROR(err);
}

# internal method which return all batnames of a collection in a
# a [void,str] bat
PROC _tj_collection_str(str ftiName) : BAT[void,bat]
{
        var tjCollBat := new(void,str).seqbase(0@0);

        tjCollBat.append(_tj_TermBat(ftiName));
        tjCollBat.append("tj_" + ftiName + "_termdict");
        tjCollBat.append(_tj_TagBat(ftiName));
        tjCollBat.append(_tj_RTagBat(ftiName));
        tjCollBat.append("tj_pfc_fti_dep");
        tjCollBat.append("tj_pfc_fti_dep_star");
        tjCollBat.append("tj_collName");
        tjCollBat.append("tj_" + ftiName + "_param");
        tjCollBat.append("tj_" + ftiName + "_doc_name");
        tjCollBat.append("tj_" + ftiName + "_doc_firstpre");
        tjCollBat.append("tj_" + ftiName + "_pfpre");
        tjCollBat.append("tj_" + ftiName + "_conceptdict");
        tjCollBat.append("tj_" + ftiName + "_concept_tid");
        tjCollBat.append("tj_" + ftiName + "_concept_elem");
        tjCollBat.append("tj_" + ftiName + "_concept_score");
        tjCollBat.append("tj_" + ftiName + "_fragments");
        tjCollBat.append("tj_" + ftiName + "_tid");
        tjCollBat.append("tj_" + ftiName + "_size");
        tjCollBat.append("tj_" + ftiName + "_path");
        if (isnil(CATCH(bat("tj_" + ftiName + "_TermIndex").count_wrd()))) {
            tjCollBat.append("tj_" + ftiName + "_Terms");
            tjCollBat.append("tj_" + ftiName + "_Tags");
            tjCollBat.append("tj_" + ftiName + "_Concepts");
            tjCollBat.append("tj_" + ftiName + "_TermIndex");
            tjCollBat.append("tj_" + ftiName + "_TagIndex");
            tjCollBat.append("tj_" + ftiName + "_ConceptIndex");
            tjCollBat.append("tj_" + ftiName + "_TagSize");
            tjCollBat.append("tj_" + ftiName + "_ConceptScore");
        }      
        return tjCollBat;
}

# internal method which return all relevant data about a collection in a
# a single [void,bat] bat
PROC _tj_collection(str ftiName) : BAT[str, bat]
{
        if (not(isnil(CATCH(bat("tj_" + ftiName + "_param").count_wrd())))) {
	     ERROR("_tj_collection(): collection(\""+ftiName+"\") does not exist!\n");
	}
	var tjCollBat := new(str,bat);

	var parbat := bat("tj_" + ftiName + "_param");
	var curversion;
	if ( parbat.exist("_version") ) {
	    curversion := parbat.find("_version");
	} else {
	    curversion := "0.0";
	}
	if ( curversion < "1.0" ) {
	     ERROR("_tj_collection():%s: pftijah index structure changed, reindex collection!!",curversion);
	}
	tjCollBat.insert("termdict", bat(_tj_TermBat(ftiName)));
	tjCollBat.insert("termfreq", bat("tj_" + ftiName + "_termfreq"));
	tjCollBat.insert("tagdict", bat(_tj_TagBat(ftiName)));
	tjCollBat.insert("rtags", bat(_tj_RTagBat(ftiName)));
	tjCollBat.insert("doc_name", bat("tj_" + ftiName + "_doc_name"));
	tjCollBat.insert("doc_firstpre", bat("tj_" + ftiName + "_doc_firstpre"));
	tjCollBat.insert("param", parbat);
	# only load the top [pre|term|size] fragments
	tjCollBat.insert("tid",       bat("tj_" + ftiName + "_tid"));
	tjCollBat.insert("size",      bat("tj_" + ftiName + "_size"));
	tjCollBat.insert("path",      bat("tj_" + ftiName + "_path"));
	tjCollBat.insert("pfpre",     bat("tj_" + ftiName + "_pfpre"));
	tjCollBat.insert("conceptdict",      bat("tj_" + ftiName + "_conceptdict"));
	tjCollBat.insert("concept_tid",  bat("tj_" + ftiName + "_concept_tid"));
	tjCollBat.insert("concept_elem", bat("tj_" + ftiName + "_concept_elem"));
	tjCollBat.insert("concept_score",bat("tj_" + ftiName + "_concept_score"));
	tjCollBat.insert("fragments", bat("tj_" + ftiName + "_fragments"));
	
	if (isnil(CATCH(bat("tj_" + ftiName + "_TermIndex").count_wrd()))) {
            tjCollBat.insert("_terms", bat("tj_" + ftiName + "_Terms"));
	    tjCollBat.insert("_tags", bat("tj_" + ftiName + "_Tags"));
	    tjCollBat.insert("_concepts", bat("tj_" + ftiName + "_Tags"));
	    tjCollBat.insert("_termIndex", bat("tj_" + ftiName + "_TermIndex"));
	    tjCollBat.insert("_tagIndex", bat("tj_" + ftiName + "_TagIndex"));
	    tjCollBat.insert("_conceptIndex", bat("tj_" + ftiName + "_TagIndex"));
	    tjCollBat.insert("_tagSize", bat("tj_" + ftiName + "_TagSize"));
	    tjCollBat.insert("_conceptScore", bat("tj_" + ftiName + "_TagSize"));
	}
	tjCollBat.insert("submitBats", new(void,str).seqbase(0@0));
	tjCollBat.insert("replaceBats", new(str,str));
	
	return tjCollBat;
}

PROC _tj_commit(BAT[str,bat] collBat) : void
{
      var replaceBats := collBat.find("replaceBats");
      replaceBats@batloop() {
      	 bat($t).persists(false).rename("del_" + $t);
	 collBat.find($h).persists(true).bbpname($t);
      }
    
      var submitBats := collBat.find("submitBats");
      submitBats.append([+](const "del_", replaceBats.tmark(0@0)));
     
      subcommit(submitBats);
}

ADDHELP("tj_add2collection", "flokstra & rode", "Jan 2007",
"PARAMETERS:\n\
- str ftiName: the name of the collection.\n\
- str uri_loc: the location of the xml document.\n\
- str uri_name: the name of the xml document (optional).\n\
- bit shred: when true the doc is shredded when necessary.\n\
DESCRIPTION:\n\
Add a document to a pftijah collection. The document is indexed and if the \n\
shred parameter is true it is also shredded in Pathfinder. \n\
The index is automatically finalized at the end of the method.",
"pftijah");
PROC tj_add2collection(str ftiName, str uri_loc, str uri_name, bit shred) : void
{
    tj_add2collection(ftiName,new(str,str).insert(uri_loc,uri_name),shred);
}

ADDHELP("tj_add2collection", "flokstra & rode", "Jan 2007",
"PARAMETERS:\n\
- str ftiName: the name of the collection.\n
- BAT[str,str]: the bat containing the [location,name] pairs of the xml docs.\n\
- bit shred: when true the doc is shredded when necessary.\n\
DESCRIPTION:\n\
The multidocument version of tj_add2collection. The main difference with the\n\
other method is the [str,str] bat which contains the location of the document\n\
in the head and the name in the tail.\n\
The advantage of this method is that the collection is finalized after all\n\
xml documents in the bat are added to the collection.",
"pftijah");
PROC tj_add2collection(str ftiName, BAT[str,str] uri, bit shred) : void
{
    var coll_lock := tj_get_collection_lock(ftiName);
    lock_set(coll_lock);
    var err := CATCH({
      var t_start := usec();
      # set access back to BAT_APPEND
      bat("tj_" + ftiName + "_doc_name").access(BAT_APPEND);
      bat("tj_" + ftiName + "_doc_firstpre").access(BAT_APPEND);
      bat("tj_" + ftiName + "_tid").access(BAT_APPEND);
      bat("tj_" + ftiName + "_size").access(BAT_APPEND);
      bat("tj_" + ftiName + "_path").access(BAT_APPEND);
      bat("tj_" + ftiName + "_fragments").access(BAT_APPEND);
      bat("tj_" + ftiName + "_pfpre").access(BAT_APPEND);
      bat("tj_" + ftiName + "_concept_tid").access(BAT_APPEND);
      bat("tj_" + ftiName + "_concept_elem").access(BAT_APPEND);
      bat("tj_" + ftiName + "_concept_score").access(BAT_APPEND);
      bat(_tj_TermBat(ftiName)).access(BAT_APPEND);
      bat(_tj_TagBat(ftiName)).access(BAT_APPEND);
      bat(_tj_RTagBat(ftiName)).access(BAT_APPEND);
      var collBat;
      collBat := _tj_collection(ftiName);
      var ws_opt := ws_create(0);
      if ( not(shred) ) {
        ws_opendoc(ws_opt,uri.tmark(0@0));
        _tj_throw2collection_bat(collBat,ws_opt,uri);
      } else {
        uri@batloop() {
          _tj_add2collection(ftiName, ws_opt, collBat, $h, $t, shred);
        }
      }
      ws_destroy(ws_opt);
      _tj_set_parameter(collBat, "status", "building");
      _tj_finalize_collection(ftiName, collBat, FALSE);
      if ( timing ) {
         var ms := (usec()-t_start)/1000;
         printf(HASH +"C[%s]:tj_add2collection(BAT): + aggregate time = %lld.%03llds.\n",ftiName,/(ms,1000),%(ms,1000));
       }
      _tj_commit(collBat); 
    });
    lock_unset(coll_lock);
    if (not(isnil(err))) ERROR(err);
}

PROC _tj_add2collection(str ftiName, BAT[oid,bat] ws_opt, BAT[str,bat] collBat, str uri_loc, str uri_name, bit shred) : void
{ 
    var ms;
    var t_start := usec();
    if ( verbose ) tj_verbose(HASH +"TJ:_tj_add2collection(\"%s\",\"%s\",\"%s\") start.\n",ftiName,uri_loc,uri_name);

    var i_start;
    if ( shred ) {
	var pf_collection := _tj_get_parameter(collBat,"pf_collection");
	if ( isnil(uri_loc) and isnil(uri_name) ) {
	    ERROR("_tj_add2collection: should specify doc_name or doc_uri.");
	}
        if ( isnil(uri_name) ) {
	  uri_name := uri_loc;
	} else if ( uri_name = "" ) {
	  uri_name := uri_loc;
	}
        # var ws := ws_create(0);
        if (not(bat("doc_name").reverse().exist(uri_name))) {
            var s_start := usec();
	    if ( isnil(pf_collection) ) {
    	        shred_doc(uri_loc,uri_name);
	    } else {
    	        shred_doc(uri_loc,uri_name,pf_collection,0LL);
	    }
            if ( timing ) {
	      ms := (usec()-s_start)/1000;
              printf(HASH +"C[%s]:add2coll(\"%s\"): shred time = %lld.%03llds.\n",ftiName,uri_name,/(ms,1000),%(ms,1000));
            }
        } else {
            if ( verbose ) tj_verbose(HASH +"TJ:_tj_add2collection(%s,..) doc(\"%s\") already shredded.\n",ftiName,uri_name);
	}
        # ws_opendoc(ws, bat(void,str,1).append(uri_name));
        ws_opendoc(ws_opt, bat(void,str,1).append(uri_name));
	i_start := usec();
        if ( verbose ) tj_verbose(HASH +"TJ:_tj_throw2collection(cb(%s),ws,\"%s\") call next.\n",ftiName,uri_name);
        _tj_throw2collection(collBat,ws_opt,uri_name);
        # ws_destroy(ws);
    } else {
	i_start := usec();
        #_tj_throw2collection_index(collBat,uri_loc);
        _tj_throw2collection(collBat,ws_opt,uri_name);
    }
    if ( timing ) {
	ms := (usec()-i_start)/1000;
        printf(HASH +"C[%s]:add2coll(\"%s\"): index time = %lld.%03llds.\n",ftiName,uri_name,/(ms,1000),%(ms,1000));
    }
           
    if ( verbose ) tj_verbose(HASH +"TJ:_tj_add2collection(\"%s\") finish.\n",ftiName);
    if ( timing ) {
	ms := (usec()-t_start)/1000;
        printf(HASH +"C[%s]:add2coll(\"%s\"): total time = %lld.%03llds.\n",ftiName,uri_name,/(ms,1000),%(ms,1000));
    }
}

# internal finalize function
PROC _tj_finalize_collection(str ftiName, BAT[str,bat] collBat, bit fforce) : void
{
    var t_start := usec();
    if ( verbose ) tj_verbose(HASH +"TJ:_tj_finalize_collection(\"%s\") called.\n",ftiName);
    
    # set BATs to BAT_READ
    bat("tj_" + ftiName + "_doc_name").access(BAT_READ);
    bat("tj_" + ftiName + "_doc_firstpre").access(BAT_READ);
    bat("tj_" + ftiName + "_tid").access(BAT_READ);
    bat("tj_" + ftiName + "_size").access(BAT_READ);
    bat("tj_" + ftiName + "_path").access(BAT_READ);
    bat("tj_" + ftiName + "_fragments").access(BAT_READ);
    bat("tj_" + ftiName + "_pfpre").access(BAT_READ);
    bat("tj_" + ftiName + "_concept_tid").access(BAT_READ);
    bat("tj_" + ftiName + "_concept_elem").access(BAT_READ);
    bat("tj_" + ftiName + "_concept_score").access(BAT_READ);
    
    var parambat := bat("tj_" + ftiName + "_param");
    if ( not(fforce) ) {
        var delfin   := lng(parambat.find("delay_finalize"));
        if ( delfin > lng(0) ) {
            var finlast  := lng(parambat.find("_last_finalizedPre"));
            var prelast  := lng(parambat.find("_last_tijahPre"));
            var fdelta   := prelast - finlast;
	    if ( (prelast - finlast) < delfin ) {
                  if ( verbose ) tj_verbose(HASH +"TJ:_tj_finalize_collection(\"%s\") delaying finalization (%d < %d).\n",ftiName,int(fdelta),int(delfin));
		  return;
	    } else {
                  if ( verbose ) tj_verbose(HASH +"TJ:_tj_finalize_collection(\"%s\") finalization treshhold reached (%d > %d).\n",ftiName,int(fdelta),int(delfin));
	    }
        }
    }
    #
    bat("tj_" + ftiName + "_tid").mmap(1);
    bat("tj_" + ftiName + "_size").mmap(1);
    collBat.find("submitBats").append("tj_" + ftiName + "_tid");
    collBat.find("submitBats").append("tj_" + ftiName + "_size");
    collBat.find("submitBats").append("tj_" + ftiName + "_pfpre");
    collBat.find("submitBats").append("tj_" + ftiName + "_conceptdict");
    collBat.find("submitBats").append("tj_" + ftiName + "_concept_tid");
    collBat.find("submitBats").append("tj_" + ftiName + "_concept_elem");
    collBat.find("submitBats").append("tj_" + ftiName + "_concept_score");
    collBat.find("submitBats").append("tj_" + ftiName + "_fragments");
    collBat.find("submitBats").append("tj_" + ftiName + "_doc_name");
    collBat.find("submitBats").append("tj_" + ftiName + "_doc_firstpre");
    collBat.find("submitBats").append("tj_" + ftiName + "_param");
    
    _buildIRindex(ftiName, collBat);
    #
    # update collection size
    var c_size := collBat.find("termfreq").[wrd]().sum();
    _tj_set_parameter(collBat, "collectionSize", str(c_size));      
    
    _tj_set_parameter(collBat, "status", "finalized");
    var lst_fpre := str(lng(parambat.find("_last_tijahPre")) - 1);
    _tj_set_parameter(collBat, "_last_finalizedPre", lst_fpre);
    #
    collBat.find("submitBats").append(_tj_TermBat(ftiName));
    collBat.find("submitBats").append("tj_" + ftiName + "_termfreq");
    collBat.find("submitBats").append(_tj_TagBat(ftiName));
    collBat.find("submitBats").append(_tj_RTagBat(ftiName));
    
    if ( timing ) {
        var ms := (usec()-t_start)/1000;
        printf(HASH +"C[%s]:finalize(): total time = %lld.%03llds.\n",ftiName,/(ms,1000),%(ms,1000));
    }
}

# set a collection parameter
PROC _tj_set_parameter(BAT[str,bat] collBat, str par, str val) : void
{
	var parbat := collBat.find("param");

	if ( parbat.exist(par) ) {
	    parbat.replace(par,val);
	} else {
	    parbat.insert(par,val);
	}
}

# set a collection parameter
PROC tj_set_parameter(str ftiName, str par, str val) : void
{
    if ( verbose ) tj_verbose(HASH +"TJ:tj_set_parameterl(%s,%s,%s) called.\n",ftiName,par,val);
    var coll_lock := tj_get_collection_lock(ftiName);
    lock_set(coll_lock);
    var err := CATCH({
	var parbat := bat("tj_" + ftiName + "_param");

	if ( parbat.exist(par) ) {
	    parbat.replace(par,val);
	} else {
	    parbat.insert(par,val);
	}
    });
    lock_unset(coll_lock);
    if (not(isnil(err))) ERROR(err);
}

# get a collection parameter
PROC _tj_get_parameter(BAT[str,bat] collBat, str par) : str
{
	var parbat := collBat.find("param");

	if ( parbat.exist(par) ) {
	    return parbat.find(par);
	} else {
	    return str(nil);
	}
}

PROC tj_dump_collection(str ftiName) : void
{
    var coll_lock := tj_get_collection_lock(ftiName);
    lock_set(coll_lock);
    var err := CATCH({
	bat("tj_" + ftiName + "_param").print();
	bat("tj_" + ftiName + "_doc_name").print();
	bat("tj_" + ftiName + "_doc_firstpre").print();
	# print(bat("tj_" + ftiName + "_doc_name"),bat("tj_" + ftiName + "_doc_firstpre"));
	bat(_tj_TermBat(ftiName)).print();
	bat(_tj_TagBat(ftiName)).print();
	print(bat("tj_" + ftiName + "_tid"));
	print(bat("tj_" + ftiName + "_size"));
	print(bat("tj_" + ftiName + "_path"));
	print(bat("tj_" + ftiName + "_pfpre"));
	print(bat("tj_" + ftiName + "_conceptdict"));
	print(bat("tj_" + ftiName + "_concept_tid"));
	print(bat("tj_" + ftiName + "_concept_elem"));
	print(bat("tj_" + ftiName + "_concept_score"));
	print(bat("tj_" + ftiName + "_fragments"));
	# print(bat("tj_" + ftiName + "_height"));
    });
    lock_unset(coll_lock);
    if (not(isnil(err))) ERROR(err);
}

PROC tj_size_collection(str ftiName) : void
{
    var sum := batdsksize(bat("tj_" + ftiName + "_tagdict"));
    sum :+=  batdsksize(bat("tj_" + ftiName + "_termdict"));
    sum :+=  batdsksize(bat("tj_" + ftiName + "_Tags"));
    sum :+=  batdsksize(bat("tj_" + ftiName + "_Terms"));
    sum :+=  batdsksize(bat("tj_" + ftiName + "_TagIndex"));
    sum :+=  batdsksize(bat("tj_" + ftiName + "_TermIndex"));
    sum :+=  batdsksize(bat("tj_" + ftiName + "_TagSize"));
    print(sum);
}

PROC tj_size_collection2(str ftiName) : void
{
    var sum := batdsksize(bat("tj_" + ftiName + "_tagdict"));
    sum :+=  batdsksize(bat("tj_" + ftiName + "_termdict"));
    sum :+=  batdsksize(bat("tj_" + ftiName + "_Tags"));
    sum :+=  batdsksize(bat("tj_" + ftiName + "_Terms"));
    sum :+=  batdsksize(bat("tj_" + ftiName + "_TagIndex"));
    sum :+=  batdsksize(bat("tj_" + ftiName + "_TermIndex"));
    sum :+=  batdsksize(bat("tj_" + ftiName + "_size"));
    sum :+=  batdsksize(bat("tj_" + ftiName + "_path"));
    print(sum);
}

#####################################################################
#                                                                   #
# New document management section		                    #
#                                                                   #
#####################################################################

PROC tj_get_ft_index(BAT[str,str] tj_options, bit chk_exists) : str 
{
    var res := dflt_ft_index;
    if ( tj_options.exist("ft-index") ) {
        res := tj_options.find("ft-index");
    }
    if ( chk_exists ) {
      if ( not(view_bbp_name().reverse().exist("tj_" + res + "_param")) ) {
        ERROR("tj_get_ft_index, ft-index \"%s\" does not exist. create full text index using tijah:create-ft-index()\n",res);
      }
      if ( not(view_bbp_name().reverse().exist("tj_" + res + "_termdict")) ) {
        ERROR("tj_get_ft_index, ft-index \"%s\" does not exist. create full text index using tijah:create-ft-index()\n",res);
      }
    }
    if ( verbose ) tj_verbose(HASH + " TJ:tj_get_ft_index() = %s.\n",res);
    return res;
}

# set a collection parameter
PROC _tj_set_parameter2(BAT[str,bat] collBat, str par, str val) : void
{
        if ( verbose ) tj_verbose(HASH +"TJ _tj_set_parameter2(\"%s\", \"%s\").\n",par, val);
	var parbat := collBat.find("param");

	if ( parbat.exist(par) ) {
	    parbat.replace(par,val);
	} else {
	    parbat.insert(par,val);
	}
}

# get a collection parameter
PROC _tj_get_parameter2(BAT[str,bat] collBat, str par) : str
{
	var parbat := collBat.find("param");

	if ( parbat.exist(par) ) {
            if ( verbose ) tj_verbose(HASH +"TJ _tj_get_parameter2(\"%s\") = %s.\n", par, parbat.find(par));
	    return parbat.find(par);
	} else {
            if ( verbose ) tj_verbose(HASH +"TJ _tj_get_parameter2(\"%s\") = nil.\n", par);
	    return str(nil);
	}
}

ADDHELP("tj_init_collection_base", "flokstra & rode", "Sept 2009",
"PARAMETERS:\n\
-` str ftiName: the name of the collection.\n
- BAT[str,str] param: the bat containing all indexing parameters (stemming, stopping, ...)\n\
DESCRIPTION:\n\
This function can be called to initialize an empty collection with certain indexing parameters\n\
which gets filled by later tj_add2collection calls.",
"pftijah");
PROC tj_init_collection_base(str ftiName, BAT[str,str] param) : void
{
    if ( verbose ) tj_verbose(HASH +"TJ tj_init_collection_base(\"%s\") called.\n",ftiName);
    var coll_lock := tj_get_collection_lock(ftiName);
    lock_set(coll_lock);
    var err := CATCH({
      var t_start := usec();
     
      var commitBats := _tj_create_commitBats();
      _tj_init_collection_base(ftiName, param, commitBats);
      _tj_commit_frag(new(str,bat), commitBats);       

      if ( timing ) {
         var ms := (usec()-t_start)/1000;
         printf(HASH +"TJ tj_init_collection_base: total time = %lld.%03llds.\n",/(ms,1000),%(ms,1000));
       }
    });
    lock_unset(coll_lock);
    if ( verbose ) tj_verbose(HASH +"TJ tj_init_collection_base(\"%s\") finished.\n",ftiName);
    if (not(isnil(err))) ERROR(err);
}

#
# _tj_init_collection_base initializes all (global, fragment independent) BATs of an ft-index
#
PROC _tj_init_collection_base(str ftiName, BAT[str,str] param, BAT[str,bat] commitBats) : void
{
    if ( verbose ) tj_verbose(HASH +"TJ _tj_init_collection_base(\"%s\") called.\n",ftiName);
    var err := CATCH({
      
      # check whether index already exists
      if ( view_bbp_name().reverse().exist("tj_" + ftiName + "_param") ) {
	  ERROR("tj_init_collection_base, ft-index already exists: %s. delete ft-index first.\n",ftiName);
      }
      
      var submitBats := commitBats.find("submitBats"); 
      # check existence of global index management BATs, initialize if necessary
      if ( not(view_bbp_name().reverse().exist("tj_pfc_fti_dep")) ) {
          if ( GLOBAL_TTBAT ) {
              new(oid,str).persists(true).bbpname(_tj_TermBat(""));
              new(oid,str).persists(true).bbpname(_tj_TagBat(""));
              new(oid,str).persists(true).bbpname(_tj_RTagBat(""));
              # add submitBats
              submitBats.append(_tj_TermBat(""));
              submitBats.append(_tj_TagBat(""));
              submitBats.append(_tj_RTagBat(""));
          }
          new(oid,str).persists(true).bbpname("tj_collName");
          new(str,str).persists(true).bbpname("tj_pfc_fti_dep");
          new(str,str).persists(true).bbpname("tj_pfc_fti_dep_star");
          # add submitBats
          submitBats.append("tj_collName");
          submitBats.append("tj_pfc_fti_dep");
          submitBats.append("tj_pfc_fti_dep_star");
      }
    
      # create term|tag|concept dictionary
      if ( not(GLOBAL_TTBAT) ) {
          new(void,str).seqbase(0@0).persists(true).bbpname(_tj_TermBat(ftiName));
          new(void,str).seqbase(0@0).persists(true).bbpname(_tj_TagBat(ftiName));
          new(oid,str).persists(true).bbpname(_tj_RTagBat(ftiName));
          new(oid,str).persists(true).bbpname("tj_" + ftiName + "_conceptdict");
          # add submitBats
          submitBats.append(_tj_TermBat(ftiName));
          submitBats.append(_tj_TagBat(ftiName));
          submitBats.append(_tj_RTagBat(ftiName));
          submitBats.append("tj_" + ftiName + "_conceptdict");
      }
      # create global term frequency table
      new(void,int).seqbase(0@0).persists(true).bbpname("tj_" + ftiName + "_termfreq");
      submitBats.append("tj_" + ftiName + "_termfreq");

      # create param BAT
      new(str,str).persists(true).bbpname("tj_" + ftiName + "_param");
      submitBats.append("tj_" + ftiName + "_param");
      var parambat := bat("tj_" + ftiName + "_param");
      
      # now init the params 
      var stemmer        := "nostemming";
      var tokenizer      := "flex";
      var tagfilter      := "";
      var whitelist      := "";
      var blacklist      := "";
      var fragsize       := str(INT_MAX / 2);
      var delay_finalize := "0";
      var docsize        := "small";
  
      param@batloop() {
        if ( verbose ) tj_verbose(HASH +"TJ _tj_init_collection_base():param[%s]=\"%s\"\n",$h,$t);
        if ( $h = "stemmer" ) {
            stemmer := $t;
        } else if ( $h = "tokenizer" ) {
            tokenizer := $t;
        } else if ( $h = "pf_collection" ) {
            parambat.insert($h,$t);
        } else if ( $h = "fragmentSize" ) {
            fragsize := $t;
        } else if ( $h = "documentSize" ) {
            docsize := toLower($t);
        } else if ( $h = "whitelist" ) {
            whitelist := $t;
        } else if ( $h = "blacklist" ) {
            blacklist := $t;
        } else if ( $h = "ft-index" ) {
            # ignore this one here
        } else if ( $h = "delay-finalize" ) {
            # the number of pre nodes to delay a finalize
            delay_finalize := $t;
        } else {
            printf(HASH + "TJ _tj_init_collection_base() unknown parameter [%s].\n",$h);
        }
      }
      parambat.insert("_version","1.1");
      parambat.insert("name",ftiName);
      parambat.insert("tokenizer",tokenizer);
      parambat.insert("stemmer",stemmer);
      parambat.insert("fragmentSize",fragsize);
      parambat.insert("documentSize",docsize);
      parambat.insert("curFragment","0");
      parambat.insert("preExpansion","4");
      parambat.insert("lastStopWord","0");
      parambat.insert("collectionSize","0");
      parambat.insert("status","building");
      parambat.insert("_last_tijahPre","1");
      parambat.insert("_last_finalizedPre","0");
      parambat.insert("delay_finalize",delay_finalize);

      if( not(whitelist = "") )
            parambat.insert("whitelist",whitelist);
      if( not(blacklist = "") )
            parambat.insert("blacklist",blacklist);
      if( not(tagfilter = "") )
            parambat.insert("tagfilter",tagfilter);

      #init first fragment
      _tj_init_collection_frag(ftiName, 0, commitBats);

    });
    if (not(isnil(err))) ERROR(err);
    if ( verbose ) tj_verbose(HASH +"TJ _tj_init_collection_base(\"%s\") finished.\n",ftiName);
}

#
# _tj_init_collection_frag initializes a new fragment
#
PROC _tj_init_collection_frag(str ftiName, int cur_frag, BAT[str,bat] commitBats) : void
{
    if ( verbose ) tj_verbose(HASH +"TJ _tj_init_collection_frag(\"%s\") called.\n",ftiName);
    var err := CATCH({
     
     var submitBats := commitBats.find("submitBats"); 
     # create new fragment
     var ftindex := ftiName + str(cur_frag);
     new(void,str).seqbase(0@0).persists(true).access(BAT_APPEND).bbpname("tj_" + ftindex + "_doc_name");
     new(void,oid).seqbase(0@0).persists(true).access(BAT_APPEND).bbpname("tj_" + ftindex + "_doc_firstpre");
     new(void,oid).seqbase(1@0).persists(true).access(BAT_APPEND).bbpname("tj_" + ftindex + "_tid");
     new(void,int).seqbase(1@0).persists(true).access(BAT_APPEND).bbpname("tj_" + ftindex + "_size");
     new(oid,oid).persists(true).access(BAT_APPEND).bbpname("tj_" + ftindex + "_pfpre");
     if (inex) new(oid,str).persists(true).access(BAT_APPEND).bbpname("tj_" + ftindex + "_path");
     if (inex) new(oid,str).persists(true).access(BAT_APPEND).bbpname("tj_" + ftindex + "_pathno");
     new(void,oid).seqbase(0@0).persists(true).access(BAT_APPEND).bbpname("tj_" + ftindex + "_concept_tid");
     new(void,oid).seqbase(0@0).persists(true).access(BAT_APPEND).bbpname("tj_" + ftindex + "_concept_elem");
     new(void,dbl).seqbase(0@0).persists(true).access(BAT_APPEND).bbpname("tj_" + ftindex + "_concept_score");
     
     # reset _last_tijahPre and _last_finalizedPre
     var parambat := bat("tj_" + ftiName + "_param");
     parambat.replace("curFragment",str(cur_frag));
     parambat.replace("_last_tijahPre","1");
     parambat.replace("_last_finalizedPre","0");

     # add submitBats
     submitBats.append("tj_" + ftindex + "_doc_name");
     submitBats.append("tj_" + ftindex + "_doc_firstpre");
     submitBats.append("tj_" + ftindex + "_tid");
     submitBats.append("tj_" + ftindex + "_size");
     submitBats.append("tj_" + ftindex + "_pfpre");
     if (inex) submitBats.append("tj_" + ftindex + "_path");
     if (inex) submitBats.append("tj_" + ftindex + "_pathno");
     submitBats.append("tj_" + ftindex + "_concept_tid");
     submitBats.append("tj_" + ftindex + "_concept_elem");
     submitBats.append("tj_" + ftindex + "_concept_score");
     submitBats.append("tj_" + ftiName + "_param");

    });
    if (not(isnil(err))) ERROR(err);
    if ( verbose ) tj_verbose(HASH +"TJ _tj_init_collection_frag(\"%s\") finished.\n",ftiName);
}

#
# _tj_get_collection_frag returns the last existing collection fragment
# if the last collection fragment is already completely filled, it creates
# a new fragment
#
PROC _tj_get_collection_frag(str ftiName, BAT[str,bat] commitBats) : void
{
        if ( verbose ) tj_verbose(HASH +"TJ _tj_get_collection_frag(\"%s\") called.\n",ftiName);

        # existence check
        if (not(isnil(CATCH(bat("tj_" + ftiName + "_param").count_wrd())))) {
             if (verbose) tj_verbose(HASH +"TJ _tj_get_collection_frag: index %s does not exist. create new index...\n",ftiName);
             _tj_init_collection_base(ftiName, new(str,str), commitBats);
	}
         
        # version check
	var parbat := bat("tj_" + ftiName + "_param");
	var curversion;
	if ( parbat.exist("_version") ) {
	     curversion := parbat.find("_version");
	} else {
	     curversion := "0.0";
	}
	if ( curversion < "1.0" ) {
	     ERROR("_tj_collection():%s: pftijah index structure changed, reindex collection!!",curversion);
	}

        # check last fragment and initialize new fragment if the last one is full
	var cur_frag := int(parbat.find("curFragment"));
	var frag_size := lng(parbat.find("fragmentSize"));
        var last_pre := lng(parbat.find("_last_tijahPre"));
        if (last_pre >= frag_size ) {
             cur_frag :+= 1;
             if ( verbose ) tj_verbose(HASH +"tj_get_collection_frag: init new fragment (last_pre: %d, frag_size: %d, cur_frag: %d).\n",int(last_pre), int(frag_size), cur_frag);
             _tj_init_collection_frag(ftiName, cur_frag, commitBats);
        }

        var tjCollBat := new(str,bat);
	tjCollBat.insert("termdict", bat(_tj_TermBat(ftiName)));
	tjCollBat.insert("tagdict", bat(_tj_TagBat(ftiName)));
	tjCollBat.insert("rtags", bat(_tj_RTagBat(ftiName)));
	tjCollBat.insert("conceptdict", bat("tj_" + ftiName + "_conceptdict"));
	tjCollBat.insert("termfreq", bat("tj_" + ftiName + "_termfreq"));
	tjCollBat.insert("param", parbat);

	# only load the top collection fragment
	var ftindex := ftiName + str(cur_frag);
        tjCollBat.insert("tid", bat("tj_" + ftindex + "_tid"));
	tjCollBat.insert("size", bat("tj_" + ftindex + "_size"));
	tjCollBat.insert("pfpre", bat("tj_" + ftindex + "_pfpre"));
        if (inex) tjCollBat.insert("path", bat("tj_" + ftindex + "_path"));
        if (inex) tjCollBat.insert("pathno", bat("tj_" + ftindex + "_pathno"));
	tjCollBat.insert("concept_tid", bat("tj_" + ftindex + "_concept_tid"));
	tjCollBat.insert("concept_elem", bat("tj_" + ftindex + "_concept_elem"));
	tjCollBat.insert("concept_score",bat("tj_" + ftindex + "_concept_score"));
	tjCollBat.insert("doc_name", bat("tj_" + ftindex + "_doc_name"));
	tjCollBat.insert("doc_firstpre", bat("tj_" + ftindex + "_doc_firstpre"));

	if (view_bbp_name().reverse().exist("tj_" + ftindex + "_Tags")) {
            tjCollBat.insert("_terms", bat("tj_" + ftindex + "_Terms"));
	    tjCollBat.insert("_tags", bat("tj_" + ftindex + "_Tags"));
	    tjCollBat.insert("_concepts", bat("tj_" + ftindex + "_Tags"));
	    tjCollBat.insert("_termIndex", bat("tj_" + ftindex + "_TermIndex"));
	    tjCollBat.insert("_tagIndex", bat("tj_" + ftindex + "_TagIndex"));
	    tjCollBat.insert("_conceptIndex", bat("tj_" + ftindex + "_TagIndex"));
	    tjCollBat.insert("_tagSize", bat("tj_" + ftindex + "_TagSize"));
	    tjCollBat.insert("_conceptScore", bat("tj_" + ftindex + "_TagSize"));
	}
        
        if ( verbose ) tj_verbose(HASH +"TJ _tj_get_collection_frag(\"%s\") finished.\n",ftiName);
	
	return tjCollBat;
}

#
# helper function to set / restrict access to the forward index
#
PROC _tj_set_forwardindex_access(BAT[str,bat] collBat, int ac) : void
{
      if ( verbose ) tj_verbose(HASH +"TJ _tj_set_forwardindex_access(\"%d\") called.\n",ac);
      
      collBat.find("doc_name").access(ac);
      collBat.find("doc_firstpre").access(ac);
      collBat.find("tid").access(ac);
      collBat.find("size").access(ac);
      collBat.find("pfpre").access(ac);
      if (inex) collBat.find("path").access(ac);
      if (inex) collBat.find("pathno").access(ac);
      collBat.find("concept_tid").access(ac);
      collBat.find("concept_elem").access(ac);
      collBat.find("concept_score").access(ac);
      collBat.find("termdict").access(ac);
      collBat.find("tagdict").access(ac);
      collBat.find("conceptdict").access(ac);
      collBat.find("rtags").access(ac);

      if ( verbose ) tj_verbose(HASH +"TJ _tj_set_forwardindex_access(\"%d\") finished.\n",ac);
}

#
# helper function to create commitBats were all BAT names are gathered that need to commited
#
PROC _tj_create_commitBats() : BAT[str,bat]
{
      var commitBats := new(str,bat);
      commitBats.insert("submitBats", new(void,str).seqbase(0@0));
      commitBats.insert("replaceBats", new(str,str));
      return commitBats;
}    

#
# convenience function
#
PROC tj_add2collection_frag(str ftiName, str uri, str filename, bit shred) : void
{
      var uris := new(str,str).insert(uri, filename);
      tj_add2collection_frag(ftiName, uris, shred);
}

ADDHELP("tj_add2collection_frag", "flokstra & rode", "Sept 2009",
"PARAMETERS:\n\
- str ftiName: the name of the collection.\n\
- BAT[str,str]: the bat containing the [location,name] pairs of the xml docs.\n\
- bit shred: when true the doc is shredded when necessary.\n\
DESCRIPTION:\n\
Adds a documents to the index. If needed, the index is split into several fragments.\n\
Each fragment is finalized after it is filled to its maximum capacity.",
"pftijah");
PROC tj_add2collection_frag(str ftiName, BAT[str,str] uri, bit shred) : void
{
    if ( verbose ) tj_verbose(HASH +"TJ tj_add2collection_frag(\"%s\") called.\n",ftiName);
    var coll_lock := tj_get_collection_lock(ftiName);
    lock_set(coll_lock);
    var err := CATCH({
      var t_start := usec();
    
      var commitBats := _tj_create_commitBats();

      # get first free collection fragment (first fragment that is not yet filled completely)       
      var collBat := _tj_get_collection_frag(ftiName, commitBats);

      # shred documents if needed
      if ( shred ) {
        var pf_collection := _tj_get_parameter2(collBat,"pf_collection");
        uri@batloop() {
          var uri_loc := $h;
          var uri_name := $t;
          if ( isnil(uri_loc) ) {
            ERROR("tj_add2collection_frag: should specify doc_uri (and doc_name).");
          }
          if ( isnil(uri_name) ) {
            uri_name := uri_loc;
          } else if ( uri_name = "" ) {
            uri_name := uri_loc;
          }
          if (not(bat("doc_name").reverse().exist(uri_name))) {
            var s_start := usec();
            if ( isnil(pf_collection) ) {
              shred_doc(uri_loc,uri_name);
            } else {
              shred_doc(uri_loc,uri_name,pf_collection,0LL);
            }
            if ( timing ) {
              ms := (usec() - s_start)/1000;
              printf(HASH +"TJ tj_add2collection_frag(\"%s\"): shred time = %lld.%03llds.\n",uri_name,/(ms,1000),%(ms,1000));
            }
          } else {
            if ( verbose ) tj_verbose(HASH +"TJ tj_add2collection_frag doc(\"%s\") already shredded.\n",uri_name);
          }
        }
      }
    
      # set access back to BAT_APPEND
      _tj_set_forwardindex_access(collBat, BAT_APPEND);
      
      _tj_set_parameter2(collBat, "status", "building");

      var frag_size := wrd(_tj_get_parameter2(collBat, "fragmentSize"));

      # for large documents, we need to check the fragment capacity limit for after each document
      # for small documents, this is too expensive, so we do it in larger batches
      var doc_size := _tj_get_parameter2(collBat, "documentSize");
      var chunksize := 10000;
      if (doc_size = "large")
        chunksize := 1;
      
      var first_doc := 0;
      var last_doc := uri.count()-1;
      var last_pre := collBat.find("size").count_wrd() + 1;
      while(first_doc <= last_doc) {
        var uri_chunk := uri.slice(first_doc, first_doc+chunksize-1);
        var ws_opt := ws_create(0); 
        ws_opendoc(ws_opt, uri_chunk.tmark(0@0));
        _tj_throw2collection_bat(collBat,ws_opt,uri_chunk);
        ws_destroy(ws_opt);
        last_pre := collBat.find("size").count_wrd() + 1;
        
        # check capacity of current fragment
        if ( last_pre >= frag_size ) {
          if ( verbose ) tj_verbose(HASH +"TJ tj_add2collection_frag(\"%s\"), fragment limit reached.\n",ftiName);
          _tj_set_parameter2(collBat, "_last_tijahPre", str(last_pre));
          _tj_finalize_collection_frag(ftiName, collBat, commitBats, false);
          collBat := _tj_get_collection_frag(ftiName, commitBats);
          _tj_set_forwardindex_access(collBat, BAT_APPEND);
        }
        first_doc := first_doc+chunksize;
      } 
      # update params
      _tj_set_parameter2(collBat, "_last_tijahPre", str(last_pre));
      _tj_finalize_collection_frag(ftiName, collBat, commitBats, false);
      _tj_commit_frag(collBat, commitBats); 

      if ( timing ) {
        var ms := (usec()-t_start)/1000;
        printf(HASH +"TJ tj_add2collection(BAT): total time = %lld.%03llds.\n",/(ms,1000),%(ms,1000));
      }
    });
    lock_unset(coll_lock);
    if ( verbose ) tj_verbose(HASH +"TJ tj_add2collection_frag(\"%s\") finished.\n",ftiName);
    if (not(isnil(err))) ERROR(err);
}


# 
# _tj_finalize_collection_frag builds an inverted index on the given fragment (if finalization is not delayed)
# 
PROC _tj_finalize_collection_frag(str ftiName, BAT[str,bat] collBat, BAT[str,bat] commitBats, bit fforce) : void
{
      var t_start := usec();
      if ( verbose ) tj_verbose(HASH +"TJ _tj_finalize_collection_frag(\"%s\") called.\n",ftiName);
    
      # set BATs to BAT_READ
      _tj_set_forwardindex_access(collBat, BAT_READ);

      # make sure that all modified BATs get submitted
      var submitBats := commitBats.find("submitBats");
      submitBats.append(collBat.find("doc_name").bbpname());
      submitBats.append(collBat.find("doc_firstpre").bbpname());
      submitBats.append(collBat.find("tid").bbpname());
      submitBats.append(collBat.find("size").bbpname());
      if (inex) submitBats.append(collBat.find("path").bbpname());
      if (inex) submitBats.append(collBat.find("pathno").bbpname());
      submitBats.append(collBat.find("pfpre").bbpname());
      submitBats.append(collBat.find("concept_tid").bbpname());
      submitBats.append(collBat.find("concept_elem").bbpname());
      submitBats.append(collBat.find("concept_score").bbpname());
      submitBats.append(collBat.find("termdict").bbpname());
      submitBats.append(collBat.find("tagdict").bbpname());
      submitBats.append(collBat.find("conceptdict").bbpname());
      submitBats.append(collBat.find("rtags").bbpname());
      submitBats.append(collBat.find("param").bbpname());
    
      if ( not(fforce) ) {
          var delfin   := lng(_tj_get_parameter2(collBat, "delay_finalize"));
          if ( delfin > lng(0) ) {
              var finlast  := lng(_tj_get_parameter2(collBat, "_last_finalizedPre"));
              var prelast  := lng(_tj_get_parameter2(collBat, "_last_tijahPre"));
              var fdelta   := prelast - finlast;
              if ( (prelast - finlast) < delfin ) {
                    if ( verbose ) tj_verbose(HASH +"TJ:_tj_finalize_collection(\"%s\") delaying finalization (%d < %d).\n",ftiName,int(fdelta),int(delfin));
          	  return;
              } else {
                    if ( verbose ) tj_verbose(HASH +"TJ:_tj_finalize_collection(\"%s\") finalization treshhold reached (%d > %d).\n",ftiName,int(fdelta),int(delfin));
              }
          }
      }
      #
      _tj_build_inverted_index_frag(ftiName, collBat, commitBats);
      #
      # update collection size
      var c_size := collBat.find("termfreq").[wrd]().sum();
      _tj_set_parameter2(collBat, "collectionSize", str(c_size));      

      _tj_set_parameter2(collBat, "status", "finalized");
      var lst_fpre := str(lng(_tj_get_parameter2(collBat,"_last_tijahPre")) - 1);
      _tj_set_parameter2(collBat, "_last_finalizedPre", lst_fpre);
      #
      
      if ( timing ) {
          var ms := (usec()-t_start)/1000;
          printf(HASH +"TJ _tj_finalize_collection_frag(): total time = %lld.%03llds.\n",/(ms,1000),%(ms,1000));
      }
      if ( verbose ) tj_verbose(HASH +"TJ _tj_finalize_collection_frag(\"%s\") finished.\n",ftiName);
}

PROC _tj_build_inverted_index_frag(str ftiName, BAT[str,bat] collBat, BAT[str,bat] commitBats) : void 
{
      if ( verbose ) tj_verbose(HASH +"TJ _tj_build_inverted_index_frag() called.\n");
	var offset := oid(lng(_tj_get_parameter2(collBat, "_last_finalizedPre")) + 1);
	var cur_frag := _tj_get_parameter2(collBat, "curFragment");
        var ftindex := ftiName + cur_frag;
	
	var pre_tid := collBat.find("tid");
	var pre_size := collBat.find("size");
        var tids := pre_tid.slice(lng(offset) - lng(pre_tid.seqbase()), lng(pre_tid.count_wrd() - 1));
	var sizes := pre_size.slice(lng(offset) - lng(pre_size.seqbase()), lng(pre_size.count_wrd() - 1));
       
    	var replaceBats := commitBats.find("replaceBats");
        var submitBats := commitBats.find("submitBats");
        collBat.find("termdict").access(BAT_WRITE);

        var split := splitbat(tids, collBat.find("pfpre"));
        var elems := split.fetch(1);
        var terms := split.fetch(0);
        split := nil;

	# incremental index merge
	if (collBat.exist("_tags")) 
        {
		# handle elements 
                var tmp := elems.reverse().ssort();
                elems := nil;
                var tmpsize := tmp.leftfetchjoin(sizes);
                var i := mergeindex2(tmp, tmpsize,
		                 collBat.find("_tagIndex"),
                                 collBat.find("_tags"),
                                 collBat.find("_tagSize"),
                                 collBat.find("tagdict").count_wrd() + 1);
                collBat.replace("_tagIndex", i.fetch(0).access(BAT_READ).mmap(1));
                collBat.replace("_tags", i.fetch(1).access(BAT_READ).mmap(1));
                collBat.replace("_tagSize", i.fetch(2).access(BAT_READ).mmap(1));
	        i := nil;
		tmp := nil;
		tmpsize := nil;
		replaceBats.insert("_tagIndex", "tj_" + ftindex + "_TagIndex");
                replaceBats.insert("_tags", "tj_" + ftindex + "_Tags");
                replaceBats.insert("_tagSize", "tj_" + ftindex + "_TagSize");
		submitBats.append("tj_" + ftindex + "_TagIndex");
		submitBats.append("tj_" + ftindex + "_Tags");
		submitBats.append("tj_" + ftindex + "_TagSize");
		
                # handle terms
                tmp := terms.reverse().ssort();
                terms := nil;
		var tf := collBat.find("termfreq");
                var termfreq := {count}(tmp, collBat.find("termdict"), false);
                tf [:+=] termfreq.slice(0,tf.count() - 1);
		tf.append(termfreq.slice(tf.count(), termfreq.count() - 1));
		i := mergeindex(tmp, collBat.find("_termIndex"),
                                         collBat.find("_terms"),
                                         collBat.find("termdict").count_wrd() + 1);       
                collBat.replace("_termIndex", i.fetch(0).access(BAT_READ).mmap(1));
                collBat.replace("_terms", i.fetch(1).access(BAT_READ).mmap(1));
	        i := nil;
		tmp := nil;
		replaceBats.insert("_termIndex", "tj_" + ftindex + "_TermIndex");
                replaceBats.insert("_terms", "tj_" + ftindex + "_Terms");
		submitBats.append("tj_" + ftindex + "_TermIndex");
		submitBats.append("tj_" + ftindex + "_Terms");
		submitBats.append(tf.bbpname());
        }
        else # create new index
        {       
		# handle elements 
                var tmp := elems.reverse().ssort();
                elems := nil;
	        var tagindex := tmp.hmark(1@0).offsetindex(collBat.find("tagdict").count_wrd() + 1);
	        var tags := tmp.tmark(1@0);
	        tmp := nil;
	        # create _Tags and _Tagindex here
	        tagindex.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftindex + "_TagIndex");
	        tags.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftindex + "_Tags");
	        tagindex := nil;
		var tagsize := tags.leftfetchjoin(sizes);
		tags := nil;
	        tagsize.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftindex + "_TagSize");
		tagsize := nil;
                collBat.insert("_tagIndex", bat("tj_" + ftindex + "_TagIndex"));
                collBat.insert("_tags", bat("tj_" + ftindex + "_Tags"));
                collBat.insert("_tagSize", bat("tj_" + ftindex + "_TagSize"));
		submitBats.append("tj_" + ftindex + "_TagIndex");
		submitBats.append("tj_" + ftindex + "_Tags");
		submitBats.append("tj_" + ftindex + "_TagSize");

		# handle terms
                tmp := terms.reverse().ssort();
                terms := nil;
		var tf := collBat.find("termfreq");
                var termfreq := {count}(tmp, collBat.find("termdict"), false);
                tf [:+=] termfreq.slice(0,tf.count() - 1);
		tf.append(termfreq.slice(tf.count(), termfreq.count() - 1));
	        var termindex := tmp.hmark(0@0).offsetindex(collBat.find("termdict").count_wrd() + 1);
	        var terms := tmp.tmark(0@0);
	        tmp := nil;
	        # create _TermIndex and _Terms here
	        termindex.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftindex + "_TermIndex");
	        terms.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftindex + "_Terms");
	        termindex := nil;
		terms := nil;
                collBat.insert("_termIndex", bat("tj_" + ftindex + "_TermIndex"));
                collBat.insert("_terms", bat("tj_" + ftindex + "_Terms"));
		submitBats.append("tj_" + ftindex + "_TermIndex");
		submitBats.append("tj_" + ftindex + "_Terms");
		submitBats.append(tf.bbpname());
        }
        
        # always create concept table from scratch
	var c_cid := collBat.find("concept_tid");
	var c_pre := collBat.find("concept_elem");
	var c_scr := collBat.find("concept_score");
        var tmp := c_pre.tsort().mirror().leftfetchjoin(c_cid).reverse().ssort();
        c_cid := tmp.leftfetchjoin(c_cid).tmark(0@0).chk_order();
        var concepts := tmp.leftfetchjoin(c_pre).tmark(0@0);
        var conceptscore := tmp.leftfetchjoin(c_scr).tmark(0@0);
        tmp := nil;
	var conceptindex := offsetindex(c_cid, collBat.find("conceptdict").count_wrd() + 1);
	# create _ConceptIndex and _Concepts here
	conceptindex.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftindex + "_ConceptIndex");
	concepts.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftindex + "_Concepts");
	conceptscore.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftindex + "_ConceptScore");
	conceptindex := nil;
        concepts := nil;
	conceptscore := nil;
	submitBats.append("tj_" + ftindex + "_ConceptIndex");
	submitBats.append("tj_" + ftindex + "_Concepts");
	submitBats.append("tj_" + ftindex + "_ConceptScore");
        collBat.find("termdict").access(BAT_READ);
      if ( verbose ) tj_verbose(HASH +"TJ _tj_build_inverted_index_frag() finished.\n");
}

PROC _tj_commit_frag(BAT[str,bat] collBat, BAT[str,bat] commitBats) : void
{
      if ( verbose ) tj_verbose(HASH +"TJ _tj_commit_frag() called.\n");
      var replaceBats := commitBats.find("replaceBats");
      replaceBats@batloop() {
      	 bat($t).persists(false).rename("del_" + $t);
	 collBat.find($h).persists(true).bbpname($t);
      }
    
      var submitBats := commitBats.find("submitBats");
      submitBats.append([+](const "del_", replaceBats.tmark(0@0)));
      subcommit(submitBats);
      if ( verbose ) tj_verbose(HASH +"TJ _tj_commit_frag() finished.\n");
}

PROC tj_collection_delete(str ftiName) : void
{
      delete_pfc_fti(ftiName);
      var tj_bats := view_bbp_name().like("tj_" + ftiName).tmark();
      [persists]([bat](tj_bats), const false);
      subcommit(tj_bats);
}

PROC tj_global_delete() : void
{
      var tj_bats := view_bbp_name().like("tj_").tmark();
      [persists]([bat](tj_bats), const false);
      subcommit(tj_bats);
}

PROC tj_used_frags(str ftiName) : bat[void,int]
{
      var parambat := bat("tj_" + ftiName + "_param");
      var last := int(parambat.find("curFragment"));
      var cur := 0;
      var res := new(void,int).seqbase(0@0);
      while (cur <= last) {
         res.append(cur);
         cur :+= 1;
      }
      return res;
}

#
# Start of ft-index / pf-collection dependency module
#

PROC modify_pfc_fti(str fti_name, BAT[void,str]  v_pfc) : BAT[str,str] 
{
    var result;

    lock_set(tj_dep_lock);
    var err := CATCH({
	var glb_fti_pfc     := bat("tj_pfc_fti_dep");
	var fti_dep := glb_fti_pfc.reverse().select(fti_name).reverse();
	if ( fti_dep.select("*").count_wrd() > wrd(0) ) {
	    ERROR(HASH + " pfc_fti_dep: unable to extend ft-index when created with *\n");
	}
	var new_fti_pfc := v_pfc.tunique().project(fti_name).reverse().sunique().tdiff(fti_dep);
	if ( verbose ) {
	    printf(HASH +"TJ:modify_pfc_fti: ***** added dep ***\n");
	    new_fti_pfc.print();
	}
	var sz := new_fti_pfc.count_wrd();
	if ( sz > wrd(0) ) {
	    if ( sz = wrd(1) ) {
		glb_fti_pfc.insert(new_fti_pfc);
		if ( new_fti_pfc.uselect("*").count_wrd() > wrd(0) ) {
		    bat("tj_pfc_fti_dep_star").insert(new_fti_pfc);
	        }
	    } else {
	    	if ( new_fti_pfc.uselect("*").count_wrd() > wrd(0) ) {
		    ERROR(HASH + " pfc_fti_dep: when using * it must be the only collection dependency.\n");
		}
		glb_fti_pfc.insert(new_fti_pfc);
	    }
	}
	result := new_fti_pfc;
    });
    if ( verbose ) {
    	printf("\n" + HASH + " LOG modify_pfc_fti(\"%s\") START, v_pfc =\n", fti_name);
	v_pfc.print();
    	printf(HASH +" Dependence BATs are [STAR|ALL]:\n");
	bat("tj_pfc_fti_dep_star").print();
	bat("tj_pfc_fti_dep").print();
    	printf(HASH +" LOG modify_pfc_fti(\"%s\") END.\n", fti_name);
    }
    lock_unset(tj_dep_lock);
    if (not(isnil(err))) ERROR(err);
    #
    return result;
}

PROC delete_pfc_fti(str fti_name) :void 
{
    lock_set(tj_dep_lock);
    var err := CATCH({
	bat("tj_pfc_fti_dep").delete(fti_name);
	bat("tj_pfc_fti_dep_star").delete(fti_name);
    });
    lock_unset(tj_dep_lock);
    if (not(isnil(err))) ERROR(err);
}



#####################################################################
#                                                                   #
# The query section				                    #
#                                                                   #
#####################################################################

# tijah function to 'package' a pathfinder [iter|item|kind|pos] operand
PROC tj_pfop(	BAT[void,oid] iter,
		BAT[void,any] item,
		BAT[void,int] kind,
		BAT[void,oid] pos) : BAT[void,bat] 
{
	var res := new(void,bat).seqbase(0@0);

	res.append(iter);
	res.append(item);
	res.append(kind);
	res.append(pos);

	return res;
}

# universal tijah query function handler. Sould work in the milprint_summer
# and in the algebra context.
PROC tj_query_handler(
	bit par_storeScore,
	BAT[void,bat] pfop_sn,
	BAT[void,bat] pfop_query,
	BAT[void,bat] pfop_opt,
	BAT[oid,any]  par_loop,
	BAT[oid,bat]  par_ws,
	BAT[void,lng] par_int_values,
	BAT[void,dbl] par_dbl_values,
        BAT[void,str] par_str_values,
	BAT[void,bat] par_scoreDB
	) : BAT[void,bat] 
{
     var result_id;
     var result_iter;
     var result_item;
     var result_pos;
     var result_frag;

     if ( par_storeScore ) {
      result_id   := new(void,lng).seqbase(0@0);
     } else {
      result_iter := new(void,oid).seqbase(0@0);
      result_item := new(void,oid).seqbase(0@0);
      result_pos  := new(void,oid).seqbase(0@0);
      result_frag := new(void,oid).seqbase(0@0);
     }

     var has_sn      := (pfop_sn.count_wrd() > wrd(0));
     var has_options := (pfop_opt.count_wrd() > wrd(0));

     par_loop@batloop() { # begin batloop over queries
      var optbat;
      if ( has_options ) {
       iter := pfop_opt.fetch(0@0).select($t);
       item := pfop_opt.fetch(1@0).semijoin(iter);
       kind := pfop_opt.fetch(2@0).semijoin(iter);
       iter := iter.tmark(0@0);
       item := item.tmark(0@0);
       kind := kind.tmark(0@0);
       optbat := serialize_tijah_opt(par_ws,1,iter,iter,item,kind,par_int_values,par_dbl_values,par_str_values);
      } else {
       optbat := new(str,str,32);
      }
      var ftindex := tj_get_ft_index(optbat,true);
      tijah_lock := tj_get_collection_lock(ftindex);
      lock_set(tijah_lock);
      var startNodes;
      if ( has_sn ) {
       iter := pfop_sn.fetch(0@0);
       var iteration := pfop_query.fetch(0@0).fetch(int($h));
       iter := iter.select(iteration);
       item := pfop_sn.fetch(1@0).semijoin(iter);
       kind := pfop_sn.fetch(2@0).semijoin(iter);
       item := item.tmark(0@0);
       kind := kind.tmark(0@0);
       var xdoc_name := bat("tj_" + ftindex + "_doc_name");
       var xdoc_firstpre := bat("tj_" + ftindex + "_doc_firstpre");
       var xpfpre := bat("tj_" + ftindex + "_pfpre");
       var doc_loaded := reverse(par_ws.fetch(OPEN_CONT)).leftfetchjoin(par_ws.fetch(OPEN_NAME));
       startNodes := pf2tijah_node(false,xdoc_name,xdoc_firstpre,xpfpre,item,kind,doc_loaded);
      } else {
       startNodes := new(void,oid);
      }
      optbat.access(BAT_WRITE);
      optbat.insert("_query",pfop_query.fetch(1@0).fetch(int($h)));
      var nexi_allscores := run_tijah_query(ftindex,optbat,has_sn,startNodes);
      var nexi_score;
      if ( optbat.exist("returnNumber") ) {
       var retNum := int(optbat.find("returnNumber"));
       nexi_score := nexi_allscores.slice(0, retNum - 1);
      } else {
       nexi_score := nexi_allscores;
      }
      var docpre := bat("tj_" + ftindex + "_doc_firstpre").[oid]();
      var pfpre :=  bat("tj_" + ftindex + "_pfpre");
      item  := nexi_score.hmark(0@0);
      var frag := [find_lower](const docpre.reverse().mark(0@0), item);
      item := item.join(pfpre).sort().tmark();
      var needed_docs := bat("tj_" + ftindex + "_doc_name").semijoin(frag.tunique());
      lock_unset(tijah_lock);
      tijah_lock := lock_nil;
      var loaded_docs := par_ws.fetch(OPEN_NAME).reverse();
      var docs_to_load := kdiff(needed_docs.reverse(),loaded_docs).hmark(0@0);
      ws_opendoc(par_ws, docs_to_load);
      var doc_loaded := reverse(par_ws.fetch(OPEN_CONT)).leftfetchjoin(par_ws.fetch(OPEN_NAME));
      var fid_pffid := needed_docs.join(doc_loaded.reverse());
      frag := frag.join(fid_pffid).sort().tmark();
      if ( par_storeScore ) {
       var tID := oid(par_scoreDB.fetch(0@0).count_wrd() + 10000);
       par_scoreDB.fetch(4@0).insert(lng(tID),lng(nexi_allscores.count_wrd()));
       par_scoreDB.fetch(0@0).append(item.project(tID));
       par_scoreDB.fetch(1@0).append(frag);
       par_scoreDB.fetch(2@0).append(item);
       par_scoreDB.fetch(3@0).append(nexi_score.tmark());
       result_id.append(lng(tID));
      } else {
       result_iter.append(item.project($t));
       result_pos.append(item.mark(1@0));
       result_frag.append(frag);
       result_item.append(item);
      }
     } # end batloop over queries
     if ( par_storeScore ) {
      item := int_values.addValues(result_id).tmark(0@0);
      iter := par_loop.tmark(oid(0));
      ipik := iter;
      pos  := oid(1);
      kind := INT;
     } else {
      iter := result_iter;
      pos := result_pos;
      kind := set_kind(result_frag, ELEM);
      item := result_item;
      ipik := iter;
     }
     var res := tj_pfop(iter.materialize(ipik),item.materialize(ipik),kind.materialize(ipik),pos.materialize(ipik));
     #
     return res;
}

var nexi_score_xfer  := nil;
var nexi_sn_xfer     := nil;
var nexi_parser_lock := lock_create();

PROC run_tijah_query(str ftiName, BAT[str,str] opt, bit use_startnodes, BAT[void,oid] nodes) : BAT[oid,dbl] 
{
	if ( verbose ) tj_verbose(HASH +"TJ:run_tijah_query(\"%s\",..) called.\n",ftiName);
	var parambat := bat("tj_" + ftiName + "_param");
	var rtagbat  := bat(_tj_RTagBat(ftiName));

	var delfin   := lng(parambat.find("delay_finalize"));
        if ( delfin > lng(0) ) {
	    if ( verbose ) tj_verbose(HASH +"TJ:run_tijah_query(\"%s\",..) checking delayed finalize.\n",ftiName);
            var finlast  := lng(parambat.find("_last_finalizedPre"));
            var prelast  := lng(parambat.find("_last_tijahPre"));
	    if ( not(prelast=finlast) ) {
	        if ( verbose ) tj_verbose(HASH +"TJ:run_tijah_query(\"%s\",..) performing delayed finalize (%d != %d).\n",ftiName,int(finlast),int(prelast));
                var collBat := _tj_collection(ftiName);
                _tj_finalize_collection(ftiName, collBat, TRUE);
                _tj_commit(collBat); 
	    }
	}
	var res := nil;
        lock_set(nexi_parser_lock);
        var err := CATCH({
	    nexi_sn_xfer := nodes;
            opt.insert("maxfrag", parambat.find("curFragment"));
	    _run_tijah_query(opt,rtagbat,use_startnodes);
	    res := nexi_score_xfer;
        });
	nexi_score_xfer := nil;
	nexi_sn_xfer := nil;
        lock_unset(nexi_parser_lock);
        if (not(isnil(err))) ERROR(err);
	return res;
}

PROC run_nexi_query(str nexi, bat[str,str] opt) : BAT[oid,dbl]
{
	var res := nil;
        var err := CATCH({
            var ftiName := dflt_ft_index;
            if (opt.exist("ft-index")) ftiName := opt.find("ft-index"); 
	    var parambat := bat("tj_" + ftiName + "_param");
	    var rtagbat  := bat(_tj_RTagBat(ftiName));
            opt.insert("_query", nexi);
            opt.insert("maxfrag", parambat.find("curFragment"));
            if (inex) opt.insert("inexout", "true");
	    _run_tijah_query(opt,rtagbat,false);
	    res := nexi_score_xfer;
        });
	nexi_score_xfer := nil;
	nexi_sn_xfer := nil;
        if (not(isnil(err))) ERROR(err);
	return res;
}

#####################################################################
#								    #
#								    #
# Experimental algebra section					    #
#								    #
#								    #
#####################################################################

# tijah function to 'package' an algebra [iter|item|kind|pos] operand
PROC ALG_tj_pfop(
		BAT[oid,oid] iter,
		BAT[oid,any] item,
		int          noKind,
		BAT[oid,oid] pos) : BAT[void,bat] 
{
	var res := new(void,bat).seqbase(0@0);

	res.append(iter);
	res.append(item);
	res.append(item.project(0));
	res.append(pos);

	return res;
}

PROC ALG_tj_pfop(
		BAT[oid,oid] iter,
		BAT[oid,any] item,
		BAT[oid,any] kind,
		BAT[oid,oid] pos) : BAT[void,bat] 
{
	var res := new(void,bat).seqbase(0@0);

	res.append(iter);
	res.append(item);
	res.append(kind);
	res.append(pos);

	return res;
}

PROC ALG_tj_pfop(
		BAT[oid,oid] iter,
		BAT[oid,any] item,
		BAT[oid,any] kind,
		BAT[oid,oid] pos,
		BAT[oid,dbl] score) : BAT[void,bat] 
{
	var res := new(void,bat).seqbase(0@0);

	res.append(iter);
	res.append(item);
	res.append(kind);
	res.append(pos);
	res.append(score);

	return res;
}

PROC ALG_tj_ft_index_info(
	BAT[oid,bat]  par_ws,
	BAT[void,any] par_loop,
	BAT[oid,bat]  pfop_names
	) : BAT[void,bat] 
{
        var ret;

	if ( pfop_names.count_wrd() > wrd(0) ) {
	    ret := ws_ft_index_info(ws, pfop_names.fetch(1@0),false);

	} else {
	    ret := reverse(par_loop).cross(ws_ft_index_info(ws,false));
	}
	var iter := ret.hmark(0@0);
	var item := ret.tmark(0@0);
	var ipik := item;
	var frag := WS;
	frag     := frag.materialize(ipik);
	var pos  := tmark_grp_unique(iter,ipik);

        var res := ALG_tj_pfop(iter,item,frag,pos);
        if ( verbose ) tj_verbose(HASH +" ALG_tj_ft_index_info: FINISH.\n");
        return res;
}

PROC ALG_tj_query_nodes(
	BAT[void,any] par_loop,
	BAT[oid,bat]  pfop_id,
	BAT[oid,bat]  tijah_scoreDB
	) : BAT[void,bat] 
{
        if ( verbose ) tj_verbose(HASH +" ALG_tj_query_nodes: START.\n");
	var item := new(void,oid).seqbase(0@0);
	var iter := new(void,oid).seqbase(0@0);
	var pos  := new(void,oid).seqbase(0@0);
	var frag := new(void,oid).seqbase(0@0);
	par_loop@batloop() { # begin of query batloop
	    var qid := oid(pfop_id.fetch(1).fetch(int($h)));
	    var tmp := tijah_scoreDB.fetch(0@0).ord_uselect(qid);
	    item.append(tmp.mirror().leftfetchjoin(tijah_scoreDB.fetch(2@0)));
	    iter.append(tmp.project($t));
	    frag.append(tmp.mirror().leftfetchjoin(tijah_scoreDB.fetch(1@0)));
	    pos.append(tmp.mark(1@0));
	} # end of query batloop
        var res := ALG_tj_pfop(iter,item,frag,pos);
        if ( verbose ) tj_verbose(HASH +" ALG_tj_query_nodes: FINISH.\n");
        return res;
}

PROC ALG_tj_query_score(
	BAT[void,any] par_loop,
	BAT[oid,bat]  pfop_id,
	BAT[oid,bat]  pfop_nodes,
	BAT[oid,bat]  tijah_scoreDB
	) : BAT[void,bat] 
{
	var score := new(oid,dbl);
	var tmp := [<<]([lng](tijah_scoreDB.fetch(1@0)), const 32);
	var tijah_fragpre := [+](tmp, [lng](tijah_scoreDB.fetch(2@0)));
	tmp := nil;
	var item1_unique := pfop_id.fetch(1).tunique();
	var item := pfop_nodes.fetch(1);
	var kind := pfop_nodes.fetch(2);
	item1_unique@batloop() {
	    var item_part := item.semijoin(pfop_id.fetch(1).uselect($h));
	    var frag_part := kind.semijoin(item_part);
	    frag_part := [<<]([lng](frag_part), const 32);
	    var fragpre_part := [+](frag_part, [lng](item_part));

	    item_part := nil;
	    frag_part := nil;
	    tmp := tijah_scoreDB.fetch(0@0).uselect(oid($h));
	    tmp := tmp.mirror().leftfetchjoin(tijah_fragpre);
	    tmp := tmp.join(fragpre_part.reverse());
	    score.insert(tmp.reverse().leftfetchjoin(tijah_scoreDB.fetch(3@0)));
	}
	var xitem := kdiff(item,score).project(dbl(0));
	score.insert(xitem);
	xitem := nil;
	score := score.sort().tmark(0@0);

        var iter := par_loop.tmark(0@0);
	var ipik := iter;
	var pos  := 1@0;
        var res := ALG_tj_pfop(iter,score,0,pos.materialize(ipik));
        if ( verbose ) tj_verbose(HASH +" ALG_tj_query_nodes: FINISH.\n");
        return res;
}

# temporary algebra query handler
PROC ALG_tj_query_handler2(
        bit par_storeScore,
        BAT[oid,bat] pfop_sn,
        BAT[oid,bat] pfop_query,
        BAT[oid,bat] pfop_opt,
        BAT[void,any]  par_loop,
        BAT[oid,bat]  par_ws,
        BAT[oid,bat] par_scoreDB
        ) : BAT[void,bat] 
{
     var result_id;
     var result_iter;
     var result_item;
     var result_pos;
     var result_frag;

    if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: START.\n");
     if ( par_storeScore ) {
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: storeScore=TRUE.\n");
      result_id   := new(void,lng).seqbase(0@0);
     } else {
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: storeScore=FALSE.\n");
      result_iter := new(void,oid).seqbase(0@0);
      result_item := new(void,oid).seqbase(0@0);
      result_pos  := new(void,oid).seqbase(0@0);
      result_frag := new(void,oid).seqbase(0@0);
     }

     var has_sn      := (pfop_sn.count_wrd() > wrd(0));
     var has_options := (pfop_opt.count_wrd() > wrd(0));

     par_loop@batloop() {
      var optbat;
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: loop start, id=%d.\n",int($t));
      if ( has_options ) {
       if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: running option handler.\n");
       var opt_iter := pfop_opt.fetch(0@0).select($t);
       var opt_item := pfop_opt.fetch(1@0).semijoin(opt_iter);
       var opt_kind := pfop_opt.fetch(2@0).semijoin(opt_iter);
       opt_iter := opt_iter.tmark(0@0);
       opt_item := opt_item.tmark(0@0);
       opt_kind := opt_kind.tmark(0@0);
       optbat := serialize_tijah_opt(par_ws,1,opt_iter,opt_iter,opt_item,set_kind(opt_kind,ELEM),new(void,lng),new(void,dbl),new(void,str));
       if ( verbose ) optbat.print();
      } else {
       optbat := new(str,str,32);
      }
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: handle startNodes.\n");
      var ftiName := tj_get_ft_index(optbat,true);
      var tijah_lock := tj_get_collection_lock(ftiName);
      lock_set(tijah_lock);
      var err := CATCH({
        var startNodes;
        if ( has_sn ) {
         var sn_iter := pfop_sn.fetch(0@0);
         var sn_iteration := pfop_query.fetch(0@0).fetch(int($h));
         sn_iter := sn_iter.select(sn_iteration);
         var sn_item := pfop_sn.fetch(1@0).semijoin(sn_iter);
         var sn_kind := pfop_sn.fetch(2@0).semijoin(sn_iter);
         sn_item := sn_item.tmark(0@0);
         sn_kind := sn_kind.tmark(0@0);

         var xdoc_name := bat("tj_" + ftiName + "0_doc_name");
         var xdoc_firstpre := bat("tj_" + ftiName + "0_doc_firstpre");
         var xpfpre := bat("tj_" + ftiName + "0_pfpre");
         var doc_loaded := par_ws.fetch(CONT_COLL).join(bat("doc_collection").reverse()).join(bat("doc_name"));
         if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: compute startnodes\n");
         startNodes := pf2tijah_node(false,xdoc_name,xdoc_firstpre,xpfpre,sn_item,[int](sn_kind),doc_loaded);
        } else {
         startNodes := new(void,oid);
        }
        optbat.access(BAT_WRITE);
        optbat.insert("_query",pfop_query.fetch(1@0).fetch(int($h)));
        if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: run tijah query.\n");
        var nexi_allscores := run_tijah_query(ftiName,optbat,has_sn,startNodes);
        var nexi_score;
        if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: handling scores.\n");
        if ( optbat.exist("returnNumber") ) {
         var retNum := int(optbat.find("returnNumber"));
         nexi_score := nexi_allscores.slice(0, retNum - 1);
        } else {
         nexi_score := nexi_allscores;
        }
        var docpre := bat("tj_" + ftiName + "0_doc_firstpre").[oid]();
        var pfpre  :=  bat("tj_" + ftiName + "0_pfpre");
        var item   := nexi_score.hmark(0@0);
        var frag := [find_lower](const docpre.reverse().mark(0@0), item);
        item := item.join(pfpre).sort().tmark();
        var needed_docs := bat("tj_" + ftiName + "0_doc_name").semijoin(frag.tunique());
        var loaded_docs := par_ws.fetch(OPEN_NAME).reverse();
        var docs_to_load := kdiff(needed_docs.reverse(),loaded_docs).hmark(0@0);
        ws_opendoc(par_ws, docs_to_load);
        var doc_loaded := reverse(par_ws.fetch(OPEN_CONT)).leftfetchjoin(par_ws.fetch(OPEN_NAME));
	# On the forced document loading size we keep using the old interface
	# until ws.fetch(OPEN_CONT|OPEN_DOC) disappears. This interface is
	# much cheaper for us and works also correct when the OPEN_CONT|DOC
	# bats are not complete.
	# var doc_loaded := par_ws.fetch(CONT_COLL).join(bat("doc_collection").reverse()).join(bat("doc_name"));
        var fid_pffid := needed_docs.join(doc_loaded.reverse());
        frag := frag.join(fid_pffid).sort().tmark();
        if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: handled new frags/documents.\n");
        if ( par_storeScore ) {
         var tID := oid(par_scoreDB.fetch(0@0).count_wrd() + 8888);
         par_scoreDB.fetch(4@0).insert(lng(tID),lng(nexi_allscores.count_wrd()));
         par_scoreDB.fetch(0@0).append(item.project(tID));
         par_scoreDB.fetch(1@0).append(frag);
         par_scoreDB.fetch(2@0).append(item);
         par_scoreDB.fetch(3@0).append(nexi_score.tmark());
         result_id.append(lng(tID));
         if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: stored loop score.\n");
        } else {
         result_iter.append(item.project($t));
         result_pos.append(item.mark(1@0));
         result_frag.append(frag);
         result_item.append(item);
        }
      });
      lock_unset(tijah_lock);
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: released lock.\n");
      if (not(isnil(err))) ERROR(err);
       if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: stored loop nodes in result.\n");
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: loop finish, id=%d.\n",int($t));
     } # end batloop over queries
     if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: batloop finished.\n");
     var iter;
     var item;
     var ipik;
     var kind;
     var pos;
     if ( par_storeScore ) {
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: create int return.\n");
      item := result_id;
      iter := par_loop.tmark(oid(0));
      ipik := iter;
      pos  := oid(1);
      kind := new(oid,oid);
     } else {
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: create node return.\n");
      iter := result_iter;
      pos  := result_pos;
      kind := result_frag;
      item := result_item;
      ipik := iter;
     }
      if ( verbose ) {
         printf(HASH +" ALG_tj_query_handler: iter/item/kind/pos result start\n");
         iter.print();
         item.print();
         kind.print();
         pos.print();
         printf(HASH +" ALG_tj_query_handler: iter/item/kind/pos result finish\n");
      }
     var res := ALG_tj_pfop(iter,item,kind,pos.materialize(ipik));
     #
     if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: FINISH.\n");
     return res;
}

# temporary algebra query handler
PROC ALG_tj_query_handler(
        bit par_storeScore,
        BAT[oid,bat] pfop_sn,
        BAT[oid,bat] pfop_query,
        BAT[oid,bat] pfop_opt,
        BAT[void,any] par_loop,
        BAT[oid,bat] par_ws,
        BAT[oid,bat] par_scoreDB
        ) : BAT[void,bat] 
{
     var result_id;
     var result_iter;
     var result_item;
     var result_pos;
     var result_frag;

    if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: START.\n");
     if ( par_storeScore ) {
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: storeScore=TRUE.\n");
      result_id   := new(void,lng).seqbase(0@0);
     } else {
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: storeScore=FALSE.\n");
      result_iter := new(void,oid).seqbase(0@0);
      result_item := new(void,oid).seqbase(0@0);
      result_pos  := new(void,oid).seqbase(0@0);
      result_frag := new(void,oid).seqbase(0@0);
     }

     var has_sn      := (pfop_sn.count_wrd() > wrd(0));
     var has_options := (pfop_opt.count_wrd() > wrd(0));

     par_loop@batloop() {
      var optbat;
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: loop start, id=%d.\n",int($t));
      if ( has_options ) {
       if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: running option handler.\n");
       var opt_iter := pfop_opt.fetch(0@0).select($t);
       var opt_item := pfop_opt.fetch(1@0).semijoin(opt_iter);
       var opt_kind := pfop_opt.fetch(2@0).semijoin(opt_iter);
       opt_iter := opt_iter.tmark(0@0);
       opt_item := opt_item.tmark(0@0);
       opt_kind := opt_kind.tmark(0@0);
       optbat := serialize_tijah_opt(par_ws,1,opt_iter,opt_iter,opt_item,set_kind(opt_kind,ELEM),new(void,lng),new(void,dbl),new(void,str));
       if ( verbose ) optbat.print();
      } else {
       optbat := new(str,str,32);
      }
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: handle startNodes.\n");
      var ftiName := tj_get_ft_index(optbat,true);
      var tijah_lock := tj_get_collection_lock(ftiName);
      lock_set(tijah_lock);
      var err := CATCH({
        var startNodes;
        if ( has_sn ) {
         var sn_iter := pfop_sn.fetch(0@0);
         var sn_iteration := pfop_query.fetch(0@0).fetch(int($h));
         sn_iter := sn_iter.select(sn_iteration);
         var sn_item := pfop_sn.fetch(1@0).semijoin(sn_iter);
         var sn_kind := pfop_sn.fetch(2@0).semijoin(sn_iter);
         sn_item := sn_item.tmark(0@0);
         sn_kind := sn_kind.tmark(0@0);

         var xdoc_name := bat("tj_" + ftiName + "0_doc_name");
         var xdoc_firstpre := bat("tj_" + ftiName + "0_doc_firstpre");
         var xpfpre := bat("tj_" + ftiName + "0_pfpre");
         var doc_loaded := par_ws.fetch(CONT_COLL).join(bat("doc_collection").reverse()).join(bat("doc_name"));
         if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: compute startnodes\n");
         startNodes := pf2tijah_node(false,xdoc_name,xdoc_firstpre,xpfpre,sn_item,[int](sn_kind),doc_loaded);
        } else {
         startNodes := new(void,oid);
        }
        optbat.access(BAT_WRITE);
        optbat.insert("_query",pfop_query.fetch(1@0).fetch(int($h)));
        if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: run tijah query.\n");
        var nexi_allscores := run_tijah_query(ftiName,optbat,has_sn,startNodes);
        var nexi_score;
        if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: handling scores.\n");
        if ( optbat.exist("returnNumber") ) {
         var retNum := int(optbat.find("returnNumber"));
         nexi_score := nexi_allscores.slice(0, retNum - 1);
        } else {
         nexi_score := nexi_allscores;
        }

        var docpre := bat("tj_" + ftiName + "0_doc_firstpre").[oid]();
        var pfpre  :=  bat("tj_" + ftiName + "0_pfpre");
        var item   := nexi_score.hmark(0@0);
        var frag := [find_lower](const docpre.reverse().mark(0@0), item);
        item := item.join(pfpre).sort().tmark();
        var needed_docs := bat("tj_" + ftiName + "0_doc_name").semijoin(frag.tunique());


        var loaded_docs := par_ws.fetch(OPEN_NAME).reverse();
        var docs_to_load := kdiff(needed_docs.reverse(),loaded_docs).hmark(0@0);
        ws_opendoc(par_ws, docs_to_load);
        var doc_loaded := reverse(par_ws.fetch(OPEN_CONT)).leftfetchjoin(par_ws.fetch(OPEN_NAME));
	# On the forced document loading size we keep using the old interface
	# until ws.fetch(OPEN_CONT|OPEN_DOC) disappears. This interface is
	# much cheaper for us and works also correct when the OPEN_CONT|DOC
	# bats are not complete.
	# var doc_loaded := par_ws.fetch(CONT_COLL).join(bat("doc_collection").reverse()).join(bat("doc_name"));
        var fid_pffid := needed_docs.join(doc_loaded.reverse());
        frag := frag.join(fid_pffid).sort().tmark();
        if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: handled new frags/documents.\n");
        if ( par_storeScore ) {
         var tID := oid(par_scoreDB.fetch(0@0).count_wrd() + 8888);
         par_scoreDB.fetch(4@0).insert(lng(tID),lng(nexi_allscores.count_wrd()));
         par_scoreDB.fetch(0@0).append(item.project(tID));
         par_scoreDB.fetch(1@0).append(frag);
         par_scoreDB.fetch(2@0).append(item);
         par_scoreDB.fetch(3@0).append(nexi_score.tmark());
         result_id.append(lng(tID));
         if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: stored loop score.\n");
        } else {
         result_iter.append(item.project($t));
         result_pos.append(item.mark(1@0));
         result_frag.append(frag);
         result_item.append(item);
        }
      });
      lock_unset(tijah_lock);
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: released lock.\n");
      if (not(isnil(err))) ERROR(err);
       if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: stored loop nodes in result.\n");
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: loop finish, id=%d.\n",int($t));
     } # end batloop over queries
     if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: batloop finished.\n");
     var iter;
     var item;
     var ipik;
     var kind;
     var pos;
     if ( par_storeScore ) {
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: create int return.\n");
      item := result_id;
      iter := par_loop.tmark(oid(0));
      ipik := iter;
      pos  := oid(1);
      kind := new(oid,oid);
     } else {
      if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: create node return.\n");
      iter := result_iter;
      pos  := result_pos;
      kind := result_frag;
      item := result_item;
      ipik := iter;
     }
      if ( verbose ) {
         printf(HASH +" ALG_tj_query_handler: iter/item/kind/pos result start\n");
         iter.print();
         item.print();
         kind.print();
         pos.print();
         printf(HASH +" ALG_tj_query_handler: iter/item/kind/pos result finish\n");
      }
     var res := ALG_tj_pfop(iter,item,kind,pos.materialize(ipik));
     #
     if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: FINISH.\n");
     return res;
}

PROC ALG_tj_terms(
	BAT[void,any] par_loop,
	BAT[oid,bat]  par_ws,
	BAT[oid,bat]  par1_el,
	BAT[oid,bat]  par2_options
	) : BAT[void,bat] 
{
	var res_iter := new(void,oid).seqbase(0@0);
	var res_item := new(void,str).seqbase(0@0);
	var res_pos  := new(void,oid).seqbase(0@0);
	var res_kind := new(void,oid).seqbase(0@0);
	var res_ipik := res_iter;

        # unpack param bats and init vars
        var el_iter := par1_el.fetch(0);
        var el_item := par1_el.fetch(1);
        var el_kind := par1_el.fetch(2);
        var opt_iter, opt_item, opt_kind;
        var has_options := (par2_options.count_wrd() > wrd(0));
        if ( has_options ) {
           opt_iter := par2_options.fetch(0);
           opt_item := par2_options.fetch(1);
           opt_kind := par2_options.fetch(2);
        }
        var optbat;
        var ftiName;
        var xdoc_name, xdoc_firstpre, xpfpre;
        var doc_loaded := par_ws.fetch(CONT_COLL).join(bat("doc_collection").reverse()).join(bat("doc_name"));
        var index_elem;

        # check for loop-invariant parameters
        var single_val_opt := (opt_item.tunique().count_wrd() = wrd(1));
        if ( single_val_opt ) {
           if ( has_options ) {
              var opt_iter_i := opt_iter.slice(0,0).tmark(0@0);
              var opt_item_i := opt_item.slice(0,0).tmark(0@0);
              var opt_kind_i := opt_kind.slice(0,0).tmark(0@0);
              if ( verbose ) printf(HASH +" ALG_tj_terms: running option handler on single value option paramter.\n");
              optbat := serialize_tijah_opt(par_ws,1,opt_iter_i,opt_iter_i,opt_item_i,set_kind(opt_kind_i,ELEM),new(void,lng),new(void,dbl),new(void,str));
              if ( verbose ) optbat.print();
           } else {
              optbat := new(str,str,32);
           }
           ftiName := tj_get_ft_index(optbat,true);
           var frags := tj_used_frags(ftiName);
           var xftiName := "tj_" + ftiName;
           var xindex := [+](const xftiName, [str](frags));
           xdoc_name := [bat]([+](xindex, const "_doc_name"));
           xdoc_firstpre := [bat]([+](xindex, const "_doc_firstpre"));
           xpfpre := [bat]([+](xindex, const "_pfpre"));

           index_elem := [pf2tijah_node](const true, xdoc_name, xdoc_firstpre, xpfpre, const el_item, const [int](el_kind), const doc_loaded);
        }
       
        # main: loop over variant params and execution 
        par_loop@batloop() {
           if ( verbose ) printf(HASH +" ALG_tj_terms: loop start, id=%d.\n",$t);
           if ( not(single_val_opt) ) {
              if ( has_options ) {
                 var opt_iter_i := opt_iter.select($t);
                 var opt_item_i := opt_item.semijoin(opt_iter_i).tmark(0@0);
                 var opt_kind_i := opt_kind.semijoin(opt_iter_i).tmark(0@0);
                 opt_iter_i := opt_iter_i.tmark(0@0);
                 if ( verbose ) printf(HASH +" ALG_tj_terms: running option handler on iter specific option params.\n");
                 optbat := serialize_tijah_opt(par_ws,1,opt_iter_i,opt_iter_i,opt_item_i,set_kind(opt_kind_i,ELEM),new(void,lng),new(void,dbl),new(void,str));
                 if ( verbose ) optbat.print();
              } else {
                 optbat := new(str,str,32);
              }
              ftiName := tj_get_ft_index(optbat,true);
              var frags := tj_used_frags(ftiName);
              var xftiName := "tj_" + ftiName;
              var xindex := [+](const xftiName, [str](frags));
              xdoc_name := [bat]([+](xindex, const "_doc_name"));
              xdoc_firstpre := [bat]([+](xindex, const "_doc_firstpre"));
              xpfpre := [bat]([+](xindex, const "_pfpre"));

              index_elem := [pf2tijah_node](const true, xdoc_name, xdoc_firstpre, xpfpre, const el_item, const [int](el_kind), const doc_loaded);
           }
         
           var el_iter_i := el_iter.select($t);
           var index_elem_i := [semijoin](index_elem, const el_iter_i);
           index_elem_i := [int](index_elem_i.reverse()).reverse();
           
           var terms := tj_terms(ftiName, index_elem_i);
           
           res_iter.append(terms.project($t));
           res_pos.append(terms.mark(1@0));
           res_item.append(terms);
        }

        # result preparation
        res_ipik := res_iter;
        var res := ALG_tj_pfop(res_iter,res_item,res_kind,res_pos.materialize(res_ipik));

        return res;
}

PROC ALG_tj_tfall(
	BAT[void,any] par_loop,
	BAT[oid,bat]  par_ws,
	BAT[oid,bat]  par1_term,
	BAT[oid,bat]  par2_options
	) : BAT[void,bat] 
{
	var res_iter := new(void,oid).seqbase(0@0);
	var res_item := new(void,lng).seqbase(0@0);
	var res_pos  := new(void,oid).seqbase(0@0);
	var res_frag := new(void,oid).seqbase(0@0);
	var res_ipik := res_iter;

        # unpack param bats and init vars
        var term_iter := par1_term.fetch(0);
        var term_item := par1_term.fetch(1);
        var term_kind := par1_term.fetch(2);
        var term_pos := par1_term.fetch(3);
        var opt_iter, opt_item, opt_kind;
        var has_options := (par2_options.count_wrd() > wrd(0));
        if ( has_options ) {
           opt_iter := par2_options.fetch(0);
           opt_item := par2_options.fetch(1);
           opt_kind := par2_options.fetch(2);
        }
        var optbat;
        var ftiName;
        var xdoc_name, xdoc_firstpre, xpfpre;
        var doc_loaded := par_ws.fetch(CONT_COLL).join(bat("doc_collection").reverse()).join(bat("doc_name"));
        var index_elem;

        # check for loop-invariant parameters
        var single_val_opt := (opt_item.tunique().count_wrd() = wrd(1));
        if ( single_val_opt ) {
           if ( has_options ) {
              var opt_iter_i := opt_iter.slice(0,0).tmark(0@0);
              var opt_item_i := opt_item.slice(0,0).tmark(0@0);
              var opt_kind_i := opt_kind.slice(0,0).tmark(0@0);
              if ( verbose ) printf(HASH +" ALG_tj_tf: running option handler on single value option paramter.\n");
              optbat := serialize_tijah_opt(par_ws,1,opt_iter_i,opt_iter_i,opt_item_i,set_kind(opt_kind_i,ELEM),new(void,lng),new(void,dbl),new(void,str));
              if ( verbose ) optbat.print();
           } else {
              optbat := new(str,str,32);
           }
           ftiName := tj_get_ft_index(optbat,true);
           var stemming := true;
           if ( optbat.exist("stemmedterms") ) {
              stemming := not(bit(optbat.find("stemmedterms")));
           }
                     
           if ( verbose ) printf(HASH +" ALG_tj_tf: stemming = %d\n", stemming);
           if ( verbose ) printf(HASH +" ALG_tj_tf: case single val elems.\n");
           
           var tids := tj_term2tid(ftiName, term_item, stemming);
           var unique_tids := tids.tunique().hmark(0@0);
           var tfs := tj_tfall(ftiName, unique_tids);
           var res_i := tids.join(tfs).union(term_item.kdiff(tids).project(lng(0))).sort().tmark(0@0);
           res_item := res_i;
           res_iter := term_iter;
           res_pos := term_pos;
           if (res_pos.count_wrd() = wrd(0)) res_pos := res_item.mark(1@0);
        }

        else {
        
           # main: loop over variant params and execution 
           par_loop@batloop() {
              if ( verbose ) printf(HASH +" ALG_tj_tf: loop start, id=%d.\n",$t);
              if ( has_options ) {
                 var opt_iter_i := opt_iter.select($t);
                 var opt_item_i := opt_item.semijoin(opt_iter_i).tmark(0@0);
                 var opt_kind_i := opt_kind.semijoin(opt_iter_i).tmark(0@0);
                 opt_iter_i := opt_iter_i.tmark(0@0);
                 if ( verbose ) printf(HASH +" ALG_tj_tf: running option handler on iter specific option params.\n");
                 optbat := serialize_tijah_opt(par_ws,1,opt_iter_i,opt_iter_i,opt_item_i,set_kind(opt_kind_i,ELEM),new(void,lng),new(void,dbl),new(void,str));
                 if ( verbose ) optbat.print();
              } else {
                 optbat := new(str,str,32);
              }
              ftiName := tj_get_ft_index(optbat,true);
              var stemming := true;
              if ( optbat.exist("stemmedterms") ) {
                 stemming := not(bit(optbat.find("stemmedterms")));
              }
            
              var term_iter_i := term_iter.select($t);
              var term_item_i := term_item.semijoin(term_iter_i);

              var tids := tj_term2tid(ftiName, term_item_i, stemming);
              var unique_tids := tids.tunique().hmark(0@0);
              var tfs := tj_tfall(ftiName, unique_tids);
              var res_i := tids.join(tfs).insert(term_item_i.kdiff(tids).project(lng(0))).sort().tmark();
              res_iter.append(res_i.project($t));
              res_pos.append(res_i.mark(1@0));
              res_item.append(res_i);
           }
        }

        # result preparation
        res_ipik := res_iter;
        var res := ALG_tj_pfop(res_iter,res_item,res_frag,res_pos.materialize(res_ipik));

        return res;
}

PROC ALG_tj_tf(
	BAT[void,any] par_loop,
	BAT[oid,bat]  par_ws,
	BAT[oid,bat]  par1_el,
	BAT[oid,bat]  par2_term,
	BAT[oid,bat]  par3_options
	) : BAT[void,bat] 
{
	var res_iter := new(void,oid).seqbase(0@0);
	var res_item := new(void,lng).seqbase(0@0);
	var res_pos  := new(void,oid).seqbase(0@0);
	var res_frag := new(void,oid).seqbase(0@0);
	var res_ipik := res_iter;

        # unpack param bats and init vars
        var el_iter := par1_el.fetch(0);
        var el_item := par1_el.fetch(1);
        var el_kind := par1_el.fetch(2);
        var term_iter := par2_term.fetch(0);
        var term_item := par2_term.fetch(1);
        var term_kind := par2_term.fetch(2);
        var term_pos := par2_term.fetch(3);
        var opt_iter, opt_item, opt_kind;
        var has_options := (par3_options.count_wrd() > wrd(0));
        if ( has_options ) {
           opt_iter := par3_options.fetch(0);
           opt_item := par3_options.fetch(1);
           opt_kind := par3_options.fetch(2);
        }
        var optbat;
        var ftiName;
        var xdoc_name, xdoc_firstpre, xpfpre;
        var doc_loaded := par_ws.fetch(CONT_COLL).join(bat("doc_collection").reverse()).join(bat("doc_name"));
        var index_elem;

        # check for loop-invariant parameters
        var single_val_opt := (opt_item.tunique().count_wrd() = wrd(1));
        var single_val_el := false;
        var stemming := true;
        if ( single_val_opt ) {
           if ( has_options ) {
              var opt_iter_i := opt_iter.slice(0,0).tmark(0@0);
              var opt_item_i := opt_item.slice(0,0).tmark(0@0);
              var opt_kind_i := opt_kind.slice(0,0).tmark(0@0);
              if ( verbose ) printf(HASH +" ALG_tj_tf: running option handler on single value option paramter.\n");
              optbat := serialize_tijah_opt(par_ws,1,opt_iter_i,opt_iter_i,opt_item_i,set_kind(opt_kind_i,ELEM),new(void,lng),new(void,dbl),new(void,str));
              if ( verbose ) optbat.print();
           } else {
              optbat := new(str,str,32);
           }
           ftiName := tj_get_ft_index(optbat,true);
           if ( optbat.exist("stemmedterms") ) {
              stemming := not(bit(optbat.find("stemmedterms")));
           }
           var frags := tj_used_frags(ftiName);
           var xftiName := "tj_" + ftiName;
           var xindex := [+](const xftiName, [str](frags));
           xdoc_name := [bat]([+](xindex, const "_doc_name"));
           xdoc_firstpre := [bat]([+](xindex, const "_doc_firstpre"));
           xpfpre := [bat]([+](xindex, const "_pfpre"));

           index_elem := [pf2tijah_node](const true, xdoc_name, xdoc_firstpre, xpfpre, const el_item, const [int](el_kind), const doc_loaded);
        
           # this tries to check the invariance of sequence params
           var x := (el_item.count_wrd() / par_loop.count_wrd());
           single_val_el := (el_item.tunique().count_wrd() = x);
        }

        if ( single_val_el ) {
           if ( verbose ) printf(HASH +" ALG_tj_tf: case single val elems.\n");
           var el_iter_i := el_iter.select(par_loop.fetch(0));
           var index_elem_i := [semijoin](index_elem, const el_iter_i);
           index_elem_i := [int](index_elem_i.reverse()).reverse();

           var tids := tj_term2tid(ftiName, term_item, stemming);
           var unique_tids := tids.tunique().hmark(0@0);
           var tfs := tj_tf(ftiName, index_elem_i, unique_tids);
           var res_i := tids.join(tfs).union(term_item.kdiff(tids).project(lng(0))).sort().tmark(0@0);
           res_item := res_i; 
           res_iter := term_iter;
           res_pos := term_pos;
           if (res_pos.count_wrd() = wrd(0)) res_pos := res_item.mark(1@0);
        }
        else {
        
           # main: loop over variant params and execution 
           par_loop@batloop() {
              if ( verbose ) printf(HASH +" ALG_tj_tf: loop start, id=%d.\n",$t);
              if ( not(single_val_opt) ) {
                 if ( has_options ) {
                    var opt_iter_i := opt_iter.select($t);
                    var opt_item_i := opt_item.semijoin(opt_iter_i).tmark(0@0);
                    var opt_kind_i := opt_kind.semijoin(opt_iter_i).tmark(0@0);
                    opt_iter_i := opt_iter_i.tmark(0@0);
                    if ( verbose ) printf(HASH +" ALG_tj_tf: running option handler on iter specific option params.\n");
                    optbat := serialize_tijah_opt(par_ws,1,opt_iter_i,opt_iter_i,opt_item_i,set_kind(opt_kind_i,ELEM),new(void,lng),new(void,dbl),new(void,str));
                    if ( verbose ) optbat.print();
                 } else {
                    optbat := new(str,str,32);
                 }
                 ftiName := tj_get_ft_index(optbat,true);
                 if ( optbat.exist("stemmedterms") ) {
                    stemming := not(bit(optbat.find("stemmedterms")));
                 }
                 var frags := tj_used_frags(ftiName);
                 var xftiName := "tj_" + ftiName;
                 var xindex := [+](const xftiName, [str](frags));
                 xdoc_name := [bat]([+](xindex, const "_doc_name"));
                 xdoc_firstpre := [bat]([+](xindex, const "_doc_firstpre"));
                 xpfpre := [bat]([+](xindex, const "_pfpre"));

                 index_elem := [pf2tijah_node](const true, xdoc_name, xdoc_firstpre, xpfpre, const el_item, const [int](el_kind), const doc_loaded);
              }
            
              var el_iter_i := el_iter.select($t);
              var index_elem_i := [semijoin](index_elem, const el_iter_i);
              index_elem_i := [int](index_elem_i.reverse()).reverse();
              var term_iter_i := term_iter.select($t);
              var term_item_i := term_item.semijoin(term_iter_i);

              var tids := tj_term2tid(ftiName, term_item_i, stemming);
              var unique_tids := tids.tunique().hmark(0@0);
              var tfs := tj_tf(ftiName, index_elem_i, unique_tids);
              var res_i := tids.join(tfs).insert(term_item_i.kdiff(tids).project(lng(0))).sort().tmark();
              res_iter.append(res_i.project($t));
              res_pos.append(res_i.mark(1@0));
              res_item.append(res_i);
           }
        }

        # result preparation
        res_ipik := res_iter;
        var res := ALG_tj_pfop(res_iter,res_item,res_frag,res_pos.materialize(res_ipik));

        return res;
}

PROC ALG_tj_fbterms(
	BAT[void,any] par_loop,
	BAT[oid,bat]  par_ws,
	BAT[oid,bat]  par1_el,
	BAT[oid,bat]  par2_options
	) : BAT[void,bat] 
{
	var res_iter := new(void,oid).seqbase(0@0);
	var res_item := new(void,str).seqbase(0@0);
	var res_pos  := new(void,oid).seqbase(0@0);
	var res_kind := new(void,oid).seqbase(0@0);
	var res_ipik := res_iter;

        # unpack param bats and init vars
        var el_iter := par1_el.fetch(0);
        var el_item := par1_el.fetch(1);
        var el_kind := par1_el.fetch(2);
        var opt_iter, opt_item, opt_kind;
        var has_options := (par2_options.count_wrd() > wrd(0));
        if ( has_options ) {
           opt_iter := par2_options.fetch(0);
           opt_item := par2_options.fetch(1);
           opt_kind := par2_options.fetch(2);
        }
        var optbat;
        var ftiName;
        var ret_num := int(nil);
        var lambda := dbl(0.5);
        var xdoc_name, xdoc_firstpre, xpfpre;
        var doc_loaded := par_ws.fetch(CONT_COLL).join(bat("doc_collection").reverse()).join(bat("doc_name"));
        var index_elem;

        # check for loop-invariant parameters
        var single_val_opt := (opt_item.tunique().count_wrd() = wrd(1));
        if ( single_val_opt ) {
           if ( has_options ) {
              var opt_iter_i := opt_iter.slice(0,0).tmark(0@0);
              var opt_item_i := opt_item.slice(0,0).tmark(0@0);
              var opt_kind_i := opt_kind.slice(0,0).tmark(0@0);
              if ( verbose ) printf(HASH +" ALG_tj_terms: running option handler on single value option paramter.\n");
              optbat := serialize_tijah_opt(par_ws,1,opt_iter_i,opt_iter_i,opt_item_i,set_kind(opt_kind_i,ELEM),new(void,lng),new(void,dbl),new(void,str));
              if ( verbose ) optbat.print();
           } else {
              optbat := new(str,str,32);
           }
           ftiName := tj_get_ft_index(optbat,true);
           if ( optbat.exist("returnNumber") ) {
              ret_num := int(optbat.find("returnNumber"));
           }
           if ( optbat.exist("collection-lambda") ) {
              lambda := dbl(optbat.find("collection-lambda"));
           }
           var frags := tj_used_frags(ftiName);
           var xftiName := "tj_" + ftiName;
           var xindex := [+](const xftiName, [str](frags));
           xdoc_name := [bat]([+](xindex, const "_doc_name"));
           xdoc_firstpre := [bat]([+](xindex, const "_doc_firstpre"));
           xpfpre := [bat]([+](xindex, const "_pfpre"));

           index_elem := [pf2tijah_node](const true, xdoc_name, xdoc_firstpre, xpfpre, const el_item, const [int](el_kind), const doc_loaded);
        }
       
        # main: loop over variant params and execution 
        par_loop@batloop() {
           if ( verbose ) printf(HASH +" ALG_tj_terms: loop start, id=%d.\n",$t);
           if ( not(single_val_opt) ) {
              if ( has_options ) {
                 var opt_iter_i := opt_iter.select($t);
                 var opt_item_i := opt_item.semijoin(opt_iter_i).tmark(0@0);
                 var opt_kind_i := opt_kind.semijoin(opt_iter_i).tmark(0@0);
                 opt_iter_i := opt_iter_i.tmark(0@0);
                 if ( verbose ) printf(HASH +" ALG_tj_terms: running option handler on iter specific option params.\n");
                 optbat := serialize_tijah_opt(par_ws,1,opt_iter_i,opt_iter_i,opt_item_i,set_kind(opt_kind_i,ELEM),new(void,lng),new(void,dbl),new(void,str));
                 if ( verbose ) optbat.print();
              } else {
                 optbat := new(str,str,32);
              }
              ftiName := tj_get_ft_index(optbat,true);
              if ( optbat.exist("returnNumber") ) {
                 ret_num := int(optbat.find("returnNumber"));
              }
              if ( optbat.exist("collection-lambda") ) {
                 lambda := dbl(optbat.find("collection-lambda"));
              }
              var frags := tj_used_frags(ftiName);
              var xftiName := "tj_" + ftiName;
              var xindex := [+](const xftiName, [str](frags));
              xdoc_name := [bat]([+](xindex, const "_doc_name"));
              xdoc_firstpre := [bat]([+](xindex, const "_doc_firstpre"));
              xpfpre := [bat]([+](xindex, const "_pfpre"));

              index_elem := [pf2tijah_node](const true, xdoc_name, xdoc_firstpre, xpfpre, const el_item, const [int](el_kind), const doc_loaded);
           }
         
           var el_iter_i := el_iter.select($t);
           var index_elem_i := [semijoin](index_elem, const el_iter_i);
           index_elem_i := [int](index_elem_i.reverse()).reverse();
           
           var terms := tj_fb_terms(ftiName, index_elem_i, ret_num, lambda);
           
           res_iter.append(terms.project($t));
           res_pos.append(terms.mark(1@0));
           res_item.append(terms);
        }

        # result preparation
        res_ipik := res_iter;
        var res := ALG_tj_pfop(res_iter,res_item,res_kind,res_pos.materialize(res_ipik));

        return res;
}

#
var ftindex;

# temporary algebra query handler
PROC ALG_tj_ftfun_handler(
        bit par_storeScore,
        BAT[oid,bat] pfop_sn,
        BAT[oid,bat] pfop_query, # == terms
        BAT[oid,bat] pfop_opt,
        BAT[oid,bat] pfop_ign,
        BAT[void,any]  par_loop,
        BAT[oid,bat]  par_ws,
        BAT[oid,bat] par_scoreDB
        ) : BAT[void,bat] 
{
     var result_id;
     var result_iter;
     var result_item_s;
     var result_kind;
     var result_ipik;
     var result_pos;
     var result_frag;

     if ( verbose ) tj_verbose(HASH +" ALG_tj_ftfun_handler: START.\n");

     # The next assigment is done to make pftijah work like it is used
     # by the tijah compiler. A variable ftiName is expected to exist
     # in the caller env. To make this work for direct calls without the
     # compiler we generate an unused ftiName var in the generated pathfinder
     # mil script and assign it with this assigment.
     ftiName := dflt_ft_index;
     ftindex := ftiName + "0";

     result_item_s := new(oid,dbl);

     var has_sn      := (pfop_sn.count_wrd() > wrd(0));
     var has_options := (pfop_opt.count_wrd() > wrd(0));
     var has_ign     := (pfop_ign.count_wrd() > wrd(0));

     if ( not(pfop_sn.count_wrd() > wrd(0)) )
     	ERROR("ALG_tj_ftfun_handler: startnodes not specified");
     if ( has_options )
     	ERROR("ALG_tj_ftfun_handler: options not implemented yet");
     if ( has_ign )
     	ERROR("ALG_tj_ftfun_handler: ignores not implemented yet");
     var single_val_opt := (pfop_query.fetch(1@0).tunique().count_wrd() = wrd(1));
     par_loop@batloop() {
        var iter_tjPre;
        var ftc_term := pfop_query.fetch(1@0).fetch(int($h));

        var ftiName := dflt_ft_index; # incomplete
        var tijah_lock := tj_get_collection_lock(ftiName);
        lock_set(tijah_lock);
        var err := CATCH({
          var sn_iter := pfop_sn.fetch(0@0);
          var sn_iteration := pfop_query.fetch(0@0).fetch(int($h));
	  if ( not(single_val_opt) )
              sn_iter := sn_iter.select(sn_iteration);
          var sn_item := pfop_sn.fetch(1@0).semijoin(sn_iter);
          var sn_kind := pfop_sn.fetch(2@0).semijoin(sn_iter);
  
          var xdoc_name := bat("tj_" + ftiName + "0_doc_name");
          var xdoc_firstpre := bat("tj_" + ftiName + "0_doc_firstpre");
          var xpfpre := bat("tj_" + ftiName + "0_pfpre");
          var doc_loaded := par_ws.fetch(CONT_COLL).join(bat("doc_collection").reverse()).join(bat("doc_name"));

	  var tjPre_score;

          if ( verbose ) tj_verbose(HASH +" ALG_tj_ftfun_handler: compute startnodes\n");
          iter_tjPre := pf2tijah_node(true,xdoc_name,xdoc_firstpre,xpfpre,sn_item,[int](sn_kind),doc_loaded);
	  if ( not(ftc_term.startsWith("%")) ) {
             if ( verbose ) tj_verbose(HASH +" ALG_tj_ftfun_handler: run precompiled term search\n");
	  
	      # now tokenize the term string and add a default weight
	      var T := tijah_tokenize2bat(ftc_term).reverse().project(dbl(1.0));
	      var Q := tj_prepare_query(T);

	      # tj_init_termHash(ftiName);
	      # tj_init_tagHash(ftiName);
	      var scorebase := dbl(0.000000);
	      var c_lambda  := dbl(0.800000);
	      var okapi_k1  := dbl(1.200000);
	      var okapi_b   := dbl(0.750000);
	      var downprop  := "max";
	      var upprop    := "max";
	      var andcomb   := "prod";
	      var orcomb    := "sum";
	      var returnall := TRUE;

	      tjPre_score := tj_containing_query_nest_pre_term_NLLR(iter_tjPre.reverse(), Q);
	  } else {
             if ( verbose ) tj_verbose(HASH +" ALG_tj_ftfun_handler: run compiled  nexi query\n");
	     ftc_term := ftc_term.substring(2); # strip the "%"
	     # the next tmark() is a bit mysterious. The result of pf2tijah_node
	     # should be a [void,oid] but is an [oid,oid]
	     iter_tjPre := iter_tjPre.tmark(0@0);
	     var opt := new(str,str);
	     opt.insert("return-all","true");
	     opt.insert("_query",ftc_term);
	     tjPre_score := run_tijah_query("DFLT_FT_INDEX",opt,true,iter_tjPre);
	  }
	  var iter_score := iter_tjPre.leftjoin(tjPre_score);

	  result_item_s.append(iter_score);
        });
        lock_unset(tijah_lock);
        if (not(isnil(err))) ERROR(err);
        
	if ( single_val_opt )
	    break;
     }
     var result_item_b;
     result_iter   := pfop_sn.fetch(0@0);
     result_item_b := [>](result_item_s,dbl(0.0));
     if ( verbose ) {
     	result_iter.print();
     	result_item_b.print();
     	result_item_s.print();
     }
     result_ipik   := result_item_b;
     result_kind   := pfop_sn.fetch(2@0).set_kind(BOOL);
     var result_pos:= pfop_sn.fetch(3@0);
     var res := ALG_tj_pfop(result_iter,result_item_b,result_kind,result_pos.materialize(result_ipik),result_item_s);
     if ( verbose ) tj_verbose(HASH +" ALG_tj_ftfun_handler: FINISH.\n");
     return res;
}

#
#
#
PROC ALG_tj_add_fti_tape(
	str           op,
	BAT[oid,bat]  pfop_coll,
	BAT[oid,bat]  pfop_opt,
	BAT[void,any] par_loop,
	BAT[oid,bat]  par_ws,
	BAT[str,bat]  tape
	) : BAT[str,bat] 
{
        if ( verbose ) tj_verbose(HASH +" ALG_tj_add_fti_tape: START xxx.\n");
        var has_coll := (pfop_coll.count_wrd() > wrd(0));
        var has_opt  := (pfop_opt.count_wrd() > wrd(0));
        par_loop@batloop() {
            if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: loop start, id=%d.\n",int($t));

	    var collbat;
	    if ( has_coll ) {
       	        if ( verbose ) tj_verbose(HASH +" ALG_tj_add_fti_tape: start collection handler.\n");
       		var iter := pfop_coll.fetch(0@0).select($t);
       		collbat := pfop_coll.fetch(1@0).semijoin(iter);

		if ( collbat.select("*").count_wrd() > wrd(0) ) {
			ERROR("not possible to use wildcards for pfcollections.");
		}
	    } else {
       	        if ( verbose ) tj_verbose(HASH +" ALG_tj_add_fti_tape: no collection.\n");
	        collbat := new(void,str).seqbase(0@0);
		collbat.append("*");
	    }

	    var optbat;
            if ( has_opt ) {
       	        if ( verbose ) tj_verbose(HASH +" ALG_tj_add_fti_tape: running option handler.\n");
       		var opt_iter := pfop_opt.fetch(0@0).select($t);
       		var opt_item := pfop_opt.fetch(1@0).semijoin(opt_iter);
       		var opt_kind := pfop_opt.fetch(2@0).semijoin(opt_iter);
       		opt_iter := opt_iter.tmark(0@0);
       		opt_item := opt_item.tmark(0@0);
       		opt_kind := opt_kind.tmark(0@0);
       		optbat := serialize_tijah_opt(par_ws,1,opt_iter,opt_iter,opt_item,set_kind(opt_kind,ELEM),new(void,lng),new(void,dbl),new(void,str));
       		if ( verbose ) optbat.print();
            } else {
       	        if ( verbose ) tj_verbose(HASH +" ALG_tj_add_fti_tape: no options.\n");
                optbat := new(str,str,32);
            } 

            if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: writing tape.\n");
	    var bb := new(void,bat).seqbase(0@0);
	    bb.append(collbat);
	    bb.append(optbat);
	    tape.insert(op,bb);
	    if ( verbose ) tape.print();
            if ( verbose ) tj_verbose(HASH +" ALG_tj_query_handler: end loop start, id=%d.\n",int($t));
	}
        if ( verbose ) tj_verbose(HASH +" ALG_tj_add_fti_tape: FINISH.\n");
	return tape;
}

#PROC DocmgmTape(BAT[void,BAT] ws,
#                BAT[void,str] location,
#                BAT[void,str] docname,
#                BAT[void,str] colname,
#                BAT[void,lng] percentage) : void
#{
#    var del_doc := percentage.ord_uselect(-1LL).hmark(0@0);
#    var add_doc := percentage.ord_uselect(0LL,lng_nil).hmark(0@0);
#
#    shred_doc_base(del_doc(bit_nil, del_doc.leftfetchjoin(docname), true),
#                   add_doc.leftfetchjoin(location),
#                   add_doc.leftfetchjoin(docname),
#                   add_doc.leftfetchjoin(colname),
#                   add_doc.leftfetchjoin(percentage),
#                   stream_nil, ws_id(ws));
#}

PROC ALG_tj_docmgmt_tape2(BAT[str,bat] tape,
		      	 BAT[void,BAT] ws,
                	 BAT[void,str] location,
                	 BAT[void,str] docnames,
                	 BAT[void,str] colnames,
                	 BAT[void,lng] percentages) : bit 
{
        if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: START.\n");
	#
	# INCOMPLETE, CHECK IF THIS REALLY STILL WORKS
	#
        if (isnil(CATCH(bat("tj_collName").count_wrd()))) {
            if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: pftijah is active.\n");
	    # pftijah is active
            if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: running document management.\n");
            var del_doc    := percentages.ord_uselect(-1LL).hmark(0@0); 
            var add_doc    := percentages.ord_uselect(0LL,lng_nil).hmark(0@0); 
	    if ( verbose ) {
	        printf(HASH +" ALG_tj_docmgmt_tape: deleted docs are:\n");
	        del_doc.print();
	        printf(HASH +" ALG_tj_docmgmt_tape: added docs are:\n");
	        add_doc.print();
	    }
            #
            var pfc_name   := docnames.reverse().leftfetchjoin(colnames);
            var pfdep      := bat("tj_pfc_fti_dep");
            var pfdep_star := bat("tj_pfc_fti_dep_star");
            var fti_dname  := pfdep.join(pfc_name.reverse());
            if ( pfdep_star.count_wrd() > wrd(0) ) {
                fti_dname.insert(pfdep_star.cross(pfc_name.reverse()));
            }

            var fti_cluster := new(str,bat);
            fti_dname@batloop() {
                var cb;
                if ( fti_cluster.exist($h) ) {
                  cb := fti_cluster.find($h);
                } else {
                  cb := new(str,str);
                  fti_cluster.insert($h,cb);
                }
                cb.insert(str(nil),$t);
            }
            fti_cluster@batloop() {
                if ( verbose ) { 
									tj_verbose(HASH +"TJ:tj_play_doc_tape() doing ft-index \"%s\".\n",$h); 
									# $t.print(); 
									# careful wuth the previous print, it may be huge
									tj_verbose(HASH +"TJ:tj_play_doc_tape() doclist is %d docs long.\n",int($t.count_wrd()));
								}
                tj_add2collection($h,$t,false);
            }

            if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: running collection management.\n");
            tape@batloop() {
	        var op       := $h;
	        var collbat  := $t.fetch(0@0);
	        var optbat   := $t.fetch(1@0);
	        var fti_name := tj_get_ft_index(optbat,(op!="create"));

	        if ( op = "create" ) {
                    if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: tj_init_collection(%s).\n",fti_name);
	            tj_init_collection(fti_name,optbat,collbat);
	        } else if ( op = "extend" ) {
                    if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: tj_extend_collection(%s).\n",fti_name);
	            tj_extend_collection(fti_name,collbat);
	        } else if ( op = "remove" ) {
                    if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: tj_delete_collection(%s).\n",fti_name);
	            tj_delete_collection(fti_name);
	        } else {
	    	    ERROR("ALG_tj_docmgmt_tape: unknown op");
	        }
	    }
	} else {
	    # pftijah is not active
	    if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: skipping doc managemnt.\n");
	}

        if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: FINISH.\n");
	return true;
}

PROC ALG_tj_docmgmt_tape(BAT[str,bat] tape,
		      	 BAT[void,BAT] ws,
                	 BAT[void,str] location,
                	 BAT[void,str] docnames,
                	 BAT[void,str] colnames,
                	 BAT[void,lng] percentages) : bit 
{
        if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: START.\n");

	# analyse doctape, create new collection dependencies, and
        # add documents to the doclist for each ft-index (fti_cluster) 

        var fti_cluster := new(str,bat);
        tape@batloop() {
	    var op       := $h;
	    var collbat  := $t.fetch(0@0);
	    var optbat   := $t.fetch(1@0);
	    var ftiName  := tj_get_ft_index(optbat,(op!="create"));
            var doclist;       
            if ( fti_cluster.exist(ftiName) ) {
              doclist := fti_cluster.find(ftiName);
            } else {
              doclist := new(str,str);
              fti_cluster.insert(ftiName, doclist);
            }
   
     	    if ( op = "create" ) {
                if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: init_collection(%s).\n",ftiName);
            tj_init_collection_base(ftiName, optbat);
            modify_pfc_fti(ftiName, collbat);
            if ( collbat.uselect("*").count_wrd() > wrd(0) ) {
               var tmp := bat("doc_name");
               doclist.insert(tmp.reverse().project(str(nil)).reverse());
            } else {
                   var tmp := bat("doc_name").semijoin(bat("doc_collection").join(bat("collection_name").join(collbat.reverse())));
                   doclist.insert(tmp.reverse().project(str(nil)).reverse());
                }
	    } else if ( op = "extend" ) {
                if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: extend_collection(%s).\n",ftiName);
                modify_pfc_fti(ftiName, collbat);
                if ( collbat.uselect("*").count_wrd() > wrd(0) ) {
                   var tmp := bat("doc_name");
                   doclist.insert(tmp.reverse().project(str(nil)).reverse());
                } else {
                   var tmp := bat("doc_name").semijoin(bat("doc_collection").join(bat("collection_name").join(collbat.reverse())));
                   doclist.insert(tmp.reverse().project(str(nil)).reverse());
                }
	    } else if ( op = "remove" ) {
                if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: tj_delete_collection(%s).\n",ftiName);
	        tj_collection_delete(ftiName);
	    } else {
	        ERROR("ALG_tj_docmgmt_tape: unknown op");
	    }
	}
    

        # commit dependency bats, since they might be changed
        var submit_bats := new(void,str).seqbase(0@0);
        submit_bats.append("tj_pfc_fti_dep");
        submit_bats.append("tj_pfc_fti_dep_star");
        subcommit(submit_bats);
    

        if (isnil(CATCH(bat("tj_collName").count_wrd()))) {
            if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: pftijah is active.\n");
	    # determine which documents added to pathfinder have to get indexed by pf/tijah due to dependencies
            # add those documents to the doclist for each ft-index (fti_cluster) 
            var pfc_name   := docnames.reverse().leftfetchjoin(colnames);
            var pfdep      := bat("tj_pfc_fti_dep");
            var pfdep_star := bat("tj_pfc_fti_dep_star");
            
            var fti_dname  := pfdep.join(pfc_name.reverse());
            if ( pfdep_star.count_wrd() > wrd(0) ) {
                fti_dname.insert(pfdep_star.cross(pfc_name.reverse()));
            }
    
            fti_dname@batloop() {
                var cb;
                if ( fti_cluster.exist($h) ) {
                  cb := fti_cluster.find($h);
                } else {
                  cb := new(str,str);
                  fti_cluster.insert($h,cb);
                }
                cb.insert(str(nil),$t);
            }
            fti_cluster@batloop() {
                if ( verbose ) { 
                  tj_verbose(HASH +"TJ:tj_play_doc_tape() doing ft-index \"%s\".\n",$h);
									# $t.print(); 
									# careful wuth the previous print, it may be huge
									tj_verbose(HASH +"TJ:tj_play_doc_tape() doclist is %d docs long.\n",int($t.count_wrd()));
                }
                tj_add2collection_frag($h,$t,false);
            }
    
	} else {
            if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: pftijah not active.\n");
	}
        if ( verbose ) tj_verbose(HASH +" ALG_tj_docmgmt_tape: FINISH.\n");
	return true;
}

var tracefile_handle := nil;
PROC tj_trace(str tracefile, str s) : void  
{
    if ( not( tracefile = "" ) ) {
        if ( isnil( tracefile_handle ) )
            tracefile_handle := open_wastream(tracefile);
        
        tracefile_handle.stream_write( sprintf( "%d %s\n", int(msec()/1000), s ) );
        tracefile_handle.stream_flush();
    }
}


var verbosefile_handle := nil;
PROC tj_verbose(str s, ..any..) : void  {
	if ( verbosefile = "" )
		verbosefile_handle := stdout();
	else
    if ( isnil( verbosefile_handle ) )
			verbosefile_handle := open_wastream(verbosefile);
	verbosefile_handle.stream_write( sprintf( "%d %s\n", time(), sprintf(s,$(2..)) ) );
	verbosefile_handle.stream_flush();
}


#
#
#

PROC tj_is_indexed(str collName) : bit 
{
    if (isnil(CATCH(bat("tj_pfc_fti_dep").count_wrd()))) {
	if ( bat("tj_pfc_fti_dep_star").count_wrd() > wrd(0) ) {
	    # eg. all collections are indexed
            return TRUE;
	} else {
	    return bat("tj_pfc_fti_dep").reverse().exist(collName);
	}
    } else {
        return FALSE;
    }
}

PROC tj_play_doc_tape(BAT[void,BAT] ws,
                      BAT[void,oid] item, 
                      BAT[void,int] kind, 
                      BAT[void,lng] int_values, 
                      BAT[void,str] str_values) : void
{
    if (isnil(CATCH(bat("tj_pfc_fti_dep").count_wrd()))) {
      if ( bat("tj_pfc_fti_dep").count_wrd() > wrd(0) ) {
        if ( verbose ) tj_verbose(HASH +"TJ:tj_play_doc_tape() start.\n");
        var IDoid       := [and]([lng](item.mirror()), 3LL).ord_uselect(0LL).hmark(0@0);
        var IDlng       := IDoid.[lng]();
        var locations   := IDoid.leftfetchjoin(item).leftfetchjoin(str_values);
        var names       := [+](IDlng, 1).[oid]().leftfetchjoin(item).leftfetchjoin(str_values);
        var colnames    := [+](IDlng, 2).[oid]().leftfetchjoin(item).leftfetchjoin(str_values);
        var percentages := [+](IDlng, 3).[oid]().leftfetchjoin(item).leftfetchjoin(int_values);
        var del_doc     := percentages.ord_uselect(-1LL).hmark(0@0); 
        var add_doc     := percentages.ord_uselect(0LL,lng_nil).hmark(0@0); 
        #
        var pfc_name   := names.reverse().leftfetchjoin(colnames);
        var pfdep      := bat("tj_pfc_fti_dep");
        var pfdep_star := bat("tj_pfc_fti_dep_star");
        var fti_dname  := pfdep.join(pfc_name.reverse());
        if ( pfdep_star.count_wrd() > wrd(0) ) {
            fti_dname.insert(pfdep_star.cross(pfc_name.reverse()));
        }

        var fti_cluster := new(str,bat);
        fti_dname@batloop() {
            var cb;
            if ( fti_cluster.exist($h) ) {
              cb := fti_cluster.find($h);
            } else {
              cb := new(str,str);
              fti_cluster.insert($h,cb);
            }
            cb.insert(str(nil),$t);
        }
        fti_cluster@batloop() {
            if ( verbose ) { 
							tj_verbose(HASH +"TJ:tj_play_doc_tape() doing ft-index \"%s\".\n",$h); 
							# $t.print(); 
							# careful wuth the previous print, it may be huge
							tj_verbose(HASH +"TJ:tj_play_doc_tape() doclist is %d docs long.\n",int($t.count_wrd()));
						}
            tj_add2collection($h,$t,false);
        }
        if ( verbose ) tj_verbose(HASH +"TJ:tj_play_doc_tape() finished.\n");
      }
    }
}

#####################################################################
#								    #
#								    #
#            IMPLEMENTATION OF PHYSICAL SRA OPERATORS		    #
#								    #
#								    #
#####################################################################


#####################################################################
# SELECTION
#####################################################################

##
# Select all element nodes in the collection
# Returns a bat [pre, any].
##
PROC tj_select_star() : bat[oid,any]  
{
    # deselect document root
    var res := bat("tj_" + ftindex + "_pfpre").slice(wrd(1), bat("tj_" + ftindex + "_pfpre").count_wrd() - 1);
    res.set_tailkeysorted();
    return res;
}

##
# Select all startNodes (node context set coming from pathfinder)
# Returns a bat [pre, any].
##
PROC tj_select_startnodes() : bat[oid,any] 
{
    return nexi_sn_xfer.reverse();
}

##
# Select all element nodes in the collection with the given name
# Returns a bat [nid, any].
##
PROC tj_select_tag(str name) : bat[oid,any] 
{
    var tids := bat("tj_" + ftiName + "_tagdict").select(name);
    if (tids.count_wrd() = wrd(0)) return new(oid,dbl);
    var tid := wrd(tids.reverse().fetch(0));
    var index := bat("tj_" + ftindex + "_TagIndex");
    if (wrd(tid) >= index.count_wrd()) return new(oid,dbl);
    var offset1 := wrd(index.fetch(tid));
    var offset2 := wrd(index.fetch(tid + 1)) - 1;
    return bat("tj_" + ftindex + "_Tags").slice(offset1, offset2).set_tailkeysorted();
}

#####################################################################
# ADD PRE IDs 
#####################################################################

##
# associate pre identifiers to the nid identifiers
# Returns a bat [nid, pre].
##
PROC tj_add_pre(bat[oid,any] nid_score) : bat[oid,oid] 
{
    return bat("tj_" + ftindex + "_Tags").semijoin(nid_score).chk_order();
}

#####################################################################
# ID TRANSLATION
#####################################################################

##
# Translate all nid identifiers to pre identifiers
# Returns a bat [pre, any].
##
PROC tj_nid2pre(bat[oid,any] nid_score) : bat[oid,any] 
{
    return nid_score.reverse().leftfetchjoin(bat("tj_" + ftindex + "_Tags")).reverse().chk_order();
}

##
# Translate all pre identifiers to nid identifiers
# Returns a bat [nid, score].
##
PROC tj_pre2nid_prop(bat[oid,any] pre_score) : bat[oid,any] 
{
    # todo: if join turns out to be expensive, we can slice out the part belonging to
    # the respective tagname. pre2nid is only used, if result region has a single tag-name.

    return bat("tj_" + ftindex + "_Tags").leftjoin(pre_score);
}
##
# Translate all pre identifiers to nid identifiers, pre remains in tail
# Returns a bat [nid, pre].
##
PROC tj_pre2nid_noprop(bat[oid,any] pre_score) : bat[oid,any] 
{
    # todo: if join turns out to be expensive, we can slice out the part belonging to
    # the respective tagname. pre2nid is only used, if result region has a single tag-name.

    return bat("tj_" + ftindex + "_Tags").leftjoin(pre_score.mirror()).chk_order();
}

#####################################################################
# Contained_by
#####################################################################

@mil

@:contained_by_noprop_nid(nest)@
@:contained_by_noprop_nid(unnest)@
@= contained_by_noprop_nid
PROC tj_contained_by_noprop_@1_nid (bat[oid,oid] left, bat[oid,oid] right) : bat[oid,any] 
{
    var size := bat("tj_" + ftindex + "_TagSize");
    var right_left := treemergejoin_@1_nid(right, size, left);
    var result := left.semijoin(right_left.reverse()).chk_order();
    return result;
}
@mil

@:contained_by_noprop_pre(nest)@
@:contained_by_noprop_pre(unnest)@
@= contained_by_noprop_pre
PROC tj_contained_by_noprop_@1_pre (bat[oid,oid] left, bat[oid,oid] right) : bat[oid,any] 
{
    var size := bat("tj_" + ftindex + "_size");
    var right_left := treemergejoin_@1_pre(right, size, left);
    var result := right_left.reverse();
    return result;
}
@mil

PROC tj_contained_by_prop_nest_nid (bat[oid,any] left, bat[oid,dbl] right) : bat[oid,any] 
{
    var size := bat("tj_" + ftindex + "_TagSize");
    var left_pre := bat("tj_" + ftindex + "_Tags").semijoin(left).chk_order().tsort();
    var right_pre := bat("tj_" + ftindex + "_Tags").semijoin(right).chk_order().tsort();
    var right_left := treemergejoin_nest_nid(right_pre, size, left_pre);
    var left_score;
    if (downprop = "sum") {
        left_score := {sum}(right, right_left, right_left.reverse().kunique()).sort();
    }
    if (downprop = "max") {
        left_score := {max}(right, right_left, right_left.reverse().kunique()).sort(); 
    }
    return left_score;
}
PROC tj_contained_by_prop_unnest_nid (bat[oid,any] left, bat[oid,dbl] right) : bat[oid,any] 
{
    var size := bat("tj_" + ftindex + "_TagSize");
    var left_pre := bat("tj_" + ftindex + "_Tags").semijoin(left).chk_order().tsort();
    var right_pre := bat("tj_" + ftindex + "_Tags").semijoin(right).chk_order().tsort();
    var right_left := treemergejoin_unnest_nid(right_pre, size, left_pre);
    var left_score := right_left.reverse().join(right).sort(); 
    return left_score;
}
PROC tj_contained_by_prop_nest_pre (bat[oid,any] left, bat[oid,dbl] right) : bat[oid,any] 
{
    var size := bat("tj_" + ftindex + "_size");
    var right_left := treemergejoin_nest_pre(right, size, left);
    var left_score;
    if (downprop = "sum") {
        left_score := {sum}(right, right_left, right_left.reverse().kunique()).sort();
    }
    if (downprop = "max") {
        left_score := {max}(right, right_left, right_left.reverse().kunique()).sort(); 
    }
    return left_score;
}
PROC tj_contained_by_prop_unnest_pre (bat[oid,any] left, bat[oid,dbl] right) : bat[oid,any] 
{
    var size := bat("tj_" + ftindex + "_size");
    var right_left := treemergejoin_unnest_pre(right, size, left);
    var left_score := right_left.reverse().join(right).sort(); 
    return left_score;
}

#####################################################################
# Containing
#####################################################################

@mil

@:containing_noprop_nid(nest)@
@:containing_noprop_nid(unnest)@
@= containing_noprop_nid
PROC tj_containing_noprop_@1_nid (bat[oid,oid] left, bat[oid,oid] right) : bat[oid,any] 
{
    var size := bat("tj_" + ftindex + "_TagSize");
    var left_right := treemergejoin_@1_nid(left, size, right);
    var result := left.semijoin(left_right);
    return result;
}
@mil

@:containing_noprop_pre(nest)@
@:containing_noprop_pre(unnest)@
@= containing_noprop_pre
PROC tj_containing_noprop_@1_pre (bat[oid,oid] left, bat[oid,oid] right) : bat[oid,any] 
{
    var size := bat("tj_" + ftindex + "_size");
    var left_right := treemergejoin_@1_pre(left, size, right);
    var result := left_right;
    return result;
}
@mil

@:containing_prop_nid(nest)@
@:containing_prop_nid(unnest)@
@= containing_prop_nid
PROC tj_containing_prop_@1_nid (bat[oid,any] left, bat[oid,dbl] right) : bat[oid,any] 
{
    var size := bat("tj_" + ftindex + "_TagSize");
    var left_pre := bat("tj_" + ftindex + "_Tags").semijoin(left).chk_order().tsort();
    var right_pre := bat("tj_" + ftindex + "_Tags").semijoin(right).chk_order().tsort();
    var left_right := treemergejoin_@1_nid(left_pre, size, right_pre);
    var left_score;
    if (upprop = "sum") {
        left_score := {sum}(right, left_right.reverse(), left_right.kunique()).sort();
    }
    if (upprop = "max") {
        left_score := {max}(right, left_right.reverse(), left_right.kunique()).sort(); 
    }
    return left_score;
}
@mil

@:containing_prop_pre(nest)@
@:containing_prop_pre(unnest)@
@= containing_prop_pre
PROC tj_containing_prop_@1_pre (bat[oid,any] left, bat[oid,dbl] right) : bat[oid,any] 
{
    var size := bat("tj_" + ftindex + "_size");
    var left_right := treemergejoin_@1_pre(left, size, right);
    var left_score;
    if (upprop = "sum") {
        left_score := {sum}(right, left_right.reverse(), left_right.kunique()).sort();
    }
    if (upprop = "max") {
        left_score := {max}(right, left_right.reverse(), left_right.kunique()).sort(); 
    }
    return left_score;
}
@mil

#####################################################################
# Containing_query_term
#####################################################################

PROC tj_prepare_query (bat[str,dbl] term_score) : bat[void,bat]
{
    var oid_weight := tj_term2tid(term_score);
    oid_weight := {sum}(oid_weight);
    var oid_cf := oid_weight.mirror().leftfetchjoin(bat("tj_" + ftiName + "_termfreq"));
    var query := new(void,bat).seqbase(0@0);
    query.append(oid_weight);
    query.append(oid_cf);
    return query; 
}

PROC tj_term2tid (bat[str,dbl] term_score) : bat[oid,dbl] 
{
    var param    := bat("tj_" + ftiName + "_param");
    var stemmer  := param.find("stemmer");
    var firstterm:= oid(param.find("lastStopWord"));
    
    var mark_term := term_score.hmark(0@0);
    var mark_score := term_score.tmark(0@0);
    var stemmed  := [tj_normalizeTerm]( [toLower](mark_term), stemmer );
    
    var mark_tid := stemmed.join(bat("tj_" + ftiName + "_termdict").reverse());
    mark_tid := mark_tid.select(firstterm,oid(nil),TRUE,FALSE);
    # it is important to keep the order of query terms (phrase queries)
    return mark_score.reverse().leftjoin(mark_tid).reverse();
}

# returns the pre-order positions of the term t 
# in the collection of the documents
PROC _getTermPositions (oid tid) : bat[void,oid] {
     var index := bat("tj_" + ftindex + "_TermIndex");
     if (wrd(tid) >= index.count_wrd()) return new(void,oid).seqbase(0@0);
     var offset1 := wrd(index.fetch(int(tid)));
     var offset2 := wrd(index.fetch(int(tid) + 1));
     var res := bat("tj_" + ftindex + "_Terms").slice(offset1, offset2 - 1);
     res := res.seqbase(0@0).set_tailkeysorted();
     return res;
}

@mil

@:getTermDocCnt_nid(nest)@
@:getTermDocCnt_nid(unnest)@
@= getTermDocCnt_nid
PROC _getTermDocCnt_@1_nid(BAT[oid,oid] e_pre, BAT[void,int] e_size, BAT[oid,oid] t_pre) : BAT[oid,int] {
    
    # get doc - term relation
    var e_tPre := treemergejoin_@1_nid(e_pre, e_size, t_pre);
    return e_tPre.reverse().histogram().sort();
}
@mil
@:getTermDocCnt_pre(nest)@
@:getTermDocCnt_pre(unnest)@
@= getTermDocCnt_pre
PROC _getTermDocCnt_@1_pre(BAT[oid,any] e_pre, BAT[void,int] e_size, BAT[oid,oid] t_pre) : BAT[oid,int] {
    
    # get doc - term relation
    var e_tPre := treemergejoin_@1_pre(e_pre, e_size, t_pre.reverse());
    return e_tPre.reverse().histogram().sort();
}
@mil

#             ___          qCnt(t) 
# LM(d|q) =   | |    dLH(t) 
#            t in q           
#
# where qCnt(t) = count of term t in query q
# where dLH(t) = likelihood of term t in doc d
#

PROC _score_LM(dbl q_tCnt, wrd c_tCnt, wrd cSize, BAT[oid,int] e_tCnt, BAT[void,int] e_size) : bat[oid,dbl] {
    var e_tScores := e_tCnt.[dbl]().access(BAT_WRITE);
    e_tScores.left_div(e_size);
    e_tScores := [log](e_tScores);
    e_tScores := e_tScores.[*](q_tCnt);
    e_tScores := [exp](e_tScores);
    return e_tScores;
}


#              ___                                         qCnt(t)      
# LMs(d|q) =   | |    ( (1-lambda) dLH(t) + lambda cLH(t) ) 
#             t in q           
#
# where qCnt(t) = count of term t in query q
# where dLH(t) = likelihood of term t in doc d
# where cLH(t) = likelihood of term t in (background) collection c
#

PROC _score_LMs(dbl q_tCnt, wrd c_tCnt, wrd cSize, BAT[oid,int] e_tCnt, BAT[void,int] e_size) : bat[oid,dbl] {
    var tmp1 := c_lambda * c_tCnt / dbl(cSize);
    var tmp2 := dbl(1) - c_lambda;
    
    var e_tScores := e_tCnt.[dbl]().access(BAT_WRITE);
    e_tScores.left_div(e_size);
    e_tScores := e_tScores.[*](tmp2);
    e_tScores := e_tScores.[+](tmp1);
    e_tScores := [log](e_tScores);
    e_tScores := e_tScores.[*](q_tCnt);
    e_tScores := [exp](e_tScores);
    return e_tScores;
}


#               __     qCnt(t)       /  (1 - lambda) * dLH(t)       \  
# NLLR(d|q) =   >_     ------- * log |  ----------------------  + 1 |  
#              t in q   qSize        \      lambda * cLH(t)         /  
#
# where qCnt(t) = count of term t in query q
# where qSize = number of terms in query q
# where dLH(t) = likelihood of term t in doc d
# where cLH(t) = likelihood of term t in (background) collection c
#

PROC _score_NLLR(dbl q_tCnt, dbl qSize, wrd c_tCnt, wrd cSize, BAT[oid,int] e_tCnt, BAT[void,int] e_size) : bat[oid,dbl] {
    var collFac := ((dbl(1) - c_lambda) / c_lambda) * cSize / dbl(c_tCnt);
    var q_tLH := q_tCnt / qSize;
    var e_tScores := e_tCnt.[dbl]().access(BAT_WRITE);
    e_tScores.left_div(e_size);
    e_tScores := e_tScores.[*](collFac);
    e_tScores := e_tScores.[+](dbl(1));
    e_tScores := [log](e_tScores);
    e_tScores := e_tScores.[*](q_tLH);
    return e_tScores;
}

#             __                /  cNdoc  \            (cK1 + 1) tf(t)
# OKAPI(q) =  >_  qCnt(t) * log | ------- | * -------------------------------------
#            t in q             \  DF(t)  /   cK1*((1-cB) + cB*(DL / cAvgDL)) + tf(t)
#
# where cNdoc    = number of elements that is scored
# where cAvgDL   = average element length
# where DL       = element length
# where cIDF(t)  = idf instead of the Robertson/Sparck-Jones weight (variation on idf)
# where tf(t)    = term frequency (number of occurences of term t in element)
# where cK1      = tuning parameter k1
# where cB       = tuning parameter b
#

PROC _score_OKAPI(dbl q_tCnt, BAT[oid,int] e_tCnt, BAT[void,int] e_size, wrd cNdoc, dbl cAvgDL) : bat[oid,dbl] {
    
    # cIDF contains Robertson/Sparck-Jones relevance weight
    var cIDF := e_tCnt.count_wrd(); # df
    cIDF  := log((cNdoc + 0.5) / (cIDF + 0.5));

    # cK contains length normalization 
    var cK := e_size.semijoin(e_tCnt); # document lengths
    cK := [/](cK, cAvgDL / okapi_b);
    cK := [+](cK, 1 - okapi_b);
    cK := [*](cK, okapi_k1);
    cK := [+](cK, e_tCnt);
    var tmp := [*](e_tCnt, okapi_k1 + 1);
    tmp := [/](tmp, cK);
    var e_tScores := [*](tmp, cIDF * q_tCnt);
    return e_tScores;
}


@:containing_query_term_LM(nest,nid,TagSize)@
@:containing_query_term_LM(unnest,nid,TagSize)@
@:containing_query_term_LM(nest,pre,size)@
@:containing_query_term_LM(unnest,pre,size)@
@= containing_query_term_LM
PROC tj_containing_query_@1_@2_term_LM (bat[oid,any] left, bat[oid,bat] query) : bat[oid,dbl] 
{
    var t_total := 0;
    t_total :-= time();
    
    var t_qCnt := query.fetch(0);
    var t_cCnt := query.fetch(1);

    if ( count_wrd(left) = wrd(0) ) return new(oid,dbl);
    if ( count_wrd(t_qCnt) = wrd(0) ) return new(oid,dbl);
    
    var e_pre := left.chk_order();
    var cSize := bat("tj_" + ftiName + "_param").find("collectionSize").wrd();
    var e_size := bat("tj_" + ftindex + "_@3");
    var eScores := new(oid,dbl);
    
    # loop over query terms
    t_qCnt@batloop()
    {
        # get collection count of term
        var t_pre := _getTermPositions($h);
        var c_tCnt := wrd(t_cCnt.find($h)); 
        # get element count of term
	var e_tCnt := _getTermDocCnt_@1_@2(e_pre, e_size, t_pre);
	# score elements by this term
        var e_tScores := _score_LM($t, c_tCnt, cSize, e_tCnt, e_size);
        e_tCnt := nil;
        e_tScores := e_tScores.kunion(left.kdiff(e_tScores).project(dbl(0))).sort();
        
	# aggregate term scores
        eScores := e_tScores.left_mul(eScores);
	e_tScores := nil;
    }
    eScores.access(BAT_READ);
    
    var res;
    if (returnall) {
        res := eScores;
    } else {
        var unchanged := eScores.uselect(dbl(0));
        res := eScores.kdiff(unchanged);
    }
    t_total :+= time();
    if (timing) printf(HASH +" LM timing: total: %d\n", t_total);
    return res;
}
@mil


@:containing_query_term_LMs(nest,nid,TagSize)@
@:containing_query_term_LMs(unnest,nid,TagSize)@
@:containing_query_term_LMs(nest,pre,size)@
@:containing_query_term_LMs(unnest,pre,size)@
@= containing_query_term_LMs
PROC tj_containing_query_@1_@2_term_LMs (bat[oid,any] left, bat[oid,bat] query) : bat[oid,dbl] 
{
    var t_total := 0;
    t_total :-= time();
    
    var t_qCnt := query.fetch(0);
    var t_cCnt := query.fetch(1);
    
    if ( count_wrd(left) = wrd(0) ) return new(oid,dbl);
    if ( count_wrd(t_qCnt) = wrd(0) ) return new(oid,dbl);
    
    var e_pre := left.chk_order();
    var cSize := bat("tj_" + ftiName + "_param").find("collectionSize").wrd();
    var e_size := bat("tj_" + ftindex + "_@3");
    var eScores := new(oid,dbl);
    var score_base := dbl(1);
    
    # loop over query terms
    t_qCnt@batloop()
    {
        # get collection count of term
        var t_pre := _getTermPositions($h);
        var c_tCnt := wrd(t_cCnt.find($h)); 
        # get element count of term
	var e_tCnt := _getTermDocCnt_@1_@2(e_pre, e_size, t_pre);
	# score elements by this term
        var e_tScores := _score_LMs($t, c_tCnt, cSize, e_tCnt, e_size);
        e_tCnt := nil;
        var base := c_lambda * c_tCnt / dbl(cSize);
        score_base :*= base;
        e_tScores := e_tScores.kunion(left.kdiff(e_tScores).project(base)).sort();

	# aggregate term scores
        eScores := e_tScores.left_mul(eScores);
	e_tScores := nil;
    }
    eScores.access(BAT_READ);
    var res;
    if (returnall) {
        res := eScores;
    } else {
        var unchanged := eScores.uselect(score_base);
        res := eScores.kdiff(unchanged);
    }
    
    t_total :+= time();
    if (timing) printf(HASH +" LMs timing: total: %d\n", t_total);
    return res;
}
@mil


@:containing_query_term_NLLR(nest,nid,TagSize)@
@:containing_query_term_NLLR(unnest,nid,TagSize)@
@:containing_query_term_NLLR(nest,pre,size)@
@:containing_query_term_NLLR(unnest,pre,size)@
@= containing_query_term_NLLR
PROC tj_containing_query_@1_@2_term_NLLR (bat[oid,any] left, bat[oid,bat] query) : bat[oid,dbl] 
{
    var t_total := 0;
    t_total :-= time();
    
    var t_qCnt := query.fetch(0);
    var t_cCnt := query.fetch(1);
    
    if ( count_wrd(left) = wrd(0) ) return new(oid,dbl);
    if ( count_wrd(t_qCnt) = wrd(0) ) return new(oid,dbl);
    
    var qSize := t_qCnt.sum();
    
    var e_pre := left.chk_order();
    var cSize := bat("tj_" + ftiName + "_param").find("collectionSize").wrd();
    var e_size := bat("tj_" + ftindex + "_@3");
    var eScores := new(oid,dbl);
    
    # loop over query terms
    t_qCnt@batloop()
    {
        # get collection count of term
        var t_pre := _getTermPositions($h);
        var c_tCnt := wrd(t_cCnt.find($h)); 
        # get element count of term
	var e_tCnt := _getTermDocCnt_@1_@2(e_pre, e_size, t_pre);
        # score elements by this term
        var e_tScores := _score_NLLR($t, qSize, c_tCnt, cSize, e_tCnt, e_size);
        e_tCnt := nil;
        
	# aggregate term scores
        eScores := eScores.union_add(e_tScores);
	e_tScores := nil;
    }
    eScores.access(BAT_READ);
    
    var res;
    if (returnall) {
        res := union(eScores,left.kdiff(eScores).project(dbl(0))).sort();
    } else {
        res := eScores;
    }
    
    t_total :+= time();
    if (timing) printf(HASH +" NLLR timing: total: %d\n", t_total);
    return res;
}
@mil


@:containing_query_term_OKAPI(nest,nid,TagSize)@
@:containing_query_term_OKAPI(unnest,nid,TagSize)@
@:containing_query_term_OKAPI(nest,pre,size)@
@:containing_query_term_OKAPI(unnest,pre,size)@
@= containing_query_term_OKAPI
PROC tj_containing_query_@1_@2_term_OKAPI (bat[oid,any] left, bat[oid,bat] query) : bat[oid,dbl] 
{
    var t_total := 0;
    t_total :-= time();
    
    var t_qCnt := query.fetch(0);
    
    if ( count_wrd(left) = wrd(0) ) return new(oid,dbl);
    if ( count_wrd(t_qCnt) = wrd(0) ) return new(oid,dbl);
    
    var e_pre := left.chk_order();
    var cSize := bat("tj_" + ftiName + "_param").find("collectionSize").wrd();
    var e_size := bat("tj_" + ftindex + "_@3");
    var eScores := new(oid,dbl);
    var cNdoc := e_pre.count_wrd();
    var cAvgDL := e_size.semijoin(e_pre).[dbl]().avg();
    
    # loop over query terms
    t_qCnt@batloop()
    {
        # get collection count of term
        var t_pre := _getTermPositions($h);
        # get element count of term
	var e_tCnt := _getTermDocCnt_@1_@2(e_pre, e_size, t_pre);
	# score elements by this term
        var e_tScores := _score_OKAPI($t, e_tCnt, e_size, cNdoc, cAvgDL);
        e_tCnt := nil;
        
	# aggregate term scores
        eScores := eScores.union_add(e_tScores);
	e_tScores := nil;
    }
    eScores.access(BAT_READ);
    
    var res;
    if (returnall) {
        res := union(eScores,left.kdiff(eScores).project(dbl(0))).sort();
    } else {
        res := eScores;
    }
    
    t_total :+= time();
    if (timing) printf(HASH +" OKAPI timing: total: %d\n", t_total);
    return res;
}
@mil

@:getTermDoc_nid(nest)@
@:getTermDoc_nid(unnest)@
@= getTermDoc_nid
PROC _getTermDoc_@1_nid(BAT[oid,oid] e_pre, BAT[void,int] e_size, BAT[oid,oid] t_pre) : BAT[oid,int] {
    
    # get doc - term relation
    return treemergejoin_@1_nid(e_pre, e_size, t_pre);
}
@mil
@:getTermDoc_pre(nest)@
@:getTermDoc_pre(unnest)@
@= getTermDoc_pre
PROC _getTermDoc_@1_pre(BAT[oid,any] e_pre, BAT[void,int] e_size, BAT[oid,oid] t_pre) : BAT[oid,int] {
    
    # get doc - term relation
    return treemergejoin_@1_pre(e_pre, e_size, t_pre.reverse());
}
@mil

@:containing_query_term(nest,nid,plus,TagSize,semijoin)@
@:containing_query_term(unnest,nid,plus,TagSize,semijoin)@
@:containing_query_term(nest,pre,plus,size,semijoin)@
@:containing_query_term(unnest,pre,plus,size,semijoin)@
@:containing_query_term(nest,nid,min,TagSize,kdiff)@
@:containing_query_term(unnest,nid,min,TagSize,kdiff)@
@:containing_query_term(nest,pre,min,size,kdiff)@
@:containing_query_term(unnest,pre,min,size,kdiff)@
@= containing_query_term
PROC tj_containing_query_@1_@2_term_@3 (bat[oid,any] left, bat[oid,bat] query) : bat[oid,dbl] 
{
    var t_total := 0;
    t_total :-= time();
    
    var t_qCnt := query.fetch(0);

    if ( count_wrd(left) = wrd(0) ) return new(oid,dbl);
    if ( count_wrd(t_qCnt) = wrd(0) ) return new(oid,dbl);
    
    var e_pre := left.chk_order();
    var e_size := bat("tj_" + ftindex + "_@4");
    
    # loop over query terms
    t_qCnt@batloop()
    {
        # get collection count of term
        var t_pre := _getTermPositions($h);
        e_pre := e_pre.@5(_getTermDoc_@1_@2(e_pre, e_size, t_pre));
	e_pre := e_pre.chk_order(); # jf order patch
    }
    
    var res := e_pre;
    
    t_total :+= time();
    if (timing) printf(HASH +" term_@3 timing: total: %d\n", t_total);
    return res;
}
@mil

#returns phrases (nid,pre) of first phrase term
PROC _selectPhrase(bat[oid,dbl] query) : bat[oid,oid] 
{
    # Select the term positions from the global term dictionary. 
    var terms := query.reverse();
    var t_pre := _getTermPositions(terms.fetch(0));
    
    var res := t_pre.reverse();
    var j := terms.count_wrd();
    var i := wrd(1); 
    while (i < j)
    {
        t_pre := _getTermPositions(terms.fetch(i));
        res := res.semijoin(t_pre.[int]().[-](i).[oid]().reverse());   
	i :+= 1;
    }	
    
    return res.reverse().chk_order(); 
}

@:containing_query_phrase(nest,nid,TagSize)@
@:containing_query_phrase(unnest,nid,TagSize)@
@:containing_query_phrase(nest,pre,size)@
@:containing_query_phrase(unnest,pre,size)@
@= containing_query_phrase
PROC tj_containing_query_@1_@2_phrase (bat[oid,any] left, bat[oid,bat] query) : bat[oid,dbl] 
{
    var t_total := 0;
    t_total :-= time();
    
    var t_qCnt := query.fetch(0);

    if ( count_wrd(left) = wrd(0) ) return new(oid,dbl);
    if ( count_wrd(t_qCnt) = wrd(0) ) return new(oid,dbl);
    
    var e_pre := left.chk_order();
    var e_size := bat("tj_" + ftindex + "_@3");
    var t_pre := _selectPhrase(t_qCnt);
    var res := e_pre.semijoin(_getTermDoc_@1_@2(e_pre, e_size, t_pre));
    
    t_total :+= time();
    if (timing) printf(HASH +" phrase timing: total: %d\n", t_total);
    return res;
}
@mil


#####################################################################
# Containing_query_entity
#####################################################################

PROC tj_ent2tid (bat[str,dbl] concept_score) : bat[oid,dbl] 
{
    return bat("tj_" + ftiName + "_conceptdict").join(concept_score);
}

# returns the pre-order positions of the concept c
# in the collection of the documents
PROC _getConceptPositions (oid tid) : bat[void,oid] {
     var index := bat("tj_" + ftindex + "_ConceptIndex");
     var offset1 := wrd(index.fetch(int(tid)));
     var offset2 := wrd(index.fetch(int(tid) + 1));
     var res := bat("tj_" + ftindex + "_Concepts").slice(offset1, offset2 - 1);
     res := res.set_tailkeysorted();
     return res;
}

@mil

@:getConceptDocScr_nid(nest)@
@:getConceptDocScr_nid(unnest)@
@= getConceptDocScr_nid
PROC _getConceptDocScr_@1_nid(BAT[oid,oid] e_pre, BAT[void,int] e_size, BAT[oid,oid] c_pre) : BAT[oid,int] {
     
	# get doc - Concept relation
	var c_Scr := bat("tj_" + ftindex + "_ConceptScore");
        var e_c := treemergejoin_@1_nid(e_pre, e_size, c_pre);
        var eself_c := e_pre.join(c_pre.reverse());
	var e_cScr := {sum}(c_Scr, e_c.reverse(), e_c.kunique()).sort();
	var eself_cScr := {sum}(c_Scr, eself_c.reverse(), eself_c.kunique()).sort();
        return union_add(e_cScr, eself_cScr);
}
@mil
@:getConceptDocScr_pre(nest)@
@:getConceptDocScr_pre(unnest)@
@= getConceptDocScr_pre
PROC _getConceptDocScr_@1_pre(BAT[oid,any] e_pre, BAT[void,int] e_size, BAT[oid,oid] c_pre) : BAT[oid,int] {
     
	# get doc - Concept relation
	var c_Scr := bat("tj_" + ftindex + "_ConceptScore");
        var e_c := treemergejoin_@1_nid(e_pre.mirror(), e_size, c_pre);
	var eself_c := e_pre.mirror().join(c_pre.reverse());
	var e_cScr := {sum}(c_Scr, e_c.reverse(), e_c.kunique()).sort();
	var eself_cScr := {sum}(c_Scr, eself_c.reverse(), eself_c.kunique()).sort();
        return union_add(e_cScr, eself_cScr);
}
@mil

#                 __              
# LogSum(d|q) =   >_   qCnt(c) * log (dScr(c) + 1)
#              c in q             
#
# where qCnt(c) = count of concept c in query q
# where dScr(c) = detector score for concept c in doc d
#

PROC _score_LogSum(dbl q_cCnt, BAT[oid,dbl] e_cScr) : bat[oid,dbl] {
    var e_cScores := e_cScr.[+](dbl(1)); 
    e_cScores := [log](e_cScores);
    e_cScores := e_cScores.[*](q_cCnt);
    return e_cScores;
}

@:containing_query_entity_LogSum(nest,nid,TagSize)@
@:containing_query_entity_LogSum(unnest,nid,TagSize)@
@:containing_query_entity_LogSum(nest,pre,size)@
@:containing_query_entity_LogSum(unnest,pre,size)@
@= containing_query_entity_LogSum
PROC tj_containing_query_@1_@2_entity_LogSum (bat[oid,any] left, bat[oid,dbl] query) : bat[oid,dbl] 
{
    var t_total := 0;
    t_total :-= time();
    
    if ( count_wrd(left) = wrd(0) ) return new(oid,dbl);
    if ( count_wrd(query) = wrd(0) ) return new(oid,dbl);
    
    var c_qCnt := {sum}(query);

    var e_pre := left.chk_order();
    var e_size := bat("tj_" + ftindex + "_@3");
    var eScores := new(oid,dbl);
    
    # loop over query terms
    c_qCnt@batloop()
    {
        # get collection count of term
        var c_pre := _getConceptPositions($h);
        # get element count of term
	var e_cScr := _getConceptDocScr_@1_@2(e_pre, e_size, c_pre);
	# score elements by this term
        var e_cScores := _score_LogSum($t, e_cScr);
        e_cScr := nil;
        
	# aggregate term scores
        eScores := eScores.union_add(e_cScores);
	e_cScores := nil;
    }
    eScores.access(BAT_READ);
    eScores := [exp](eScores);
    
    var res;
    if (returnall) {
        res := union(eScores,left.kdiff(eScores).project(dbl(0)));
    } else {
        res := eScores;
    }
    
    t_total :+= time();
    if (timing) printf(HASH +" LogSum timing: total: %d\n", t_total);
    return res;
}
@mil

@:containing_query_entity(nest,nid,plus,TagSize,semijoin)@
@:containing_query_entity(unnest,nid,plus,TagSize,semijoin)@
@:containing_query_entity(nest,pre,plus,size,semijoin)@
@:containing_query_entity(unnest,pre,plus,size,semijoin)@
@:containing_query_entity(nest,nid,min,TagSize,kdiff)@
@:containing_query_entity(unnest,nid,min,TagSize,kdiff)@
@:containing_query_entity(nest,pre,min,size,kdiff)@
@:containing_query_entity(unnest,pre,min,size,kdiff)@
@= containing_query_entity
PROC tj_containing_query_@1_@2_entity_@3 (bat[oid,any] left, bat[oid,dbl] query) : bat[oid,dbl] 
{
    var t_total := 0;
    t_total :-= time();
    
    if ( count_wrd(left) = wrd(0) ) return new(oid,dbl);
    if ( count_wrd(query) = wrd(0) ) return new(oid,dbl);
    
    var e_pre := left.chk_order();
    var e_size := bat("tj_" + ftindex + "_@4");
    
    # loop over query terms
    query@batloop()
    {
        # get collection count of term
        var t_pre := _getConceptPositions($h);
        e_pre := e_pre.@5(_getTermDoc_@1_@2(e_pre, e_size, t_pre));
	e_pre := e_pre.chk_order(); # jf order patch
    }
    
    var res := e_pre;
    
    t_total :+= time();
    if (timing) printf(HASH +" entity_@3 timing: total: %d\n", t_total);
    return res;
}
@mil


#####################################################################
# and/or combination
#####################################################################

PROC tj_and_nocomb(bat left, bat right) : bat 
{
    return left.semijoin(right).sort();
}

PROC tj_and_comb(bat left, bat right) : bat 
{
    if (andcomb = "sum") return [+](left,right).sort();
    if (andcomb = "prod") return [*](left,right).sort();
    if (andcomb = "max") return [max](left,right).sort();
    if (andcomb = "min") return [min](left,right).sort();
    if (andcomb = "prob") return [-](dbl(1),[*]([-](dbl(1),left),[-](dbl(1),right))).sort();
}

PROC tj_or_nocomb(bat left, bat right) : bat 
{
    return left.kunion(right).sort();
}

PROC tj_or_comb(bat left, bat right) : bat 
{
    if (orcomb = "sum") return left.union_add(right).sort();
    if (orcomb = "prod") return left.union_mul(right).sort();
    if (orcomb = "max") {
        var intersect := [max](left,right);
        var onlyleft  := left.kdiff(right);
        var onlyright := right.kdiff(left);
	var outer := onlyleft.kunion(onlyright);
        return intersect.kunion(outer).sort();
    }
    if (orcomb = "prob") {
	var intersect := [-](dbl(1),[*]([-](dbl(1),left),[-](dbl(1),right)));
        var onlyleft  := left.kdiff(right);
        var onlyright := right.kdiff(left);
	var outer := onlyleft.kunion(onlyright);
        return intersect.kunion(outer).sort();
    }
}

################################################################################
# PRIOR
################################################################################

PROC tj_prior_ls(BAT[oid,dbl] region) : bat  
{
    var cName := qenv.find(QENV_FTINAME);
    var tag_size := bat("tj_" + ftindex + "_TagSize");
    return [*](region, tag_size);
}
#ADDHELP("prior_ls", "vojkan", "March 16, 2005",
#"Adds element prior based on element length to the region score.",
#"TIJAH");

################################################################################
# OVERLAP REMOVAL
################################################################################

PROC tj_rm_overlap(BAT[oid,dbl] ctx) : bat  
{
   if ( count_wrd( ctx ) = wrd(0) ) {
       return ctx;
   } else {
       var size := bat("tj_" + ftindex + "_size");
       var a_d := treemergejoin_nest_pre(ctx, size, ctx);
       var x_a := a_d.hmark(0@0);
       var x_d := a_d.tmark(0@0);
       var x_ascore := x_a.join(ctx);
       var x_dscore := x_d.join(ctx);

       # deselect all ancestors having a higher scored descendant
       var tmp := [<](x_ascore, x_dscore).uselect(true).mirror().join(x_a);
       var res1 := ctx.kdiff(tmp.reverse());
       # deselect all descendants having a higher scored ancestor
       # select descendants having a higher scored ancestor in res1
       tmp := x_a.kdiff(tmp).join(res1).mirror().join(x_d); 
       var res := res1.kdiff(tmp.reverse());

       return res;
   }
}
#ADDHELP("rm_overlap","henning", "Oktober, 2008",
#"Removes overlapping elements from result list.",
#"TIJAH");

################################################################################
# Pathfinder PRE output 
################################################################################

##
# Map all pre identifiers to their corresponding pathfinder pre IDs / documents
# Returns a bat [void, bat]: bat1 (rank,pfpre), bat2 (rank,score), bat3 (rank,docname)
##
PROC tj_pre2pfpre(bat[oid,dbl] pre_score) : bat[void,bat] 
{
    var t_total := 0 - time();

    if (pre_score.count_wrd() = wrd(0)) return new(str,dbl);
    var pres := pre_score.hmark(0@0);
    var scores := pre_score.tmark(0@0);
    var pfpres := pres.leftjoin(bat("tj_" + ftindex + "_pfpre")).tmark(0@0);
    var docpre := bat("tj_" + ftindex + "_doc_firstpre");
    var mark_did := [find_lower](const docpre.reverse(), pres);
    var mark_docname := mark_did.leftjoin(bat("tj_" + ftindex + "_doc_name")).tmark(0@0);

    var res := new(void,bat).seqbase(0@0);
    res.append(pfpres);
    res.append(scores);
    res.append(mark_docname);

    t_total :+= time();
    if (timing) printf(HASH +" add inexpath timing: total: %d\n", t_total);
    return res;
}

################################################################################
# INEX output 
################################################################################

##
# Map all pre identifiers to their stored inexpath expressions
# Returns a bat [pre, any].
##
PROC tj_pre2inexpath(bat[oid,dbl] pre_score) : bat[str,dbl] 
{
    var t_total := 0 - time();

    if (pre_score.count_wrd() = wrd(0)) return new(str,dbl);
    var pres := pre_score.hmark(0@0);
    var scores := pre_score.tmark(0@0);
    var docpre := bat("tj_" + ftindex + "_doc_firstpre");
    var mark_did := [find_lower](const docpre.reverse(), pres);
    var mark_docname := mark_did.leftjoin(bat("tj_" + ftindex + "_doc_name"));
    var mark_path := pres.leftjoin(bat("tj_" + ftindex + "_path"));
    var mark_pathno := pres.leftjoin(bat("tj_" + ftindex + "_pathno"));
    var mark_docname_path := [+](mark_docname, mark_path);
    mark_docname_path := [+](mark_docname_path, mark_pathno);
    var res := mark_docname_path.reverse().leftfetchjoin(scores);    

    t_total :+= time();
    if (timing) printf(HASH +" add inexpath timing: total: %d\n", t_total);
    return res;
}

################################################################################
# MERGE output 
################################################################################

##
# Merge the results of all index fragments.
# Returns a bat [void, bat]: bat1 (rank,pfpre), bat2 (rank,score), bat3 (rank,docname)
##
PROC tj_merge_frag_results(bat[void,bat] res_frag, int topk) : bat[str,dbl] 
{
    var res := new(str,dbl);
    res_frag@batloop(){
        res.insert($t);
    }
    if (topk > 0) {
        return res.tsort_rev().slice(0, topk - 1);
    }
    return res.tsort_rev();
}

##
# Merge the results of all index fragments.
# Returns a bat [pre, any].
##
PROC tj_merge_frag_results_inex(bat[void,bat] res_frag, int topk) : bat[str,dbl] 
{
    var res := new(str,dbl);
    res_frag@batloop(){
        res.insert($t);
    }
    if (topk > 0) {
        return res.tsort_rev().slice(0, topk - 1);
    }
    return res.tsort_rev();
}


################################################################################
# Support for index access functions: tijah:terms, tijah:tf, tijah:tf-all 
################################################################################

PROC tj_terms_contained_by(str ftindex, bat[oid,any] elem) : bat[void,oid]
{
    var size := bat("tj_" + ftindex + "_size");
    var elem_desc := treemergejoin_nest_pre(elem.reverse(), size, size);
    var elem_terms := elem_desc.reverse().kdiff(bat("tj_" + ftindex + "_pfpre")).reverse();
    var elem_tid := elem_terms.leftfetchjoin(bat("tj_" + ftindex + "_tid"));
    return elem_tid;
}

##
# return contained terms
##
PROC tj_terms(str ftiName, bat[int,bat] index_elem) : bat[void,str] 
{
    var ftindex := [+](const ftiName, [str](index_elem.hmark(0@0))); 
    var tid_bats := [tj_terms_contained_by](ftindex, index_elem.tmark(0@0));
    var tid_bat := new(oid,oid);
    [insert](const tid_bat, tid_bats);
    var tids_unique := tid_bat.reverse().kunique().mark(0@0);
    var terms := bat("tj_" + ftiName + "_termdict").semijoin(tids_unique).tmark(0@0);
    return terms;
}

PROC tj_fb_terms(str ftiName, bat[int,bat] index_elem, int ret_num, dbl lambda) : bat[void,str]
{
    var ftindex := [+](const ftiName, [str](index_elem.hmark(0@0))); 
    var tid_bats := [tj_terms_contained_by](ftindex, index_elem.tmark(0@0));
    
    #assign new fragment independent elem IDs to union the containment join results into one bat
    var e_tid := new(oid,oid);
    var base := 0@0;
    var elems := new(void,oid).seqbase(base);
    tid_bats@batloop() {
       var e_tid_frag := $t;
       var es := e_tid_frag.kunique().hmark(base);
       e_tid.insert(es.join(e_tid_frag));
       elems.append(es);
       base := oid(int(elems.reverse().max()) + 1);
    }
    elems := elems.reverse();
    var coll_freq := bat("tj_" + ftiName + "_termfreq");
    var c_size := bat("tj_" + ftiName + "_param").find("collectionSize").wrd();
    
    # calculate collection frequencies of occurring terms
    var tids := e_tid.tunique().sort();
    var tid_collfreq := coll_freq.semijoin(tids).[dbl]().[/](dbl(c_size));
    var lambda := dbl(0.5);
    var _lambda := dbl(1.0) - lambda;
    var tid_collfreq_lambda := tid_collfreq.[*](lambda); 
 
    # calculate and aggregate term frequencies in fb elements (mixture model to avoid zero freqs)
    var ex_tid := [uselect](const e_tid.reverse(), elems);
    var ex_hist := [histogram]([reverse](ex_tid)).[sort]();
    ex_tid := nil;
    var e_size := [sum](ex_hist);
    # unavoidable batloop part
    var tid_prob := new(oid,dbl);
    ex_hist@batloop() {
       var tids := $t.hmark(0@0);
       var prob := [dbl]($t.tmark(0@0)).access(BAT_WRITE);
       prob [:/=] dbl(e_size.find($h));
       prob [:*=] _lambda;
       prob := tids.reverse().leftfetchjoin(prob);
       tid_prob.insert(left_add(tid_collfreq_lambda, prob));
    }
    ex_hist := nil;
    e_size := nil;
    var tid_logprob := [log](tid_prob);
    tid_prob := nil;
    var tid_sumlogprob := {sum}(tid_logprob); 
    tid_logprob := nil;
    
    # subtract log collection term likelihood from normalized log fb term likelihood
    var fac1 := dbl(1.0) / (_lambda * elems.count_wrd());
    var fac2 := dbl(-1.0) * lambda / _lambda;
    var tid_normsumlogprob := tid_sumlogprob.[*](fac1);
    tid_sumlogprob := nil;
    var tid_collfreqlog := [log](tid_collfreq);
    var tid_normcollfreqlog := tid_collfreqlog.[*](fac2);
    tid_collfreqlog := nil;
    tid_normsumlogprob.chk_order();
    tid_normcollfreqlog.chk_order();
    var fbtids := left_add(tid_normsumlogprob, tid_normcollfreqlog).[exp]().tsort_rev();

    if (not(isnil(ret_num))) fbtids := fbtids.slice(0, ret_num - 1);
    var fbterms := fbtids.hmark(0@0).leftfetchjoin(bat("tj_" + ftiName + "_termdict"));
    return fbterms;
}

PROC tj_term2tid (str ftiName, bat[void,str] terms, bit stemming) : bat[oid,oid] 
{
    var param    := bat("tj_" + ftiName + "_param");
    var firstterm:= oid(param.find("lastStopWord"));
    
    var stemmed := terms;
    if ( stemming ) 
    {
       var stemmer  := param.find("stemmer");
       stemmed  := [tj_normalizeTerm]( [toLower](stemmed), stemmer );
    }
    
    var mark_tid := stemmed.join(bat("tj_" + ftiName + "_termdict").reverse());
    mark_tid := mark_tid.select(firstterm,oid(nil),TRUE,FALSE);
    return mark_tid;
}

##
# return term frequencies
##
PROC tj_tf(str ftiName, bat[int,bat] index_elem, bat[void,oid] tids) : bat[oid,lng] 
{
    var ftindex := [+](const ftiName, [str](index_elem.hmark(0@0)));
    var tid_bats := [tj_terms_contained_by](ftindex, index_elem.tmark(0@0));
    var tid_bat := new(oid,oid);
    [insert](const tid_bat, tid_bats);
    tid_bat := tid_bat.reverse().semijoin(tids.reverse()).reverse();
    var tid_histo := tid_bat.histogram().[lng]();
    return tid_histo;
}

##
# return global term frequencies
##
PROC tj_tfall(str ftiName, bat[void,oid] tids) : bat[oid,lng] 
{
    return bat("tj_" + ftiName + "_termfreq").semijoin(tids.reverse()).[lng](); 
}


#####################################################################
#
#   OLD VERSION START
#
#####################################################################

const virtRoot := 0@0;

##
# Compute ancestor-descendant relation. 
#
# Forwards to anc_desc_llscj: see below.
##

PROC tj_nid2pre( bat[oid,any] nid_score, bat[oid,str] qenv ) : bat[oid,any] 
{
    var cName := qenv.find(QENV_FTINAME);
    var res := nid_score.reverse().leftfetchjoin(bat("tj_" + cName + "_Tags")).reverse();
    return res;
}

PROC anc_desc( bat[oid,any] anc, bat[oid,any] desc, bat[oid,str] qenv ) : bat[oid,oid] 
{
    var cName := qenv.find(QENV_FTINAME);
    var a_pre;
    var a_size;
    if (isnil(anc.fetch(0))) {
       var offset1 := wrd(anc.reverse().fetch(0));
       var offset2 := wrd(anc.reverse().fetch(1));
       a_pre := bat("tj_" + cName + "_Tags").slice(offset1, offset2).tsort();
       a_size := bat("tj_" + cName + "_TagSize").slice(offset1, offset2);
    } else {
       a_pre := bat("tj_" + cName + "_Tags").semijoin(anc).tsort();
       a_size := bat("tj_" + cName + "_TagSize");
    }
    var d_pre;
    if (isnil(desc.fetch(0))) {
       var offset1 := wrd(desc.reverse().fetch(0));
       var offset2 := wrd(desc.reverse().fetch(1));
       d_pre := bat("tj_" + cName + "_Tags").slice(offset1, offset2).tsort();
    } else {
       d_pre := bat("tj_" + cName + "_Tags").semijoin(desc).tsort();
    }
  
    var nested := false;
    if (qenv.find(QENV_RECURSIVE_TAGS) = "1") {nested := true;}
    var a_d;
    if (nested) {
       a_d := treemergejoin_sort(a_pre, a_size, d_pre);
    } else {
       a_d := treemergejoin_sort_unnested(a_pre, a_size, d_pre);
    }
    return a_d;
}


##
# Converts a list of query terms to a list of term ids
#
# Stemming on the query terms is performed using the same stemmer
# that was used for the collection.
##
PROC _terms2void_tid( bat[void,str] Qterms, str bg_cName): bat[void,oid] 
{
    var param    := bat("tj_"+ bg_cName +"_param");
    var stemmer  := param.find("stemmer");
    var firstterm:= oid(param.find("lastStopWord"));
    var stemmed  := [tj_normalizeTerm]( [toLower](Qterms), stemmer );
    var tids := bat(_tj_TermBat(bg_cName)).join( stemmed.reverse() ).sort().hmark(oid(0));
    #var stopwords := tids.uselect(0@0,firstterm,TRUE,FALSE);
    #tids := tids.kdiff(stopwords);
    tids := tids.select(firstterm,oid(nil),TRUE,FALSE);
    return tids;
}


##
# Return only the element nodes from region ctx
##
PROC nodes( bat[oid,any] ctx, BAT[oid,str] qenv ) : bat[oid,any] 
{
    # The pfpre table only stores element nodes, so we can use it as a filter:
    var pfpre  := bat( "tj_" + qenv.find(QENV_FTINAME) + "_pfpre");
    var result := ctx.semijoin(pfpre);
    return result;
}


##
# Return only the terms from region ctx
##
PROC terms( bat[oid,any] ctx, BAT[oid,str] qenv ) : bat[oid,any] 
{
    # A term is everything that is not an element node
    var nodes  := nodes( ctx, qenv );
    var result := ctx.kdiff( nodes );
    return result;
}


################################################################################
# SELECTION
################################################################################

##
# Select the root node of the collection
#
# Returns a bat [preorder rank,score].
# The score is initalized based on the scorebase environment variable
##
PROC select_root(bat[void,oid] par_startNodes, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    if ( not( isnil( par_startNodes ) ) ) {
        # Start from a set of starting nodes if available. 
        # It is assumed that the startNodes are [any, pre]
        if ( count_wrd( par_startNodes ) > wrd(0) ) {
            var root_reg := par_startNodes.reverse().sort().project( dbl(qenv.find(QENV_SCOREBASE)) );
            return root_reg;
        } else {
            var root_reg := new(oid,dbl,1);
            
            root_reg.insert( virtRoot, dbl(qenv.find(QENV_SCOREBASE)) );
            return root_reg;
        }
    } else {
        # Because TIJAH expects all documents in a collection to be contained by one 
        # "virtual root" element, this behaviour should be emulated by the light index. 
        # An element with preorder oid(0) will indicate that it is the collection root.
        var root_reg := new(oid,dbl,1);
        
        root_reg.insert( virtRoot, dbl(qenv.find(QENV_SCOREBASE)) );
        return root_reg;
    }
}

PROC select_root(BAT[oid,str] qenv) : bat[oid,dbl] 
{
    var res := new(oid,dbl,1);
    res.insert(virtRoot, dbl(qenv.find(QENV_SCOREBASE)));
    return res;
}

PROC select_startnodes(bat[void,oid] startNodes, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    var cName := qenv.find(QENV_FTINAME);
    var res := startNodes.join(bat("tj_" + cName + "_Tags").reverse()).reverse();
    res := res.project(dbl(qenv.find(QENV_SCOREBASE))).sort();
    return res;
}

##
# Select all element nodes in the collection
#
# Returns a bat [preorder rank,score].
# The score is initalized based on the scorebase environment variable
##
PROC select_node(BAT[oid,str] qenv) : bat[oid,dbl]  
{
     var cName := qenv.find(QENV_FTINAME);
     var index := bat("tj_" + cName + "_TagIndex");
     var offset1 := index.fetch(1);
     var offset2 := oid(wrd(index.fetch(index.count_wrd() - 1)) - 1);
     var res := new(void,oid).seqbase(0@0);
     res.append(offset1);
     res.append(offset2);
     res := res.reverse().project(dbl(nil)); 

     # set the recursive tag flag on "true" because all tags are selected
     modify_qenv(qenv,QENV_RECURSIVE_TAGS,"1");

    return res;
}

##
# Select all element nodes in the collection with the given name
#
# Returns a bat [preorder rank,score].
# The score is initalized based on the scorebase environment variable
##
PROC _getTagPositions(oid tid, str cName) : bat[void,oid] {
     var index := bat("tj_" + cName + "_TagIndex");
     var offset1 := index.fetch(wrd(tid));
     var offset2 := oid(wrd(index.fetch(int(tid) + 1)) - 1);
     var res := new(void,oid).seqbase(0@0);
     res.append(offset1);
     res.append(offset2);
     return res;
}

PROC select_node(str name, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    var tids := bat(_tj_TagBat(qenv.find(QENV_FTINAME))).select(name);
    if (tids.count_wrd() = wrd(0)) return new(oid,dbl);
    var tid := tids.reverse().fetch(0);

    var cName := qenv.find(QENV_FTINAME);
    # set the recursive tag flag on "true" because all tags are selected
    if ( bat(_tj_RTagBat(cName)).exist(tid) ) {
        modify_qenv(qenv,QENV_RECURSIVE_TAGS,"1");
    }
    var result := _getTagPositions(tid, cName); 
    result := result.reverse().project(dbl(nil)); 

    return result;
}

PROC select_node(str name, bit e_class, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    if ( e_class ) {
        printf("error occurred in select node. not supported class def feature.\n");
	return new(oid,dbl);
    } else {
        return select_node(name,qenv);
    }
}

PROC split2frag(bat[oid,any] nodes, bat[void,oid] frags) : bat[oid,bat] 
{
    var res := new(oid,bat);
    
    var lst_frag := frags.reverse().fetch(frags.count_wrd() - 1);
    var i := wrd(0);
    var j := nodes.count_wrd();
    while( i < j)
    {
    	var frag := find_lower(frags.reverse(), nodes.reverse().fetch(i));
        if (frag < lst_frag)
	{
	    var frag_limit := oid(wrd(frags.fetch(wrd(frag))) -1); #only correct if frag numbering starts at 1
	    var nodes_limit := wrd(find_lower(nodes.mark(0@0), frag_limit));
	    res.insert(frag, nodes.slice(i, nodes_limit));
            i := nodes_limit + 1;
	}
	if (frag = lst_frag)
	{
	    res.insert(frag, nodes.slice(i, j - 1));
            i := j;
	}
    }

    return res;
}

##
# Select all terms with the given value
# 
# Returns a bat [preorder rank,score].
# The score is initalized based on the scorebase environment variable
##
PROC select_term(str name, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    var stemmer := bat("tj_"+ qenv.find(QENV_FTINAME) +"_param").find("stemmer");
    var term    := tj_normalizeTerm( toLower(name), stemmer );
    
    # Select the term positions from the global term dictionary.
    var tids := bat(tj_TermBat(qenv.find(QENV_FTINAME))).uselect(term).mark(0@0).sort().reverse();
    
    var result := indexfetchjoin( tids,
    				  bat("tj_" + qenv.find(QENV_FTINAME) + "_TermIndex"),
    				  bat("tj_" + qenv.find(QENV_FTINAME) + "_Terms") );
    result := result.reverse().sort().project(dbl(qenv.find(QENV_SCOREBASE))); 
    

    return result;
}

##
# Select all terms with the given value, possibly performing stemming on the argument.
#
# This variant of the select_term function is present for compatibility reasons:
# at the moment, stemming is always performed using the same stemmer that was
# used to index the collection.
# 
# Returns a bat [preorder rank,score].
# The score is initalized based on the scorebase environment variable
##
PROC select_term(str name, int stemming, BAT[oid,str] qenv) : bat[oid,dbl]  
{
    return select_term( name,qenv );
}


##
# Select a number of terms by their term-id.
# 
# Returns a bat [preorder rank,score].
# The score is initalized based on the scorebase environment variable
##
PROC select_phrase(bat[void,oid] terms, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    # Select the term positions from the global term dictionary. 
   
    var tid := terms.fetch(0);
    var tmp := indexfetchjoin( new(int,oid).insert(0,tid),
    				  bat("tj_" + qenv.find(QENV_FTINAME) + "_TermIndex"),
    				  bat("tj_" + qenv.find(QENV_FTINAME) + "_Terms") );
    var res := tmp.reverse();
    var j := terms.count_wrd();
    var i := wrd(1); 
    while (i < j)
    {
        tid := terms.fetch(i);
        tmp := indexfetchjoin( new(int,oid).insert(0,tid),
    				  bat("tj_" + qenv.find(QENV_FTINAME) + "_TermIndex"),
    				  bat("tj_" + qenv.find(QENV_FTINAME) + "_Terms") );
        res := res.semijoin(tmp.[int]().[-](i).[oid]().reverse());   
	i :+= 1;
    }	
    
    res := res.sort().project(dbl(qenv.find(QENV_SCOREBASE))); 
    
    return res;
}


################################################################################
# CONTAINMENT
################################################################################


#####################################
# left CONTAINED_BY right:
#
#   +--------------------+
#   |       right        |
#   | +---------------+  |
#   | |      left     |  |
#   | +---------------+  |
#   |                    |
#   +--------------------+
#
# Returns: region from left if it is contained a region in right
#
#####################################

PROC contained_by(bat[oid,dbl] left, bat[oid,dbl] right, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    if ( count_wrd(left) = wrd(0) ) return new(oid,dbl);
    if ( count_wrd(right) = wrd(0) ) return new(oid,dbl);
    
    # Check for the virtual root
    if ( count_wrd(left) = wrd(1) )
       if ( left.reverse().fetch(0) = virtRoot ) 
          return new(oid,dbl);
    if ( count_wrd( right ) = wrd(1) )
       if ( right.reverse().fetch(0) = virtRoot ) 
          return left;
    
    var anc_desc := anc_desc( right, left, qenv );

    # Attach the scores to the resulting nodes again:
    var result;
    if (isnil(left.fetch(0))) {
       result := anc_desc.reverse().kunique().project(dbl(qenv.find(QENV_SCOREBASE)));
    } else {
       result := left.semijoin(anc_desc.reverse());
    }
    
    return result.sort();
}

##
# Returns all regions in the collection that are contained by the argument. 
# Equivalent with a descendant step in XPath.
#
# Returns a bat [preorder rank,score].
# The score is initalized based on the scorebase environment variable
##

PROC contained_by(bat[oid,dbl] region, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    var all_nodes := select_node(qenv);
    var result := contained_by(all_nodes, region, qenv);
    
    return result;
}


#####################################
# left CONTAINING right:
#
#   +--------------------+
#   |       left         |
#   | +---------------+  |
#   | |      right    |  |
#   | +---------------+  |
#   |                    |
#   +--------------------+
#
# Returns: region from left if it contains a region in right
#
#####################################

PROC containing(bat[oid,dbl] left, bat[oid,dbl] right, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    # Check for the virtual root
    if ( count_wrd(left) = wrd(1) )
       if ( left.reverse().fetch(0) = virtRoot ) 
          return right;
    if ( count_wrd( right ) = wrd(1) )
       if ( right.reverse().fetch(0) = virtRoot ) 
          return new(oid,dbl);
    
    var anc_desc := anc_desc( left, right, qenv );
    
    # Attach the scores to the resulting nodes again:
    var result;
    if (isnil(left.fetch(0))) {
       result := anc_desc.project(dbl(qenv.find(QENV_SCOREBASE)));
    } else {
       result := left.semijoin(anc_desc);
    }
    
    return result.sort();
}


################################################################################
# PROBABILISTIC CONTAINMENT
################################################################################

# returns the pre-order positions of the term t 
# in the collection of the documents
PROC _getTermPositions(oid tid, BAT[oid,str] qenv) : bat[void,oid] {
     var cName := qenv.find(QENV_FTINAME);
     var index := bat("tj_" + cName + "_TermIndex");
     var offset1 := wrd(index.fetch(wrd(tid)));
     var offset2 := wrd(index.fetch(wrd(tid) + 1));
     var res := bat("tj_" + cName + "_Terms").slice(offset1, offset2 - 1);
     res := res.seqbase(0@0).chk_order();
     return res;
}

# returns the collection count cCnt(t) of term t
# in the background collection
# (the background collection can be different from collection
# the documents are coming from) 
PROC _getTermColCnt(oid tid, BAT[oid,str] qenv) : int {
     var bg_cName := qenv.find(QENV_FTIBGNAME);
     var index := bat("tj_" + bg_cName + "_TermIndex");
     var offset1 := wrd(index.fetch(wrd(tid)));
     var offset2 := wrd(index.fetch(wrd(tid) + 1));
     return (offset2 - offset1);
}

# returns the collection count cCnt(t) of term t
# in the background collection
# (the background collection can be different from collection
# the documents are coming from) 
PROC _getTermDocCnt(oid tid, BAT[oid,oid] e_pre, BAT[void,int] e_size, BAT[oid,str] qenv) : BAT[oid,int] {
     
        # get term positions in the entire collection
        var t_pre := _getTermPositions(tid, qenv);
	
	# get doc - term relation
        var e_tPre;
        if (nested) {
           e_tPre := treemergejoin_sort(e_pre, e_size, t_pre);
        } else {
           e_tPre := treemergejoin_sort_unnested(e_pre, e_size, t_pre);
        }
	t_pre := nil;
        return e_tPre.reverse().histogram().sort();
}


#             ___          qCnt(t) 
# LM(d|q) =   | |    dLH(t) 
#            t in q           
#
# where qCnt(t) = count of term t in query q
# where dLH(t) = likelihood of term t in doc d
#
# NOTE by Djoerd: The current implementation of LM might retrieve
# documents if one or more terms have zero frequency in background-col
# which should not happen

PROC _score_LM(int q_tCnt, wrd qSize, wrd c_tCnt, wrd cSize, BAT[oid,int] e_tCnt, BAT[void,int] e_size, dbl cLambda) : bat[oid,dbl] {
    var e_tScores := e_tCnt.[dbl]().access(BAT_WRITE);
    e_tScores.left_div(e_size);
    var tmp := e_tScores;
    while (q_tCnt > 1) {
        e_tScores := e_tScores.[*](tmp);
	q_tCnt :-= 1;
    }
    return e_tScores;
}


#              ___                                         qCnt(t)      
# LMs(d|q) =   | |    ( (1-lambda) dLH(t) + lambda cLH(t) ) 
#             t in q           
#
# where qCnt(t) = count of term t in query q
# where dLH(t) = likelihood of term t in doc d
# where cLH(t) = likelihood of term t in (background) collection c
#

PROC _score_LMs(int q_tCnt, wrd qSize, wrd c_tCnt, wrd cSize, BAT[oid,int] e_tCnt, BAT[void,int] e_size, dbl cLambda) : bat[oid,dbl] {
    var tmp1 := cLambda * c_tCnt / dbl(cSize);
    var tmp2 := dbl(1) - cLambda;
    var e_tScores := e_tCnt.[dbl]().access(BAT_WRITE);
    e_tScores.left_div(e_size);
    e_tScores := e_tScores.[*](tmp2);
    e_tScores := e_tScores.[+](tmp1);
    tmp1 := e_tScores;
    while (q_tCnt > 1) {
        e_tScores := e_tScores.[*](tmp1);
	q_tCnt :-= 1;
    }
    return e_tScores;
}

#               __     qCnt(t)       /  (1 - lambda) * dLH(t)       \  
# NLLR(d|q) =   >_     ------- * log |  ----------------------  + 1 |  
#              t in q   qSize        \      lambda * cLH(t)         /  
#
# where qCnt(t) = count of term t in query q
# where qSize = number of terms in query q
# where dLH(t) = likelihood of term t in doc d
# where cLH(t) = likelihood of term t in (background) collection c
#

PROC _score_NLLR(int q_tCnt, wrd qSize, wrd c_tCnt, wrd cSize, BAT[oid,int] e_tCnt, BAT[void,int] e_size, dbl cLambda) : bat[oid,dbl] {
    var collFac := ((dbl(1) - cLambda) / cLambda) * cSize / dbl(c_tCnt);
    var q_tLH := dbl(q_tCnt) / dbl(qSize);
    var e_tScores := e_tCnt.[dbl]().access(BAT_WRITE);
    e_tScores.left_div(e_size);
    e_tScores := e_tScores.[*](collFac);
    e_tScores := e_tScores.[+](dbl(1));
    e_tScores := [log](e_tScores);
    e_tScores := e_tScores.[*](q_tLH);
    return e_tScores;
}

#             __                /  cNdoc  \            (cK1 + 1) tf(t)
# OKAPI(q) =  >_  qCnt(t) * log | ------- | * -------------------------------------
#            t in q             \  DF(t)  /   cK1*((1-cB) + cB*(DL / cAvgDL)) + tf(t)
#
# where cNdoc    = number of elements that is scored
# where cAvgDL   = average element length
# where DL       = element length
# where cIDF(t)  = idf instead of the Robertson/Sparck-Jones weight (variation on idf)
# where tf(t)    = term frequency (number of occurences of term t in element)
# where cK1      = tuning parameter k1
# where cB       = tuning parameter b
#

PROC _score_OKAPI(int q_tCnt, BAT[oid,int] e_tCnt, BAT[void,int] e_size, wrd cNdoc, dbl cAvgDL, dbl cK1, dbl cB) : bat[oid,dbl] {
    
    # cIDF contains Robertson/Sparck-Jones relevance weight
    var cIDF := e_tCnt.count_wrd(); # df
    cIDF  := log((cNdoc + 0.5) / (cIDF + 0.5));

    # cK contains length normalization 
    var cK := e_size.semijoin(e_tCnt); # document lengths
    cK := [/](cK, cAvgDL / cB);
    cK := [+](cK, 1 - cB);
    cK := [*](cK, cK1);
    cK := [+](cK, e_tCnt);
    var tmp := [*](e_tCnt, cK1 + 1);
    tmp := [/](tmp, cK);
    
    var e_tScores := [*](tmp, cIDF * q_tCnt); 
    return e_tScores;
}

@= init_scoring
    var cName := qenv.find(QENV_FTINAME);
    var bg_cName := qenv.find(QENV_FTIBGNAME);
    
    # get term ids and drop all terms with zero frq in background-col and calculate query LM
    var terms := _terms2void_tid( Qterms, bg_cName );
    var qSize := terms.count_wrd();
    var t_qCnt := terms.histogram();
    
    if ( count_wrd(left) = wrd(0) ) return new(oid,dbl);
    if ( qSize = wrd(0) ) { if (returnAllElements) return left; else return new(oid,dbl); }
    
    # init further variables
    var nested := false;
    if (qenv.find(QENV_RECURSIVE_TAGS) = "1") {nested := true;}
    var cSize := bat("tj_" + bg_cName + "_Terms").count_wrd();
    var cLambda := dbl(qenv.find(QENV_C_LAMBDA));
    
    var e_pre;
    var e_size;
    if (isnil(left.fetch(0))) {
       var offset1 := int(left.reverse().fetch(0));
       var offset2 := int(left.reverse().fetch(1));
       e_pre := bat("tj_" + cName + "_Tags").slice(offset1, offset2).tsort();
       e_size := bat("tj_" + cName + "_TagSize").slice(offset1, offset2);
    } else {
       e_pre := bat("tj_" + cName + "_Tags").semijoin(left).tsort();
       e_size := bat("tj_" + cName + "_TagSize");
    }
@

@= end_scoring_addmodel
    var res;
    # score combination with prior scores
    if (isnil(left.fetch(0))) {
        if (returnAllElements) {
            left := e_pre.project(dbl(qenv.find(QENV_SCOREBASE)));
	    res := left_add(left,eScores);
        } else {
            res := eScores;
        }
    } else {
        if (returnAllElements) {
            res := left_add(left,eScores);
        } else {
            res := left_add(eScores,left);
        }
    }
@

@= end_scoring_mulmodel
    var res;
    # score combination with prior scores
    if (returnAllElements) {
        res := eScores;
    } else {
        var unchanged := eScores.uselect(score_base);
        res := eScores.kdiff(unchanged);
    }
    if (not(isnil(left.fetch(0)))) {
        res := [*](left,res);
    }
@mil

PROC p_containing_q_NLLR(bat[oid,dbl] left, bat[void,str] Qterms, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    var t_total := 0;
    t_total :-= time();
  
@:init_scoring@

    var eScores := new(oid,dbl);
    
    # loop over query terms
    t_qCnt@batloop()
    {
        # get collection count of term
        var c_tCnt := _getTermColCnt($h, qenv); 
        # get element count of term
	var e_tCnt := _getTermDocCnt($h, e_pre, e_size, qenv);
	# score elements by this term
        var e_tScores := _score_NLLR($t, qSize, c_tCnt, cSize, e_tCnt, e_size, cLambda);
        e_tCnt := nil;
        
	# aggregate term scores
        eScores := eScores.union_add(e_tScores);
	e_tScores := nil;
    }
    eScores.access(BAT_READ);
    
@:end_scoring_addmodel@

    t_total :+= time();
    if (timing) printf(HASH +" NLLR timing: total: %d\n", t_total);
    return res;
}

PROC p_containing_q_LMs(bat[oid,dbl] left, bat[void,str] Qterms, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    var t_total := 0;
    t_total :-= time();
    
@:init_scoring@

    var eScores := e_pre.project(dbl(1));
    var score_base := dbl(1);

    # loop over query terms
    t_qCnt@batloop()
    {
        # get collection count of term
        var c_tCnt := _getTermColCnt($h, qenv); 
        # get element count of term
	var e_tCnt := _getTermDocCnt($h, e_pre, e_size, qenv);
	# score elements by this term
        var e_tScores := _score_LMs($t, qSize, c_tCnt, cSize, e_tCnt, e_size, cLambda);
        e_tCnt := nil;
        var base := cLambda * c_tCnt / dbl(cSize);
        score_base :*= base;
        e_tScores := e_tScores.union(eScores.kdiff(e_tScores).project(base));

	# aggregate term scores
        eScores := eScores.[*](e_tScores);
	e_tScores := nil;
    }
    eScores.access(BAT_READ);
    
@:end_scoring_mulmodel@

    t_total :+= time();
    if (timing) printf(HASH +" LMs timing: total: %d\n", t_total);
    return res;
}

PROC p_containing_q_LM(bat[oid,dbl] left, bat[void,str] Qterms, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    var t_total := 0;
    t_total :-= time();
    
@:init_scoring@

    var eScores := e_pre.project(dbl(1));
    var score_base := dbl(1);

    # loop over query terms
    t_qCnt@batloop()
    {
        # get collection count of term
        var c_tCnt := _getTermColCnt($h, qenv); 
        # get element count of term
	var e_tCnt := _getTermDocCnt($h, e_pre, e_size, qenv);
	# score elements by this term
        var e_tScores := _score_LM($t, qSize, c_tCnt, cSize, e_tCnt, e_size, cLambda);
        e_tCnt := nil;
        var base := dbl(0);
        score_base :*= base;
        e_tScores := e_tScores.union(eScores.kdiff(e_tScores).project(base));

	# aggregate term scores
        eScores := eScores.[*](e_tScores);
	e_tScores := nil;
    }
    eScores.access(BAT_READ);
    
@:end_scoring_mulmodel@

    t_total :+= time();
    if (timing) printf(HASH +" LM timing: total: %d\n", t_total);
    return res;
}

PROC p_containing_q_OKAPI(bat[oid,dbl] left, bat[void,str] Qterms, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    var t_total := 0;
    t_total :-= time();

@:init_scoring@

    var cNdoc := e_pre.count_wrd();
    var cAvgDL := e_size.semijoin(e_pre).[dbl]().avg();
    var cK1 := dbl(qenv.find(QENV_OKAPI_K1));
    var cB := dbl(qenv.find(QENV_OKAPI_B));
    var eScores := new(oid,dbl);
    
    # loop over query terms
    t_qCnt@batloop()
    {
        # get element count of term
	var e_tCnt := _getTermDocCnt($h, e_pre, e_size, qenv);
	# score elements by this term
        var e_tScores := _score_OKAPI($t, e_tCnt, e_size, cNdoc, cAvgDL, cK1, cB);
        e_tCnt := nil;
        
	# aggregate term scores
        eScores := eScores.union_add(e_tScores);
	e_tScores := nil;
    }
    eScores.access(BAT_READ);
    
@:end_scoring_addmodel@

    t_total :+= time();
    if (timing) printf(HASH +" OKAPI timing: total: %d\n", t_total);
    return res;
}


# Pseudo Relevance Feedback algorithm Implemented by 
# Stefan Teijgeler and Jan-Willem Beusink (added by Djoerd.)
#
PROC p_containing_q_PRF(bat[oid,dbl] left, bat[void,str] Qterms, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    var t_total := 0;
    t_total :-= time();


    var qResults := left.p_containing_q_NLLR(Qterms, qenv);

    qResults := tj_nid2pre(qResults, qenv);
    qResults := qResults.tsort_rev();

    #Initialize variables
    var size, offset1, offset2, words, temp, score, tmp1, tmp2, test1, test2;
    var test_terms := new(int,oid);
    var new_terms := new(oid,dbl);
    var prfLambda := 0.0;
    var stopWoordLambda := 0.65;
    var dSize := dbl(0);                                                        # Sum of relevant document size
    var cSize := bat("tj_" + qenv.find(QENV_FTIBGNAME) + "_Terms").count_wrd(); # Total collection size
    var qSize := Qterms.count_wrd();                                                # Query size

    # Get new term candidates
    qResults.slice(0,9)@batloop()
    {
            size := bat("tj_" + qenv.find(QENV_FTINAME) +"_size").find($h);
            dSize :+= size;
            offset1 := int($h);
            offset2 := offset1+size-1;
            words := bat("tj_" + qenv.find(QENV_FTINAME) +"_size").slice(offset1, offset2);
            words := words.select(0,0);
            temp := words.reverse().join(bat("tj_" + qenv.find(QENV_FTINAME) +"_tid"));
            test_terms.insert(temp);
    }

    # Calculate the score to the new terms, and select the top 10
    test_terms.histogram()@batloop()
    {

            # Count of term in total collection
            var c_tCnt := _getTermColCnt($h, qenv);

            #test1 := bat("tj_" + qenv.find(QENV_FTINAME) +"_termdict").find($h);
            test2 := (c_tCnt / dbl(cSize)) /  ($t / dSize);

            if ( test2 < dbl(stopWoordLambda) ) {

                    tmp1 := prfLambda * c_tCnt / dbl(cSize);
                    tmp2 := dbl(1) - prfLambda;

                    # Calculate score: ((1-prfLambda) * likeliness of t in d) + (prfLambda * likeliness of t in c)
                    score := $t / dSize;
                    score := score * tmp2;
                    score := score + tmp1;
            } else {
                    score := dbl(0);
            }

            new_terms.insert($h, score);
    }

    new_terms := new_terms.tsort_rev();
    #bat(new_terms).reverse().join(bat("tj_" + qenv.find(QENV_FTINAME) +"_termdict")).reverse().print();

    #Qterms := new(void,str).seqbase(oid(0));

    new_terms.slice(0,19)@batloop()
    {
            Qterms.append(find(bat("tj_" + qenv.find(QENV_FTINAME) +"_termdict"), $h));
    }

    qResults := left.p_containing_q_NLLR(Qterms, qenv);

    t_total :+= time();
    if (timing) printf(HASH +" PRF timing: total: %d\n", t_total);
    return qResults;
}


################################################################################
# PROBABILISTIC CONTAINMENT
################################################################################

# down propagation 
@:p_contained_by(max)@
@:p_contained_by(sum)@

@= p_contained_by
PROC p_contained_by_@1(bat[oid,dbl] region, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    var candidates := select_node(qenv);
    return p_contained_by_@1(candidates, region, qenv);    
}

PROC p_contained_by_@1(bat[oid,dbl] left, bat[oid,dbl] right, BAT[oid,str] qenv) : bat[oid,dbl]  
{
    var t := 0 - time();
    
    if ( count_wrd(left) = wrd(0) ) return new(oid,dbl);
    if ( count_wrd(right) = wrd(0) ) return new(oid,dbl);

    var a_d := anc_desc(right, left, qenv);
    var tmp := a_d.reverse().kunique();

    if (isnil(right.fetch(0))) { printf(" error in p_contained_by_@1 \n");}
    # if "right" is unnested, aggregation is not necessary"
    var reg_score;
    if (qenv.find(QENV_RECURSIVE_TAGS) = "0") {
    	reg_score := a_d.reverse().join(right);
    } else {
        reg_score := {@1}(right, a_d, tmp);
    }
    
    reg_score := reg_score.sort();
   
    if (not(isnil(left.fetch(0)))) {
        if (int(qenv.find(QENV_SCOREBASE)) = 0)
            reg_score := [+](left, reg_score);
        if (int(qenv.find(QENV_SCOREBASE)) = 1)
            reg_score := [*](left, reg_score);
    }

    t :+= time();
    if (timing) printf(HASH +" contained_by_@1 timing: %d\n", t);
    return reg_score.sort();
}
@mil

# up propagation 
@:p_containing(max)@
@:p_containing(sum)@

@= p_containing
PROC p_containing_@1(bat[oid,dbl] left, bat[oid,dbl] right, BAT[oid,str] qenv) : bat[oid,dbl] 
{
    var t := 0 - time();
    
    if ( count_wrd(left) = wrd(0) ) return new(oid,dbl);
    if ( count_wrd(right) = wrd(0) ) return new(oid,dbl);

    var a_d := anc_desc( left, right, qenv );
   
    if (isnil(right.fetch(0))) { printf(" error in p_containing_@1 \n");}
    var tmp := a_d.kunique();
    var reg_score := {@1}(right, a_d.reverse(), tmp); 
    
    reg_score := reg_score.sort();

    if (not(isnil(left.fetch(0)))) {
        if (int(qenv.find(QENV_SCOREBASE)) = 0)
            reg_score := [+](left, reg_score);
        if (int(qenv.find(QENV_SCOREBASE)) = 1)
            reg_score := [*](left, reg_score);
    }

    t :+= time();
    if (timing) printf(HASH +" containing_@1 timing: %d\n", t);
    return reg_score.sort();
}
@mil

################################################################################
# SET OPERATORS
################################################################################

### UNION
PROC set_union(bat left, bat right, BAT[oid,str] qenv) : bat 
{
    if ( count_wrd(left) = wrd(0) ) return right;
    if ( count_wrd(right) = wrd(0) ) return left;

    var cName := qenv.find(QENV_FTINAME);
    
    if (isnil(left.fetch(0))) {
       var offset1 := wrd(left.reverse().fetch(0));
       var offset2 := wrd(left.reverse().fetch(1));
       left := bat("tj_" + cName + "_Tags").slice(offset1, offset2).project( dbl(qenv.find(QENV_SCOREBASE)));
    }
    if (isnil(right.fetch(0))) {
       var offset1 := wrd(right.reverse().fetch(0));
       var offset2 := wrd(right.reverse().fetch(1));
       right := bat("tj_" + cName + "_Tags").slice(offset1, offset2).project( dbl(qenv.find(QENV_SCOREBASE)));
    }

    # set recurse tag flag to TRUE since the union might result in a nested set
    modify_qenv(qenv,QENV_RECURSIVE_TAGS,"1");

    return left.kunion(right).sort();
}

### INTERSECTION
PROC set_intersect(bat left, bat right, BAT[oid,str] qenv) : bat  
{
    if ( count_wrd(left) = wrd(0) ) return right;
    if ( count_wrd(right) = wrd(0) ) return left;

    var cName := qenv.find(QENV_FTINAME);
    
    if (isnil(left.fetch(0))) {
       var offset1 := wrd(left.reverse().fetch(0));
       var offset2 := wrd(left.reverse().fetch(1));
       left := bat("tj_" + cName + "_Tags").slice(offset1, offset2).project( dbl(qenv.find(QENV_SCOREBASE)));
    }
    if (isnil(right.fetch(0))) {
       var offset1 := wrd(right.reverse().fetch(0));
       var offset2 := wrd(right.reverse().fetch(1));
       right := bat("tj_" + cName + "_Tags").slice(offset1, offset2).project( dbl(qenv.find(QENV_SCOREBASE)));
    }

    return left.kintersect(right).sort();
}


################################################################################
# SCALING
################################################################################

PROC scale(bat region, flt importance) : bat  
{

	var res_reg := new(oid,dbl,ENTITY_NUM);
	res_reg := [*](dbl(importance),region);
	return res_reg;

}


################################################################################
# PROBABILISTIC SET OPERATORS
################################################################################

# Compute symmetric difference between two sets: all element that are not in the intersection
PROC ksymmdiff(bat left, bat right) : bat  
{
    var onlyleft  := left.kdiff(right);
    var onlyright := right.kdiff(left);
    return onlyleft.kunion(onlyright);
}

PROC or_sum(bat left, bat right) : bat 
{
    return left.union_add(right);
}

PROC or_max(bat left, bat right) : bat 
{

    var inters := [max](left,right);

    return inters.kunion(ksymmdiff(left,right)).sort();

}

PROC or_prob(bat left, bat right) : bat 
{

	var inters := [-](dbl(1),[*]([-](dbl(1),left),[-](dbl(1),right)));

    return inters.kunion(ksymmdiff(left,right)).sort();

}

PROC or_exp(bat left, bat right, int A) : bat  
{

	var paramA := dbl(A-1);
	var eq_regions := new(oid,dbl,ENTITY_NUM);

	var res_reg := new(oid,dbl,ENTITY_NUM);

	eq_regions := [*](paramA, [+](left.mirror().join(right), right.mirror().join(left)));

	res_reg := {sum}(eq_regions.sunion(left).sunion(right));

	return res_reg;

}

PROC or_min(bat left, bat right) : bat 
{

    var inters := [min](left,right);

    return inters.kunion(ksymmdiff(left,right)).sort();

}

PROC or_prod(bat left, bat right) : bat 
{
    return left.union_mul(right);
}

PROC and_prod(bat left, bat right) : bat 
{

	return [*](left,right);

}

PROC and_min(bat left, bat right) : bat 
{

	return [min](left,right);

}

PROC and_sum(bat left, bat right) : bat 
{

	return [+](left,right);

}

PROC and_exp(bat left, bat right, int A) : bat 
{

	var paramA := dbl(A-1);
	var eq_regions := new(oid,dbl,ENTITY_NUM);

	var res_reg := new(oid,dbl,ENTITY_NUM);

	eq_regions := [*](paramA, [+](left.mirror().join(right), right.mirror().join(left)));

	res_reg := {sum}(eq_regions.sunion(left).sunion(right));

	return res_reg;

}

PROC and_max(bat left, bat right) : bat 
{
	return [max](left,right);
}

PROC and_prob(bat left, bat right) : bat 
{
	return [-](dbl(1),[*]([-](dbl(1),left),[-](dbl(1),right)));
}


################################################################################
# PRIOR
################################################################################

PROC prior_ls(BAT[oid,dbl] region, BAT[oid,str] qenv) : bat  
{
    var cName := qenv.find(QENV_FTINAME);
    var tag_size := bat("tj_" + cName + "_TagSize");
    return [*](region, tag_size);
}
#ADDHELP("prior_ls", "vojkan", "March 16, 2005",
#"Adds element prior based on element length to the region score.",
#"TIJAH");

################################################################################
# OVERLAP REMOVAL
################################################################################

PROC rm_overlap(BAT ctx, BAT[oid,str] qenv) : bat  
{
 if ( count_wrd( ctx ) = wrd(0) ) {
   return ctx;
 }
 else {
   if (qenv.find(QENV_RECURSIVE_TAGS) = "0") {return ctx;}

   var a_d := anc_desc(ctx, ctx, qenv);
   var x_a := a_d.hmark(0@0);
   var x_d := a_d.tmark(0@0);
   var x_ascore := x_a.join(ctx);
   var x_dscore := x_d.join(ctx);

   # deselect all ancestors having a higher scored descendant
   var tmp := [<](x_ascore, x_dscore).uselect(true).mirror().join(x_a);
   var res1 := ctx.kdiff(tmp.reverse());

   # deselect all descendants having a higher scored ancestor
   tmp := x_a.kdiff(tmp).semijoin(res1).mirror().join(x_d); # select descendants having a higher scored ancestor in res1
   var res := res1.kdiff(tmp.reverse());

   return res;
 }
}
#ADDHELP("rm_overlap","henning", "Oktober, 2008",
#"Removes overlapping elements from result list.",
#"TIJAH");


################################################################################
# ORDER
################################################################################

PROC order_regions(bat region) : bat 
{

	region := region.reverse().sort_rev().reverse();

	return region;

}
#ADDHELP("order_regions", "vojkan", "March 29, 2005",
#"Order regions in descending order based on their score values.",
#"TIJAH");

##########################################
# Collection Management Functions
#
##########################################

PROC _tj_chk_modified_fragments(str ftiName, BAT[str,bat] collBat) : BAT[void,str] 
{
	var offset := oid(int(_tj_get_parameter(collBat, "_last_finalizedPre")) + 1);
        var fragments := collBat.find("_fragments");
	var frag_offset := wrd(find_lower(fragments.reverse(), offset));
	var frag_last := fragments.count_wrd();
	
	var mod_frags := new(void, str).seqbase(0@0);
	while (frag_offset <= frag_last)
	{
		mod_frags.append("tj_" + ftiName + "_tid");
		mod_frags.append("tj_" + ftiName + "_size");
		frag_offset :+= 1;
	}
	
	return mod_frags;
}

PROC _buildIRindex(str ftiName, BAT[str,bat] collBat) : void 
{
    if ( verbose ) tj_verbose(HASH +"TJ:_buildIRindex(\"%s\") called.\n",ftiName);
	var offset := oid(lng(_tj_get_parameter(collBat, "_last_finalizedPre")) + 1);
        var fragments := collBat.find("fragments");
	var frag_offset := wrd(find_lower(fragments.reverse(), offset));
	#var frag_last := fragments.count_wrd();
	
	var pre_tid := bat("tj_" + ftiName + "_tid");
	var pre_size := bat("tj_" + ftiName + "_size");
        var tids := pre_tid.slice(lng(offset) - lng(pre_tid.seqbase()), lng(pre_tid.count_wrd() - 1));
	var sizes := pre_size.slice(lng(offset) - lng(pre_size.seqbase()), lng(pre_size.count_wrd() - 1));
       
    	var replaceBats := collBat.find("replaceBats");
        var submitBats := collBat.find("submitBats");
        collBat.find("termdict").access(BAT_WRITE);

	# incremental index merge
	if (isnil(CATCH(bat("tj_" + ftiName + "_TermIndex").count_wrd()))) 
        {
		# handle elements 
	        var elements := tids.semijoin(bat("tj_" + ftiName + "_pfpre"));
                var tmp := elements.reverse().ssort();
		var tmpsize := tmp.leftfetchjoin(sizes);
                var i := mergeindex2(tmp, tmpsize,
		                 collBat.find("_tagIndex"),
                                 collBat.find("_tags"),
                                 collBat.find("_tagSize"),
                                 collBat.find("tagdict").count_wrd() + 1);
                collBat.replace("_tagIndex", i.fetch(0).access(BAT_READ).mmap(1));
                collBat.replace("_tags", i.fetch(1).access(BAT_READ).mmap(1));
                collBat.replace("_tagSize", i.fetch(2).access(BAT_READ).mmap(1));
	        i := nil;
		tmp := nil;
		tmpsize := nil;
		replaceBats.insert("_tagIndex", "tj_" + ftiName + "_TagIndex");
                replaceBats.insert("_tags", "tj_" + ftiName + "_Tags");
                replaceBats.insert("_tagSize", "tj_" + ftiName + "_TagSize");
		submitBats.append("tj_" + ftiName + "_TagIndex");
		submitBats.append("tj_" + ftiName + "_Tags");
		submitBats.append("tj_" + ftiName + "_TagSize");
		
                # handle terms
                tmp := tids.kdiff(elements);
                elements := nil;
                tmp := tmp.reverse().ssort();
		var tf := collBat.find("termfreq");
                var termfreq := {count}(tmp, collBat.find("termdict"), false);
                tf [:+=] termfreq.slice(0,tf.count() - 1);
		tf.append(termfreq.slice(tf.count(), termfreq.count() - 1));
		i := mergeindex(tmp, collBat.find("_termIndex"),
                                         collBat.find("_terms"),
                                         collBat.find("termdict").count_wrd() + 1);       
                collBat.replace("_termIndex", i.fetch(0).access(BAT_READ).mmap(1));
                collBat.replace("_terms", i.fetch(1).access(BAT_READ).mmap(1));
	        i := nil;
		tmp := nil;
		replaceBats.insert("_termIndex", "tj_" + ftiName + "_TermIndex");
                replaceBats.insert("_terms", "tj_" + ftiName + "_Terms");
		submitBats.append("tj_" + ftiName + "_TermIndex");
		submitBats.append("tj_" + ftiName + "_Terms");
		submitBats.append(tf.bbpname());
        }
        else # create new index
        {       
		# handle elements 
	        var elements := tids.semijoin(bat("tj_" + ftiName + "_pfpre"));
                var tmp := elements.reverse().ssort();
	        var tagindex := tmp.hmark(1@0).offsetindex(bat(_tj_TagBat(ftiName)).count_wrd() + 1);
	        var tags := tmp.tmark(1@0);
	        tmp := nil;
	        # create _Tags and _Tagindex here
	        tagindex.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftiName + "_TagIndex");
	        tags.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftiName + "_Tags");
	        tagindex := nil;
		var tagsize := tags.leftfetchjoin(sizes);
		tags := nil;
	        tagsize.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftiName + "_TagSize");
		tagsize := nil;
		submitBats.append("tj_" + ftiName + "_TagIndex");
		submitBats.append("tj_" + ftiName + "_Tags");
		submitBats.append("tj_" + ftiName + "_TagSize");

		# handle terms
                tmp := tids.kdiff(elements);
                elements := nil;
                tmp := tmp.reverse().ssort();
		var tf := collBat.find("termfreq");
                var termfreq := {count}(tmp, collBat.find("termdict"), false);
                tf [:+=] termfreq.slice(0,tf.count() - 1);
		tf.append(termfreq.slice(tf.count(), termfreq.count() - 1));
	        var termindex := tmp.hmark(0@0).offsetindex(bat(_tj_TermBat(ftiName)).count_wrd() + 1);
	        var terms := tmp.tmark(0@0);
	        tmp := nil;
	        # create _TermIndex and _Terms here
	        termindex.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftiName + "_TermIndex");
	        terms.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftiName + "_Terms");
	        termindex := nil;
		terms := nil;
		submitBats.append("tj_" + ftiName + "_TermIndex");
		submitBats.append("tj_" + ftiName + "_Terms");
		submitBats.append(tf.bbpname());
        }
        
        # always create concept table from scratch
	var c_cid := bat("tj_" + ftiName + "_concept_tid");
	var c_pre := bat("tj_" + ftiName + "_concept_elem");
	var c_scr := bat("tj_" + ftiName + "_concept_score");
        var tmp := c_pre.tsort().mirror().leftfetchjoin(c_cid).reverse().ssort();
        c_cid := tmp.leftfetchjoin(c_cid).tmark(0@0).chk_order();
        var concepts := tmp.leftfetchjoin(c_pre).tmark(0@0);
        var conceptscore := tmp.leftfetchjoin(c_scr).tmark(0@0);
        tmp := nil;
	var conceptindex := offsetindex(c_cid, bat("tj_" + ftiName + "_conceptdict").count_wrd() + 1);
	# create _ConceptIndex and _Concepts here
	conceptindex.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftiName + "_ConceptIndex");
	concepts.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftiName + "_Concepts");
	conceptscore.persists(true).access(BAT_READ).mmap(1).bbpname("tj_" + ftiName + "_ConceptScore");
	conceptindex := nil;
        concepts := nil;
	conceptscore := nil;
	submitBats.append("tj_" + ftiName + "_ConceptIndex");
	submitBats.append("tj_" + ftiName + "_Concepts");
	submitBats.append("tj_" + ftiName + "_ConceptScore");
        collBat.find("termdict").access(BAT_READ);
    if ( verbose ) tj_verbose(HASH +"TJ:_buildIRindex(\"%s\") finished.\n",ftiName);
}

######################################
# PF interface functions
#
######################################

@h

#define ENABLE_TDEBUG

#ifdef ENABLE_TDEBUG
extern int pftijah_debug;
#define SET_TDEBUG(V) pftijah_debug = V
#define TDEBUG(V) (pftijah_debug && (((V<=pftijah_debug)&&(pftijah_debug<100)) || ((V==pftijah_debug)&&(pftijah_debug>=100))) )
#else
#define SET_TDEBUG(V)
#define TDEBUG(V) 0
#endif

#define TJ_TIMINGS 777

@c
#include <pf_config.h>

#include <monet.h>
#include <gdk.h>
#include <gdk_scanselect.h>	/* for type-specific HT_bunfastins_nocheck_noinc(), until they're moved to gdk.mx */
#include <math.h>

#include <pathfinder.h>

#include "pftijah.h"
#include "pftijah_util.h"

#include "termdb.h"

#ifdef ENABLE_TDEBUG
/* 
 * The main pftijah variable, settable from the command line by the
 * <TijahOptions debug=number ..... from the query env.
 * Current strategy is not to reset the debug variable after the query
 * finished and to make it a global for ease of use.
 * The number has three possiblilities:
 * 0             : no debug
 * 1   - 99      : leveled debug
 * 100 - INT_MAX : debug a specific event 
 *
 * usage: if (TDEBUG ) expression
 */
int pftijah_debug = 0;
#endif

int executeMIL(char* str) {
    return monet_exec(str);
}

/*
 * the CMDtj_log is created to be able to print in very difficult IO areas
 */

static char* tj_log_fileName = NULL; /* set by [CMD]tj_setlog(filename) */

int CMDtj_setlog(str filename) {
	FILE* f;
	
	if ( (f = fopen(filename,"w")) ) {
	    fprintf(f,"# Start TIJAH logger:\n");
	    fclose(f);
	    tj_log_fileName = (char*)GDKstrdup(filename);
	}
	return GDK_SUCCEED;
}

int CMDtj_log(str format, int* i) {
	FILE* f;
	
	if ( tj_log_fileName != NULL ) {
	    if ( (f = fopen(tj_log_fileName,"a")) ) {
	        fprintf(f,(const char*)format,*i);
	        fclose(f);
	    }
	}
	return GDK_SUCCEED;
}

int CMDtj_chk_dict_hash(BAT* b_tag, BAT* b_term)
{
	if ( b_tag->T->hash == NULL ) {
	     // stream_printf(GDKout,"C[]: ADD HASHTABLE TO TAG DICTIONARY\n");
#ifdef TJ_TRACE
	     if ( TJ_TRACE ) stream_printf(GDKout,"C[]: CREATE NEW HASHTABLE ON TAG DICTIONARY\n");
#endif
	     if ( !BAThash(BATmirror(b_tag),0) ) {
                 GDKerror("CMDtj_chk_dict_hash: adding hashtable to Tag fails\n");
	         return GDK_FAIL;
	     }
	}
	if ( b_term->T->hash == NULL ) {
	     // stream_printf(GDKout,"C[]: ADD HASHTABLE TO TERM DICTIONARY\n");
#ifdef TJ_TRACE
	     if ( TJ_TRACE ) stream_printf(GDKout,"C[]: CREATE NEW HASHTABLE ON TERM DICTIONARY\n");
#endif
	     if ( !BAThash(BATmirror(b_term),0) ) {
                 GDKerror("CMDtj_chk_dict_hash: adding hashtable to Term fails\n");
	         return GDK_FAIL;
	     }
	}
	return GDK_SUCCEED;
}

extern char* tijahParse(BAT* optbat, char* startNodes_name, char** errBUFF);

extern char* tjc_new_parse(char* query, BAT* optbat, BAT* rtagbat, int use_sn, char** errBUFF);

int CMDcheckHashTable(BAT* b) {
    if ( b->H->hash == NULL ) {
         if ( !BAThash(b,0) ) {
                 stream_printf(GDKout,"#termdb:tdb_checkHashTable: fail to creat hashtable on [oid,str] bat.\n");
             return GDK_FAIL;
         } else {
            if(0) stream_printf(GDKout,"#termdb:tdb_checkHashTable(): created hashtable on [oid,str] bat.\n");
	}
    }
    return GDK_SUCCEED;
}

int CMDtijah_query(BAT* optbat, BAT *rtagbat, bit* use_startnodes) {
	char* err;
	char* mil;
	int use_sn;

        int parser_timing = 0;
	lng time_start = GDKusec();

	if (TDEBUG(1)) stream_printf(GDKout,"# CMDtijah_query: start.\n");

	use_sn = 0;
        if (*use_startnodes) use_sn = 1;

	if ( !optbat ) {
            GDKerror("CMDtijah_query: missing option bat.\n");
	    return GDK_FAIL;
	}
	if (TDEBUG(2)) stream_printf(GDKout,"# CMDtijah_query: call tijahParse.\n");

        int newversion = 1;
        BUN bun;
        if ( (bun = BUNfnd(optbat,"newversion")) != BUN_NONE ) {
            BATiter bi = bat_iterator(optbat);
            str val = (str)BUNtail(bi,bun);
	    if (strcmp(val,"true")==0)
	        newversion = 1;
	    else if (strcmp(val,"false")==0)
	        newversion = 0;
        }
	str query_text = NULL;

        if ( (bun = BUNfnd(optbat,"_query")) != BUN_NONE ) {
            BATiter bi = bat_iterator(optbat);
            query_text = (str)BUNtail(bi,bun);
        } else
	    stream_printf(GDKerr,"Error: cannot find \"_query\" tag.\n");


	lng time_parse_start = GDKusec();
	if ( newversion ) {
	    if ( !(mil=tjc_new_parse(query_text,optbat,rtagbat,use_sn,&err)) ) {
                GDKerror("CMDtijah_query: %s.\n", err);
	        return GDK_FAIL;
	    }
	} else {
	    if ( !(mil=tijahParse(optbat,"nexi_sn_xfer",&err)) ) {
                GDKerror("CMDtijah_query: %s.\n", err);
	        return GDK_FAIL;
	    }
	}
	if (TDEBUG(2)) stream_printf(GDKout,"# CMDtijah_query: finish tijahParse.\n");
	if (TDEBUG(2)) stream_printf(GDKout,"# CMDtijah_query: start MIL script.\n");
	if (TDEBUG(9)) {
		stream_printf(GDKout,"# CMDtijah_query: generated MIL script:\n");
		stream_printf(GDKout,"%s",mil);
		stream_printf(GDKout,"# CMDtijah_query: end of MIL script:\n");
	}
	if (TDEBUG(2)) stream_printf(GDKout,"# CMDtijah_query: start executing MIL script.\n");
	lng time_mil_start = GDKusec();
        if ( executeMIL(mil)<0 ) {
            GDKerror("CMDtijah_query: execute MIL failed.\n");
	    return GDK_FAIL;
	}
	if ( newversion )
		GDKfree(mil);
	if (TDEBUG(2)) stream_printf(GDKout,"# CMDtijah_query: finish MIL script.\n");
	lng time_end = GDKusec();

	if (TDEBUG(1)) stream_printf(GDKout,"# CMDtijah_query: finish.\n");

	if ( parser_timing ) {
		long time_total = (time_end - time_start);
		long time_parse = (time_mil_start - time_parse_start);
		long time_mil   = (time_end - time_mil_start);
	        stream_printf(GDKout,"#! Tijah query timing: [total/parse/mil] = [ " "%ld" "us/" "%ld"  "us/" "%ld" "us]\n",time_total,time_parse,time_mil);
	}
        return GDK_SUCCEED;
}

char* tijah_tokenize_string(char* buf, int len, char* outbuf);
BAT* tokenize2bat(char* buf);

int CMDtijah_tokenize (str* res, str arg)
{
	int sz    = strlen(arg);
	char* buf = GDKmalloc(sz + 1);

	if (!buf) {
            GDKerror("CMDtijah_tokenize: GDKmalloc() failed.\n");
	    return GDK_FAIL;
	}

	buf[0] = 0;
	*res = tijah_tokenize_string(arg,sz,buf);

	return GDK_SUCCEED;
}

int CMDtijah_tokenize2bat (BAT** res, str arg)
{
	if ( !(*res = tokenize2bat(arg)))
	    return GDK_FAIL;
	
	return GDK_SUCCEED;
}


/**
 * In-place synchronized oid computation experiment by Henning and Jan
 *
 */

#define FIND_OID(FOID,BBAT,BPTR,BTAIL) \
        /* use peter's poor mans binary search here */ \
        while (BPTR+1048576 < BTAIL && (*(oid*)BUNhead(BBAT,BPTR+1048576)) < FOID) \
            BPTR += 1048576; \
        while (BPTR+32768 < BTAIL && (*(oid*)BUNhead(BBAT,BPTR+32768)) < FOID) \
            BPTR += 32768; \
        while (BPTR+1024 < BTAIL && (*(oid*)BUNhead(BBAT,BPTR+1024)) < FOID) \
            BPTR += 1024; \
        while (BPTR+32 < BTAIL && (*(oid*)BUNhead(BBAT,BPTR+32)) < FOID) \
            BPTR += 32; \
        do { \
                BPTR++; \
        } while ( (BPTR < BTAIL) && ((*(oid*)BUNhead(BBAT,BPTR))<FOID) );
 
#define INPLACE_OID_CALC_HEADER \
        BATiter li = bat_iterator(l);   \
        BATiter ri = bat_iterator(r);   \
        if ( !bat_oid_sort_chck(l) || !bat_oid_sort_chck(r) ) \
            return  GDK_FAIL; \
        *res = BATsetaccess(l,BAT_WRITE); \
        BUN lp = BUNfirst(l), ll = BUNlast(l); \
        BUN rp = BUNfirst(r), rl = BUNlast(r); \
        while ( (lp < ll) && (rp < rl) ) { \
                oid lv = *(oid*)BUNhead(li,lp); \
                oid rv = *(oid*)BUNhead(ri,rp); \
                if ( lv == rv ) { \
                    dbl* dres = (dbl*)Tloc(l,lp);

#define INPLACE_OID_CALC_FOOTER \
                    lp++; rp++; \
                } else if ( lv < rv ) { \
                    FIND_OID(rv,li,lp,ll); \
                } else /* lv > rv */ { \
                    FIND_OID(lv,ri,rp,rl); \
                } \
        } \
        BBPfix(BBPcacheid(*res)); \
        (*res)->batDirty = TRUE; \
        (*res)->tsorted = FALSE; \
        return GDK_SUCCEED;

static int bat_oid_sort_chck(BAT* b) {
	/* incomplete, the head should also be key */
	if ( !b->hsorted ) {
	    GDKerror("bat_oid_sort_chck: BAT should be head sorted.\n");
	    return 0;
	}
	if (BAThtype(b) != TYPE_oid ) {
	    GDKerror("bat_oid_sort_chck: BAT shouled have oid head type.\n");
	    return 0;
	}
	return 1;
}

int CMDleft_add_dbl(BAT** res, BAT*l, BAT*r) {
        INPLACE_OID_CALC_HEADER;
        *dres += *(dbl*)Tloc(r,rp);
        INPLACE_OID_CALC_FOOTER;
}

int CMDleft_sub_dbl(BAT** res, BAT*l, BAT*r) {
        INPLACE_OID_CALC_HEADER;
	*dres -= *(dbl*)Tloc(r,rp);
        INPLACE_OID_CALC_FOOTER;
}

int CMDleft_mul_dbl(BAT** res, BAT*l, BAT*r) {
        INPLACE_OID_CALC_HEADER;
	*dres *= *(dbl*)Tloc(r,rp);
        INPLACE_OID_CALC_FOOTER;
}

int CMDleft_div_dbl(BAT** res, BAT*l, BAT*r) {
        INPLACE_OID_CALC_HEADER;
	*dres /= *(dbl*)Tloc(r,rp);
        INPLACE_OID_CALC_FOOTER;
}

int CMDleft_div_dbl_int(BAT** res, BAT*l, BAT*r) {
        INPLACE_OID_CALC_HEADER;
	*dres = (dbl)(*dres / *(int*)Tloc(r,rp));
        INPLACE_OID_CALC_FOOTER;
}

int CMDleft_log_dbl(BAT** res, BAT*l) {
	if ( !bat_oid_sort_chck(l) )
	    return  GDK_FAIL;
	/* make the left/res bat writable */
	*res = BATsetaccess(l,BAT_WRITE);
	(*res)->batDirty = TRUE;
 
	dbl *lp = (dbl*)Tloc(l, BUNfirst(l)), *lq = (dbl*)Tloc(l, BUNlast(l)); 

	for (; lp < lq; lp++ ) {
		*lp = log(*lp);
	}
	/* BBPfix(BBPcacheid(*res)); ERROR, MEMORY LEAK */
	(*res)->tsorted = FALSE;
	return GDK_SUCCEED;
}

/*
 *
 * And now the union variant for Henning
 *
 */

#define UNION_FIND_OID(FOID,BBAT,BPTR,BTAIL,RESBAT) \
        do { \
		if (!BUNins(RESBAT,(oid*)BUNhead(BBAT,BPTR),(dbl*)BUNtail(BBAT,BPTR), FALSE) ) \
		    return GDK_FAIL; \
                BPTR++; \
        } while ( (BPTR < BTAIL) && ((*(oid*)BUNhead(BBAT,BPTR))<FOID) );

#define UNION_OID_CALC_HEADER \
        BATiter li = bat_iterator(l);   \
        BATiter ri = bat_iterator(r);   \
        if ( !bat_oid_sort_chck(l) || !bat_oid_sort_chck(r) ) \
            return  GDK_FAIL; \
        *res = BATnew(TYPE_oid,TYPE_dbl,0); \
        BUN lp = BUNfirst(l), ll = BUNlast(l); \
        BUN rp = BUNfirst(r), rl = BUNlast(r); \
        while ( (lp < ll) || (rp < rl) ) { \
		oid lv, rv; \
                lv = (lp < ll) ? *(oid*)BUNhead(li,lp) : oid_nil; \
                rv = (rp < rl) ? *(oid*)BUNhead(ri,rp) : oid_nil; \
                if ( lv == rv ) { \
                    dbl* dres = (dbl*)Tloc(l,lp); \
		    dbl  newdbl;

#define UNION_OID_CALC_FOOTER \
		    if ( !BUNins(*res, &lv, &newdbl, FALSE) ) \
		        return GDK_FAIL; \
                    lp++; rp++; \
                } else if ( (rv==oid_nil) || (lv < rv) ) { \
                    UNION_FIND_OID(rv,li,lp,ll,*res); \
                } else /* (lv==oid_nil) || (lv > rv) */ { \
                    UNION_FIND_OID(lv,ri,rp,rl,*res); \
                } \
        } \
        /* BBPfix(BBPcacheid(*res)); ERROR MEMORY LEAK */ \
        (*res)->batDirty = TRUE; \
        (*res)->tsorted = FALSE; \
        return GDK_SUCCEED;

int CMDunion_add_dbl(BAT** res, BAT*l, BAT*r) {
        UNION_OID_CALC_HEADER;
        newdbl = *dres + *(dbl*)Tloc(r,rp);
        UNION_OID_CALC_FOOTER;
}

int CMDunion_sub_dbl(BAT** res, BAT*l, BAT*r) {
        UNION_OID_CALC_HEADER;
        newdbl = *dres - *(dbl*)Tloc(r,rp);
        UNION_OID_CALC_FOOTER;
}

int CMDunion_mul_dbl(BAT** res, BAT*l, BAT*r) {
        UNION_OID_CALC_HEADER;
        newdbl = *dres * *(dbl*)Tloc(r,rp);
        UNION_OID_CALC_FOOTER;
}
int CMDunion_div_dbl(BAT** res, BAT*l, BAT*r) {
        UNION_OID_CALC_HEADER;
        newdbl = *dres / *(dbl*)Tloc(r,rp);
        UNION_OID_CALC_FOOTER;
}

/*
 *
 * END of experiment
 *
 *
 */

#define LEAK_PROBLEM

int CMDpf2tijah_node(BAT** res, bit* preserve_head, BAT* doc_name, BAT* doc_firstpre, BAT* doc_pfpre, BAT* item, BAT* kind, BAT* doc_loaded ) {
        int debug = 0;
        int nDocs;
        BAT **rangeBAT;

        if (BATcount(item) == 0) {
            *res = BATnew(TYPE_void, TYPE_oid, 0);
            return GDK_SUCCEED;
        }

        nDocs = BATcount(doc_loaded);
        rangeBAT = (BAT**)GDKmalloc(nDocs*sizeof(BAT*));
        if (!rangeBAT) {
            GDKerror("CMDpf2tijah_node: GDKmalloc() failed.\n");
            return GDK_FAIL;
        }
        for(int i=0; i<nDocs; i++) {
            rangeBAT[i] = NULL;
        }

	if ( *preserve_head ) 
	    *res = BATnew(TYPE_oid, TYPE_oid, BATcount(item));
	else
	    *res = BATnew(TYPE_void, TYPE_oid, BATcount(item));

        if ( debug ) stream_printf(GDKout,"* Start of CMDpf2tijah_node():\n");
	if ( 1 && debug ) {
	    stream_printf(GDKout,"#!BAT: item\n");
	    BATprintf(GDKout,item);
	    stream_printf(GDKout,"#!BAT: kind\n");
	    BATprintf(GDKout,kind);
	    stream_printf(GDKout,"#!BAT: doc_loaded\n");
	    BATprintf(GDKout,doc_loaded);
	}
	if ( 1 && debug ) {
	    stream_printf(GDKout,"#!BAT: tijah:doc_name\n");
	    BATprintf(GDKout,doc_name);
	    stream_printf(GDKout,"#!BAT: tijah:doc_firstpre\n");
	    BATprintf(GDKout,doc_firstpre);
	    stream_printf(GDKout,"#!BAT: tijah:doc_pfpre\n");
	    BATprintf(GDKout,doc_pfpre);
	}

	BUN p,q;
        BATiter itemi = bat_iterator(item);
	BATloop(item, p, q) {
	    oid idx      = *(oid*) BUNhead(itemi, p);
	    ptr itemTAIL = BUNtail(itemi, p);
	    oid pfpre    = *(oid*) itemTAIL;

	    BUN kindBUN = BUNfnd(kind,&idx);
	    if ( kindBUN == BUN_NONE ) {
	        stream_printf(GDKout,"READ KIND failed\n");
		return GDK_FAIL;
	    }
	    int kval = *(int*)Tloc(kind, kindBUN);
	    // ALGEBRA NODES ONLY CONTAIN THE FRAG
	    oid container;
	    if ( XTRACT_KIND(kval) != ELEM ) {
	        // stream_printf(GDKout,"CMDpf2tijah_node: startNodes: no node\n");
		// return GDK_FAIL;
		container = (oid)kval;
		if ( debug ) stream_printf(GDKout,"* container = %d.\n",container);
            } else {
	    	container = (oid)XTRACT_CONT(kval);
	    }

	    int myindex = container - 1;
	    /* make it a switch */
	    if ( rangeBAT[myindex] == NULL ) {

	      BAT* dlmirror = BATmirror(doc_loaded);
	      BAT* docs_in_cont = BATselect(dlmirror,&container,&container);
              BATiter docs_in_conti = bat_iterator(docs_in_cont);
	      BUN p_dic,q_dic;
	      BATloop(docs_in_cont, p_dic, q_dic) {
	        oid doc_start;
		oid doc_end;

	        str docname = (str) BUNhead(docs_in_conti, p_dic);
		BAT* b = BATmirror(doc_name);
	        BUN yy = BUNfnd(b,docname);
		if ( yy != BUN_NONE ) {
                    BATiter bi = bat_iterator(b);
		    if ( debug ) stream_printf(GDKout,"* pf2tijah_index: preparing doc(%s)[] nodes for translation\n",docname);	
		    oid tj_docIndex = *(oid*)BUNtail(bi,yy);

		    BUN r;
		    r = BUNfnd(doc_firstpre,&tj_docIndex);
		    if ( r == BUN_NONE ) {
	    	        stream_printf(GDKout,"Cannot find tijah-firstpre @  %d.\n",tj_docIndex);
		        return GDK_FAIL;
		    }

                    bi.b = doc_firstpre;
	            doc_start = *(oid*)BUNtail(bi,r);
		    oid tj_nextIndex = tj_docIndex +  1;
		    if ( BATcount(doc_firstpre) > tj_nextIndex ) {
		        r = BUNfnd(doc_firstpre,&tj_nextIndex);
			if ( r == BUN_NONE ) {
	    	            stream_printf(GDKout,"Cannot do range for tijah-firstpre @  %d.\n",tj_docIndex);
			    return GDK_FAIL;
			}
	                doc_end = *(oid*)BUNtail(bi,r) - 1;
		    } else {
	                doc_end = oid_nil;
		    }
		    BAT* dpfpm = BATmirror(doc_pfpre);
		    BAT* ds = BATselect(dpfpm,(ptr)&doc_start,(ptr)&doc_end);
		    if ( rangeBAT[myindex] == NULL ) {
		        rangeBAT[myindex] = BATnew(TYPE_oid, TYPE_oid, BATcount(ds));
			// BBPfix(BBPcacheid(rangeBAT[myindex]));
		    } 
		    if ( !BATins(rangeBAT[myindex],ds,1) ) {
	    	       stream_printf(GDKout,"CMDpf2tijah_node: BATins in rangeBAT fails.\n");
		       return GDK_FAIL;
		    }
	            BBPunfix(BBPcacheid(ds));
		} {
		} } 
	        BBPunfix(BBPcacheid(docs_in_cont));
	      }
	      if ( rangeBAT[myindex] ) {
		    BUN range_bun = BUNfnd(rangeBAT[myindex],&pfpre);
		    if ( range_bun != BUN_NONE ) {
			/* found the tijah index value */
                        BATiter bi = bat_iterator(rangeBAT[myindex]);
		        oid tj_index = *(oid*)BUNtail(bi,range_bun);
			if ( *preserve_head )
			    BUNins(*res,&idx,&tj_index,FALSE);
			else
			    BUNappend(*res,&tj_index,1);
			if ( debug ) stream_printf(GDKout,"* pf2tijah_index: pre(%d@0) @ cont(%d) = tijah(%d@0).\n", pfpre, container,tj_index);
		    } else {
		        if ( debug ) stream_printf(GDKout,"* pf2tijah_index: pre(%d@0) @ cont(%d) = NOT INDEXED.\n", pfpre, container);
		    }
		    
	      } else {
			if ( debug ) stream_printf(GDKout,"* pf2tijah_index: pre(%d@0) @ cont(%d) = NOT INDEXED.\n", pfpre, container);
	      }
	}
	/* cleanup BAT's */
	for(int i=0; i<nDocs; i++) {
	    if ( rangeBAT[i] ) {
	        BBPunfix(BBPcacheid(rangeBAT[i]));
		rangeBAT[i] = NULL;
	    }
        }
	GDKfree(rangeBAT);

	if ( !*preserve_head ) {
	    BAT *r1 = BATmirror(*res);
	    BAT *r2 = BATmark(r1, 0);
	    BBPunfix(BBPcacheid(*res));
	    *res    = BATmirror(r2);
	}

	/* */
	if ( debug ) 
	    BATprintf(GDKout,*res);
	/* */
        return GDK_SUCCEED;
}

int CMDoffsetindex ( BAT** result, BAT* tid, wrd* res_size)
{
	char *name = "TJoffsetindex";
	BAT *res = NULL;
        BUN p, q;
        oid *dst = NULL, *sdst = NULL;
	oid t, s;

	/* --------------------------- checks ---------------------------------- */

	BATcheck(tid, name);
	if (!(BATtordered(tid) & 1))
	{
		/* BUG#1732596 this test currently fails on Itanium */
        	GDKerror("%s: index-bat must be ordered on tail.\n", name);
    		return GDK_FAIL;
	}
	if (!(BAThdense(tid)))
    	{
        	GDKerror("%s: index-bat must have a dense head.\n", name);
    		return GDK_FAIL;
	}

	if (*res_size < 0 || *res_size > (wrd) BUN_MAX)
	{
        	GDKerror("%s: res_size out of range.\n", name);
    		return GDK_FAIL;
	}

	/* ---------------------------- inits ---------------------------------- */

	res = BATnew(TYPE_void, TYPE_oid, *res_size);
        if (res == NULL) 
        { 
            	GDKerror("%s: could not allocate a result BAT[void,oid] of size "BUNFMT".\n", name, (BUN) *res_size);
            	return(GDK_FAIL);
        }
	sdst = dst = (oid*)Tloc(res, BUNlast(res));
    
	t = (oid)0;
	*(oid*)dst = (oid)0;
	dst++;
	
	/* ----------------------------- main ---------------------------------- */

        BATiter tidi = bat_iterator(tid);
	BATloop(tid, p, q)
	{
		s = *(oid*) BUNtail(tidi, p);
		if (t != s)
		{
			for(; t < s; t++, dst++)
			{
				*(oid*)dst = p;
			}
		}
	}

	s = (oid) (*res_size - 1);
	for(; t < s; t++, dst++)
	{
		*dst = p;
	}
	
	/* ---------------------------- tidy up --------------------------------- */
	
	BATsetcount(res, dst - sdst);
    	res->batDirty = TRUE;
        res->tsorted = GDK_SORTED;
        BATkey (res, TRUE);
	BATset(res, TRUE);
	BATseqbase(res, 0);
	
	*result = res;
	return GDK_SUCCEED;
}	

int CMDmergeindex ( BAT** result, BAT* tidpre, BAT* oldindex, BAT* oldpre, wrd* indsize )
{
        BATiter tidprei, oldindexi, oldprei;
	char *name = "TJmergeindex";
	BAT *res = NULL;
	BAT *newindex = NULL;
	BAT *newpre = NULL;
	BUN i,j, ressize = 0;
        BUN lst_tidpre, lst_oldindex, lst_copy, lst_res, cur_tidpre, cur_oldindex, cur_oldpre;
        oid *s_newindex, *lst_newindex, *s_newpre, *lst_newpre;
	oid tid;
	
	/* --------------------------- checks ---------------------------------- */
	
	BATcheck(tidpre, name);
	BATcheck(oldindex, name);
	BATcheck(oldpre, name);
        
	if (!(BAThordered(tidpre) & 1))
	{
        	GDKerror("%s: term-bat must be ordered on tail.\n", name);
    		return GDK_FAIL;
	}

	if (*indsize < 0 || *indsize > (wrd) BUN_MAX)
	{
        	GDKerror("%s: indsize out of range.\n", name);
    		return GDK_FAIL;
	}

	/* ---------------------------- inits ---------------------------------- */

	ressize = 2;
	res = BATnew(TYPE_void, TYPE_bat, ressize);
        if (res == NULL) 
        { 
            	GDKerror("%s: could not allocate a result BAT[void,oid] of size "BUNFMT".\n", name, ressize);
            	return(GDK_FAIL);
        }
	
	ressize = BATcount(tidpre) + BATcount(oldpre);
	newpre = BATnew(TYPE_void, TYPE_oid, ressize);
        if (newpre == NULL) 
        { 
            	GDKerror("%s: could not allocate a result BAT[void,oid] of size "BUNFMT".\n", name, ressize);
            	BATfree(res);
                return(GDK_FAIL);
        }
	
	ressize = *indsize;
	newindex = BATnew(TYPE_void, TYPE_oid, ressize);
        if (newindex == NULL) 
        { 
            	GDKerror("%s: could not allocate a result BAT[void,oid] of size "BUNFMT".\n", name, ressize);
            	BATfree(res);
            	BATfree(newpre);
            	return(GDK_FAIL);
        }
	
	lst_tidpre = BUNlast(tidpre);
	lst_oldindex = BUNlast(oldindex) - 1; /* last index is not a real term */
	s_newindex = lst_newindex = (oid*)Tloc(newindex, BUNlast(newindex));
	s_newpre = lst_newpre = (oid*)Tloc(newpre, BUNlast(newpre));
	lst_res = BUNlast(res);
	
	cur_tidpre = BUNfirst(tidpre);
	cur_oldindex = BUNfirst(oldindex);
	cur_oldpre = BUNfirst(oldpre);
	
        tidprei = bat_iterator(tidpre);
        oldindexi = bat_iterator(oldindex);
        oldprei = bat_iterator(oldpre);
	/* ----------------------------- main ---------------------------------- */
	
	j = *indsize - 1;
	for(i = 0; i < j; i++)
        {
	        tid = (oid) i;
		*lst_newindex++ = lst_newpre - s_newpre;
               
                /* copy old nodes to new index */
                if (cur_oldindex < lst_oldindex && tid == *(oid*)BUNhead(oldindexi, cur_oldindex))
                {
		        lst_copy = *(int*) BUNtail(oldindexi, cur_oldindex + 1);
		        while (cur_oldpre < lst_copy)
		        {
			        *lst_newpre++ = *(oid*)BUNtail(oldprei, cur_oldpre);
			        cur_oldpre++;
		        }
                        cur_oldindex++;
                }
                /* merge-in new nodes */
                while(cur_tidpre < lst_tidpre && tid == *(oid*)BUNhead(tidprei, cur_tidpre))
                {
                        *lst_newpre++ = *(oid*)BUNtail(tidprei, cur_tidpre);
	        	cur_tidpre++;
                }
        }

	/* write limit of index as last item to index bat */
	*lst_newindex = lst_newpre - s_newpre;
	lst_newindex++;

	/* ---------------------------- tidy up --------------------------------- */

	BATsetcount(newindex, lst_newindex - s_newindex);
    	newindex->batDirty = TRUE;
        newindex->hsorted = GDK_SORTED;
        newindex->tsorted = GDK_SORTED;
        BATkey(newindex, TRUE);
        BATkey(BATmirror(newindex), FALSE);
	BATseqbase(newindex, (oid)0);

	BATsetcount(newpre, lst_newpre - s_newpre);
    	newpre->batDirty = TRUE;
        newpre->hsorted = GDK_SORTED;
        newpre->tsorted = FALSE;
        BATkey(newpre, TRUE);
        BATkey(BATmirror(newpre), TRUE);
	BATseqbase(newpre, (oid)0);
	
        /* insert bats in result */		
	BATseqbase(res, (oid)0);
	voidfix_bunfastins_nocheck_noinc(res, lst_res, 0, (void*)&newindex->batCacheid);
	BBPunfix(newindex->batCacheid);	
	lst_res++;
	voidfix_bunfastins_nocheck_noinc(res, lst_res, 0, (void*)&newpre->batCacheid); 
	BBPunfix(newpre->batCacheid);	
	lst_res++;
	
	BATsetcount(res, 2);
	res->batDirty = TRUE;
	BATkey(res, TRUE);
	BATkey(BATmirror(res), TRUE);
        res->hsorted = GDK_SORTED;
        res->tsorted = FALSE;
        res->H->nonil = 1;
        res->T->nonil = 0;
	
	*result = res;
	return GDK_SUCCEED;
}

int CMDmergeindex2 ( BAT** result, BAT* tidpre, BAT* tidsize, BAT* oldindex, BAT* oldpre, BAT* oldsize, wrd* indsize )
{
	char *name = "TJmergeindex2";
	BAT *res = NULL;
	BAT *newindex = NULL;
	BAT *newpre = NULL;
	BAT *newsize = NULL;
	BUN i,j, ressize = 0;
        BUN lst_tidpre, lst_oldindex, lst_copy, lst_res, cur_tidpre, cur_tidsize, cur_oldindex, cur_oldpre, cur_oldsize;
        BATiter tidprei, tidsizei, oldindexi, oldprei, oldsizei;
        oid *s_newindex, *lst_newindex, *s_newpre, *lst_newpre;
	int *s_newsize, *lst_newsize;
	oid tid;
	
	/* --------------------------- checks ---------------------------------- */
	
	BATcheck(tidpre, name);
	BATcheck(tidsize, name);
	BATcheck(oldindex, name);
	BATcheck(oldpre, name);
	BATcheck(oldsize, name);
        
	if (!(BAThordered(tidpre) & 1))
	{
        	GDKerror("%s: term-bat must be ordered on tail.\n", name);
    		return GDK_FAIL;
	}

if (*indsize < 0 || *indsize > (wrd) BUN_MAX)
	{
        	GDKerror("%s: indsize out of range.\n", name);
    		return GDK_FAIL;
	}

	/* ---------------------------- inits ---------------------------------- */

	ressize = 3;
	res = BATnew(TYPE_void, TYPE_bat, ressize);
        if (res == NULL) 
        { 
            	GDKerror("%s: could not allocate a result BAT[void,oid] of size "BUNFMT".\n", name, ressize);
            	return(GDK_FAIL);
        }
	
	ressize = BATcount(tidpre) + BATcount(oldpre);
	newpre = BATnew(TYPE_void, TYPE_oid, ressize);
        if (newpre == NULL) 
        { 
            	GDKerror("%s: could not allocate a result BAT[void,oid] of size "BUNFMT".\n", name, ressize);
            	BATfree(res);
                return(GDK_FAIL);
        }
	
	newsize = BATnew(TYPE_void, TYPE_int, ressize);
        if (newsize == NULL) 
        { 
            	GDKerror("%s: could not allocate a result BAT[void,int] of size "BUNFMT".\n", name, ressize);
            	BATfree(res);
            	BATfree(newpre);
            	return(GDK_FAIL);
        }
	
	ressize = *indsize;
	newindex = BATnew(TYPE_void, TYPE_oid, ressize);
        if (newindex == NULL) 
        { 
            	GDKerror("%s: could not allocate a result BAT[void,oid] of size "BUNFMT".\n", name, ressize);
            	BATfree(res);
            	BATfree(newpre);
            	BATfree(newsize);
            	return(GDK_FAIL);
        }
	
	lst_tidpre = BUNlast(tidpre);
	lst_oldindex = BUNlast(oldindex) - 1; /* last index is not a real term */
	s_newindex = lst_newindex = (oid*)Tloc(newindex, BUNlast(newindex));
	s_newpre = lst_newpre = (oid*)Tloc(newpre, BUNlast(newpre));
	s_newsize = lst_newsize = (int*)Tloc(newsize, BUNlast(newsize));
	lst_res = BUNlast(res);
	
	cur_tidpre = BUNfirst(tidpre);
	cur_tidsize = BUNfirst(tidsize);
	cur_oldindex = BUNfirst(oldindex);
	cur_oldpre = BUNfirst(oldpre);
	cur_oldsize = BUNfirst(oldsize);
	
        tidprei = bat_iterator(tidpre);
        tidsizei = bat_iterator(tidsize);
        oldindexi = bat_iterator(oldindex);
        oldprei = bat_iterator(oldpre);
        oldsizei = bat_iterator(oldsize);

	/* ----------------------------- main ---------------------------------- */
	
	j = *indsize - 1;
	for(i = 0; i < j; i++)
        {
	        tid = (oid) i;
		*lst_newindex++ = lst_newpre - s_newpre;
               
                /* copy old nodes to new index */
                if (cur_oldindex < lst_oldindex && tid == *(oid*)BUNhead(oldindexi, cur_oldindex))
                {
		        lst_copy = *(int*) BUNtail(oldindexi, cur_oldindex + 1);
		        while (cur_oldpre < lst_copy)
		        {
			        *lst_newpre++ = *(oid*)BUNtail(oldprei, cur_oldpre);
			        *lst_newsize++ = *(int*)BUNtail(oldsizei, cur_oldsize);
			        cur_oldpre++;
			        cur_oldsize++;
		        }
                        cur_oldindex++;
                }
                /* merge-in new nodes */
                while(cur_tidpre < lst_tidpre && tid == *(oid*)BUNhead(tidprei, cur_tidpre))
                {
                        *lst_newpre++ = *(oid*)BUNtail(tidprei, cur_tidpre);
                        *lst_newsize++ = *(int*)BUNtail(tidsizei, cur_tidsize);
	        	cur_tidpre++;
	        	cur_tidsize++;
                }
        }

	/* write limit of index as last item to index bat */
	*lst_newindex = lst_newpre - s_newpre;
	lst_newindex++;

	/* ---------------------------- tidy up --------------------------------- */

	BATsetcount(newindex, lst_newindex - s_newindex);
    	newindex->batDirty = TRUE;
        newindex->hsorted = GDK_SORTED;
        newindex->tsorted = GDK_SORTED;
        BATkey(newindex, TRUE);
        BATkey(BATmirror(newindex), FALSE);
	BATseqbase(newindex, (oid)0);

	BATsetcount(newpre, lst_newpre - s_newpre);
    	newpre->batDirty = TRUE;
        newpre->hsorted = GDK_SORTED;
        newpre->tsorted = FALSE;
        BATkey(newpre, TRUE);
        BATkey(BATmirror(newpre), TRUE);
	BATseqbase(newpre, (oid)0);
	
	BATsetcount(newsize, lst_newsize - s_newsize);
    	newsize->batDirty = TRUE;
        newsize->hsorted = GDK_SORTED;
        newsize->tsorted = FALSE;
        BATkey(newsize, TRUE);
	BATseqbase(newsize, (oid)0);
	
        /* insert bats in result */		
	BATseqbase(res, (oid)0);
	voidfix_bunfastins_nocheck_noinc(res, lst_res, 0, (void*)&newindex->batCacheid);
	BBPunfix(newindex->batCacheid);	
	lst_res++;
	voidfix_bunfastins_nocheck_noinc(res, lst_res, 0, (void*)&newpre->batCacheid); 
	BBPunfix(newpre->batCacheid);	
	lst_res++;
	voidfix_bunfastins_nocheck_noinc(res, lst_res, 0, (void*)&newsize->batCacheid); 
	BBPunfix(newsize->batCacheid);	
	lst_res++;
	
	BATsetcount(res, 3);
	res->batDirty = TRUE;
	BATkey(res, TRUE);
	BATkey(BATmirror(res), TRUE);
        res->hsorted = GDK_SORTED;
        res->tsorted = FALSE;
        res->H->nonil = 1;
        res->T->nonil = 0;
	
	*result = res;
	return GDK_SUCCEED;
}

int CMDindexfetchjoin ( BAT** result, BAT* tid, BAT* index, BAT* pre )
{
	char *name = "TJindexfetchjoin";
	BAT *res = NULL;
        oid *sdst = NULL, *hdst = NULL, *tdst = NULL;

	BUN ressize = 0;
	oid t, *ind;
	BUN p, q;
        BUN j, i = 0;
	/* bit one_tid = FALSE; */
    
	/* --------------------------- checks ---------------------------------- */
	
	BATcheck(tid, name);
	BATcheck(index, name);
	BATcheck(pre, name);
	
        /* if (BATcount(tid) <= 1) one_tid = TRUE; */
	
	if (!(BATtordered(tid) & 1))
	{
        	GDKerror("%s: term-bat must be ordered on tail.\n", name);
    		return GDK_FAIL;
	}

	/* ---------------------------- inits ---------------------------------- */

	ind = (oid*)GDKmalloc(sizeof(oid) * BATcount(tid) * 3);
        if (ind == NULL) 
        { 
            	GDKerror("%s: could not allocate a offset stack of size "BUNFMT".\n", name, BATcount(tid));
            	return(GDK_FAIL);
        }
	
        BATiter tidi = bat_iterator(tid);
	BATloop(tid, p, q) {
		t = *(oid*) BUNtail(tidi, p);
		ind[i++] = t;
		ind[i++] = *(oid*) Tloc(index, (int)t);
		ind[i++] = *(oid*) Tloc(index, (int)t + 1);
		ressize += (ind[i - 1] - ind[i - 2]);
	}
	
	res = BATnew(TYPE_oid, TYPE_oid, ressize);
        if (res == NULL) 
        { 
            	GDKerror("%s: could not allocate a result BAT[oid,oid] of size "BUNFMT".\n", name, ressize);
	        GDKfree(ind);
            	return(GDK_FAIL);
        }
	sdst = hdst = (oid*)Hloc(res, BUNlast(res));
               tdst = (oid*)Tloc(res, BUNlast(res));
	
	/* ----------------------------- main ---------------------------------- */

	j = 0;
	while (j < i) {
        	t = ind[j++];
		p = ind[j++];
		q = ind[j++];
		for (; p < q; p++) {
			*hdst++ = t;
			*tdst++ = *(oid*)Tloc(pre,p);
		}
	}

	/* ---------------------------- tidy up --------------------------------- */

	GDKfree(ind);
	BATsetcount(res, hdst - sdst);
    	res->batDirty = TRUE;
        res->hsorted = GDK_SORTED;
        res->tsorted = FALSE;
        BATkey (BATmirror(res), TRUE);
	BATset(res, TRUE);
	
	*result = res;
	return GDK_SUCCEED;
}


int CMDsplitbat ( BAT** result, BAT* origbat, BAT* splitbat )
{
	char *name = "TJsplitbat";
	BAT *res = NULL;
	BAT *diffbat = NULL;
	BAT *joinbat = NULL;
	BUN ressize = 0;
        BUN lst_split, cur_split, lst_res;
        oid cur_orig, lst_orig, split_oid;
        oid *tid;
	
	/* --------------------------- checks ---------------------------------- */
	
	BATcheck(origbat, name);
	BATcheck(splitbat, name);
 
        if (origbat->htype != TYPE_void) {
            GDKerror("%s: head (oid) of original BAT must NOT be materialized.\n", name);
            return(GDK_FAIL);
        }
        if (origbat->ttype != TYPE_oid) {
            GDKerror("%s: tail of original BAT must be of type OID.\n", name);
            return(GDK_FAIL);
        }
        if (splitbat->htype != TYPE_oid) {
            GDKerror("%s: head of split BAT must be of type OID.\n", name);
            return(GDK_FAIL);
        }
        if (!(BAThordered(splitbat)&1)) { 
            GDKerror("%s: head of split BAT must be sorted.\n",name); 
            return(GDK_FAIL);
        }

	/* ---------------------------- inits ---------------------------------- */

	ressize = 2;
	res = BATnew(TYPE_void, TYPE_bat, ressize);
        if (res == NULL) 
        { 
            	GDKerror("%s: could not allocate a result BAT[void,oid] of size "BUNFMT".\n", name, ressize);
            	return(GDK_FAIL);
        }
        
	ressize = BATcount(origbat);
	diffbat = BATnew(TYPE_oid, TYPE_oid, ressize);
        if (diffbat == NULL) 
        { 
            	GDKerror("%s: could not allocate a result BAT[oid,oid] of size "BUNFMT".\n", name, ressize);
            	BATfree(res);
                return(GDK_FAIL);
        }
	
	ressize = BATcount(splitbat);
	joinbat = BATnew(TYPE_oid, TYPE_oid, ressize);
        if (joinbat == NULL) 
        { 
            	GDKerror("%s: could not allocate a result BAT[oid,oid] of size "BUNFMT".\n", name, ressize);
            	BATfree(res);
            	BATfree(diffbat);
            	return(GDK_FAIL);
        }
	
	lst_split = BUNlast(splitbat);
	lst_res = BUNlast(res);
	cur_split = BUNfirst(splitbat);
        cur_orig = origbat->hseqbase;
        lst_orig = cur_orig + BATcount(origbat);
	
	/* ----------------------------- main ---------------------------------- */

        while (cur_split < lst_split && *(oid*)Hloc(splitbat, cur_split) < cur_orig) cur_split++;
        split_oid = *(oid*)Hloc(splitbat, cur_split);

        for (;cur_orig < lst_orig; cur_orig++) {
            tid = ((oid*)Tloc(origbat, cur_orig)) - origbat->hseqbase;
            if (cur_orig == split_oid) { 
                BUNfastins(joinbat, &cur_orig, tid);
                if (cur_split < lst_split) {
                    cur_split++;
                    split_oid = *(oid*)Hloc(splitbat, cur_split);
                }
            } else {
                BUNfastins(diffbat, &cur_orig, tid);
            }
        }

	/* ---------------------------- tidy up --------------------------------- */

    	diffbat->batDirty = TRUE;
        diffbat->hsorted = GDK_SORTED;
        diffbat->tsorted = FALSE;
        BATkey(diffbat, TRUE);

    	joinbat->batDirty = TRUE;
        joinbat->hsorted = GDK_SORTED;
        joinbat->tsorted = FALSE;
        BATkey(joinbat, TRUE);
	
        /* insert bats in result */		
	BATseqbase(res, (oid)0);
	voidfix_bunfastins_nocheck_noinc(res, lst_res, 0, (void*)&diffbat->batCacheid);
	BBPunfix(diffbat->batCacheid);	
	lst_res++;
	voidfix_bunfastins_nocheck_noinc(res, lst_res, 0, (void*)&joinbat->batCacheid); 
	BBPunfix(joinbat->batCacheid);	
	lst_res++;
	
	BATsetcount(res, 2);
	res->batDirty = TRUE;
	BATkey(res, TRUE);
	BATkey(BATmirror(res), TRUE);
        res->hsorted = GDK_SORTED;
        res->tsorted = FALSE;
        res->H->nonil = 1;
        res->T->nonil = 0;
	
	*result = res;
	return GDK_SUCCEED;
}





@= init_result
{
	REGISTER BUN _p = BUNlast(bn);

	bn->tsorted = bn->hsorted = 0;
	ALIGNsetH(bn, e);
	BATloop(e, p, q) {
		oiddbl_bunfastins_nocheck_noinc(bn, _p, Hloc(e,p), &zero);
		_p++;
	}
	ALGODEBUG THRprintf(GDKout, "#init_result(dbl): BAThordered(e)&1, \n");
	BATsetcount(bn, _p - BUNfirst(bn));
	if ( !BATprepareHash(bn) ) {
	    /* do nothing yet */;	
	}
	if (!bn->batDirty)
		bn->batDirty = TRUE;
}
@

@c
int
CMDsettailkeysorted(BAT **result, BAT *input)
{
	*result = input;
	BATkey(BATmirror(*result), BOUND2BTRUE);
	(*result)->tsorted = GDK_SORTED;
	BBPfix(input->batCacheid);
	return GDK_SUCCEED;
}

#define max_stack_size 128

typedef struct stack_item si;

struct stack_item {
    oid ctx;            /* ctx */
    oid eocs;           /* end of ctx scope (pre + size) */
};

int CMDtreemergejoin_sort(BAT **result, BAT *Astart, BAT *nid_size, BAT *Dstart) {

    /* ---------------------------- declarations ------------------------------------ */
    char *name = "TJ_treemergejoin_sort";
    BAT *res = *result;
    BUN D_cur, D_last, 
        A_cur, A_last;
    BATiter Ai, Di;
    oid D_cur_pre;

    si *stack; 
    BUN stack_top = 0, i;
	
    int *size;
    BUN free;	
    oid *sdst = NULL, *hdst = NULL, *tdst = NULL;
    
    /* ------------------------------- checks ---------------------------------------- */
    if (!(BATtordered(Astart)&1)) { 
        GDKerror("%s: Ancestor pre BAT not sorted (on start).\n",name); 
        return(GDK_FAIL);
    }
    if (!(BATtordered(Dstart)&1)) { 
        GDKerror("%s: Descendant BAT not sorted (on start).\n",name); 
        return(GDK_FAIL);
    }
    if (nid_size->ttype != TYPE_int) {
        GDKerror("%s: tail of size BAT must be type INT.\n", name);
        return(GDK_FAIL);
    }
    if (nid_size->htype != TYPE_void) {
        GDKerror("%s: head (oid) of size BAT must NOT be materialized.\n", name);
        return(GDK_FAIL);
    }
    if (BATcount(Astart) == 0 || BATcount(nid_size) == 0 || BATcount(Dstart) == 0)
    {
        res = BATnew(TYPE_oid, TYPE_oid, 0);
        *result = res;    
        return(GDK_SUCCEED);
    }

    /* ----------------------------- initialize -------------------------------------- */
    // The maximum depth of the stack is the depth of the XML tree
    if ((stack = (si*)GDKmalloc(sizeof(si) * max_stack_size)) == NULL) {
        GDKerror("treemergejoin_sort: could not allocate memory for stack.\n"); 
        return(GDK_FAIL);
    }

    // the size of the bat may not be correct (could be more, could be less)
    free = BATcount(Dstart);
    res = BATnew(TYPE_oid, TYPE_oid, free); 
    if (res == NULL) 
    { 
       GDKerror("%s: could not allocate result BAT.\n", name);
       GDKfree(stack);
       return(GDK_FAIL);
    }
    free = BATcapacity(res);
    
    size = ((int*) Tloc(nid_size, BUNfirst(nid_size))) - (int)nid_size->hseqbase;
    D_cur = BUNfirst(Dstart);
    D_last = BUNlast(Dstart);  
    A_cur = BUNfirst(Astart);
    A_last = BUNlast(Astart);
    Ai = bat_iterator(Astart);
    Di = bat_iterator(Dstart);
    sdst = hdst = (oid*)Hloc(res, BUNlast(res));
           tdst = (oid*)Tloc(res, BUNlast(res));

    /* -------------------------------- main ---------------------------------------- */
    
    while(D_cur < D_last) {
      
      D_cur_pre = *(oid*)BUNtail(Di, D_cur);
      /* printf("0. eocs: %d, desc: %d\n", stack[stack_top-1].eocs, *(oid*)BUNtail(Di, D_cur)); */
      
      /* remove ancestor candidates that ended before D_cur */
      while (stack_top && D_cur_pre > stack[stack_top-1].eocs) {
        /* pop */
	stack_top--;
      }	
      
      /* printf("1.stacksize: %d\n", stack_top); */
      
      /* Put ancestors on stack until we reach the current descendent */ 
      while (A_cur < A_last && *(oid*)BUNtail(Ai, A_cur) < D_cur_pre){		
	if (D_cur_pre <= (*(oid*)BUNtail(Ai, A_cur) + size[*(oid*)BUNhead(Ai, A_cur)])) {
           /* push */
	   si new_stack_item;
           new_stack_item.ctx = *(oid*)BUNhead(Ai, A_cur);
           new_stack_item.eocs = *(oid*)BUNtail(Ai, A_cur) + size[*(oid*)BUNhead(Ai, A_cur)];
           stack[stack_top++] = new_stack_item;
           if (stack_top >= max_stack_size) {
               GDKerror("%s: ancestor stack grew beyond stack-size.\n", name);
               GDKfree(stack);
               BATfree(res);
               return(GDK_FAIL);
           }
	}
	A_cur++;
      }
      
      /* output everything that is on the stack (the ancestors) */
      /* It has started before Dstart and since it's a tree, */
      /* it has to end after Dend. */
      if (free < stack_top)
      {
	BATsetcount(res, hdst - sdst);
        BUN sz = BATgrows(res);
        while (sz < ((hdst - sdst) + stack_top)) 
          sz = 2 * sz;
        res = BATextend(res, sz);
        if (res == NULL)
    	{ 
       	  GDKerror("%s: could not extend result BAT.\n", name);
          GDKfree(stack);
          BATfree(res);
          return(GDK_FAIL);
    	}
        sdst = (oid*)Hloc(res, BUNfirst(res));
        hdst = (oid*)Hloc(res, BUNlast(res));
        tdst = (oid*)Tloc(res, BUNlast(res));
        free = sz - BATcount(res) - stack_top;
      } else {
          free -= stack_top;
      }
     
      for (i=0;i<stack_top;i++) {
        /* printf("3. anc/desc: (%d/%d)\n", stack[i].ctx, *(oid*)BUNtail(Di, D_cur)); */
        *hdst++ = stack[i].ctx;
        *tdst++ = *(oid*)BUNhead(Di, D_cur);
      }
      D_cur++;
    }
     /* it is possible there are still ancestor candidates left on the stack, but we are out of descendants, so they starve... */
    
    /* ----------------------------- tidy up -------------------------------------- */
     GDKfree(stack); 
	
     BATsetcount(res, hdst - sdst);
     res->batDirty = TRUE;
     res->tsorted = FALSE;
     res->hsorted = FALSE;
     BATset(res, TRUE);
     
     *result = res;    
     return(GDK_SUCCEED);
}

int CMDtreemergejoin_nid(BAT **result, BAT *Astart, BAT *nid_size, BAT *Dstart) {

    /* ---------------------------- declarations ------------------------------------ */
    char *name = "TJ_treemergejoin_nid";
    BAT *res = *result;
    BUN D_cur, D_last, 
        A_cur, A_last;
    BATiter Ai, Di;
    oid D_cur_pre;

    si *stack; 
    BUN stack_top = 0, i;
	
    int *size;
    BUN free;	
    oid *sdst = NULL, *hdst = NULL, *tdst = NULL;
    
    /* ------------------------------- checks ---------------------------------------- */
    if (!(BATtordered(Astart)&1)) { 
        GDKerror("%s: Ancestor BAT not sorted on pre.\n",name); 
        return(GDK_FAIL);
    }
    if (!(BAThordered(Dstart)&1)) { 
        GDKerror("%s: Descendant BAT not sorted on nid.\n",name); 
        return(GDK_FAIL);
    }
    if (!(BATtordered(Dstart)&1)) { 
        GDKerror("%s: Descendant BAT not sorted on pre.\n",name); 
        return(GDK_FAIL);
    }
    if (nid_size->ttype != TYPE_int) {
        GDKerror("%s: tail of size BAT must be type INT.\n", name);
        return(GDK_FAIL);
    }
    if (nid_size->htype != TYPE_void) {
        GDKerror("%s: head (oid) of size BAT must NOT be materialized.\n", name);
        return(GDK_FAIL);
    }
    if (BATcount(Astart) == 0 || BATcount(nid_size) == 0 || BATcount(Dstart) == 0)
    {
        res = BATnew(TYPE_oid, TYPE_oid, 0);
        *result = res;    
        return(GDK_SUCCEED);
    }

    /* ----------------------------- initialize -------------------------------------- */
    // The maximum depth of the stack is the depth of the XML tree
    if ((stack = (si*)GDKmalloc(sizeof(si) * max_stack_size)) == NULL) {
        GDKerror("treemergejoin_sort: could not allocate memory for stack.\n"); 
        return(GDK_FAIL);
    }

    // the size of the bat may not be correct (could be more, could be less)
    free = BATcount(Dstart);
    res = BATnew(TYPE_oid, TYPE_oid, free); 
    if (res == NULL) 
    { 
       GDKerror("%s: could not allocate result BAT.\n", name);
       GDKfree(stack); 
       return(GDK_FAIL);
    }
    free = BATcapacity(res);
    
    size = ((int*) Tloc(nid_size, BUNfirst(nid_size))) - (int)nid_size->hseqbase;
    D_cur = BUNfirst(Dstart);
    D_last = BUNlast(Dstart);  
    A_cur = BUNfirst(Astart);
    A_last = BUNlast(Astart);
    Ai = bat_iterator(Astart);
    Di = bat_iterator(Dstart);
    sdst = hdst = (oid*)Hloc(res, BUNlast(res));
           tdst = (oid*)Tloc(res, BUNlast(res));

    /* -------------------------------- main ---------------------------------------- */
 
    while(D_cur < D_last) {
      
      D_cur_pre = *(oid*)BUNtail(Di, D_cur);
      /* printf("0. eocs: %d, desc: %d\n", stack[stack_top-1].eocs, *(oid*)BUNtail(Di, D_cur)); */
      
      /* remove ancestor candidates that ended before D_cur */
      while (stack_top && D_cur_pre > stack[stack_top-1].eocs) {
        /* pop */
	stack_top--;
      }	
      
      /* printf("1.stacksize: %d\n", stack_top); */
      
      /* Put ancestors on stack until we reach the current descendent */ 
      while (A_cur < A_last && *(oid*)BUNtail(Ai, A_cur) < D_cur_pre){		
	if (D_cur_pre <= (*(oid*)BUNtail(Ai, A_cur) + size[*(oid*)BUNhead(Ai, A_cur)])) {
           /* push */
	   si new_stack_item;
           new_stack_item.ctx = *(oid*)BUNhead(Ai, A_cur);
           new_stack_item.eocs = *(oid*)BUNtail(Ai, A_cur) + size[*(oid*)BUNhead(Ai, A_cur)];
           stack[stack_top++] = new_stack_item;
           if (stack_top >= max_stack_size) {
               GDKerror("%s: ancestor stack grew beyond stack-size.\n", name);
               GDKfree(stack);
               BATfree(res); 
               return(GDK_FAIL);
           }
	}
	A_cur++;
      }
      
      /* output everything that is on the stack (the ancestors) */
      /* It has started before Dstart and since it's a tree, */
      /* it has to end after Dend. */
      if (free < stack_top)
      {
        BATsetcount(res, hdst - sdst);
        BUN sz = BATgrows(res);
        while (sz < ((hdst - sdst) + stack_top)) 
          sz = 2 * sz;
        res = BATextend(res, sz);
        if (res == NULL)
    	{ 
       	  GDKerror("%s: could not extend result BAT.\n", name);
          GDKfree(stack);
          BATfree(res); 
          return(GDK_FAIL);
    	}
        sdst = (oid*)Hloc(res, BUNfirst(res));
        hdst = (oid*)Hloc(res, BUNlast(res));
        tdst = (oid*)Tloc(res, BUNlast(res));
        free = sz - BATcount(res) - stack_top;
      } else {
          free -= stack_top;
      }
     
      for (i=0;i<stack_top;i++) {
        /* printf("3. anc/desc: (%d/%d)\n", stack[i].ctx, *(oid*)BUNtail(Di, D_cur)); */
        *hdst++ = stack[i].ctx;
        *tdst++ = *(oid*)BUNhead(Di, D_cur);
      }
      D_cur++;
    }
     /* it is possible there are still ancestor candidates left on the stack, but we are out of descendants, so they starve... */
    
    /* ----------------------------- tidy up -------------------------------------- */
     GDKfree(stack); 
	
     BATsetcount(res, hdst - sdst);
     res->batDirty = TRUE;
     if (BAThordered(Dstart)&1) res->tsorted = GDK_SORTED;
     else res->tsorted = FALSE;
     res->hsorted = FALSE;
     BATset(res, TRUE);
     
     *result = res;    
     return(GDK_SUCCEED);
}

int CMDtreemergejoin_pre(BAT **result, BAT *Astart, BAT *pre_size, BAT *Dstart) {

    /* ---------------------------- declarations ------------------------------------ */
    char *name = "TJ_treemergejoin_pre";
    BAT *res = *result;
    BUN D_cur, D_last, 
        A_cur, A_last;
    BATiter Ai, Di;
    oid D_cur_pre, A_cur_pre;

    si *stack; 
    BUN stack_top = 0, i;
	
    int *size;
    BUN free;	
    oid *sdst = NULL, *hdst = NULL, *tdst = NULL;
    
    /* ------------------------------- checks ---------------------------------------- */
    if (!(BAThordered(Astart)&1)) { 
        GDKerror("%s: Ancestor pre BAT not sorted (on start).\n",name); 
        return(GDK_FAIL);
    }
    if (!(BAThordered(Dstart)&1)) { 
        GDKerror("%s: Descendant BAT not sorted (on start).\n",name); 
        return(GDK_FAIL);
    }
    if (pre_size->ttype != TYPE_int) {
        GDKerror("%s: tail of size BAT must be type INT.\n", name);
        return(GDK_FAIL);
    }
    if (pre_size->htype != TYPE_void) {
        GDKerror("%s: head (oid) of size BAT must NOT be materialized.\n", name);
        return(GDK_FAIL);
    }
    if (BATcount(Astart) == 0 || BATcount(pre_size) == 0 || BATcount(Dstart) == 0)
    {
        res = BATnew(TYPE_oid, TYPE_oid, 0);
        *result = res;    
        return(GDK_SUCCEED);
    }

    /* ----------------------------- initialize -------------------------------------- */
    // The maximum depth of the stack is the depth of the XML tree
    if ((stack = (si*)GDKmalloc(sizeof(si) * max_stack_size)) == NULL) {
        GDKerror("treemergejoin_sort: could not allocate memory for stack.\n"); 
        return(GDK_FAIL);
    }

    // the size of the bat may not be correct (could be more, could be less)
    free = BATcount(Dstart);
    res = BATnew(TYPE_oid, TYPE_oid, free); 
    if (res == NULL) 
    { 
       GDKerror("%s: could not allocate result BAT.\n", name);
       GDKfree(stack);
       return(GDK_FAIL);
    }
    free = BATcapacity(res);
    
    size = ((int*) Tloc(pre_size, BUNfirst(pre_size))) - (int)pre_size->hseqbase;
    D_cur = BUNfirst(Dstart);
    D_last = BUNlast(Dstart);  
    A_cur = BUNfirst(Astart);
    A_last = BUNlast(Astart);
    Ai = bat_iterator(Astart);
    Di = bat_iterator(Dstart);
    sdst = hdst = (oid*)Hloc(res, BUNlast(res));
           tdst = (oid*)Tloc(res, BUNlast(res));

    /* -------------------------------- main ---------------------------------------- */
    
    while(D_cur < D_last) {
      
      D_cur_pre = *(oid*)BUNhead(Di, D_cur);
      /* printf("0. eocs: %d, desc: %d\n", stack[stack_top-1].eocs, *(oid*)BUNtail(Di, D_cur)); */
      
      /* remove ancestor candidates that ended before D_cur */
      while (stack_top && D_cur_pre > stack[stack_top-1].eocs) {
        /* pop */
	stack_top--;
      }	
      
      /* printf("1.stacksize: %d\n", stack_top); */
      
      /* Put ancestors on stack until we reach the current descendent */ 
      while (A_cur < A_last && D_cur_pre > (A_cur_pre = *(oid*)BUNhead(Ai, A_cur))){		
	if (D_cur_pre <= (A_cur_pre + size[A_cur_pre])) {
           /* push */
	   si new_stack_item;
           new_stack_item.ctx = A_cur_pre;
           new_stack_item.eocs = A_cur_pre + size[A_cur_pre];
           stack[stack_top++] = new_stack_item;
           if (stack_top >= max_stack_size) {
               GDKerror("%s: ancestor stack grew beyond stack-size.\n", name);
               GDKfree(stack);
               BATfree(res);
               return(GDK_FAIL);
           }
	}
	A_cur++;
      }
      
      /* output everything that is on the stack (the ancestors) */
      /* It has started before Dstart and since it's a tree, */
      /* it has to end after Dend. */
      if (free < stack_top)
      {
     	BATsetcount(res, hdst - sdst);
        BUN sz = BATgrows(res);
        while (sz < ((hdst - sdst) + stack_top)) 
          sz = 2 * sz;
        res = BATextend(res, sz);
        if (res == NULL)
    	{ 
       	  GDKerror("%s: could not extend result BAT.\n", name);
          GDKfree(stack);
          BATfree(res);
          return(GDK_FAIL);
    	}
        sdst = (oid*)Hloc(res, BUNfirst(res));
        hdst = (oid*)Hloc(res, BUNlast(res));
        tdst = (oid*)Tloc(res, BUNlast(res));
        free = sz - BATcount(res) - stack_top;
      } else {
          free -= stack_top;
      }
     
      for (i=0;i<stack_top;i++) {
        *hdst++ = stack[i].ctx;
        *tdst++ = D_cur_pre;
      }
      D_cur++;
    }
     /* it is possible there are still ancestor candidates left on the stack, but we are out of descendants, so they starve... */
    
    /* ----------------------------- tidy up -------------------------------------- */
     GDKfree(stack); 
	
     BATsetcount(res, hdst - sdst);
     res->batDirty = TRUE;
     res->tsorted = GDK_SORTED;
     res->hsorted = FALSE;
     BATset(res, TRUE);
     
     *result = res;    
     return(GDK_SUCCEED);
}

int CMDtreemergejoin_sort_unnested(BAT **result, BAT *Astart, BAT *nid_size, BAT *Dstart) {

    /* ---------------------------- declarations ------------------------------------ */
    char *name = "TJ_treemergejoin_sort_unnested";
    BAT *res = *result;
    BUN D_cur, D_last, 
        A_cur, A_last;
    BATiter Ai, Di;
    oid D_cur_pre;
    int *size;
    BUN free;	
    oid *sdst = NULL, *hdst = NULL, *tdst = NULL;
    
    /* ------------------------------- checks ---------------------------------------- */
    if (!(BATtordered(Astart)&1)) { 
        GDKerror("%s: Ancestor pre BAT not sorted (on start).\n",name); 
        return(GDK_FAIL);
    }
    if (!(BATtordered(Dstart)&1)) { 
        GDKerror("%s: Descendant BAT not sorted (on start).\n",name); 
        return(GDK_FAIL);
    }
    if (nid_size->ttype != TYPE_int) {
        GDKerror("%s: tail of size BAT must be type INT.\n", name);
        return(GDK_FAIL);
    }
    if (nid_size->htype != TYPE_void) {
        GDKerror("%s: head (oid) of size BAT must NOT be materialized.\n", name);
        return(GDK_FAIL);
    }
    if (BATcount(Astart) == 0 || BATcount(nid_size) == 0 || BATcount(Dstart) == 0)
    {
        res = BATnew(TYPE_oid, TYPE_oid, 0);
        *result = res;    
        return(GDK_SUCCEED);
    }

    /* ----------------------------- initialize -------------------------------------- */
    // the size of the bat may not be correct (could be more, could be less)
    free = BATcount(Dstart);
    res = BATnew(TYPE_oid, TYPE_oid, free); 
    if (res == NULL) 
    { 
       GDKerror("%s: could not allocate result BAT.\n", name);
       return(GDK_FAIL);
    }
    free = BATcapacity(res);
    
    size = ((int*) Tloc(nid_size, BUNfirst(nid_size))) - (int)nid_size->hseqbase;
    D_cur = BUNfirst(Dstart);
    D_last = BUNlast(Dstart);  
    A_cur = BUNfirst(Astart);
    A_last = BUNlast(Astart);
    Ai = bat_iterator(Astart);
    Di = bat_iterator(Dstart);
    sdst = hdst = (oid*)Hloc(res, BUNlast(res));
           tdst = (oid*)Tloc(res, BUNlast(res));

    /* -------------------------------- main ---------------------------------------- */
    
    /* skip descendant candidates before the next ancestor candidate */
    while(D_cur < D_last && *(oid*)Tloc(Dstart, D_cur) <= *(oid*)BUNtail(Ai,A_cur))
      D_cur++; 
      
    while(D_cur < D_last && A_cur < A_last) {
      
      /* skip ancestor candidates before the next descendant candidate */
      D_cur_pre = *(oid*)Tloc(Dstart, D_cur);
      /* poor man's binary search / exploiting forward scan */ 
      while (A_cur+1048576 < A_last && *(oid*)Tloc(Astart, A_cur+1048576) < D_cur_pre)
          A_cur += 1048576; 
      while (A_cur+32768 < A_last && *(oid*)Tloc(Astart, A_cur+32768) < D_cur_pre)
          A_cur += 32768; 
      while (A_cur+1024 < A_last && *(oid*)Tloc(Astart, A_cur+1024) < D_cur_pre)
          A_cur += 1024;  
      while (A_cur+1 < A_last && *(oid*)Tloc(Astart, A_cur+1) < D_cur_pre)
          A_cur++;

      /* write to result */ 
      while (D_cur < D_last && *(oid*)Tloc(Dstart, D_cur) <= (*(oid*)BUNtail(Ai, A_cur) + size[*(oid*)BUNhead(Ai, A_cur)])) {
          *hdst++ = *(oid*)BUNhead(Ai, A_cur);
          *tdst++ = *(oid*)BUNhead(Di, D_cur);
          D_cur++;
      }
      /* this ancestor cannot have further results (tree properties) */
      A_cur++;
    
      /* skip descendant candidates before the next ancestor candidate */
      if (A_cur < A_last)
          while(D_cur < D_last && *(oid*)Tloc(Dstart, D_cur) <= *(oid*)Tloc(Astart,A_cur))
              D_cur++; 
    }
    
    /* ----------------------------- tidy up -------------------------------------- */
    BATsetcount(res, hdst - sdst);
    res->batDirty = TRUE;
    if (BAThordered(Astart)&1) res->hsorted = GDK_SORTED;
    if (BAThordered(Dstart)&1) res->tsorted = GDK_SORTED;
    BATset(res, TRUE);
    
    *result = res;    
    return(GDK_SUCCEED);
}

int CMDtreemergejoin_unnested_nid(BAT **result, BAT *Astart, BAT *nid_size, BAT *Dstart) {

    /* ---------------------------- declarations ------------------------------------ */
    char *name = "TJ_treemergejoin_unnested_nid";
    BAT *res = *result;
    BUN D_cur, D_last, 
        A_cur, A_last;
    BATiter Ai, Di;
    oid D_cur_pre;
    int *size;
    BUN free;	
    oid *sdst = NULL, *hdst = NULL, *tdst = NULL;
    
    /* ------------------------------- checks ---------------------------------------- */
    if (!(BATtordered(Astart)&1)) { 
        GDKerror("%s: Ancestor BAT not sorted on pre.\n",name); 
        return(GDK_FAIL);
    }
    if (!(BATtordered(Dstart)&1)) { 
        GDKerror("%s: Descendant BAT not sorted on pre.\n",name); 
        return(GDK_FAIL);
    }
    if (nid_size->ttype != TYPE_int) {
        GDKerror("%s: tail of size BAT must be type INT.\n", name);
        return(GDK_FAIL);
    }
    if (nid_size->htype != TYPE_void) {
        GDKerror("%s: head (oid) of size BAT must NOT be materialized.\n", name);
        return(GDK_FAIL);
    }
    if (BATcount(Astart) == 0 || BATcount(nid_size) == 0 || BATcount(Dstart) == 0)
    {
        res = BATnew(TYPE_oid, TYPE_oid, 0);
        *result = res;    
        return(GDK_SUCCEED);
    }

    /* ----------------------------- initialize -------------------------------------- */
    // the size of the bat may not be correct (could be more, could be less)
    free = BATcount(Dstart);
    res = BATnew(TYPE_oid, TYPE_oid, free); 
    if (res == NULL) 
    { 
       GDKerror("%s: could not allocate result BAT.\n", name);
       return(GDK_FAIL);
    }
    free = BATcapacity(res);
    
    size = ((int*) Tloc(nid_size, BUNfirst(nid_size))) - (int)nid_size->hseqbase;
    D_cur = BUNfirst(Dstart);
    D_last = BUNlast(Dstart);  
    A_cur = BUNfirst(Astart);
    A_last = BUNlast(Astart);
    Ai = bat_iterator(Astart);
    Di = bat_iterator(Dstart);
    sdst = hdst = (oid*)Hloc(res, BUNlast(res));
           tdst = (oid*)Tloc(res, BUNlast(res));

    /* -------------------------------- main ---------------------------------------- */
    
    /* skip descendant candidates before the next ancestor candidate */
    while(D_cur < D_last && *(oid*)Tloc(Dstart, D_cur) <= *(oid*)BUNtail(Ai,A_cur))
      D_cur++; 
      
    while(D_cur < D_last && A_cur < A_last) {
      
      /* skip ancestor candidates before the next descendant candidate */
      D_cur_pre = *(oid*)Tloc(Dstart, D_cur);
      /* poor man's binary search / exploiting forward scan */ 
      while (A_cur+1048576 < A_last && *(oid*)Tloc(Astart, A_cur+1048576) < D_cur_pre)
          A_cur += 1048576; 
      while (A_cur+32768 < A_last && *(oid*)Tloc(Astart, A_cur+32768) < D_cur_pre)
          A_cur += 32768; 
      while (A_cur+1024 < A_last && *(oid*)Tloc(Astart, A_cur+1024) < D_cur_pre)
          A_cur += 1024;  
      while (A_cur+1 < A_last && *(oid*)Tloc(Astart, A_cur+1) < D_cur_pre)
          A_cur++;

      /* write to result */ 
      while (D_cur < D_last && *(oid*)Tloc(Dstart, D_cur) <= (*(oid*)BUNtail(Ai, A_cur) + size[*(oid*)BUNhead(Ai, A_cur)])) {
          *hdst++ = *(oid*)BUNhead(Ai, A_cur);
          *tdst++ = *(oid*)BUNhead(Di, D_cur);
          D_cur++;
      }
      /* this ancestor cannot have further results (tree properties) */
      A_cur++;
    
      /* skip descendant candidates before the next ancestor candidate */
      if (A_cur < A_last)
          while(D_cur < D_last && *(oid*)Tloc(Dstart, D_cur) <= *(oid*)Tloc(Astart,A_cur))
              D_cur++; 
    }
    
    /* ----------------------------- tidy up -------------------------------------- */
    BATsetcount(res, hdst - sdst);
    res->batDirty = TRUE;
    if (BAThordered(Astart)&1) res->hsorted = GDK_SORTED;
    else res->hsorted = FALSE;
    if (BAThordered(Dstart)&1) res->tsorted = GDK_SORTED;
    else res->tsorted = FALSE;
    BATset(res, TRUE);
    
    *result = res;    
    return(GDK_SUCCEED);
}

int CMDtreemergejoin_unnested_pre(BAT **result, BAT *Astart, BAT *pre_size, BAT *Dstart) {

    /* ---------------------------- declarations ------------------------------------ */
    char *name = "TJ_treemergejoin_unnested_pre";
    BAT *res = *result;
    BUN D_cur, D_last, 
        A_cur, A_last;
    oid D_cur_pre;
    int *size;
    BUN free;	
    oid *sdst = NULL, *hdst = NULL, *tdst = NULL;
    
    /* ------------------------------- checks ---------------------------------------- */
    if (!(BAThordered(Astart)&1)) { 
        GDKerror("%s: Ancestor pre BAT not sorted (on start).\n",name); 
        return(GDK_FAIL);
    }
    if (!(BAThordered(Dstart)&1)) { 
        GDKerror("%s: Descendant BAT not sorted (on start).\n",name); 
        return(GDK_FAIL);
    }
    if (pre_size->ttype != TYPE_int) {
        GDKerror("%s: tail of size BAT must be type INT.\n", name);
        return(GDK_FAIL);
    }
    if (pre_size->htype != TYPE_void) {
        GDKerror("%s: head (oid) of size BAT must NOT be materialized.\n", name);
        return(GDK_FAIL);
    }
    if (BATcount(Astart) == 0 || BATcount(pre_size) == 0 || BATcount(Dstart) == 0)
    {
        res = BATnew(TYPE_oid, TYPE_oid, 0);
        *result = res;    
        return(GDK_SUCCEED);
    }

    /* ----------------------------- initialize -------------------------------------- */
    // the size of the bat may not be correct (could be more, could be less)
    free = BATcount(Dstart);
    res = BATnew(TYPE_oid, TYPE_oid, free); 
    if (res == NULL) 
    { 
       GDKerror("%s: could not allocate result BAT.\n", name);
       return(GDK_FAIL);
    }
    free = BATcapacity(res);
    
    size = ((int*) Tloc(pre_size, BUNfirst(pre_size))) - (int)pre_size->hseqbase;
    D_cur = BUNfirst(Dstart);
    D_last = BUNlast(Dstart);  
    A_cur = BUNfirst(Astart);
    A_last = BUNlast(Astart);
    sdst = hdst = (oid*)Hloc(res, BUNlast(res));
           tdst = (oid*)Tloc(res, BUNlast(res));

    /* -------------------------------- main ---------------------------------------- */
    
    /* skip descendant candidates before the next ancestor candidate */
    while(D_cur < D_last && *(oid*)Hloc(Dstart, D_cur) <= *(oid*)Hloc(Astart,A_cur))
      D_cur++; 
      
    while(D_cur < D_last && A_cur < A_last) {
      
      /* skip ancestor candidates before the next descendant candidate */
      D_cur_pre = *(oid*)Hloc(Dstart, D_cur);
      /* poor man's binary search / exploiting forward scan */ 
      while (A_cur+1048576 < A_last && *(oid*)Hloc(Astart, A_cur+1048576) < D_cur_pre)
          A_cur += 1048576; 
      while (A_cur+32768 < A_last && *(oid*)Hloc(Astart, A_cur+32768) < D_cur_pre)
          A_cur += 32768; 
      while (A_cur+1024 < A_last && *(oid*)Hloc(Astart, A_cur+1024) < D_cur_pre)
          A_cur += 1024;  
      while (A_cur+1 < A_last && *(oid*)Hloc(Astart, A_cur+1) < D_cur_pre)
          A_cur++;

      /* write to result */ 
      while (D_cur < D_last && *(oid*)Hloc(Dstart, D_cur) <= (*(oid*)Hloc(Astart, A_cur) + size[*(oid*)Hloc(Astart, A_cur)])) {
          *hdst++ = *(oid*)Hloc(Astart, A_cur);
          *tdst++ = *(oid*)Hloc(Dstart, D_cur);
          D_cur++;
      }
      /* this ancestor cannot have further results (tree properties) */
      A_cur++;
    
      /* skip descendant candidates before the next ancestor candidate */
      if (A_cur < A_last)
          while(D_cur < D_last && *(oid*)Hloc(Dstart, D_cur) <= *(oid*)Hloc(Astart,A_cur))
              D_cur++; 
    }
    
    /* ----------------------------- tidy up -------------------------------------- */
    BATsetcount(res, hdst - sdst);
    res->batDirty = TRUE;
    res->hsorted = GDK_SORTED;
    res->tsorted = GDK_SORTED;
    BATset(res, TRUE);
    
    *result = res;    
    return(GDK_SUCCEED);
}

bat *
pftijah_prelude(void)
{
    if (!TBL_module_lookup("pathfinder"))
        GDKerror("pathfinder must be loaded first.");
    termdb_prelude();
    return NULL;
}

void
pftijah_epilogue(void)
{
}

@
/* vim:set shiftwidth=4 expandtab: */
