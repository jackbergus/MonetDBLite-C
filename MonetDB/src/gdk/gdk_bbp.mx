@' The contents of this file are subject to the MonetDB Public License
@' Version 1.1 (the "License"); you may not use this file except in
@' compliance with the License. You may obtain a copy of the License at
@' http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html
@'
@' Software distributed under the License is distributed on an "AS IS"
@' basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
@' License for the specific language governing rights and limitations
@' under the License.
@'
@' The Original Code is the MonetDB Database System.
@'
@' The Initial Developer of the Original Code is CWI.
@' Portions created by CWI are Copyright (C) 1997-2005 CWI.
@' All Rights Reserved.

@f gdk_bbp
@a M. L. Kersten, P. Boncz, N. J. Nes
@* BAT Buffer Pool (BBP)
The BATs created and loaded are collected in a BAT buffer pool.  
The Bat Buffer Pool has a number of functions:
@table @code

@item[administration and lookup]
The BBP is a directory which contains status information about all known BATs. 
This interface may be used very heavily, by data-intensive applications.
To eliminate all overhead, read-only access to the BBP may be done by 
table-lookups. The integer index type for these lookups is @%bat@, as 
retrieved by @%BBPcacheid(b)@. The @%bat@ zero is reserved for the nil bat. 

@item[persistence]
The BBP is made persistent by saving it to the dictionary file 
called @emph{BBP.dir} in the database. The dictionary can always be 
reconstructed from the @emph{ .desc} files. Its main role is to 
speed-up system restart, because now it requires just a few IOs 
instead of a complete directory scan and reading all descriptors
to find all BATs.

When the number of BATs rises, having all files in one directory
becomes a bottleneck.  The BBP therefore implements a scheme that distributes
all BATs in a growing directory tree with at most 64 BATs stored in one node.

@item[buffer management]
The BBP is responsible for loading and saving of BATs to disk. It also 
contains routines to unload BATs from memory when memory resources 
get scarce. For this purpose, it administers BAT memory reference 
counts (to know which BATs can be unloaded) and BAT usage statistics 
(it unloads the least recently used BATs).

@item[recovery]
When the database is closed or during a run-time syncpoint, the system
tables must be written to disk in a safe way, that is immune for system 
failures (like disk full). To do so, the BBP implements an atomic commit and 
recovery protocol: first all files to be overwritten are moved to a BACKUP/
dir. If that succeeds, the writes are done. If that also fully succeeds
the BACKUP/ dir is renamed to DELETE_ME/ and subsequently deleted.
If not, all files in BACKUP/ are moved back to their original location.

@item [unloading]
Bats which have a logical reference (ie. a lrefs > 0) but no memory
reference (refcnt == 0) can be unloaded. Unloading dirty bats means,
moving the original (committed version) to the BACKUP/ dir and saving
the bat. This complicates the commit and recovery/abort issues.
The commit has to check if the bat is already moved. And The recovery
has to always move back the files from the BACKUP/ dir.

@item [reference counting]
Bats use have two kinds of references: logical and physical (pointer) ones.
Both are administered with the BBPincref/BBPdecref routines. For 
backward compatibility, we maintain BBPfix/BBPunfix as shorthands
for the adjusting the pointer references.

@item [share counting]
Views use the heaps of there parent bats. To save guard this, the
parent has a shared counter, which is incremented and decremented
using BBPshare and BBPunshare. These functions make sure the
parent is memory resident as required because of the 'pointer' sharing.
@end table
@{
@h
#ifndef _GDK_BBP_H_
#define _GDK_BBP_H_

#define BBPINIT		2048
#define BBPMAXSIZE	1024*1024

#define BBPLOADED	1	/* set if bat in memory */
#define BBPSWAPPED	2	/* set if dirty bat is not in memory */
#define BBPTMP          4	/* set if non-persistent bat has image on disk */
#define BBPDELETED	16	/* set if bat persistent at last commit is now transient */
#define BBPEXISTING	32	/* set if bat was already persistent at end of last commit */
#define BBPNEW 		64	/* set if bat has become persistent since last commit */
#define BBPPERSISTENT	96	/* mask for currently persistent bats */
#define BBPSTATUS	127

#define BBPUNLOADING	128	/* set while we are unloading */
#define BBPLOADING	256	/* set while we are loading */
#define BBPSAVING       512	/* set while we are saving */
#define BBPWAITING      896
#define BBPRENAMED	1024	/* set when bat is renamed in this transaction */

#define BBPTRIM_ALL	(((size_t)1) << (sizeof(size_t)*8 - 2))	/* very large positive size_t */
#define BBPLASTUSED(x)  ((x) & 0x7fffffff)	/* stamp is always a positive int */

gdk_export int BBPin;		/* BATs swapped into BBP  */
gdk_export int BBPout;		/* BATs swapped out of BBP */
gdk_export int BBPsize;		/* current occupied size of BBP array */

/* global calls */
gdk_export void BBPinit(void);
gdk_export void BBPexit(void);
gdk_export int BBPdir(int previous);

/* update interface */
gdk_export void BBPclear(bat bid);
gdk_export bat BBPinsert(BAT *b);
gdk_export void BBPcacheit(BAT *b);
gdk_export void BBPuncacheit(bat bid);
gdk_export int BBPreclaim(BAT *b);
gdk_export int BBPsave(BAT *b);
gdk_export int BBPrename(bat bid, str nme);
gdk_export BAT * BBPrecycle(int ht, int tt, size_t cap);

/* query interface */
gdk_export bat BBPindex(str nme);
gdk_export BAT *BBPdescriptor(bat b);

/* swapping interface */
gdk_export int BBPrecover(void);
gdk_export lng BBPdiskscan(void);
gdk_export int BBPsync(int commit);
gdk_export int BBPincref(bat b, int logical);
gdk_export void BBPkeepref(bat i);
gdk_export void BBPreleaseref(bat i);
gdk_export void BBPreleaselref(bat i);
gdk_export int BBPdecref(bat b, int logical);
gdk_export void BBPshare(bat b);
gdk_export void BBPunshare(bat b);
gdk_export void BBPextend(dbl factor, int buildhash);

gdk_export void BBPatom_drop(int atom);
gdk_export void BBPatom_load(int atom);
@
@c
#include "gdk.h"
#include "gdk_storage.h"
@}
@-
The BBP has now a fixed address, so re-allocation due to a growing BBP 
caused by one thread does not disturb reads to the old entries by another.
This is implemented using anonymous virtual memory; extensions on the same 
address are guaranteed because a large non-committed VM area is requested 
initially. New slots in the BBP are found at O(1) by keeping a freelist
that uses the 'next' field in the BBPrec records.
@{
@c
BBPrec *BBP = NULL;		/* fixed base VM address of BBP array */
bat BBPmaxsize = BBPMAXSIZE;	/* size of non-commited VM BBP array */
bat BBPlimit = 0;		/* current committed VM BBP array */
bat BBPsize = 0;		/* current used size of BBP array */
bat BBP_free = 0;		/* first free slot in BBP array */

@}
@-
The hash index uses a bucket index (int array) of size mask that is
tuned for perfect hashing (1 lookup). The bucket chain uses the 'next'
field in the BBPrec records.
@{
@h
#define BBPnamecheck(s) (((s)[0]=='t' && (s)[1]=='m' && (s)[2]=='p' &&\
			  (s)[3]=='_')?strtol(s+4,NULL,8):0)

@c
bat *BBP_hash = NULL;		/* BBP logical name hash buckets */
bat BBP_mask = 0;		/* number of buckets = & mask */

static void BBPspin(bat bid, str debug, int event);
static int BBPfree(BAT *b, str calledFrom );
static int BBPdestroy(BAT *b);
static void BBPuncacheit_(bat bid, int unloaddesc);


static int stamp = 0;
static INLINE int
BBPstamp(void)
{
	return ++stamp;
}

static void
BBPsetstamp(int newstamp)
{
	stamp = newstamp;
}


static void
BBP_insert(bat i)
{
	bat idx = (bat) (strHash(BBP_logical(i)) & BBP_mask);

	BBP_next(i) = BBP_hash[idx];
	BBP_hash[idx] = i;
}

static void
BBP_delete(bat i)
{
	bat *h = BBP_hash;
	str s = BBP_logical(i);
	bat idx = (bat) (strHash(s) & BBP_mask);

	for (h += idx; (i = *h) != 0; h = &BBP_next(i)) {
		if (strcmp(BBP_logical(i), s) == 0) {
			*h = BBP_next(i);
			break;
		}
	}
}

@-
other globals
@c
int BBP_curstamp = 0;		/* unique stamp for creation of a bat */
MT_Id BBP_notrim = ~((MT_Id) 0);	/* avoids BBPtrim when we really do not want it */
int BBP_dirty = 0;		/* BBP structures modified? */
int BBPin = 0;			/* bats loaded statistic */
int BBPout = 0;			/* bats saved statistic */

@}

@+ BBP Consistency and Concurrency
While GDK provides the basic building blocks for an ACID system, in
itself it is not such a system, as we this would entail too much overhead
that is often not needed. Hence, some consistency control is left to the
user. The first important user constraint is that if a user updates a 
BAT, (s)he himself must assure that no-one else accesses this BAT. 

Concerning buffer management, the BBP carries out a swapping policy.
BATs are kept in memory till the memory is full. If the memory is full,
the malloc functions initiate BBP trim actions, that unload the coldest BATs 
that have a zero reference count. The second important user constraint 
is therefore that a user may only manipulate live BAT data in memory if it 
is sure that there is at least one reference count to that BAT.

The main BBP array is protected by two locks:
@table @code
@item[GDKcacheLock] 
this lock guards the free slot management in the BBP array.  The BBP 
operations that allocate a new slot for a new BAT (@%BBPinit@,@%BBPcacheit@), 
delete the slot of a destroyed BAT (@%BBPreclaim@), or rename a BAT 
(@%BBPrename@), hold this lock. It also protects all BAT (re)naming actions 
include (read and write) in the hash table with BAT names.
@item[GDKswapLock]
this lock guards the swap (loaded/unloaded) status of the BATs. Hence, all
BBP routines that influence the swapping policy, or actually carry out the
swapping policy itself, acquire this lock (e.g. @%BBPfix@,@%BBPunfix@).
Note that this also means that updates to the BBP\_status indicator array
must be protected by GDKswapLock. 

To reduce contention GDKswapLock was split into multiple locks; it is now 
an array of lock pointers which is accessed by GDKswapLock[ABS(bat)\&BBPLOCKMASK]
@end table

Routines that need both locks should first acquire the locks in the GDKswapLock 
array (in ascending order) and then GDKcacheLock (and release them in reverse order).

To obtain maximum speed, read operations to existing elements in the BBP are 
unguarded. As said, it is the users responsibility that the BAT that is being 
read is not being modified. BBP update actions that modify the BBP data structure 
itself are locked by the BBP functions themselves. Hence, multiple concurrent BBP read 
operations may be ongoing while at the same time at most one BBP write operation 
{\bf on a different BAT} is executing.  This holds for accesses to the public (quasi-)
arrays @%BBPcache@, @%BBPstatus@, @%BBPrefs@, @%BBPlogical@ and @%BBPphysical@. These 
arrays are called quasi as now they are actually stored together in one big BBPrec 
array called BBP, that is allocated in anonymous VM space, so we can reallocate 
this structure without changing the base address (a crucial feature if read 
actions are to go on unlocked while other entries in the BBP may be modified). 
@{
@h
#define BBP_status_set(bid, mode, nme) {				\
		BBP_status(bid) = mode;					\
}

#define BBP_status_on(bid, flags, nme) \
		BBP_status_set(bid, BBP_status(bid) | flags, nme);

#define BBP_status_off(bid, flags, nme) \
		BBP_status_set(bid, BBP_status(bid) & ~(flags), nme);

#define BBP_unload_cnt(bid, nme) {						\
		gdk_set_lock(GDKunloadLock, nme);				\
		BBPunloadCnt++;							\
		gdk_unset_lock(GDKunloadLock, nme); 				}

#define BBP_unload_on(bid, nme) {						\
		BBP_status_on(bid, BBPUNLOADING, nme);				\
		BBP_unload_cnt(bid, nme); 					}

#define BBP_unload_off(bid, nme) {						\
		BBP_status_off(bid, BBPUNLOADING, nme);				\
		gdk_set_lock(GDKunloadLock, nme);				\
		if (--BBPunloadCnt == 0) gdk_signal_cond(GDKunloadCond, nme);	\
		assert(BBPunloadCnt >= 0);					\
		gdk_unset_lock(GDKunloadLock, nme);				}
@c
static MT_Id locked_by = 0;

static INLINE MT_Id
BBP_getpid(void)
{
	MT_Id x = MT_getpid();

	return x;
}

static int BBPunloadCnt = 0;

void
BBPlock(str nme)
{
	int i;

	/* wait for all pending unloads to finish */
	gdk_set_lock(GDKunloadLock, nme);
	if (BBPunloadCnt > 0)
		gdk_wait_cond(GDKunloadCond, GDKunloadLock, nme);

	gdk_set_lock(GDKtrimLock, nme);
	BBP_notrim = BBP_getpid();
	gdk_set_lock(GDKcacheLock, nme);
	for (i = 0; i <= BBPLOCKMASK; i++)
		gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], nme);
	locked_by = BBP_notrim;

	gdk_unset_lock(GDKunloadLock, nme);
}

void
BBPunlock(str nme)
{
	int i;

	for (i = BBPLOCKMASK; i >= 0; i--)
		gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], nme);
	gdk_unset_lock(GDKcacheLock, nme);
	BBP_notrim = 0;
	locked_by = 0;
	gdk_unset_lock(GDKtrimLock, nme);
}


void
BBPinithash(void)
{
	bat i = BBPsize;

	for (BBP_mask = 1; (BBP_mask << 1) <= BBPlimit; BBP_mask <<= 1)
		;
	BBP_hash = (bat *) GDKmalloc(BBP_mask * sizeof(bat));
	memset(BBP_hash, 0, BBP_mask * sizeof(bat));
	BBP_mask--;

	while (--i > 0) {
		if (BBPvalid(i)) {
			if (BBPnamecheck(BBP_logical(i)) == 0) {
				BBP_insert(i);
			}
			if (BBP_logical(-i)) {
				BBP_insert(-i);
			}
		} else {
			BBP_next(i) = BBP_free;
			BBP_free = i;
		}
	}
}

@-
BBPextend must take the trimlock, as it is called when other BBP locks are
held and it will allocate memory. This could trigger a BBPtrim, causing deadlock.
@c
void
BBPextend(dbl factor, int buildhash)
{
	int newsize = (int) (BBPlimit * factor);
	size_t maxsize = MAX(newsize * 2, BBPmaxsize) * sizeof(BBPrec);

	gdk_set_lock(GDKtrimLock, "BBPextend");
	BBP_notrim = BBP_getpid();
	BBP = (BBPrec *) GDKvmrealloc(BBP, BBPlimit * sizeof(BBPrec), newsize * sizeof(BBPrec), BBPmaxsize * sizeof(BBPrec), &maxsize, 1);
	if (BBP == NULL)
		GDKfatal("BBPextend: failed to extend BAT pool\n");

	memset(BBP + BBPlimit, 0, (newsize - BBPlimit) * sizeof(BBPrec));
	BBPlimit = newsize;
	BBPmaxsize = (int) (maxsize / sizeof(BBPrec));

	if (buildhash) {
		GDKfree(BBP_hash);
		BBP_hash = NULL;
		BBP_free = 0;
		BBPinithash();
	}
	BBP_notrim = 0;
	gdk_unset_lock(GDKtrimLock, "BBPextend");
}

static INLINE char *
BBPparse(str *cur)
{
	char *base, *c = *cur;

	for (c++; GDKisspace(*c); c++)
		;
	for (base = c; !(GDKisspace(*c) || *c == ','); c++)
		;
	*c = 0;
	*cur = c;
	return base;
}

@T
In order to start, we read the BBP.dir in the bat/ directory, BUT:
- if there is a BACKUP/ directory, we try to use that 
- if BBP.dir is lost, we try BBP.bak 
- if we do not use the original BBP.dir; move the previous to BBP.bak
@c
static int backuped_files = 0, backuped_dir = 0;

static int
prepare_backup(void)
{
	int ret = 0;

	if (backuped_files == 0) {
		struct stat st;

		ret = GDKremovedir(DELDIR);	/* remove previous DELETE_ME dir */
		if (ret == 0) {
			if (stat(BAKDIR, &st) == 0) {
				ret = BBPrecover();	/* BAKDIR still exists, must finish recover first! */
			}
			if (ret == 0) {
				ret = mkdir(BAKDIR, 0755);
				IODEBUG THRprintf(GDKerr, "mkdir %s = %d\n", BAKDIR, ret);
			}
		}
		if (ret == 0) {
		  	backuped_dir = 0; 
		}
	}
	if (ret == 0 && !backuped_dir) {
		/* a valid backup dir *must* at least contain BBP.dir */ 
		if (GDKmove(BATDIR, "BBP", "dir", BAKDIR, "BBP", "dir")) {
			ret = -1;
		} else {
		  	backuped_dir = 1; 
		}
	}
	if (ret == 0)
		backuped_files++;
	return ret;
}

static INLINE str
BBPtmpname(str s, int len, bat i)
{
	s[--len] = 0;
	while(i>0) {
		s[--len] = '0' + (i & 7);
		i >>= 3;
	}
	s[--len] = '_';
	s[--len] = 'p';
	s[--len] = 'm';
	s[--len] = 't';
	return s + len;
}

static 
int recover_dir(int direxists) 
{
	if (direxists) {
		/* just try; don't care about these nonvital files */
		GDKunlink(BATDIR, "BBP", "bak");
		GDKmove(BATDIR, "BBP", "dir", BATDIR, "BBP", "bak");
	}
 	return GDKmove(BAKDIR, "BBP", "dir", BATDIR, "BBP", "dir");
}

#define CONTINUE_IF_NO_SIZES_IN_BBP 1 /* provide backward compatibility */
void
BBPinit(void)
{
	FILE *fp = GDKfilelocate("BBP", "rb", "dir");
	int i = 0, max_stamp = 0, min_stamp = 0x7fffffff;
	char *s, logical[1024], batname[1024], path[1024];
	char *c, buffer[3000];
	struct stat st;
	oid BBPoid = 0;
	

	/* try to obtain a BBP.dir */
	GDKfilepath(path, BAKDIR, "BBP", "dir");
	if (stat(path, &st) == 0) {
		/* backup exists: *must* use it */
		if (fp) fclose(fp);
		fp = recover_dir(fp != NULL)?
			NULL:GDKfilelocate("BBP", "rb", "dir");
	} else if (fp == NULL) {
		/* try to use a BBP.bak */
		GDKfilepath(path, BAKDIR, "BBP", "bak");
		if (stat(path, &st)) {
			/* no BBP.bak (nor BBP.dir or BACKUP/BBP.dir): create a new one */
			GDKwarning("BBPdir: initializing BBP.\n");
			if (BBPdir(FALSE) == 0)
				fp = GDKfilelocate("BBP", "rb", "dir");
		} else if (GDKmove(BATDIR, "BBP", "bak", BATDIR, "BBP", "dir") == 0) {
			GDKwarning("BBPinit: reverting to dir saved in BBP.bak.\n");
			fp = GDKfilelocate("BBP", "rb", "dir");
		}
	}
	if (fp == NULL) {
		/* now it is time for real panic */
		GDKfatal("BBPinit: could not write %sBBP.dir\n", BATDIR);
	}

	/* scan the BBP.dir to obtain its current size */
	BBPlimit = BBPINIT;
	BBPsize = 1;
	if ((c = fgets(buffer, sizeof(buffer), fp)) != NULL) {
		int ptrsize, oidsize;
		if (sscanf(c, "%d %d", &ptrsize, &oidsize) != 2) {
#ifdef CONTINUE_IF_NO_SIZES_IN_BBP
			GDKwarning("old BBP without size indications: assuming compatible with current server");
			GDKwarning("if this assumption is not correct, quit() immediately!");
			GDKwarning("otherwise, first commit() to write a new BBP");
			ptrsize = SIZEOF_SIZE_T;
			oidsize = SIZEOF_OID;
#else
			GDKerror("old BBP without size indications");
			GDKerror("add a line to the top of the BBP file with two numbers:");
			GDKerror("the size (in bytes) of pointers and the size (in bytes) of OIDs\nfor the server the BBP was created with");
			exit(1);
#endif
		} else {
			c = fgets(buffer, sizeof(buffer), fp);
		}
		if (ptrsize != SIZEOF_SIZE_T || oidsize != SIZEOF_OID) {
			GDKerror("database created with incompatible Mserver");
			exit(1);
		}
		if (c != NULL) {
			BBPoid = OIDread(c);
			if ((c = strstr(c, "BBPsize")) != NULL) {
				sscanf(c, "BBPsize=%d", &i);
				i = (int) (i * BATMARGIN);
				if (i > BBPlimit)
					BBPlimit = i;
			}
		}
	}


	/* alloc structures; try to reserve as much space as possible */
	for (;;) {
		size_t size = (size_t) BBPlimit * sizeof(BBPrec);
		size_t maxsize = (size_t) BBPmaxsize * sizeof(BBPrec);

		BBP = (BBPrec *) GDKvmalloc(size, &maxsize, 1);
		MT_alloc_register(BBP, maxsize, 'P');
		if (BBP && maxsize >= BBPmaxsize * sizeof(BBPrec)) {
			BBPmaxsize = (int) (maxsize / sizeof(BBPrec));
			break;
		}
		MT_alloc_register(BBP, maxsize, 'p');
		if (BBP)
			GDKvmfree(BBP, size, maxsize);
		if ((BBPmaxsize /= 2) < BBPlimit) {
			GDKfatal("BBPinit: could not alloc arena\n");
		}
	}
	memset(BBP, 0, BBPlimit * sizeof(BBPrec));
	MT_mmap_pin(BBP, BBPlimit * sizeof(BBPrec));

	/* scan the BBP.dir, and insert the BATs into the BBP */
	while ((c = fgets(buffer, sizeof(buffer), fp)) != NULL) {
		int j = 0;

		while (*c != '[')
			c++;
		for (c++; GDKisspace(*c); c++)
			;
		i = atoi(c);
		if (GDKisdigit(*c) && i > 0) {
			for (c++; *c != ','; c++)
				;
			for (c++; GDKisspace(*c); c++)
				;
			j = atoi(c);
			if (!GDKisdigit(*c))
				c--;
			else
				for (c++; *c != ','; c++)
					;
		} else {
			GDKerror("BBPinit: ignore line %s\n", buffer);

			continue;
		}
		if (i >= BBPsize) {
			BBPsize = i + 1;
			if (BBPsize >= BBPlimit)
				BBPextend(BATMARGIN, FALSE);
		}
		strcpy(batname, BBPparse(&c));
		BBP_status_set(i, BBPEXISTING | (j & ~(BBPLOADED | BBPNEW)), "BBPinit");
		BBP_physical(i) = GDKstrdup(BBPparse(&c));
		BBP_lastused(i) = BBPLASTUSED(atoi(BBPparse(&c)));
		if (BBP_lastused(i) > max_stamp)
			max_stamp = BBP_lastused(i);
		if (BBP_lastused(i) < min_stamp)
			min_stamp = BBP_lastused(i);
		BBP_lrefs(i) = 0;
		BBP_lrefs(i) = 1;	/* any BAT we encounter here is persistent, so has a logical reference */
		c = strchr(batname, '~');
		if (c && c == batname) {
			s = BBPtmpname(logical, 64, i);
		} else {
			if (c)
				*c = 0;
			strcpy(logical, batname);
			s = logical;
			j++;
		}
		/* the backup of the logical name is set too */
		BBP_logical(i) = GDKstrdup(s);
		BBP[ABS(i)].bak[(i)<0]= BBP_logical(i);
		i = -i;
		if (c && c[1]) {
			BBP_logical(i) = GDKstrdup(c + 1);
			BBP[ABS(i)].bak[(i)<0]= BBP_logical(i);
			j++;
		} else {
			BBP_logical(i) = NULL;
			BBP[ABS(i)].bak[(i)<0]= NULL;
		}
	}
	fclose(fp);

	/* normalize saved LRU stamps */
	if (min_stamp <= max_stamp) {
		for (i = 1; i < BBPsize; i++)
			if (BBPvalid(i))
				BBP_lastused(i) -= min_stamp;
		BBPsetstamp(max_stamp - min_stamp);
	}

	/* init hash table */
	BBPinithash();
	BBP_notrim = 0;

	if (BBPoid == 0) {
		OIDseed(OIDrand());	/* if not yet done, init oid */
	}
	OIDbase(BBPoid);

	/* will call BBPrecover if needed */
	if (prepare_backup()) {
		GDKfatal("BBPinit: cannot properly process %s.\n", BAKDIR);
	}

	/* cleanup any leftovers (must be done after BBPrecover) */
	BBPdiskscan();
}

@}
@- 
During the exit phase all non-persistent BATs are removed.
Upon exit the status of the BBP tables is saved on disk.
This function is called once and during the shutdown of the
server. Since shutdown may be issued from any thread (dangerous)
it may lead to interference in a parallel session.
@{
@c

void
BBPexit(void)
{
	bat i;

	if (!BBP)
		return;		/* AARGH */

	BBPlock("BBPexit");	/* stop all threads ever touching more descriptors */

	/* free all memory (just for leak-checking in Purify) */
	for (i = 0; i < BBPsize; i++) {
		if (BBPvalid(i)) {
			BAT *b = BBP_cache(i);

			if (b) {
				if (b->batParentid)
					VIEWdestroy(b);
				else
					BATfree(b);
			}
			BBPuncacheit_(i, TRUE);
			GDKfree(BBP_logical(i));
			BBP_logical(i) = NULL;
			BBP[ABS(i)].bak[(i)<0]= NULL;
		}
		if (BBP_physical(i)) {
			GDKfree(BBP_physical(i));
			BBP_physical(i) = NULL;
		}
	}
	GDKfree(BBP_hash);
	BBP_hash = 0;
}

@}
@-
The routine @%BBPdir@ creates the BAT pool dictionary file. 
It includes some information about the current state of affair in the pool.
The location in the buffer pool is saved for later use as well.
This is merely done for ease of debugging and of no importance to front-ends.
The tail of non-used entries is reclaimed as well. 
@{
@c
static int
new_bbpentry(stream *s, bat i)
{
	int r = stream_printf(s, "[  %d, %d, %s",
			      (int) i, BBP_status(i) & BBPPERSISTENT, BBPname(i));

	if (r < 0)
		return r;
	if (BBPvalid(-i)) {
		r = stream_printf(s, "~%s", BBPname(-i));
		if (r < 0)
			return r;
	}
	return stream_printf(s, ", %s, %d ]\n", BBP_physical(i), BBP_lastused(i));
}

int
BBPdir(int previous)
{
	FILE *fp = NULL;
	stream *s = NULL;
	bat i=0;

	if (previous && prepare_backup()) 
		return -1; /* TMsubcommit must assure a BAKDIR/BBP.dir */ 

	if (GDKdebug & 17)
		THRprintf(GDKerr, "#BBPdir: writing BBP.dir (%d bats).\n", (int) BBPsize);
	IODEBUG {
		THRprintf(GDKerr, "BBPdir start oid=");
		OIDwrite(GDKerr);
		THRprintf(GDKerr, "\n");
	}
	fp = (FILE *) GDKfilelocate("BBP", "wb", "dir");
	if (fp)
		s = file_wastream(fp, "BBP.dir");
	if (s && 
	    stream_printf(s, "%d %d\n", SIZEOF_SIZE_T, SIZEOF_OID) >= 0 &&
	    OIDwrite(s) == 0 &&
	    stream_printf(s, " BBPsize=%d\n", (int) BBPsize) >= 0)
	{
		for (i = 1; i < BBPsize; i++) {
			if (BBP_status(i) & (previous?BBPEXISTING:BBPPERSISTENT)) {
				if (new_bbpentry(s, i) < 0) break;
				IODEBUG new_bbpentry(GDKerr, i);
			}
		}
	}
	if (s) {
		stream_close(s);
		stream_destroy(s);
	} else if (fp) {
		fclose(fp);
	}
	IODEBUG THRprintf(GDKerr, "BBPdir end\n");

	if (i < BBPsize) {
		GDKsyserror("BBPdir failed:\n");
		return -1;
	}
	if (previous) {
		/* TMsubcommit: deleting BAKDIR/BBP.dir is the atomic commit */
		if (GDKunlink(BAKDIR, "BBP", "dir")) return -1; 
		backuped_dir = 0;
	}
	return 0;
}

@}
@+ BBP Readonly Interface

These interface functions do not change the BBP tables. If they only
access one specific BAT, the called must have ensured that no other thread
is modifying that BAT, therefore such functions do not need locking.
@{
@- 
BBP index lookup by BAT name:
@c
static INLINE bat
BBP_find(str nme, int lock)
{
	bat i = BBPnamecheck(nme);

	if (i > 0) {
		/* for tmp_X BATs, we already know X */
		str s = BBP_logical(i);

		if (i >= BBPsize || s == NULL || strcmp(s, nme)) {
			i = 0;
		}
	} else {
		/* must lock since hash-lookup traverses other BATs */
		if (lock)
			gdk_set_lock(GDKcacheLock, "BBPindex");
		for (i = BBP_hash[strHash(nme) & BBP_mask]; i; i = BBP_next(i)) {
			if (strcmp(BBP_logical(i), nme) == 0)
				break;
		}
		if (lock)
			gdk_unset_lock(GDKcacheLock, "BBPindex");
	}
	return i;
}

bat
BBPindex(str nme)
{
	return BBP_find(nme, TRUE);
}

BATstore *
BBPgetdesc(bat i)
{
	BAT *b = NULL;

	if (i < 0)
		i = -i;
	if (i != bat_nil && i < BBPsize && i && BBP_logical(i)) {
		str nme = BBP_physical(i);

		b = BBP_cache(i);
		if (b == NULL) 
			b = (BAT *) BBP_desc(i);
		if (b == NULL && nme) {
			int lock = locked_by ? BBP_getpid() != locked_by : 1;

			b = BATloaddesc(nme);
			IODEBUG THRprintf(GDKerr, "BATloaddesc(%s) = %d\n", nme, (b==NULL)?-1:0); 
			if (b == NULL) {
				GDKerror("BBPgetdesc: deleting illegal bat(%d) %s\n", i, nme);
				BBPclear(i);
			} else if (BBP_desc(i) == NULL) {
				if (lock)
					gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPgetdesc");
				BBP_desc(i) = (BATstore *) b;
				if (lock)
					gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPgetdesc");
			}
		}
		if (b)
			BBP_lastused(i) = BBPLASTUSED(BBPstamp());
	}
	return (BATstore *) b;
}

str
BBPlogical(bat bid, str buf)
{
	if (buf == NULL) {
		return NULL;
	} else if (BBPcheck(bid, "BBPlogical")) {
		if (bid < 0 && BBP_logical(bid) == NULL)
			bid = -bid;
		strcpy(buf, BBP_logical(bid));
	} else {
		*buf = 0;
	}
	return buf;
}

str
BBPphysical(bat bid, str buf)
{
	if (buf == NULL) {
		return NULL;
	} else if (BBPcheck(bid, "BBPphysical")) {
		strcpy(buf, BBP_physical(ABS(bid)));
	} else {
		*buf = 0;
	}
	return buf;
}

@}
@+ BBP Update Interface
Operations to insert, delete, clear, and modify BBP entries.
Our policy for the BBP is to provide unlocked BBP access for 
speed, but still write operations have to be locked.
@{
#ifdef DEBUG_THREADLOCAL_BATS
Create the shadow version (reversed) of a bat.
@- 
An existing BAT is inserted into the BBP 
@c
static INLINE str
BBPsubdir_recursive(str s, bat i)
{
	i >>= 6;
	if (i >= 64) {
		s = BBPsubdir_recursive(s, i);
	}
	i &= 63;
	*s++ = '0' + (i >> 3);
	*s++ = '0' + (i & 7);
	*s++ = DIR_SEP;
	return s;
}

static INLINE void
BBPgetsubdir(str s, bat i)
{
	if (i >= 64) {
		s = BBPsubdir_recursive(s, i);
	}
	*s = 0;
}

bat
BBPinsert(BAT *b)
{
	int lock = locked_by ? BBP_getpid() != locked_by : 1;
	str s;
	long_str dirname;
	bat i;

	/* ciritical section: get a new BBP entry */
	if (lock)
		gdk_set_lock(GDKcacheLock, "BBPinsert");

	/* find an empty slot */
	if (BBP_free <= 0) {
		if (++BBPsize >= BBPlimit)
			BBPextend(BATMARGIN, TRUE);
		else
			BBP_free = BBPsize - 1;
	}
	i = BBP_free;
	BBP_free = BBP_next(BBP_free);

	if (lock)
		gdk_unset_lock(GDKcacheLock, "BBPinsert");
	/* rest of the work outside the lock , as GDKstrdup/GDKmalloc may trigger a BBPtrim */

	/* fill in basic BBP fields for the new bat */

	if (++BBP_curstamp < 0)
		BBP_curstamp = 0;
	b->batCacheid = i;
	b->batStamp = BBP_curstamp;
	b->creator_tid = BBP_getpid();

	BBP_status_set(i, 0, "BBPentry");
	BBP_cache(i) = NULL;
	BBP_desc(i) = NULL;
	BBP_refs(i) = 1;	/* new bats have 1 pin */
	BBP_lrefs(i) = 0;	/* ie. no logical refs */

	if( i == BBPsize-1){ /* new entry */
		BBP[ABS(i)].bak[(i)<0] = NULL;
		BBP[ABS(i)].bak[(-i)<0] = NULL;
	}

	if( BBP[ABS(i)].bak[(i)<0] == NULL ){
		s = BBPtmpname(dirname, 64, i);
		BBP_logical(i) = GDKstrdup(s);
		BBP[ABS(i)].bak[(i)<0] = BBP_logical(i);
	} else 
		BBP_logical(i)=  BBP[ABS(i)].bak[(i)<0];
	BBP_logical(-i) = NULL;
	BBP[ABS(i)].bak[(-i)<0]= NULL;

	/* Keep the physical location around forever */
	if( BBP_physical(i) == NULL){
		BBPgetsubdir(dirname, i);
		BBP_physical(i) = (str) GDKmalloc(strlen(dirname) + strLen(BATgetId(b)) - 4);
		GDKfilepath(BBP_physical(i), dirname, BATgetId(b) + 4, NULL);

	BATDEBUG THRprintf(GDKerr, "%d = new %s(%s,%s)\n", (int) i, BATgetId(b), ATOMname(b->htype), ATOMname(b->ttype));
	}

	return i;
}

void
BBPcacheit(BAT *b)
{
	int lock = locked_by ? BBP_getpid() != locked_by : 1;
	bat i = b->batCacheid;
	int mode;
	BAT *bm = (BAT *) GDKmalloc(sizeof(BAT));	/* alloc before lock to prevent trim problems */

	if (i) {
		assert(i > 0);
	} else {
		i = BBPinsert(b);	/* bat was not previously entered */
	}
	if (lock)
		gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPcacheit");
	mode = (BBP_status(i) | BBPLOADED) & ~BBPWAITING;
	BBP_status_set(i, mode, "BBPcacheit");
	BBP_lastused(i) = BBPLASTUSED(BBPstamp() + ((mode == BBPLOADED) ? 150 : 0));
	BBP_desc(i) = (BATstore *) b;

	/* fill in the mirror record */
	bm->GDKversion = b->GDKversion;
	bm->batCacheid = -i;
	bm->batBuns = b->batBuns;
	bm->dims.headtype = b->dims.tailtype;
	bm->dims.tailtype = b->dims.headtype;
	bm->dims.headloc = b->dims.tailloc;
	bm->dims.tailloc = b->dims.headloc;
	bm->dims.headkey = b->dims.tailkey;
	bm->dims.tailkey = b->dims.headkey;
	bm->dims.headvarsized = b->dims.tailvarsized;
	bm->dims.tailvarsized = b->dims.headvarsized;
	bm->dims.bunwidth = b->dims.bunwidth;
	bm->dims.bunshift = b->dims.bunshift;
	bm->dims.hseq = b->dims.tseq;
	bm->dims.tseq = b->dims.hseq;
	bm->H = b->T;
	bm->T = b->H;
	bm->P = b->P;
	bm->U = b->U;
	bm->hhash = b->thash;
	bm->thash = b->hhash;

	/* cache it! */
	BBP_cache(i) = b;
	BBP_cache(-i) = bm;

	if (lock)
		gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPcacheit");
}

@
@%BBPuncacheit@ changes the BBP status to swapped out.  Currently only 
used in BBPfree (bat swapped out) and BBPclear (bat destroyed forever).
@c

void
BBPuncacheit(bat i)
{
	BBPuncacheit_(i, FALSE);
}

static void
BBPuncacheit_(bat i, int unloaddesc)
{
	if (i < 0)
		i = -i;
	if (BBPcheck(i, "BBPuncacheit")) {
		BAT *b = (BAT *) BBP_desc(i);

		if (b) {
			if (BBP_cache(i)) {
				BATDEBUG THRprintf(GDKerr, "uncache %d (%s)\n", (int) i, BBPname(i));

				BBP_cache(i) = BBP_cache(-i) = NULL;
				BBP_status_off(i, BBPLOADED, "BBPuncacheit");
			}
			if (unloaddesc) {
				BBP_desc(i) = NULL;
				BATdestroy(b);
			}
		}
	}
}

@- BBPclear
@%BBPclear@ removes a BAT from the BBP directory forever.
@c
void
BBPclear(bat i)
{
	int lock = locked_by ? BBP_getpid() != locked_by : 1;

	if (BBPcheck(i, "BBPclear")) {
		i = ABS(i);
		if (lock)
			gdk_set_lock(GDKcacheLock, "BBPclear");
		BATDEBUG {
			THRprintf(GDKerr, "clear %d (%s)\n", (int) i, BBPname(i));
		}
		BBPuncacheit_(i, TRUE);
		if (BBPnamecheck(BBP_logical(i)) == 0) {
			BBP_delete(i);
		}
		if (BBP_logical(-i)) {
			BBP_delete(-i);
			if( BBP_logical(-i) != BBP[ABS(i)].bak[(-i)<0])
				GDKfree(BBP_logical(-i));
			BBP_logical(-i) = NULL;
		}
		if( BBP_logical(i) != BBP[ABS(i)].bak[(i)<0])
			GDKfree(BBP_logical(i));
		BBP_logical(i) = NULL;
		/* keep the physical location around forever
		GDKfree(BBP_physical(i));
		BBP_physical(i) = NULL;
		*/
		BBP_status_set(i, 0, "BBPclear");
		BBP_refs(i) = 0;
		BBP_lrefs(i) = 0;
		BBP_next(i) = BBP_free;
		BBP_free = i;
		if (lock)
			gdk_unset_lock(GDKcacheLock, "BBPclear");
	}
}

@}
@- BBP rename

Each BAT has a logical name that is globally unique. Its reverse view can
also be assigned a name, that also has to be globally unique.  The batId is 
the same as the logical BAT name.

The default logical name of a BAT is tmp_X, where X is the batCacheid.
Apart from being globally unique, new logical bat names cannot be of the 
form tmp_X, unless X is the batCacheid.

Physical names consist of a directory name followed by a logical name suffix. 
The directory name is derived from the batCacheid, and is currently organized 
in a hierarchy that puts max 64 bats in each directory (see BBPgetsubdir). 

Concerning the physical suffix: it is almost always bat_X. This saves us
a whole lot of trouble, as bat_X is always unique and no conflicts can occur.
Other suffixes are only supported in order just for backward compatibility with 
old repositories (you won't see them anymore in new repositories).
@{
@c
int
BBPrename(bat bid, str nme)
{
	BAT *b = BBPdescriptor(bid);
	long_str dirname;
	bat tmpid = 0, i;

	if (b == NULL)
		return 0;

	/* If name stays same, do nothing */
	if (BBP_logical(bid) && strcmp(BBP_logical(bid), nme) == 0)
		return 0;

	BBPgetsubdir(dirname, ABS(bid));

	if ((tmpid = BBPnamecheck(nme)) && (bid < 0 || tmpid != bid)) {
		return BBPRENAME_ILLEGAL;
	}
	if (strlen(dirname) + strLen(nme) >= IDLENGTH) {
		return BBPRENAME_LONG;
	}
	gdk_set_lock(GDKtrimLock, "BBPrename");
	gdk_set_lock(GDKcacheLock, "BBPrename");
	i = BBP_find(nme, FALSE);
	if (i != 0) {
		gdk_unset_lock(GDKcacheLock, "BBPrename");
		gdk_unset_lock(GDKtrimLock, "BBPrename");
		return BBPRENAME_ALREADY;
	}
	BBP_notrim = BBP_getpid();

	/* carry through the name change */
	if (BBP_logical(bid) && BBPnamecheck(BBP_logical(bid)) == 0) {
		BBP_delete(bid);
	}
	if( BBP_logical(bid) != BBP[ABS(bid)].bak[(bid)<0])
		GDKfree(BBP_logical(bid));
	BBP_logical(bid) = GDKstrdup(nme);
	if (tmpid == 0) {
		BBP_insert(bid);
	}
	b->batDirtydesc = 1;
	if (b->batPersistence == PERSISTENT) {
		int lock = locked_by ? BBP_getpid() != locked_by : 1;

		if (lock)
			gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPrename");
		BBP_status_on(ABS(bid), BBPRENAMED, "BBPrename");
		if (lock)
			gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPrename");
		BBPdirty(1);
	}
	gdk_unset_lock(GDKcacheLock, "BBPrename");
	BBP_notrim = 0;
	gdk_unset_lock(GDKtrimLock, "BBPrename");
	return 0;
}

@}

@-
A key performance drain is the management of small temporary BATs for
a very short time. It would be interesting to see if a re-use scheme
would make a big difference in SQL settings. 

A potential danger of delaying destruction of temporary BATs lies in
their blocking of scarce resources. We would not like to spent all
memory to garbage. In an ideal world we would quickly learn what
BATs are wordt to be recycled. 

The policy to start with consists of only considering BATs
without string heaps, because they require more complex re-initialization,
and BATs that are too 'large'. A refinement and merge with BBPtrim
is for the future to explore.

The storage structure is based on a circular buffer. Picking
the BATs for recycling is also not intelligent yet.
@{
@c
#define MAXBIN 5
static BAT *batbin[MAXBIN];
static int bintop=0;

/* #define BBPBINTST*/
static void BBPaddtobin(BAT *b){
	BAT *bn;
	/* this routine still runs with a lock enabled */
	/* remove any view dependencies */
	if(  VIEWparent(b) ){
		BBPdestroy(b);
		return;
	}
	/* pre-filter the BATs */
	if( BAThtype(b)>= TYPE_str || BATttype(b)>= TYPE_str ||
		BATcount(b)> 16*1024 ||
		BBP_logical(b->batCacheid) != BBP[ABS(b->batCacheid)].bak[(b->batCacheid)<0]){
		BBPdestroy(b);
		return;
	}
	if( (bn= batbin[bintop])){
		gdk_set_lock(GDKcacheLock, "BBPaddtobin");
		batbin[bintop]= 0;
		gdk_unset_lock(GDKcacheLock, "BBPaddtobin");
		BBP_status_on(bn->batCacheid, BBPUNLOADING, "BBPaddtobin");
#ifdef BBPBINTST
		printf("delete from bin %d\n",bn->batCacheid);
#endif
		BBPdestroy(bn);
	}
	/* push element onto the bin */
#ifdef BBPBINTST
	printf("add to bin %d %d\n",b->batCacheid, (int)BATcapacity(b));
#endif
	gdk_set_lock(GDKcacheLock, "BBPaddtobin");
	batbin[bintop]=b;
	BBP_status_off(b->batCacheid, BBPUNLOADING, "BBPaddtobin");
	bintop = (bintop+1) % MAXBIN;
	gdk_unset_lock(GDKcacheLock, "BBPaddtobin");
}

BAT *
BBPrecycle(int ht, int tt, size_t cap){
	int i;
	BAT *b, *bm;

	gdk_set_lock(GDKcacheLock, "BBPrecycle");
	for(i=0; i<MAXBIN; i++)
		if( (b= batbin[i]) && BAThtype(b)==ht && 
			BATttype(b)==tt &&	BATcapacity(b)>= cap){
#ifdef BBPBINTST
	printf("try from bin %d \n",b->batCacheid);
#endif
			bm= BATmirror(b);
			if( bm == NULL)
				continue;
#ifdef BBPBINTST
	printf("get from bin %d %d %d \n",b->batCacheid,(int) cap, (int) BATcapacity(b));
#endif

			batbin[i]=0;
			BBP_refs(b->batCacheid)=1;
			BBP_lrefs(b->batCacheid)=0;
			
			/* experimental code to reset the BAT */
			b->batRestricted = 0;
			b->hkey= b->tkey = FALSE;
			bm->dims.tailkey= b->dims.headkey;
			b->halign = OIDnew(2);
			b->talign = b->halign + 1;
			b->hseqbase = (ht == TYPE_void) ? oid_nil : 0;
			b->tseqbase = (tt == TYPE_void) ? oid_nil : 0;
			b->H->props = b->T->props = NULL;
			b->H->sorted = b->T->sorted = 0;
			b->H->align = b->T->align = 0;
			b->H->nosorted = b->T->nosorted = 0;
			b->H->nosorted_rev = b->T->nosorted_rev = 0;
			b->H->nokey[0] = b->T->nokey[0] = 0;
			b->H->nokey[1] = b->T->nokey[1] = 0;
			b->batPersistence = TRANSIENT;
			b->void_tid= -1;
			b->void_cnt=0;
			b->void_seq1= b->void_seq2= oid_nil;
			HASHdestroy(b);
			DELTAinit(b);
			b->batDirty= TRUE;
			gdk_unset_lock(GDKcacheLock, "BBPrecycle");
			if( BBP_cache(-b->batCacheid) == 0){
				BBPcacheit(b);
			}
			return b;
		}
	gdk_unset_lock(GDKcacheLock, "BBPrecycle");
	return NULL;
}
@}
@+ BBP swapping Policy
The BAT can be moved back to disk using the routine @%BBPfree@.
It frees the storage for other BATs. After this call BAT* references
maintained for the BAT are wrong.
We should keep track of dirty unloaded BATs. They may have to be committed
later on, which may include reading them in again.

BBPswappable: may this bat be unloaded?
Only real bats without memory references can be unloaded.
@{
@h
#define BBPswappable(b) ((b) && BBP_refs((b)->batCacheid) == 0)
#define BBPtrimmable(b) (BBPswappable(b) && VIEWparent(b) == 0 && (BBP_status((b)->batCacheid)&BBPWAITING) == 0)

#endif /* _GDK_BBP_H_ */
@- 
The @%BBP_ref@ contains the amount of live references to a BAT.
These might be in recursive BATs, C or MIL variables.  The count is 
incremented with @%BBPfix@ and decremented with @%BBPunfix@.
@c
static INLINE void
BBPspin(bat i, str s, int event)
{
	if (BBPcheck(i, "BBPspin") && (BBP_status(i) & event)) {
		lng spin = LL_CONSTANT(0);

		while (BBP_status(i) & event) {
			MT_sleep_ms(1);
			spin++;
		}
		BATDEBUG THRprintf(GDKout, "BBPspin(%d,%s,%d): " LLFMT " loops\n", (int) i, s, event, spin);
	}
}

int
BBPincref(bat i, int logical)
{
	int lock = locked_by ? BBP_getpid() != locked_by : 1;
	int refs = 0;

	if (i == bat_nil) {
		/* Stefan: May this happen? Or should we better call GDKerror(), here? */
		/* GDKerror("BBPincref() called with bat_nil!\n"); */
		return refs;
	}
	if (i < 0)
		i = -i;
	if (BBPcheck(i, "BBPincref")) {
		if (lock)
			gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPincref");

		while (BBP_status(i) & BBPUNLOADING) {
			if (lock)
				gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPincref spin wait");
			MT_sleep_ms(1);
			if (lock)
				gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPincref spin wait");
		}
		/* got the lock */
		if (logical) {
			refs = ++BBP_lrefs(i);
		} else {
			refs = ++BBP_refs(i);
		}
		if (lock)
			gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPfix");
	}
	return refs;
}

void
BBPshare(bat parent)
{
	int lock = locked_by ? BBP_getpid() != locked_by : 1;
	int fix = 0;

	if (parent < 0)
		parent = -parent;
	if (lock)
		gdk_set_lock(GDKswapLock[parent & BBPLOCKMASK], "BBPshare");
	if (++BBP_cache(parent)->batSharecnt == 1)
		fix = 1;
	if (lock)
		gdk_unset_lock(GDKswapLock[parent & BBPLOCKMASK], "BBPshare");
	if (fix)
		BBPincref(parent, FALSE);
}

static INLINE int
decref(bat i, int logical, int lock)
{
	int refs = 0, swap = 0;
	BAT *b;


	/* decrement references by one */
	if (logical) {
		if (BBP_lrefs(i) == 0) {
			GDKerror("BBPdecref: %s does not have logical references.\n", BBPname(i));
		} else {
			refs = --BBP_lrefs(i);
		}
	} else {
		if (BBP_refs(i) == 0) {
			GDKerror("BBPdecref: %s does not have pointer fixes.\n", BBPname(i));
		} else {
			refs = --BBP_refs(i);
		}
	}

	/* we destroy transients asap and unload persistent bats only if they have been made cold */
	b = BBP_cache(i);
	if (BBP_refs(i) > 0 || (BBP_lrefs(i) > 0 && BBP_lastused(i) != 0)) {
		/* bat cannot be swapped out. renew its last usage stamp for the BBP LRU policy */
		int sec = BBPLASTUSED(BBPstamp());

		if (sec > BBPLASTUSED(BBP_lastused(i)))
			BBP_lastused(i) = sec;
	} else if (b || (BBP_status(i) & BBPTMP)) {
		/* bat will be unloaded now. set the UNLOADING bit while locked so no other thread thinks its available anymore */
		BBP_status_on(i, BBPUNLOADING, "BBPdecref");
		swap = TRUE;
	}

	/* unlock before re-locking in unload; as saving a dirty persistent bat may take a long time */
	if (lock)
		gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPdecref");

	if (swap) {
		int destroy = BBP_lrefs(i) == 0 && (BBP_status(i) & BBPDELETED) == 0;
		b = BBPquickdesc(i, TRUE);
		if (destroy) {
			 BBPdestroy(b);	 /* free memory of transient */
			 /* BBPaddtobin(b);	  plan for re-use */
		} else if (b) {
			BBP_unload_cnt(i, "BBPdecref");
			BBPfree(b, "BBPdecref" );	/* free memory (if loaded) and delete from disk (if transient but saved) */
		}
	}
	return refs;
}

int
BBPdecref(bat i, int logical)
{
	int lock = locked_by ? BBP_getpid() != locked_by : 1;

	if (BBPcheck(i, "BBPdecref") == 0) {
		return -1;
	}
	if (i < 0)
		i = -i;
	if (lock)
		gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPdecref");
	return decref(i, logical, lock);
}
@-
M5 often changes the physical ref into a logical reference.
This state change consist of the sequence BBPincref(b,TRUE);BBPunfix(b).
A faster solution is given below, because it does not trigger
the BBP management actions, such as garbage collecting the bats.
[first step, initiate code change]
@c
void
BBPkeepref(bat i)
{
	int lock = locked_by ? BBP_getpid() != locked_by : 1;

	if (i == bat_nil) 
		return ;
	if (i < 0)
		i = -i;
	if (BBPcheck(i, "BBPkeepref")) {
		if (lock)
			gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPkeepref");

		while (BBP_status(i) & BBPUNLOADING) {
			if (lock)
				gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPincref spin wait");
			MT_sleep_ms(1);
			if (lock)
				gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPincref spin wait");
		}
		/* got the lock */
		++BBP_lrefs(i);
		--BBP_refs(i);
		if (lock)
			gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPfix"); 
		/* decref(i, FALSE, lock);*/
	}
}
void
BBPreleaselref(bat i)
{
	int lock = locked_by ? BBP_getpid() != locked_by : 1;

	if (i == bat_nil || BBP_lrefs(i)<= 0) 
		return ;
	if (i < 0)
		i = -i;
	if (BBPcheck(i, "BBPreleaseref")) {
		if (lock)
			gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPreleaseref");

		while (BBP_status(i) & BBPUNLOADING) {
			if (lock)
				gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPincref spin wait");
			MT_sleep_ms(1);
			if (lock)
				gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPincref spin wait");
		}
		/* got the lock */
		--BBP_lrefs(i);
		if (lock)
			gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPfix"); 
	}
}
void
BBPreleaseref(bat i)
{
	int lock = locked_by ? BBP_getpid() != locked_by : 1;

	if (i == bat_nil || BBP_lrefs(i)<= 0) 
		return ;
	if (i < 0)
		i = -i;
	if (BBPcheck(i, "BBPreleaseref")) {
		if (lock)
			gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPreleaseref");

		while (BBP_status(i) & BBPUNLOADING) {
			if (lock)
				gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPincref spin wait");
			MT_sleep_ms(1);
			if (lock)
				gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPincref spin wait");
		}
		/* got the lock */
		--BBP_refs(i);
		if (lock)
			gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPfix"); 
	}
}

void
BBPunshare(bat parent)
{
	int lock = locked_by ? BBP_getpid() != locked_by : 1;

	if (parent < 0)
		parent = -parent;
	if (lock)
		gdk_set_lock(GDKswapLock[parent & BBPLOCKMASK], "BBPunshare");
	if (--BBP_cache(parent)->batSharecnt == 0) {
		(void) decref(parent, FALSE, lock);
	} else if (lock) {
		gdk_unset_lock(GDKswapLock[parent & BBPLOCKMASK], "BBPunshare");
	}
}

@- 
BBPreclaim is a user-exported function; the common way to destroy a BAT the hard way. 

Return values:
-1 = bat cannot be unloaded (it has more than your own memory fix)
 0 = unloaded successfully
 1 = unload failed (due to write-to-disk failure)
@c
int
BBPreclaim(BAT *b)
{
	int lock = locked_by ? BBP_getpid() != locked_by : 1;
	bat i = ABS(b->batCacheid);
	int ret = 0;

	if (lock)
		gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPreclaim");

	BATDEBUG THRprintf(GDKerr, "BBPreclaim: bat(%d) view=%d lrefs=%d ref=%d stat=%d\n", (int) b->batCacheid, b->batSharecnt, BBP_lrefs(b->batCacheid), BBP_refs(b->batCacheid), BBP_status(b->batCacheid));

	if (BBP_refs(b->batCacheid) > 1) {
		GDKerror("BBPreclaim: %d refs > 1 (%d)\n", i, BBP_refs(i));
		ret = -1;
	} else {
		/* unload whatever the LRU in the BBP */
		BBP_refs(b->batCacheid) = 0;
		BBP_status_on(i, BBPUNLOADING, "BBPreclaim");
	}
	if (lock)
		gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPreclaim");

	/* BBPfree potentially saves the BAT. Do this after releasing the short-term lock */
	if (ret == 0) {
		int destroy = BBP_lrefs(i) == 0 && (BBP_status(i) & BBPDELETED) == 0;
		if (destroy) {
			ret = BBPdestroy(b);
		} else {
			BBP_unload_cnt(i, "BBPreclaim");
			ret = BBPfree(b, "BBPreclaim" );
		}
	}
	return ret;
}

@-
BBPdescriptor checks whether BAT needs loading and does so if necessary. You must
have at least one fix on the BAT before calling this.
@c
BAT *
BBPdescriptor(bat i)
{
	int lock = locked_by ? BBP_getpid() != locked_by : 1;
	int load = FALSE;
	bat j = ABS(i);
	BAT *b = NULL;

	if (!BBPcheck(i, "BBPdescriptor")) {
		return NULL;
	}
	assert(BBP_refs(i));
	if ((b = BBP_cache(i)) == NULL) {

		if (lock)
			gdk_set_lock(GDKswapLock[j & BBPLOCKMASK], "BBPdescriptor");
		while (BBP_status(j) & BBPWAITING) {	/* wait for bat to be loaded by other thread */
			if (lock)
				gdk_unset_lock(GDKswapLock[j & BBPLOCKMASK], "BBPdescriptor");
			MT_sleep_ms(1);
			if (lock)
				gdk_set_lock(GDKswapLock[j & BBPLOCKMASK], "BBPdescriptor");
		}
		if (BBPvalid(j)) {
			b = BBP_cache(i);
			if (b == NULL) {
				load = TRUE;
				BBP_status_on(j, BBPLOADING, "BBPdescriptor");
			}
		}
		if (lock)
			gdk_unset_lock(GDKswapLock[j & BBPLOCKMASK], "BBPdescriptor");
	}
	if (load) {
		IODEBUG THRprintf(GDKerr, "load %s\n", BBPname(i));

		b = BATload_intern(i);
		BBPin++;

		/* clearing bits can be done without the lock */
		BBP_status_off(j, BBPLOADING, "BBPdescriptor");
	}
	return b;
}


static int
file_move(str srcdir, str dstdir, str name, str e)
{
	long_str ext;
	int ret = 0;

	strcpy(ext, e);
	ret = GDKmove(srcdir, name, ext, dstdir, name, ext);
	if (ret == 0) {
		return 0;
	}
	if (ret == 0) {
		return 0;
	} else {
		long_str path;
		struct stat st;

		GDKfilepath(path, srcdir, name, ext);
		if (stat(path, &st)) {
			/* source file does not exist; the best recovery is to give an error but continue
			 * by considering the BAT as not saved; making sure that this time it does get saved.
			 */
			return 2;	/* indicate something fishy, but not fatal */
		}
	}
	return 1;
}

/* returns 1 if the file exists */
static int
file_exists(str dir, str name, str ext)
{
	long_str path;
	struct stat st;

	GDKfilepath(path, dir, name, ext);
	return (stat(path, &st) == 0);
}

static int
heap_move(Heap *hp, str srcdir, str dstdir, str nme, str ext)
{
	/* see doc at BATsetaccess()/gdk_bat.mx for an expose on .priv heap modes */
	if (hp->storage == STORE_MMAP) {
		return 0;	/* memory mapped heaps under append need not be backed up! */
	} else if (file_exists(dstdir, nme, ext)) {
		return 0;	/* dont overwrite heap with the committed state already in dstdir */
	} else if (hp->filename && hp->storage == STORE_PRIV) {
		long_str path;
		struct stat st;

		GDKfilepath(path, srcdir, nme, ext);
		if (stat(path, &st)) {
			/* in order to prevent half-saved X files surviving a recover
			 * we create a dummy file in the BACKUP(dstdir) whose precense
			 * will trigger BBPrecover to remove them. Thus, X.priv will 
			 * prevail where it otherwise wouldn't have.
			 */
			FILE *fp;
			long_str kill_ext;

			strcpy(kill_ext, ext);
			strcat(kill_ext, ".kill");
			GDKfilepath(path, dstdir, nme, kill_ext);
			if ((fp = fopen(path, "w")) != NULL) {
				fclose(fp);
				return 0;
			} else {
				return 1;
			}
		}
		/* if X.priv already has a saved X, that one is backed up as normal.. */
	}
	return file_move(srcdir, dstdir, nme, ext);
}

@- backup_bat
backup_bat backups the bat to the BACKUP/ DIR. In case a 
backup exists no new backup is needed.

@c
static int
backup_bat(BAT *b)
{
	long_str srcdir, nme;
	str s = BBP_physical(b->batCacheid);
	int ret = 0;

	if (prepare_backup()) {
		return -1;
	}
	if (b->batCopiedtodisk == 0 || nme == NULL) {
		return 0;
	}
	/* determine location dir and physical suffix */
	strcpy(srcdir, BATDIR);
	strcat(srcdir, s);
	s = strrchr(srcdir, DIR_SEP);
	strcpy(nme, ++s);
	srcdir[s - srcdir] = 0;

	if (b->batDirty || b->batDirtydesc) {
		/* if a backup exists we are done */
		if (!file_exists(BAKDIR, nme, "desc")) 
			ret |= file_move(srcdir, BAKDIR, nme, "desc");
		if (ret & 1)
			return -1;
	}
	if (b->batDirty || b->batDirtybuns) {
		ret |= heap_move(b->batBuns, srcdir, BAKDIR, nme, "buns");
		if (ret & 1)
			return -1;
	}
	if ((b->batDirty || b->hheapdirty) && b->htype && b->hvarsized) {
		ret |= heap_move(b->hheap, srcdir, BAKDIR, nme, "hheap");
		if (ret & 1)
			return -1;
	}
	if ((b->batDirty || b->theapdirty) && b->ttype && b->tvarsized) {
		ret |= heap_move(b->theap, srcdir, BAKDIR, nme, "theap");
		if (ret & 1)
			return -1;
	}
	return 0;
}

@-
In BBPsave executes unlocked; it just marks the BBP_status of the BAT to BBPsaving, so others
that want to save or unload this BAT must spin lock on the BBP_status field.
@c
int
BBPsave(BAT *b)
{
	int lock = locked_by ? BBP_getpid() != locked_by : 1;
	bat bid = ABS(b->batCacheid);
	int ret = 0;

	if (BBP_lrefs(bid) == 0 || !BATdirty(b)) 
		/* do nothing */
		return 0;

	if (lock)
		gdk_set_lock(GDKswapLock[bid & BBPLOCKMASK], "BBPsave");

	if (BBP_status(bid) & BBPSAVING) {
		/* wait until save in other thread completes */
		BBPspin(bid, "BBPsave", BBPSAVING);
		if (lock)
			gdk_unset_lock(GDKswapLock[bid & BBPLOCKMASK], "BBPsave");
	} else {
		/* save it */
		int flags = BBPSAVING;

		if (DELTAdirty(b)) {
			flags |= BBPSWAPPED;
			BBPdirty(1);
		}
		if (b->batPersistence != PERSISTENT) {
			flags |= BBPTMP;
		}
		BBP_status_on(bid, flags, "BBPsave");
		if (lock)
			gdk_unset_lock(GDKswapLock[bid & BBPLOCKMASK], "BBPsave");

		IODEBUG THRprintf(GDKerr, "save %s\n", BATgetId(b));

		/* do the time-consuming work unlocked */
		if (BBP_status(bid) & BBPEXISTING)
			ret = backup_bat(b);
		if (ret == 0) {
			BBPout++;
			ret = (BATsave(b) == NULL);
		}
		if (lock)
			gdk_set_lock(GDKswapLock[bid & BBPLOCKMASK], "BBPsave");
		BBP_status_off(bid, BBPSAVING, "BBPsave");
		if (lock)
			gdk_unset_lock(GDKswapLock[bid & BBPLOCKMASK], "BBPsave");
	}
	return ret;
}


@-
TODO merge BBPfree with BATfree? Its function is to prepare a BAT for being
unloaded (or even destroyed, if the BAT is not persistent).
@c

static int
BBPdestroy(BAT *b) 
{
	bat bid = ABS(b->batCacheid), parent = VIEWparent(b);

	if (!parent) {
		/* bats that get destroyed must unfix their atoms */
		int (*hunfix) (ptr) = BATatoms[b->htype].atomUnfix;
		int (*tunfix) (ptr) = BATatoms[b->ttype].atomUnfix;
		BUN p, q;
		int xx;

		assert(b->batSharecnt == 0);
		if (hunfix) {
			DELloop(b, p, q, xx) {
				(*hunfix) (BUNhead(b, p));
			}
			BATloopFast(b, p, q, xx) {
				(*hunfix) (BUNhead(b, p));
			}
		}
		if (tunfix) {
			DELloop(b, p, q, xx) {
				(*tunfix) (BUNtail(b, p));
			}
			BATloopFast(b, p, q, xx) {
				(*tunfix) (BUNtail(b, p));
			}
		}
		BATdelete(b);	/* remove persistent info and free memory */
	} else {
		VIEWdestroy(b);
	}
	BBPclear(bid);	/* if destroyed; de-register from BBP */

	if (parent)	/* parent released when completely done with child */
		BBPunshare(parent);
	return 0;
}

static int
BBPfree(BAT *b, str calledFrom )
{
	int ret;
	bat bid = ABS(b->batCacheid), parent = VIEWparent(b);

	assert(BBPswappable(b));

	/* write dirty BATs before being unloaded */

	if ((ret = BBPsave(b)) != 0)
		return ret;	/* error while saving: no go */

	if (!parent) {
		assert(b->batSharecnt == 0);

 		if (BBP_cache(bid)) 
			BATfree(b);	/* free memory */
	} else {
		VIEWdestroy(b);
	}
	BBPuncacheit_(bid, FALSE);
	if (b->batMapdirty) {
		DESCsetmodes(b, b);
		b->batMapdirty = 0;
	}
	BBP_unload_off(bid, calledFrom);

	if (parent)	/* parent released when completely done with child */
		BBPunshare(parent);
	return 0;
}
@}
@- Storage trimming
BBPtrim unloads the least recently used BATs to free memory resources.
It gets passed targets in bytes of physical memory and logical
virtual memory resources to free. Overhead costs are reduced by
making just one scan, analyzing the first BBPMAXTRIM bats
and keeping the result in a list for later use (the oldest bat 
now is going to be the oldest bat in the future as well).
This list is sorted on last-used timestamp. BBPtrim keeps unloading
BATs till the targets are met or there are no more BATs to unload.

In determining whether a BAT will be unloaded, first it has
to be BBPswappable, and second its resources occupied must
be of the requested type. The algorithm actually makes two passes,
in the first only clean bats are unloaded (in order of their stamp).

In order to keep this under control with multiple threads all
running out of memory at the same time, we make sure that 
@itemize
@item 
just one thread does a BBPtrim at a time (by having a BBPtrimLock set).
@item
while decisions are made as to which bats to unload (1) the BBP is
scanned, and (2) unload decisions are made. Due to these properties,
the search\&decide phase of BBPtrim acquires both GDKcacheLock (due to (1))i
and all GDKswapLocks (due to (2)). They must be released during the actual 
unloading.  (as otherwise deadlock occurs => unloading a bat may e.g. kill 
an accelerator that is a BAT, which in turn requires BBP lock acquisition).
@item
to avoid further deadlock, the update functions in BBP that hold either 
GDKcacheLock or a GDKswapLock may never cause a BBPtrim (notice that BBPtrim 
could theoretically be set off just by allocating a little piece of memory, e.g. 
GDKstrdup()). If these routines must alloc memory, they must set the BBP\_notrim 
variable, acquiring the addition GDKtrimLock, in order to prevent such deadlock.
@item
the BBPtrim is atomic; only releases its locks when all BAT unload 
work is done. This ensures that if all memory requests that triggered
BBPtrim could possible be satisfied by unloading BATs, this will succeed.
@end itemize

The scan phase was optimized further in order to stop early when
it is a priori known that the targets are met (which is the case if the
BBPtrim is not due to memory shortage but due to the ndesc quota).
Note that scans may always stop before BBPsize as the BBPMAXTRIM is a fixed
number which may be smaller. As such, a mechanism was added to resume
a broken off scan at the point where scanning was broken off rather than
always starting at BBP[1] (this does more justice to the lower numbered 
bats and will more quickly find fresh unload candidates).

We also refined the swap criterion. If the BBPtrim was initiated due to:
- too much descriptors: small bats are unloaded first (from LRU cold to hot)  
- too little memory: big bats are unloaded first (from LRU cold to hot).
Unloading-first is enforced by subtracting $2^31$ from the stamp in the
field where the candidates are sorted on.
@{
@c
#define BBPMAXTRIM 40000
#define BBPSMALLBAT 1000

typedef struct {
	int lastused;		/* bat lastused stamp; sort on this field */
	bat bid;		/* bat id */
	int cnt;		/* bat count */
	int next;		/* next position in list */
} bbptrim_t;

bbptrim_t bbptrim[BBPMAXTRIM];
int bbptrimfirst = BBPMAXTRIM, bbptrimlast = 0, bbpunloadtail, bbpunload, bbptrimmax = BBPMAXTRIM, bbpscanstart = 1;

static bat
BBPtrim_scan(int mem, int vm, bat bbppos, bat bbplim)
{
	bbptrimlast = 0;
	bbptrimmax = BBPMAXTRIM;
	MEMDEBUG THRprintf(GDKerr, "TRIMSCAN: mem=%d vm=%d, start=%d, limit=%d\n", mem, vm, (int) bbppos, (int) bbplim);

	if (bbppos < BBPsize)
		do {
			if (BBPvalid(bbppos)) {
				BAT *b = BBP_cache(bbppos);

				if (BBPtrimmable(b)) {
					/* when unloading for memory, treat small BATs with a preference over big ones.
					 * rationale: I/O penalty for cache miss is relatively higher for small bats 
					 */
					int swap_first = 0, cnt = -1;

					if (b) {
						cnt = BATcount(b);
						swap_first = (cnt >= BBPSMALLBAT);
					}

					/* however, when we are looking to decrease the amount of descriptors,
					 * try to put the small bats in front of the load list instead..
					 */

					/* subtract 2-billion to make sure the swap_first class bats are unloaded first */
					bbptrim[bbptrimlast].lastused = BBPLASTUSED(BBP_lastused(bbppos)) | (swap_first << 31);
					bbptrim[bbptrimlast].bid = bbppos;
					bbptrim[bbptrimlast].cnt = cnt;
					if (++bbptrimlast == bbptrimmax)
						break;
				}
			}
			if (++bbppos == BBPsize)
				bbppos = 1;	/* treat BBP as a circular buffer */
		} while (bbppos != bbplim);

	if (bbptrimlast > 0) {
		int i;
		GDKqsort(bbptrim, NULL, bbptrimlast, sizeof(bbptrim_t), TYPE_int, 0);
		for (i = bbptrimfirst = 0; i < bbptrimlast; i++) {
			MEMDEBUG THRprintf(GDKerr, "TRIMSCAN: %11d%c %9d=%s\t(#%d)\n", BBPLASTUSED(bbptrim[i].lastused), (bbptrim[i].lastused & 0x80000000) ? '*' : ' ', i, BBPname(bbptrim[i].bid), bbptrim[i].cnt);

			bbptrim[i].next = i + 1;
		}
		bbptrim[bbptrimlast - 1].next = BBPMAXTRIM;
	} else {
		bbptrimfirst = BBPMAXTRIM;
	}
	MEMDEBUG THRprintf(GDKerr, "TRIMSCAN: end at %d (size=%d)\n", bbppos, (int) BBPsize);

	return bbppos;
}


/* insert BATs to unload from bbptrim list into bbpunload list; rebuild bbptrimlist only with the useful leftovers */
static
    void
BBPtrim_select(size_t * memtarget, size_t * vmtarget, int dirty)
{
	int bbptrimtail = BBPMAXTRIM, next = bbptrimfirst;

	MEMDEBUG THRprintf(GDKerr, "TRIMSELECT: dirty = %d\n", dirty );

	/* make the bbptrim-list empty; we will insert the untouched elements in it */
	bbptrimfirst = BBPMAXTRIM;

	while (next != BBPMAXTRIM) {
		int cur = next;	/* cur is the entry in the old bbptrimlist we are processing */
		int untouched = BBPLASTUSED(BBP_lastused(bbptrim[cur].bid)) <= BBPLASTUSED(bbptrim[cur].lastused);
		BAT *b = BBP_cache(bbptrim[cur].bid);

		next = bbptrim[cur].next;	/* do now, because we overwrite bbptrim[cur].next below */

		MEMDEBUG if (b) {
			THRprintf(GDKerr, "TRIMSELECT: candidate=%s BAT*=" PTRFMT "\n", BBPname(bbptrim[cur].bid), PTRFMTCAST(void *)b);

			THRprintf(GDKerr, "            (cnt=%d, mode=%d, refs=%d, wait=%d, parent=%d, lastused=%u,%u,%d)\n", bbptrim[cur].cnt, b->batPersistence, BBP_refs(b->batCacheid), (BBP_status(b->batCacheid) & BBPWAITING) != 0, VIEWparent(b),
				  BBP_lastused(b->batCacheid), BBPLASTUSED(bbptrim[cur].lastused), bbptrim[cur].lastused);
		}
		/* recheck if conditions encountered by trimscan in the past still hold */
		if (BBPtrimmable(b) && untouched) {
			size_t memdelta = BATmemsize(b, FALSE);
			size_t vmdelta = BATvmsize(b, FALSE);
			size_t memdirty = BATmemsize(b, TRUE);
			size_t vmdirty = BATvmsize(b, TRUE);

			if (((b->batPersistence == TRANSIENT && BBP_lrefs(bbptrim[cur].bid) == 0) ||	/* needs not be saved when unloaded, OR.. */
			     (vmdirty == 0 && memdirty <= sizeof(BATstore)) ||	/* the BAT is actually clean, OR.. */
			     dirty)	/* we are allowed to cause I/O (second run).. */
			    &&	/* AND ... */
			    ((*memtarget > 0 && (memdelta > 0)) || (*vmtarget > 0 && (vmdelta > 0))))
			     /* there is some reward in terms of memory requirements */
			{
				/* only then we unload! */
				MEMDEBUG {
					THRprintf(GDKerr, "TRIMSELECT: unload %s [" SZFMT "," SZFMT "] bytes [" SZFMT "," SZFMT "] dirty\n", BBPname(b->batCacheid), memdelta, vmdelta, memdirty, vmdirty);
				}
				BBP_unload_on(bbptrim[cur].bid, "BBPtrim_select");
				*memtarget = *memtarget > memdelta ? *memtarget - memdelta : 0;
				*vmtarget = *vmtarget > vmdelta ? *vmtarget - vmdelta : 0;

				/* add to bbpunload list */
				if (bbpunload == BBPMAXTRIM) {
					bbpunload = cur;
				} else {
					bbptrim[bbpunloadtail].next = cur;
				}
				bbptrim[cur].next = BBPMAXTRIM;
				bbpunloadtail = cur;
			} else if (!dirty) {
				/* do not unload now, but keep around; insert at the end of the new bbptrim list */
				MEMDEBUG {
					THRprintf(GDKerr, "TRIMSELECT: keep %s [" SZFMT "," SZFMT "] bytes [" SZFMT "," SZFMT "] dirty target(mem=" SZFMT " vm=" SZFMT ")\n", BBPname(b->batCacheid), memdelta, vmdelta, memdirty, vmdirty, MAX(0, *memtarget), MAX(0, *vmtarget));
				}
				if (bbptrimtail == BBPMAXTRIM) {
					bbptrimfirst = cur;
				} else {
					bbptrim[bbptrimtail].next = cur;
				}
				bbptrim[cur].next = BBPMAXTRIM;
				bbptrimtail = cur;
			} else {
				/* bats that even in the second (dirty) run are not selected, should be acquitted from the trimlist until a next scan */
				MEMDEBUG THRprintf(GDKerr, "TRIMSELECT: delete %s from trimlist (does not match trim needs)\n", BBPname(bbptrim[cur].bid));
			}
		} else {
			/* BAT was touched (or unloaded) since trimscan =>  it is discarded from both lists */
			char buf[80], *bnme = BBP_logical(bbptrim[cur].bid);

			if (bnme == NULL) {
				bnme = BBPtmpname(buf, 64, bbptrim[cur].bid);
			}
			MEMDEBUG THRprintf(GDKerr, "TRIMSELECT: delete %s from trimlist (has been %s)\n", bnme, b ? "touched since last scan" : "unloaded already");
		}

		if (*memtarget == 0 && *vmtarget == 0) {
			/* we're done; glue the rest of the old bbptrim list to the new bbptrim list */
			if (bbptrimtail == BBPMAXTRIM) {
				bbptrimfirst = next;
			} else {
				bbptrim[bbptrimtail].next = next;
			}
			break;
		}
	}
	MEMDEBUG THRprintf(GDKerr, "TRIMSELECT: end\n");
}

extern int monet_exec(str);

void
BBPtrim(size_t memtarget, size_t vmtarget)
{
	int i, limit, scan, did_scan = FALSE;
	int msec = 0, bats_written = 0, bats_unloaded = 0;	/* performance info */
	MT_Id t = BBP_getpid();

	PERFDEBUG msec = GDKms();

	if (BBP_notrim == t)
		return;		/* avoid deadlock by one thread going here twice */

	gdk_set_lock(GDKtrimLock, "BBPtrim");
	BBP_notrim = t;

	/* recheck targets to see whether the work was already done by another thread */
	if (memtarget && memtarget != BBPTRIM_ALL) {
		memtarget = GDKmem_inuse();
		if (memtarget > GDK_mem_maxsize)
			memtarget -= GDK_mem_maxsize;
		else
			memtarget = 0;
	}
	if (vmtarget && vmtarget != BBPTRIM_ALL) {
		vmtarget = GDKvm_cursize();
		if (vmtarget > GDK_vm_maxsize)
			vmtarget -= GDK_vm_maxsize;
		else
			vmtarget = 0;
	}
	MEMDEBUG THRprintf(GDKerr, "BBPTRIM_ENTER: memsize=" SZFMT ",vmsize=" SZFMT "\n", GDKmem_inuse(), GDKvm_cursize());

	MEMDEBUG THRprintf(GDKerr, "BBPTRIM: memtarget=" SZFMT " vmtarget=" SZFMT "\n", memtarget, vmtarget );
	PERFDEBUG THRprintf(GDKerr, "BBPtrim(mem=%d,vm=%d)\n", memtarget > 0, vmtarget > 0 );

	scan = (bbptrimfirst == BBPMAXTRIM);
	if (bbpscanstart >= BBPsize)
		bbpscanstart = 1;	/* sometimes, the BBP shrinks! */
	limit = bbpscanstart;

	while (memtarget > 0 || vmtarget > 0) {
		/* acquire the BBP locks */
		gdk_set_lock(GDKcacheLock, "BBPtrim");
		for (i = 0; i <= BBPLOCKMASK; i++)
			gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPtrim");

		/* gather a list of unload candidate BATs, but try to avoid scanning by reusing previous leftovers first */
		if (scan) {
			did_scan = TRUE;
			bbpscanstart = BBPtrim_scan((memtarget > 0), (vmtarget > 0), bbpscanstart, limit);
			scan = (bbpscanstart != limit);
		} else {
			scan = TRUE;
		}

		/* decide which of the candidates to unload using LRU */
		bbpunload = BBPMAXTRIM;
		BBPtrim_select(&memtarget, &vmtarget, FALSE);	/* first try to select only clean BATs */
		if (did_scan && (memtarget > 0 || vmtarget > 0)) {
			BBPtrim_select(&memtarget, &vmtarget, TRUE);	/* if that is not enough, also unload dirty BATs */
		}

		/* release the BBP locks */
		for (i = 0; i <= BBPLOCKMASK; i++)
			gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPtrim");
		gdk_unset_lock(GDKcacheLock, "BBPtrim");

		/* do the unload work unlocked */
		MEMDEBUG THRprintf(GDKerr, "BBPTRIM: %s\n", (bbpunload != BBPMAXTRIM) ? " lastused   batid name" : "no more unload candidates!");

		for (i = bbpunload; i != BBPMAXTRIM; i = bbptrim[i].next) {
			BAT *b = BBP_cache(bbptrim[i].bid);
			MEMDEBUG THRprintf(GDKerr, "BBPTRIM: %9u %7d %s\n", bbptrim[i].lastused, (int) bbptrim[i].bid, BBPname(bbptrim[i].bid));

			bats_written += (b->batPersistence != TRANSIENT && BATdirty(b));
			bats_unloaded++;
			BBPfree(b, "BBPtrim" );
		}
		/* continue while we can scan for more candiates */
		if (!scan)
			break;
	}
	/* done trimming */
	MEMDEBUG THRprintf(GDKerr, "BBPTRIM_EXIT: memsize=" SZFMT ",vmsize=" SZFMT "\n", GDKmem_cursize(), GDKvm_cursize());
	PERFDEBUG THRprintf(GDKerr, "BBPtrim(did_scan=%d, bats_unloaded=%d, bats_written=%d) %d ms\n", did_scan, bats_unloaded, bats_written, GDKms() - msec);

	BBP_notrim = 0;
	gdk_unset_lock(GDKtrimLock, "BBPtrim");
}

void
BBPhot(bat i)
{
	if (i < 0)
		i = -i;
	if (BBPcheck(i, "BBPhot")) {
		int lock = locked_by ? BBP_getpid() != locked_by : 1;

		if (lock)
			gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPhot");
		BBP_lastused(i) = BBPLASTUSED(BBPstamp() + 30000);
		if (lock)
			gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPhot");
	}
}

void
BBPcold(bat i)
{
	if (i < 0)
		i = -i;
	if (BBPcheck(i, "BBPcold")) {
		int lock = locked_by ? BBP_getpid() != locked_by : 1;

		gdk_set_lock(GDKtrimLock, "BBPcold");
		if (lock)
			gdk_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPcold");
		/* make very cold and insert on top of trim list */
		BBP_lastused(i) = 0;
		if (BBP_cache(i) && bbptrimlast < bbptrimmax) {
			bbptrim[--bbptrimmax].lastused = 0;
			bbptrim[bbptrimmax].bid = i;
			bbptrim[bbptrimmax].next = bbptrimfirst;
			bbptrimfirst = bbptrimmax;
		}
		if (lock)
			gdk_unset_lock(GDKswapLock[i & BBPLOCKMASK], "BBPcold");
		gdk_unset_lock(GDKtrimLock, "BBPcold");
	}
}

@}
@-
BBPquickdesc loads a BAT descriptor without loading the entire BAT, of which the
result be used only for a *limited* number of purposes. Specifically, during the 
global sync/commit, we do not want to load any BATs that are not already loaded, both 
because this costs performance, and because getting into memory shortage during a commit 
is extremely dangerous, as the global sync has all the BBPlocks, so no BBPtrim() can be 
done to free memory when needed. Loading a BAT tends not to be required, since the commit 
actions mostly involve moving some pointers in the BAT descriptor. However, some column 
types do require loading the full bat. This is tested by the complexatom() routine. Such 
columns are those of which the type has an fix/unfix method, or those that have HeapDelete
methods. The HeapDelete actions are not always required and therefore the BBPquickdesc
is parametrized.
@{
@c
static int
complexatom(int t, int delaccess)
{
	if (t >= 0 && (BATatoms[t].atomFix || (delaccess && BATatoms[t].atomDel))) {
		return TRUE;
	}
	return FALSE;
}

BAT *
BBPquickdesc(bat bid, int delaccess)
{
	BAT *b = BBP_cache(bid);

	if (bid < 0) {
		GDKerror("BBPquickdesc: called with negative batid.\n");
		return NULL;
	}
	if (b) {
		return b;	/* already cached */
	}
	b = (BAT *) BBPgetdesc(bid);
	if (b == NULL || 
	   complexatom(b->htype, delaccess) || 
	   complexatom(b->ttype, delaccess)) {
		b = BATload_intern(bid);
		BBPin++;
	}
	return b;
}

@}

@- Is a bat dirty at commit time?

Used to be simple: look if it is loaded. If not, only its cached descriptor might still
be dirty. Otherwise look at the union of all dirty bits.

But, sometimes clean BATs must be made dirty, just because this is called from a commit!

This happens in a commit where we have persistent BATs that fulfill all following conditions:
@itemize
item (1) 
are updatable (non BAT_READ) 
item (2) 
are new in this commit
item (3) 
have at least one huge STORE_MMAP .priv heap
@end itemize

These BATs are a problem, as after the commit, the STORE_MMAP status should be a STORE_PRIV
(subsequent updates followed by a crash corrupt the stable heap image).

Also, if such a BAT was already clean at commit time (due to a BBPtrim or explicit save),
its descriptor would not even be saved. Recall that HEAPcheckmodes in gdk_storage.mx would 
at least have re-set the heap->storage modes in the desc correctly for subsequent BAT loads. 
Not even that will happen if the BAT is clean.

So, one thing we do is making the descriptor dirty always for such BATs. This solves the
latter problem.

Also, if there are no hot-locks on this BAT, we just unload the BAT inside the commit.
In this case, we do not modify the storage modes yet. Thus, its heaps get saved with 
an efficient msync(). After the unload, a re-load will use the correct STORE_PRIV mode. 

Only if the BAT cannot be unloaded, we hack the storage state of the BAT, such that it 
appears to be STORE_PRIV. This works, but causes a very expensive write()-based save of
the entire bat, and duplicates disk consumption for its heap.
@{
@c
static BAT *
dirty_bat(bat i, int *unload)
{
	if (BBPvalid(i)) {
		int unloadable = (BBP_refs(i) == 0);	/* are no other threads currently executing on this image?? */
		int newbat = (BBP_status(i) & BBPNEW);
		BAT *b;

		BBPspin(i, "dirty_bat", BBPSAVING);
		b = BBP_cache(i);
		if (b != NULL) {
			if (BBP_status(i) & BBPPERSISTENT) {
				if (unload)
					*unload = BATcheckmodes(b, newbat, unloadable) && unloadable;
				if (BATdirty(b))
					return b;	/* the bat is loaded, persistent and dirty */
			}
		} else if (BBP_status(i) & BBPSWAPPED) {
			b = (BAT *) BBPquickdesc(i, TRUE);
			if (b) {
				if (unload)
					(void) BATcheckmodes(b, newbat, 0);
				if (b->batDirtydesc)
					return b;	/* only the desc is loaded & dirty */
			}
		}
	}
	return NULL;
}

@}
@+ Atomic Write
The atomic BBPsync() function first safeguards the old images of all files 
to be written in BAKDIR. It then saves all files. If that succeeds
fully, BAKDIR is renamed to DELDIR. The rename is considered an 
atomic action. If it succeeds, the DELDIR is removed.
If something fails, the pre-sync status can be obtained by moving
back all backed up files; this is done by BBPrecover().

The BBP.dir is also moved into the BAKDIR.
@{
@c
int
BBPsync(int commit)
{
	bat i;
	int ret = 0, bbpdirty = 0;
	int t0 = 0, t1 = 0;

	PERFDEBUG t0 = t1 = GDKms();

	if (!commit) {
		BBPlock("BBPsync");
		PERFDEBUG THRprintf(GDKerr, "BBPsync (lock time %d)\n", (t0 = GDKms()) - t1);
	}
	/* PHASE 1: safeguard everything in BACKUP dir */
	if (commit) {
		bbpdirty = BBP_dirty;
		if (OIDdirty()) {
			bbpdirty = BBP_dirty = 1;
		}
	}
	if (ret == 0) {
		for (i = 1; i < BBPsize; i++) 
			if (BBP_status(i) & BBPEXISTING) {
				BAT *b = dirty_bat(i, NULL);

				if (b != NULL && backup_bat(b))
					break;
			}
		ret = (i != BBPsize);
	}
	PERFDEBUG THRprintf(GDKerr, "BBPsync (move time %d) %d files\n", (t1 = GDKms()) - t0, backuped_files);

	/* PHASE 2: save the repository */
	if (ret == 0) {
		for (i = 1; i < BBPsize; i++) 
			if (BBP_status(i) & BBPPERSISTENT) {
				int unload = FALSE;
				BAT *b = dirty_bat(i, &unload);

				if (b != NULL) {
					if (BATsave(b) == NULL)
						break;	/* write error */
					if (unload) {
						/* BATs that became persistent and have heaps that should in the 
						   future be STORE_PRIV (but are not yet), are unloaded */
						BATfree(b);
						BBPuncacheit_(i, TRUE);
					}
				}
			}
		ret = (i != BBPsize);
	}

	PERFDEBUG THRprintf(GDKerr, "BBPsync (write time %d)\n", (t0 = GDKms()) - t1);

	if (ret == 0) {
		if (bbpdirty) {
			ret = BBPdir(FALSE);
		} else if (backuped_dir && GDKmove(BAKDIR, "BBP", "dir", BATDIR, "BBP", "dir")) {
			ret = -1; /* tried a cheap way to get BBP.dir; but it failed */
		} else {
			/* commit might still fail; we must remember that we moved BBP.dir out of BAKDIR */
			backuped_dir = 0; 
		}
        }

	PERFDEBUG THRprintf(GDKerr, "BBPsync (dir time %d) %d bats\n", (t1 = GDKms()) - t0, BBPsize);

	if (bbpdirty || backuped_files > 0) {
		if (ret == 0) {
			/* atomic switchover */
			/* this is the big one: this call determines
			 * whether the operation of this function
			 * succeeded, so no changing of ret after this
			 * call anymore */
			ret = rename(BAKDIR, DELDIR);
			if (ret)
				GDKsyserror("BBPsync: rename(%s,%s) failed.\n", BAKDIR, DELDIR);
			IODEBUG THRprintf(GDKerr, "BBPsync: rename %s %s = %d\n", BAKDIR, DELDIR, ret);
		}

		/* AFTERMATH */
		if (ret == 0) {
			BBP_dirty = 0;
			backuped_dir = backuped_files = 0;
			(void) prepare_backup(); /* (try to) remove DELDIR and set up new BAKDIR */ 
		}
	}

	if (!commit)
		BBPunlock("BBPsync");
	PERFDEBUG THRprintf(GDKerr, "BBPsync (ready time %d)\n", (t0 = GDKms()) - t1);

	return ret;
}

@}
@-
Recovery just moves all files back to their original location. this is an incremental
process: if something fails, just stop with still files left for moving in BACKUP/. 
The recovery process can resume later with the left over files.
@{
@c
static int
force_move(str srcdir, str dstdir, str name)
{
	char *p;
	long_str srcpath, dstpath, killfile;
	int ret = 0;

	if ((p = strrchr(name, '.')) != NULL && strcmp(p, ".kill") == 0) {
		struct stat st;
		ptrdiff_t len = p - name;

		strncpy(srcpath, name, len);
		srcpath[len] = '\0';
		GDKfilepath(dstpath, dstdir, srcpath, NULL);

		/* step 1: remove the X file that is going to be overwritten by X.priv */
		if (stat(dstpath, &st) == 0) {
			ret = unlink(dstpath);	/* clear destination */
			if (ret) {
				/* if it exists and cannot be removed, all this is going to fail */
				GDKsyserror("force_move: unlink(%s)\n", dstpath);
				return ret;
			}
		}

		/* step 2: now remove the .kill file. This one is crucial, otherwise we'll never finish recovering */
		strcpy(killfile, srcdir);
		strcat(killfile, name);
		ret = unlink(killfile);
		if (ret) {
			GDKsyserror("force_move: unlink(%s)\n", killfile);
			return ret;
		}

		/* step 3: move X.priv to X. Even if this fails, HEAPload will retry to do this later */
		if (GDKcreatedir(dstdir))
			ret = 0;
		ret = GDKmove(dstdir, srcpath, "priv", dstdir, srcpath, NULL);
		if (ret)
			GDKsyserror("force_move: link(%s%c%s.priv,%s)=%d\n", srcdir, DIR_SEP, srcpath, dstpath);

		IODEBUG THRprintf(GDKerr, "link %s%c%s.priv %s = %d\n", srcdir, DIR_SEP, srcpath, dstpath, ret);

		return 0;
	}
	/* try to rename it */
	ret = GDKmove(srcdir, name, NULL, dstdir, name, NULL);

	if (ret) {
		/* two legal possible causes: file exists or dir notexist */
		GDKfilepath(dstpath, dstdir, name, NULL);
		GDKfilepath(srcpath, srcdir, name, NULL);
		ret = unlink(dstpath);	/* clear destination */
		IODEBUG THRprintf(GDKerr, "unlink %s = %d\n", dstpath, ret);

		if (GDKcreatedir(dstdir))
			ret = 0;
		ret = GDKmove(srcdir, name, NULL, dstdir, name, NULL);
		if (ret)
			GDKsyserror("force_move: link(%s,%s)=%d\n", srcpath, dstpath, ret);
		IODEBUG THRprintf(GDKerr, "link %s %s = %d\n", srcpath, dstpath, ret);
	}
	return ret;
}

int
BBPrecover(void)
{
	DIR *dirp = opendir(BAKDIR);
	struct dirent *dent;
	long_str path, dstpath;
	bat i;
	size_t j;
	int ret = 0, dirseen = FALSE;
	str dstdir;

	if (dirp == NULL) {
		return 0;		/* nothing to do */
	}
	strcpy(dstpath, BATDIR);
	dstdir = dstpath + strlen(dstpath);
	IODEBUG THRprintf(GDKerr, "BBPrecover(start)\n");

	mkdir(LEFTDIR, 0755);

	/* move back all files */
	while ((dent = readdir(dirp)) != NULL) {
		str q = strchr(dent->d_name, '.');

		if (q == dent->d_name) {
			int j;

			if (strcmp(dent->d_name, ".") == 0 || strcmp(dent->d_name, "..") == 0)
				continue;
			GDKfilepath(path, BAKDIR, dent->d_name, NULL);
			j = unlink(path);
			IODEBUG THRprintf(GDKerr, "unlink %s = %d\n", path, j);

			continue;
		} else if (strcmp(dent->d_name, "BBP.dir") == 0) {
			dirseen = TRUE;
			continue;
		}
		if (q == NULL)
			q = dent->d_name + strlen(dent->d_name);
		if ((j = q - dent->d_name) + 1 > sizeof(path)) {
			/* name too long: ignore */
			continue;
		}
		strncpy(path, dent->d_name, j);
		path[j] = 0;
		if (GDKisdigit(*path)) {
			i = strtol(path, NULL, 8);
		} else {
			i = BBP_find(path, FALSE);
			if (i < 0)
				i = -i;
		}
		if (i == 0 || i >= BBPsize || !BBPvalid(i)) {
			force_move(BAKDIR, LEFTDIR, dent->d_name);
		} else {
			BBPgetsubdir(dstdir, i);
			ret += force_move(BAKDIR, dstpath, dent->d_name);
		}
	}
	closedir(dirp);
	if (dirseen && ret == 0) {	/* we have a saved BBP.dir; it should be moved back!! */
		struct stat st;
		GDKfilepath(path, BATDIR, "BBP", "dir");
		ret = recover_dir(stat(path, &st) == 0);
	}

	if (ret == 0) {
		ret = rmdir(BAKDIR);
		IODEBUG THRprintf(GDKerr, "rmdir %s = %d\n", BAKDIR, ret);
	}
	if (ret)
		GDKerror("BBPrecover: recovery failed. Please check whether your disk is full or write-protected.\n");

	IODEBUG THRprintf(GDKerr, "BBPrecover(end)\n");
	return ret;
}

@}
@- The diskscan
The BBPdiskscan routine walks through the BAT dir, cleans up leftovers, and measures disk occupancy. 
Leftovers are files that cannot belong to a BAT. in order to establish this for [ht]heap files, 
the BAT descriptor is loaded in order to determine whether these files are still required. 

The routine gathers all bat sizes in a bat that contains bat-ids and bytesizes. The return value is
the number of bytes of space freed.
@{
@c
static int
persistent_bat(bat bid)
{
	if (bid >= 0 && bid < BBPsize && BBPvalid(bid)) {
		BAT *b = BBP_cache(bid);

		if (b == NULL || b->batCopiedtodisk) {
			return TRUE;
		}
	}
	return FALSE;
}

static BAT *
getdesc(int bid)
{
	BAT *b = (BAT *) BBPgetdesc(bid);

	if (b == NULL)
		BBPclear(bid);
	return b;
}

lng
BBPdiskscan_r(str parent)
{
	str dir = parent ? parent : BATDIR;
	DIR *dirp = opendir(dir);
	struct dirent *dent;
	long_str fullname;
	str dst = fullname, src = dir;
	lng ret, tot = LL_CONSTANT(0);

	if (dirp == NULL) {
		return LL_CONSTANT(-1);	/* nothing to do */
	}
	while (*src)
		*dst++ = *src++;
	if (dst[-1] != DIR_SEP)
		*dst++ = DIR_SEP;

	while ((dent = readdir(dirp)) != NULL) {
		str p = strchr(dent->d_name, '.');
		bat bid = strtol(dent->d_name, NULL, 8);
		int r, ok = (p && bid), delete = FALSE;
		off_t filesize;
		struct stat st;

		if (dent->d_name[0] == '.')
			continue;	/* ignore .dot files and directories (. ..) */
		if (strncmp(dent->d_name, "BBP.", 4) == 0) {
			if (parent == NULL || strncmp(parent, BAKDIR, strlen(BAKDIR)-1) == 0) 
				continue;
		}
		strcpy(dst, dent->d_name);
		if (p == NULL) {
			ret = BBPdiskscan_r(fullname);
			if (ret >= 0) {
				tot += ret;	/* it was a directory; add subtotal */
				continue;
			}
		}
		r = stat(fullname, &st);
		if (r) {
			GDKsyserror("BBPdiskscan: stat(%s)", fullname);
			continue;
		} else {
			/* record the real disk occupancy; not just the bytesize */
			filesize = st.st_size;
		}

		/* if X exists, then X.priv can always be deleted */
		r = (int) strlen(fullname);
		if (r > 5 && strcmp(fullname + r - 5, ".priv") == 0) {
			chr bak = fullname[r - 5];

			fullname[r - 5] = 0;	/* cut off the .priv bit */
			delete = (stat(fullname, &st) == 0);
			fullname[r - 5] = bak;
		}
		if (ok == FALSE || delete == TRUE || !persistent_bat(bid)) {
			delete = TRUE;
		} else if (strncmp(p + 1, "hheap", 5) == 0) {
			BAT *b = getdesc(bid);

			delete = (b == NULL || !b->hheap) || (b->batCopiedtodisk == 0);
		} else if (strncmp(p + 1, "theap", 5) == 0) {
			BAT *b = getdesc(bid);

			delete = (b == NULL || !b->theap) || (b->batCopiedtodisk == 0);
		} else if (strncmp(p + 1, "hhash", 5) == 0) {
			BAT *b = getdesc(bid);

			delete = (b == NULL || !b->hhash);
		} else if (strncmp(p + 1, "thash", 5) == 0) {
			BAT *b = getdesc(bid);

			delete = (b == NULL || !b->thash);
		} else if (strcmp(p + 1, "desc") && strncmp(p + 1, "buns", 4)) {
			ok = FALSE;
		}
		if (!ok) {
			/* found an unknown file; stop pruning in this subdir */
			GDKwarning("BBPdiskscan: unexpected file %s, leaving %s.\n", dent->d_name, dir);
			break;
		}
		if (delete) {
			r = unlink(fullname);
			if (r) {
				GDKsyserror("BBPdiskscan: unlink(%s)", fullname);
			} else {
				tot += filesize;
			}
			IODEBUG THRprintf(GDKerr, "BBPcleanup: unlink(%s) = %d\n", fullname, r);
		}
		IODEBUG THRprintf(GDKerr, "BBPdiskscan: stat(%s) = %d\n", fullname, r);
	}
	closedir(dirp);
	return tot;
}

lng
BBPdiskscan(void)
{
	return BBPdiskscan_r(NULL);
}

@}
@- BBPreplace
BBP replace allows to replace a BAT in the BBP by another BAT. It is useful,
e.g. for copy/cleanup operations that build a fresh copy of an existing BAT 
(without dead space e.g. in string heaps) and then replace the old BAT by the
new image. Now we have BATmaterialize (converts void into oid) and VIEWreset
(make a view independent of its parent) also use this interface.
@{
@c
void
BBPreplace(BAT *b, BAT *bn)
{
	bat bid = b->batCacheid;
	bat bnid = bn->batCacheid;

	/* trim lock keeps BBPsync out as well as of course BBPtrims */
	gdk_set_lock(GDKtrimLock, "BBPreplace");
	if (b->batCacheid < 0 && bn->batCacheid < 0) {
		b = BATmirror(b);
		bn = BATmirror(bn);
	}
	if (bid < 0) {
		GDKerror("BBPreplace: %s may not be reversed.\n", BBPname(bid));
	} else if (bnid < 0) {
		GDKerror("BBPreplace: %s may not be reversed.\n", BBPname(bnid));
	} else if (ATOMtype(b->htype) != ATOMtype(bn->htype) || ATOMtype(b->ttype) != ATOMtype(bn->ttype)) {
		GDKerror("BBPreplace: %s[%s,%s] is incompatible with %s[%s,%s]\n", BBPname(bid), ATOMname(b->htype), ATOMname(b->ttype), BBPname(bnid), ATOMname(bn->htype), ATOMname(bn->ttype));
	} else if (BBP_status(bnid) & BBPPERSISTENT) {
		GDKerror("BBPreplace: %s is persistent and cannot disappear.", BBPname(bnid));
	} else if (BBP_status(bnid) & BBPDELETED) {
		GDKerror("BBPreplace: %s was persistent at the last commit and cannot disappear yet.", BBPname(bnid));
	} else if (BBP_lrefs(bnid)) {
		GDKerror("BBPreplace: %s has MIL variable refcount %d and cannot disappear.", BBPname(bnid), BBP_lrefs(bnid) - (BBP_status(bnid) & BBPPERSISTENT) ? 1 : 0);
	} else {
		int dirtyb = b->batDirty, dirtybn = bn->batDirty;
		int ok = TRUE, newmode = b->batPersistence, oldmode = bn->batPersistence;
		int persistentb = (BBP_status(bid) & (BBPPERSISTENT | BBPDELETED));
		int hugebn = bn->batBuns->storage | (bn->hheap?bn->hheap->storage:0) | (bn->theap?bn->theap->storage:0) | STORE_MMAP;

		BATsetaccess(bn, b->batRestricted);
		BATmmap(bn, 
			b->batBuns->storage, 
			b->hheap?b->hheap->storage:-1, 
			b->theap?b->theap->storage:-1);

		if (persistentb) {
			/* backup the persistent b */
			b->batDirty = 1;
			ok = (backup_bat(b) == 0);
		}

		if (ok) {
			/* make bn appear to BATsave (and others) as if it were b */
			bn->batCacheid = bid;
			if (hugebn) {
				/* save bn entirely, on the location of b */
				if (persistentb) BATmode(bn, PERSISTENT);
				bn->batDirty = 1;
				ok = (BATsave(bn) != NULL);
			}
		}
		if (!ok) {
			/* FAILED: restore batId, cacheid and mode in bn */
			bn->batCacheid = bnid;
			BATmode(bn, oldmode);
			b->batDirty = dirtyb;
			bn->batDirty = dirtybn;
		} else {
			/* SUCCEEDED: free b, remove bn hash */
			BATfree(b);
			BBPuncacheit_(bid, TRUE);
			BBPcacheit(bn);
			if (hugebn) {
				/* although not persistent: has heaps on disk. must delete/reload */
				bn->batCacheid = bnid;
				BATdelete(bn);
				b = NULL;
			} else {
				b = bn;
			}
			/* free mirror image and give back bn BBP slot */
			BBPclear(bnid);

			if (hugebn) {	/* do the reload now */
				b = BBPdescriptor(bid);
				if (b == NULL)
					GDKfatal("BBPreplace: failed to load the new BAT image %d\n", bid);
			}
			BATmode(b, newmode);
		}

	}
	gdk_unset_lock(GDKtrimLock, "BBPreplace");
}

void 
BBPatom_drop(int atom)
{
	int i;
	str nme = ATOMname(atom);
	int unknown = ATOMunknown_add(nme);

	BBPlock("BBPatom_drop");
	for (i = 0; i < BBPsize; i++) {
		if (BBPvalid(i)) {
			BATstore *b = BBP_desc(i);

			if (!b) continue;
			
			if (b->B.htype == atom)
				b->B.htype = unknown; 
			if (b->B.ttype == atom)
				b->B.ttype = unknown; 
		}
	}
	BBPunlock("BBPatom_drop");
}

void 
BBPatom_load(int atom)
{
	str nme;
	int i, unknown;

	BBPlock("BBPatom_load");
 	nme = ATOMname(atom);
 	unknown = ATOMunknown_find(nme);
	ATOMunknown_del(unknown);
	for (i = 0; i < BBPsize; i++) {
		if (BBPvalid(i)) {
			BATstore *b = BBP_desc(i);

			if (!b) continue;

			if (b->B.htype == unknown)
				b->B.htype = atom; 
			if (b->B.ttype == unknown)
				b->B.ttype = atom; 
		}
	}
	BBPunlock("BBPatom_load");
}
@}

